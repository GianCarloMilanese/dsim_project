{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_colab_mode= False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcpAdLEIAOMh"
   },
   "source": [
    "# Just for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p-dutOrvAPZg",
    "outputId": "b3c51368-3f49-4296-f170-cd4d5a9f7ade"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import urllib\n",
    "\n",
    "user = input('User name: ')\n",
    "password = getpass('Password: ')\n",
    "password = urllib.parse.quote(password) # your password is converted into url format\n",
    "\n",
    "cmd_string = 'git clone https://{0}:{1}@github.com/GianCarloMilanese/dsim_project.git'.format(user, password)\n",
    "\n",
    "os.system(cmd_string)\n",
    "cmd_string, password = \"\", \"\" # removing the password from the variable\n",
    "google_colab_mode=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "mVoN9qvnGPqR",
    "outputId": "252dcd03-1a49-4a08-8f84-c2c441fc5408"
   },
   "outputs": [],
   "source": [
    "!ls -lh dsim_project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "7_p69CQOG8Sn",
    "outputId": "a6271bc7-a6c0-45ce-d49b-62404ffb80e0"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git && mv free-spoken-digit-dataset/recordings dsim_project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "PAQ5VI3zHei1",
    "outputId": "a99953d0-6eac-4870-8ea3-b804f52270c8"
   },
   "outputs": [],
   "source": [
    "!ls -lh dsim_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"dsim_project/Audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SD8Nx-3tAJY_"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_colab_mode=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SP35h9g6AJZB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import data_augmentation\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wQvjtLSAJZG"
   },
   "source": [
    "# Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSZ1nRq_AJZH"
   },
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "tf.random.set_random_seed(SEED)# if working on tf < 2.0\n",
    "#tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YLZTM3YDAJZK"
   },
   "source": [
    "# Load recordings\n",
    "## STANDARD RECORDINGS - No spectrogram normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1G8haE_GIkzR"
   },
   "outputs": [],
   "source": [
    "if google_colab_mode:\n",
    "    fsdd_dir=\"dsim_project/Audio/recordings\"\n",
    "    our_recs_dir=\"dsim_project/Audio/preprocessed_recs\"\n",
    "else:\n",
    "    fsdd_dir=\"./recordings/\"\n",
    "    our_recs_dir=\"./preprocessed_recs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "74521556c16e4badb587537f36771810",
      "5f5badcb0b1e4938901d1ccebf26bc1f",
      "041ee309cd2a4523b8cbb817a7133aeb",
      "ab519d0c6d6241c5afbc76dbde2306fd",
      "8f16c91328fb4555af28b4fa2522f1b6",
      "8db829965d284a9b848aa89f1d6e1a7e",
      "eef3bdb92f1e43eb9241be66f3360fbc",
      "c29d5436c6514002b1380c6dfb229f76",
      "b20e330bbd0541b9ad6e8897ba359fc3",
      "6532c85805db453f8a76edaf34996c0c",
      "bce824cee09446879776ce8440927c32",
      "d877478de1de4e2a9e67d33302b19075",
      "a9b4078544ee4fc4b203252a8539169c",
      "b365514386b341d6896420c06f2a9a86",
      "0471feee5a704241bc959bf9f25cf86b",
      "f110b274d39141b892be18de60d7fd3b"
     ]
    },
    "colab_type": "code",
    "id": "EhEjE2JZAJZL",
    "outputId": "bc2b6b8d-494b-4745-ecf0-82ee4b51fadc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./recordings/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d6ae29ef2f40c381ead0a9f3b09e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ./preprocessed_recs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c166904552184f2dab14227073cff0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrZ1SrCyAJZO"
   },
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "USN0CDHyAJZO",
    "outputId": "2126cd10-edbe-4ef7-b2a3-2c41e50a6be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 18262\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is quite huge! Let's see which are the longest recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18262, 17567, 9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two recordings have length 18262 and 17567, while the others are around 20K. Let's identify them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "first_length=18262\n",
    "second_length=17567\n",
    "index_first = a.index(first_length)\n",
    "index_second = a.index(second_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18262"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recordings[index_first])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17567"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recordings[index_second])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have found them. For knowing to which digit and speaker they are associated I first need to load the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest track is associated with speaker theo, digit 9\n",
      "Second longest track is associated with speaker theo, digit 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_first],labels_digits[index_first]))\n",
    "print(\"Second longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_second],labels_digits[index_second]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problem is with theo, which has 500 recordings, digit 9 and 7, which respectively have 200 recordings. We can safely delete them and saving to pad many thousands of 0s (there will be (18262 - 9015) less zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "max_track_length=17000 # it will be useful later on\n",
    "print(\"Before: {}\".format(len(recordings)))\n",
    "recordings=np.delete(recordings,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(recordings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_speakers)))\n",
    "labels_speakers=np.delete(labels_speakers,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_speakers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_digits)))\n",
    "labels_digits=np.delete(labels_digits,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_digits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now double check to see if everything went well. Now the longest recording will be around 9 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356, 7147, 7038]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIOfNR7UAJZR"
   },
   "source": [
    "Yes! However the recordings have all different lengths: for this reason we can add 0s at the beginning and at the end in order to uniform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DAqhOQfXAJZS",
    "outputId": "f4fb11ac-3e4e-4ef7-92cc-4106a989315c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_zeros >>>\n",
      "pad_zeros <<<\n"
     ]
    }
   ],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knxJsuQHAJZV"
   },
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UH4CNtcaAJZV",
    "outputId": "70f33b43-ad02-4214-dc91-4c934af961cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9015 9015\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzTvIWFqAJZY"
   },
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBOpha3yAJZZ"
   },
   "outputs": [],
   "source": [
    "spects = [data_preparation.compute_spectrogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UcS3jm3hAJZf"
   },
   "source": [
    "Let's also compute \"normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBHB2jB0AJZf"
   },
   "outputs": [],
   "source": [
    "norm_spects = [data_preparation.compute_spectrogram(x, normalize=True) for x in pad_recordings]\n",
    "norm_spects = np.array(norm_spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NifXsIaiAJZi"
   },
   "source": [
    "##Â Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "S7lJzOxaAJZi",
    "outputId": "d7dd58d8-9103-4b00-9784-7e872b59eab9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 5min 37s, sys: 14 s, total: 5min 51s\n",
      "Wall time: 4min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digit, y_train_digit, X_val_digit, y_val_digit, X_test_digit, y_test_digit = data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=max_track_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q7kf01G8AJZl",
    "outputId": "70bde817-b594-4519-f3cd-ed14aafec37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 18462, 18462, 4616, 4616, 300, 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}, {}, {}\".format(len(X_train_digit),\n",
    "                                                len(y_train_digit),\n",
    "                                                len(X_val_digit),\n",
    "                                                len(y_val_digit),\n",
    "                                                len(X_test_digit),\n",
    "                                                len(y_test_digit),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "mAS0dEAeAJZn",
    "outputId": "5f5b8ee6-7d0b-4575-d9d6-ac9708bbda97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 4min 9s, sys: 11.7 s, total: 4min 21s\n",
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(\n",
    "    audio_dirs= [our_recs_dir, fsdd_dir],\n",
    "    y_type= ['speakers_us', 'speakers_default'],\n",
    "    n_category_test=30,\n",
    "    include_pitch=False,\n",
    "    max_length=max_track_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U7pt5gp8AJZq",
    "outputId": "264e985b-797d-4478-fb22-19febb261b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 10358, 10358, 2590, 2590, 240, 240\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}, {}, {}\".format(len(X_train_speaker),\n",
    "                                        len(y_train_speaker),\n",
    "                                        len(X_val_speaker),\n",
    "                                        len(y_val_speaker),\n",
    "                                        len(X_test_speaker),\n",
    "                                        len(y_test_speaker)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcNM7Ju3AJZt"
   },
   "source": [
    "# Standard recordings\n",
    "## Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z08J1Ly2AJZu"
   },
   "source": [
    "Split data in train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zxTeijsAJZu"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pq-h50cLAJZx"
   },
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pGL-51TeAJZ0",
    "outputId": "c8c1f7ec-0a59-4df0-e6a4-80a897a32e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.7 s, sys: 222 ms, total: 27.9 s\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "eOuf4fYdAJZ3",
    "outputId": "8de901a9-de7a-466a-b29a-8f8ada4fe913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.12      0.20        43\n",
      "           1       0.41      0.35      0.38        43\n",
      "           2       0.53      0.17      0.25        48\n",
      "           3       0.62      0.23      0.34        56\n",
      "           4       0.23      0.44      0.30        43\n",
      "           5       0.81      0.35      0.49        48\n",
      "           6       0.15      0.64      0.24        55\n",
      "           7       0.88      0.27      0.41        56\n",
      "           8       0.85      0.23      0.37        47\n",
      "           9       0.67      0.49      0.56        41\n",
      "\n",
      "    accuracy                           0.33       480\n",
      "   macro avg       0.60      0.33      0.35       480\n",
      "weighted avg       0.60      0.33      0.35       480\n",
      "\n",
      "CPU times: user 5.59 s, sys: 47.8 ms, total: 5.63 s\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZIG3MZXAJZ5"
   },
   "source": [
    "### Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adr8LZdqAJZ5"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PVFxb6UAAJZ-",
    "outputId": "f1631091-a65e-410d-869f-982e7a25e54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.2 s, sys: 200 ms, total: 17.4 s\n",
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "9YNlZ5ZGAJaB",
    "outputId": "408a182d-3e8d-4b53-a8bc-403523798c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.82      0.72      0.77        43\n",
      "           2       0.57      0.92      0.70        48\n",
      "           3       0.91      0.52      0.66        56\n",
      "           4       0.94      0.72      0.82        43\n",
      "           5       0.95      0.77      0.85        48\n",
      "           6       0.63      0.84      0.72        55\n",
      "           7       0.80      0.88      0.84        56\n",
      "           8       0.84      0.66      0.74        47\n",
      "           9       0.81      0.93      0.86        41\n",
      "\n",
      "    accuracy                           0.78       480\n",
      "   macro avg       0.82      0.79      0.79       480\n",
      "weighted avg       0.82      0.78      0.78       480\n",
      "\n",
      "CPU times: user 5.3 s, sys: 62.3 ms, total: 5.36 s\n",
      "Wall time: 5.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjYwbLVWAJaD"
   },
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaUkrMXHAJaD"
   },
   "source": [
    "#### Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWl0glyyAJaE"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "jp-yDTbVAJaG",
    "outputId": "8f73212b-eec8-474f-d751-4583a963eee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               38500     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 77,436\n",
      "Trainable params: 77,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjsYe2MZAJaJ"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "dorwbEtUAJaM",
    "outputId": "41eeef7c-3bf0-4747-e426-5864708d9951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1438 samples, validate on 480 samples\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.2941 - acc: 0.1189 - val_loss: 2.2513 - val_acc: 0.1500\n",
      "Epoch 2/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.2452 - acc: 0.1516 - val_loss: 2.1974 - val_acc: 0.2146\n",
      "Epoch 3/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.1722 - acc: 0.2316 - val_loss: 2.0930 - val_acc: 0.3313\n",
      "Epoch 4/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.0813 - acc: 0.2656 - val_loss: 1.9382 - val_acc: 0.4458\n",
      "Epoch 5/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 1.9531 - acc: 0.2928 - val_loss: 1.7715 - val_acc: 0.4646\n",
      "Epoch 6/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 1.7468 - acc: 0.3679 - val_loss: 1.5091 - val_acc: 0.4896\n",
      "Epoch 7/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 1.6246 - acc: 0.4047 - val_loss: 1.4082 - val_acc: 0.5042\n",
      "Epoch 8/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 1.4936 - acc: 0.4395 - val_loss: 1.3711 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "1438/1438 [==============================] - 4s 2ms/sample - loss: 1.4096 - acc: 0.4694 - val_loss: 1.1638 - val_acc: 0.5771\n",
      "Epoch 10/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 1.3586 - acc: 0.4819 - val_loss: 1.1202 - val_acc: 0.5917\n",
      "CPU times: user 1min, sys: 3.75 s, total: 1min 4s\n",
      "Wall time: 31.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd8a6663550>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "z1EFnJFhAJaP",
    "outputId": "abe441d8-2f01-4ef9-b3df-688dcd232937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        43\n",
      "           1       0.50      0.56      0.53        43\n",
      "           2       0.43      0.73      0.54        48\n",
      "           3       0.83      0.09      0.16        56\n",
      "           4       0.80      0.81      0.80        43\n",
      "           5       1.00      0.48      0.65        48\n",
      "           6       0.56      0.67      0.61        55\n",
      "           7       0.70      0.62      0.66        56\n",
      "           8       0.52      0.55      0.54        47\n",
      "           9       0.50      0.78      0.61        41\n",
      "\n",
      "    accuracy                           0.59       480\n",
      "   macro avg       0.65      0.60      0.58       480\n",
      "weighted avg       0.66      0.59      0.57       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ab3NBIvkAJaR"
   },
   "source": [
    "#### Standard spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sWPsfH8AJaS"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "9RPhwIyPAJaU",
    "outputId": "bf9606af-72d8-4fdf-f2ee-77049129bd1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               38500     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 77,436\n",
      "Trainable params: 77,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "tEl6k7s6AJaX",
    "outputId": "e26b03f7-b375-467e-adf7-99259cf371b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1438 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.5060 - acc: 0.1224 - val_loss: 2.2313 - val_acc: 0.1458\n",
      "Epoch 2/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 2.2642 - acc: 0.1495 - val_loss: 2.1794 - val_acc: 0.2021\n",
      "Epoch 3/10\n",
      "1438/1438 [==============================] - 4s 2ms/sample - loss: 2.2063 - acc: 0.1822 - val_loss: 2.1506 - val_acc: 0.1979\n",
      "Epoch 4/10\n",
      "1438/1438 [==============================] - 4s 2ms/sample - loss: 2.1890 - acc: 0.2017 - val_loss: 2.1144 - val_acc: 0.2229\n",
      "Epoch 5/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.1330 - acc: 0.2211 - val_loss: 2.1030 - val_acc: 0.1854\n",
      "Epoch 6/10\n",
      "1438/1438 [==============================] - 2s 2ms/sample - loss: 2.1050 - acc: 0.2427 - val_loss: 2.0784 - val_acc: 0.2000\n",
      "Epoch 7/10\n",
      "1438/1438 [==============================] - 2s 2ms/sample - loss: 2.0841 - acc: 0.2427 - val_loss: 2.0601 - val_acc: 0.2271\n",
      "Epoch 8/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.0199 - acc: 0.2615 - val_loss: 1.9866 - val_acc: 0.2458\n",
      "Epoch 9/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 2.0320 - acc: 0.2768 - val_loss: 2.0190 - val_acc: 0.2250\n",
      "Epoch 10/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.9963 - acc: 0.2830 - val_loss: 1.9201 - val_acc: 0.3104\n",
      "CPU times: user 1min 1s, sys: 3.62 s, total: 1min 5s\n",
      "Wall time: 26.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7a65d5710>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "3e7-NrFzAJaZ",
    "outputId": "1be23cb6-6ef8-4ffa-c296-6b3ec5764a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.42      0.45        43\n",
      "           1       0.26      0.40      0.31        43\n",
      "           2       0.38      0.60      0.46        48\n",
      "           3       0.43      0.11      0.17        56\n",
      "           4       0.62      0.23      0.34        43\n",
      "           5       0.48      0.23      0.31        48\n",
      "           6       0.56      0.35      0.43        55\n",
      "           7       0.58      0.12      0.21        56\n",
      "           8       0.31      0.11      0.16        47\n",
      "           9       0.15      0.66      0.24        41\n",
      "\n",
      "    accuracy                           0.31       480\n",
      "   macro avg       0.43      0.32      0.31       480\n",
      "weighted avg       0.43      0.31      0.31       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hm-UCrvqAJac"
   },
   "source": [
    "From what we can see normalising spectrograms is the way to go. Let's use it by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AzfoB2vwAJad"
   },
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "9UD8AN11h68p",
    "outputId": "dd4a9cd9-5bb7-45dd-f7ec-9256a6b4a8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88        44\n",
      "           1       0.88      0.86      0.87        49\n",
      "           2       0.76      0.91      0.83        56\n",
      "           3       0.97      0.70      0.81        43\n",
      "           4       0.98      0.90      0.94        49\n",
      "           5       0.90      0.87      0.88        52\n",
      "           6       0.69      0.83      0.75        42\n",
      "           7       0.79      0.98      0.88        47\n",
      "           8       0.97      0.72      0.83        50\n",
      "           9       0.90      0.79      0.84        48\n",
      "\n",
      "    accuracy                           0.85       480\n",
      "   macro avg       0.87      0.85      0.85       480\n",
      "weighted avg       0.87      0.85      0.85       480\n",
      "\n",
      "CPU times: user 30.5 s, sys: 225 ms, total: 30.7 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_digits)\n",
    "X_train = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train = np.concatenate([y_train, y_val], axis=0)\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RofgNOXIAJaf"
   },
   "source": [
    "## Speakers\n",
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsOEsXNrAJag"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nq86YnS3AJai",
    "outputId": "056c8fa2-0ed7-463f-f38a-e9e06c370911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 101 ms, total: 10.2 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3qK9OpoAJam",
    "outputId": "b8e82428-9b91-4849-e078-6139ac8ed99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.91      0.95      0.93        21\n",
      "      alinda       0.90      0.90      0.90        20\n",
      "        gian       1.00      1.00      1.00        20\n",
      "     jackson       1.00      1.00      1.00        86\n",
      "      khaled       0.91      1.00      0.95        21\n",
      "     nicolas       0.98      1.00      0.99       103\n",
      "        theo       0.86      0.87      0.86       105\n",
      "    yweweler       0.92      0.87      0.89       104\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.93      0.95      0.94       480\n",
      "weighted avg       0.94      0.94      0.94       480\n",
      "\n",
      "CPU times: user 3.96 s, sys: 29.4 ms, total: 3.99 s\n",
      "Wall time: 4.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Px6AnQPyAJap"
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qw6UWfD6AJap"
   },
   "source": [
    "For neural networks it is not possible to pass the labels as-is: we need to transform them in numbers. The safest way is through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MEyOqyZAJaq"
   },
   "outputs": [],
   "source": [
    "y, target_names = data_preparation.transform_categorical_y(labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4ZWZPxSAJas"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, y, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5nbGXEqAJav",
    "outputId": "c22a47d5-52ab-4bfa-bc21-b919ef3d4b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 67,744\n",
      "Trainable params: 67,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzq1wprbAJay",
    "outputId": "f3a4929c-1629-4a45-b07a-cad28a8cf1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1438 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1438/1438 [==============================] - 2s 2ms/sample - loss: 1.9019 - acc: 0.2364 - val_loss: 1.8318 - val_acc: 0.2625\n",
      "Epoch 2/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.8193 - acc: 0.2949 - val_loss: 1.7708 - val_acc: 0.2854\n",
      "Epoch 3/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.7627 - acc: 0.3519 - val_loss: 1.6811 - val_acc: 0.4396\n",
      "Epoch 4/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.6879 - acc: 0.4124 - val_loss: 1.5829 - val_acc: 0.5604\n",
      "Epoch 5/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.5869 - acc: 0.4513 - val_loss: 1.4760 - val_acc: 0.5813\n",
      "Epoch 6/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.5152 - acc: 0.4861 - val_loss: 1.3654 - val_acc: 0.5708\n",
      "Epoch 7/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.4035 - acc: 0.5216 - val_loss: 1.2527 - val_acc: 0.6292\n",
      "Epoch 8/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.3214 - acc: 0.5473 - val_loss: 1.1532 - val_acc: 0.6271\n",
      "Epoch 9/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.1921 - acc: 0.5904 - val_loss: 1.0358 - val_acc: 0.6583\n",
      "Epoch 10/10\n",
      "1438/1438 [==============================] - 2s 1ms/sample - loss: 1.1300 - acc: 0.5904 - val_loss: 1.1313 - val_acc: 0.5750\n",
      "CPU times: user 1min 1s, sys: 3.72 s, total: 1min 5s\n",
      "Wall time: 21.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7a5d41050>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F15PVwnlAJa0",
    "outputId": "cc510785-80ce-4518-bdfe-7ab7707d93ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.57      0.56        21\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.50      0.15      0.23        20\n",
      "           3       0.84      0.77      0.80        86\n",
      "           4       1.00      0.10      0.17        21\n",
      "           5       0.53      0.36      0.43       103\n",
      "           6       0.59      0.79      0.68       105\n",
      "           7       0.46      0.70      0.56       104\n",
      "\n",
      "    accuracy                           0.57       480\n",
      "   macro avg       0.56      0.43      0.43       480\n",
      "weighted avg       0.58      0.57      0.55       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qk3vDDTAJa4"
   },
   "source": [
    "#### Paper - batch_normalisation=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NibB6mqLAJa4",
    "outputId": "08b73978-af62-44fb-c3a1-40508d4f7683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJFqES0hAJa8",
    "outputId": "e87aa981-bfcb-4d60-ee8e-47448a8d0482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1438 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1438/1438 [==============================] - 9s 6ms/sample - loss: 1.7556 - acc: 0.4242 - val_loss: 1.7411 - val_acc: 0.4354\n",
      "Epoch 2/10\n",
      "1438/1438 [==============================] - 7s 5ms/sample - loss: 1.0340 - acc: 0.6933 - val_loss: 1.6581 - val_acc: 0.3979\n",
      "Epoch 3/10\n",
      "1438/1438 [==============================] - 8s 5ms/sample - loss: 0.8612 - acc: 0.7288 - val_loss: 1.7820 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      "1438/1438 [==============================] - 9s 6ms/sample - loss: 0.7052 - acc: 0.7830 - val_loss: 1.9644 - val_acc: 0.3854\n",
      "Epoch 5/10\n",
      "1438/1438 [==============================] - 8s 5ms/sample - loss: 0.5870 - acc: 0.8220 - val_loss: 1.8893 - val_acc: 0.3938\n",
      "CPU times: user 1min 15s, sys: 13.5 s, total: 1min 28s\n",
      "Wall time: 41.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7c0b8d450>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eePEJDMdAJa_",
    "outputId": "dc423068-db5d-46fc-a0ed-c24f08820613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.46      0.99      0.63        86\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.71      0.10      0.17       103\n",
      "           6       0.34      0.91      0.49       105\n",
      "           7       0.00      0.00      0.00       104\n",
      "\n",
      "    accuracy                           0.40       480\n",
      "   macro avg       0.19      0.25      0.16       480\n",
      "weighted avg       0.31      0.40      0.26       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLz38np3juZf"
   },
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5PZSGZljsLN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.96      0.98        24\n",
      "      alinda       0.90      1.00      0.95        19\n",
      "        gian       0.96      1.00      0.98        24\n",
      "     jackson       1.00      1.00      1.00       121\n",
      "      khaled       0.93      1.00      0.97        14\n",
      "     nicolas       1.00      1.00      1.00        89\n",
      "        theo       0.95      0.86      0.90        98\n",
      "    yweweler       0.89      0.96      0.92        91\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.97      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "CPU times: user 21.7 s, sys: 332 ms, total: 22 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_speakers)\n",
    "X_train = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train = np.concatenate([y_train, y_val], axis=0)\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJh1FkRdAJbD"
   },
   "source": [
    "# Data augmentation\n",
    "## Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_2d = X_train_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_2d = X_val_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 53s, sys: 2.23 s, total: 1min 56s\n",
      "Wall time: 2min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Switch to LinearSVC because SVC with RBF kernel takes a lot of time\n",
    "from sklearn.svm import LinearSVC\n",
    "clf1 = LinearSVC(class_weight='balanced')\n",
    "clf1 = clf1.fit(X_train_speaker_2d, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.93      0.86      0.89        86\n",
      "      alinda       1.00      0.92      0.96        85\n",
      "        gian       0.95      0.94      0.94        82\n",
      "     jackson       0.98      0.98      0.98       596\n",
      "      khaled       0.93      0.93      0.93        83\n",
      "     nicolas       0.96      0.97      0.96       545\n",
      "        theo       0.79      0.79      0.79       579\n",
      "    yweweler       0.78      0.79      0.78       534\n",
      "\n",
      "    accuracy                           0.89      2590\n",
      "   macro avg       0.91      0.90      0.91      2590\n",
      "weighted avg       0.89      0.89      0.89      2590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf1.predict(X_val_speaker_2d)\n",
    "print(classification_report(y_val_speaker, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HurXrYSAAJbE"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y_train_speaker = enc.fit_transform(y_train_speaker.reshape(-1, 1)).toarray()\n",
    "y_val_speaker = enc.transform(y_val_speaker.reshape(-1, 1)).toarray()\n",
    "y_test_speaker = enc.transform(y_test_speaker.reshape(-1, 1)).toarray()\n",
    "label_0 = enc.inverse_transform(np.array([1, 0, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_1 = enc.inverse_transform(np.array([0, 1, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_2 = enc.inverse_transform(np.array([0, 0, 1, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_3 = enc.inverse_transform(np.array([0, 0, 0, 1, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_4 = enc.inverse_transform(np.array([0, 0, 0, 0, 1, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_5 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 1, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_6 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 1, 0]).reshape(1, -1))[0][0]\n",
    "label_7 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 0, 1]).reshape(1, -1))[0][0]\n",
    "target_names = [label_0, label_1, label_2, label_3, label_4, label_5, label_6, label_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSJDK6FnAJbJ"
   },
   "outputs": [],
   "source": [
    "X_train_speaker = X_train_speaker.reshape(X_train_speaker.shape[0],\n",
    "                                          X_train_speaker.shape[1],\n",
    "                                          X_train_speaker.shape[2],\n",
    "                                          1)\n",
    "X_val_speaker = X_val_speaker.reshape(X_val_speaker.shape[0],\n",
    "                                      X_val_speaker.shape[1],\n",
    "                                      X_val_speaker.shape[2],\n",
    "                                      1)\n",
    "X_test_speaker = X_test_speaker.reshape(X_test_speaker.shape[0],\n",
    "                                        X_test_speaker.shape[1],\n",
    "                                        X_test_speaker.shape[2],\n",
    "                                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHT6j2GWAJbL"
   },
   "outputs": [],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K47DbwgyAJbO",
    "outputId": "fa96fcc6-7da6-432f-885e-9648fda4bd42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 67,744\n",
      "Trainable params: 67,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzGH3FQYAJbQ",
    "outputId": "fdfd9b3e-a399-4628-d74f-4b2ad118821e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10358 samples, validate on 2590 samples\n",
      "Epoch 1/10\n",
      "10358/10358 [==============================] - 23s 2ms/sample - loss: 1.7699 - acc: 0.3083 - val_loss: 1.5724 - val_acc: 0.5054\n",
      "Epoch 2/10\n",
      "10358/10358 [==============================] - 24s 2ms/sample - loss: 1.4804 - acc: 0.4800 - val_loss: 1.2220 - val_acc: 0.5525\n",
      "Epoch 3/10\n",
      "10358/10358 [==============================] - 23s 2ms/sample - loss: 1.2099 - acc: 0.5571 - val_loss: 0.9510 - val_acc: 0.6734\n",
      "Epoch 4/10\n",
      "10358/10358 [==============================] - 34s 3ms/sample - loss: 1.0140 - acc: 0.6167 - val_loss: 0.8133 - val_acc: 0.6907\n",
      "Epoch 5/10\n",
      "10358/10358 [==============================] - 22s 2ms/sample - loss: 0.8770 - acc: 0.6640 - val_loss: 0.8376 - val_acc: 0.6421\n",
      "Epoch 6/10\n",
      "10358/10358 [==============================] - 19s 2ms/sample - loss: 0.7540 - acc: 0.7086 - val_loss: 0.5789 - val_acc: 0.7757\n",
      "Epoch 7/10\n",
      "10358/10358 [==============================] - 33s 3ms/sample - loss: 0.6494 - acc: 0.7420 - val_loss: 0.5259 - val_acc: 0.7683\n",
      "Epoch 8/10\n",
      "10358/10358 [==============================] - 25s 2ms/sample - loss: 0.5925 - acc: 0.7649 - val_loss: 0.4221 - val_acc: 0.8552\n",
      "Epoch 9/10\n",
      "10358/10358 [==============================] - 17s 2ms/sample - loss: 0.5207 - acc: 0.7972 - val_loss: 0.3579 - val_acc: 0.8668\n",
      "Epoch 10/10\n",
      "10358/10358 [==============================] - 26s 3ms/sample - loss: 0.4798 - acc: 0.8125 - val_loss: 0.5885 - val_acc: 0.7463\n",
      "CPU times: user 7min 34s, sys: 30.8 s, total: 8min 5s\n",
      "Wall time: 4min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7a4656810>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLNYwlEQAJbW",
    "outputId": "60fc3bfa-a1ef-4523-8e2d-b052f3733d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.81      0.78      0.79        86\n",
      "      alinda       0.69      0.45      0.54        85\n",
      "        gian       0.58      0.70      0.63        82\n",
      "     jackson       0.81      1.00      0.89       596\n",
      "      khaled       0.80      0.53      0.64        83\n",
      "     nicolas       0.72      0.85      0.78       545\n",
      "        theo       0.95      0.50      0.65       579\n",
      "    yweweler       0.62      0.71      0.66       534\n",
      "\n",
      "    accuracy                           0.75      2590\n",
      "   macro avg       0.75      0.69      0.70      2590\n",
      "weighted avg       0.77      0.75      0.74      2590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5KqZBYNZAJbZ"
   },
   "source": [
    "### Batch_normalization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH6cPoI9AJba",
    "outputId": "96517b9b-1c96-4d34-cdf8-e57eca5ce5da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Y6DRC5kAJbg",
    "outputId": "a4dd3912-a1ef-48ef-ac89-7bca897cc3a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10358 samples, validate on 2590 samples\n",
      "Epoch 1/10\n",
      "10358/10358 [==============================] - 72s 7ms/sample - loss: 1.1763 - acc: 0.5926 - val_loss: 0.8747 - val_acc: 0.7185\n",
      "Epoch 2/10\n",
      "10358/10358 [==============================] - 57s 6ms/sample - loss: 0.7152 - acc: 0.7333 - val_loss: 0.8116 - val_acc: 0.7004\n",
      "Epoch 3/10\n",
      "10358/10358 [==============================] - 61s 6ms/sample - loss: 0.5687 - acc: 0.7837 - val_loss: 0.3933 - val_acc: 0.8571\n",
      "Epoch 4/10\n",
      "10358/10358 [==============================] - 74s 7ms/sample - loss: 0.4963 - acc: 0.8119 - val_loss: 0.4268 - val_acc: 0.8255\n",
      "Epoch 5/10\n",
      "10358/10358 [==============================] - 60s 6ms/sample - loss: 0.4388 - acc: 0.8314 - val_loss: 0.8710 - val_acc: 0.6768\n",
      "Epoch 6/10\n",
      "10358/10358 [==============================] - 66s 6ms/sample - loss: 0.4063 - acc: 0.8457 - val_loss: 0.3571 - val_acc: 0.8591\n",
      "Epoch 7/10\n",
      "10358/10358 [==============================] - 56s 5ms/sample - loss: 0.3688 - acc: 0.8629 - val_loss: 0.3109 - val_acc: 0.8656\n",
      "Epoch 8/10\n",
      "10358/10358 [==============================] - 54s 5ms/sample - loss: 0.3452 - acc: 0.8679 - val_loss: 0.2118 - val_acc: 0.9336\n",
      "Epoch 9/10\n",
      "10358/10358 [==============================] - 52s 5ms/sample - loss: 0.3223 - acc: 0.8788 - val_loss: 0.2421 - val_acc: 0.9162\n",
      "Epoch 10/10\n",
      "10358/10358 [==============================] - 49s 5ms/sample - loss: 0.3053 - acc: 0.8834 - val_loss: 0.2399 - val_acc: 0.9058\n",
      "CPU times: user 17min 34s, sys: 3min 29s, total: 21min 3s\n",
      "Wall time: 10min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7c24fcbd0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhMXBIZLAJbj",
    "outputId": "404da482-df82-4797-c591-e8f13f7b0074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.90      0.98      0.94        86\n",
      "      alinda       0.91      0.93      0.92        85\n",
      "        gian       0.93      0.87      0.90        82\n",
      "     jackson       0.94      1.00      0.97       596\n",
      "      khaled       0.93      0.93      0.93        83\n",
      "     nicolas       1.00      0.92      0.96       545\n",
      "        theo       0.78      0.95      0.86       579\n",
      "    yweweler       0.94      0.72      0.82       534\n",
      "\n",
      "    accuracy                           0.91      2590\n",
      "   macro avg       0.92      0.91      0.91      2590\n",
      "weighted avg       0.91      0.91      0.90      2590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fw0IuGRwAJbm"
   },
   "source": [
    "### Different architecture\n",
    "Let's change a bit the architecture and see if we can improve scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4DjuMehAJbn",
    "outputId": "584137dc-46a7-4bc1-d237-ff87e41fa1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 607,976\n",
      "Trainable params: 607,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRqPhHRsAJbs",
    "outputId": "439effc6-cd35-40a0-ece9-7b5339bfb048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10358 samples, validate on 2590 samples\n",
      "Epoch 1/10\n",
      "10358/10358 [==============================] - 40s 4ms/sample - loss: 1.4051 - acc: 0.4826 - val_loss: 1.1135 - val_acc: 0.6019\n",
      "Epoch 2/10\n",
      "10358/10358 [==============================] - 74s 7ms/sample - loss: 0.8388 - acc: 0.6935 - val_loss: 0.6079 - val_acc: 0.7722\n",
      "Epoch 3/10\n",
      "10358/10358 [==============================] - 91s 9ms/sample - loss: 0.5335 - acc: 0.7962 - val_loss: 0.3671 - val_acc: 0.8598\n",
      "Epoch 4/10\n",
      "10358/10358 [==============================] - 35s 3ms/sample - loss: 0.3754 - acc: 0.8531 - val_loss: 0.2500 - val_acc: 0.9008\n",
      "Epoch 5/10\n",
      "10358/10358 [==============================] - 37s 4ms/sample - loss: 0.2962 - acc: 0.8845 - val_loss: 0.2317 - val_acc: 0.9050\n",
      "Epoch 6/10\n",
      "10358/10358 [==============================] - 36s 4ms/sample - loss: 0.2471 - acc: 0.9003 - val_loss: 0.1753 - val_acc: 0.9344\n",
      "Epoch 7/10\n",
      "10358/10358 [==============================] - 36s 4ms/sample - loss: 0.2166 - acc: 0.9144 - val_loss: 0.1685 - val_acc: 0.9351\n",
      "Epoch 8/10\n",
      "10358/10358 [==============================] - 40s 4ms/sample - loss: 0.1906 - acc: 0.9194 - val_loss: 0.1588 - val_acc: 0.9355\n",
      "Epoch 9/10\n",
      "10358/10358 [==============================] - 35s 3ms/sample - loss: 0.1762 - acc: 0.9276 - val_loss: 0.1537 - val_acc: 0.9363\n",
      "Epoch 10/10\n",
      "10358/10358 [==============================] - 36s 3ms/sample - loss: 0.1582 - acc: 0.9366 - val_loss: 0.1361 - val_acc: 0.9506\n",
      "CPU times: user 14min 58s, sys: 2min, total: 16min 59s\n",
      "Wall time: 7min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7c07e0d10>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0c85SLvAJbu",
    "outputId": "b1dfcfd5-ff0e-4b40-bb8e-260f0563788f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.97      0.98        86\n",
      "      alinda       1.00      0.98      0.99        85\n",
      "        gian       0.95      0.95      0.95        82\n",
      "     jackson       1.00      0.99      1.00       596\n",
      "      khaled       0.98      0.98      0.98        83\n",
      "     nicolas       0.99      0.99      0.99       545\n",
      "        theo       0.85      0.99      0.91       579\n",
      "    yweweler       0.97      0.81      0.89       534\n",
      "\n",
      "    accuracy                           0.95      2590\n",
      "   macro avg       0.97      0.96      0.96      2590\n",
      "weighted avg       0.96      0.95      0.95      2590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model\n",
    "Based on the f1-score, the best model is the \"custom cnn\" one. Let's see its result on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 607,976\n",
      "Trainable params: 607,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "12948/12948 [==============================] - 43s 3ms/sample - loss: 1.3358 - acc: 0.5089\n",
      "Epoch 2/10\n",
      "12948/12948 [==============================] - 50s 4ms/sample - loss: 0.7536 - acc: 0.7173\n",
      "Epoch 3/10\n",
      "12948/12948 [==============================] - 48s 4ms/sample - loss: 0.4494 - acc: 0.8282\n",
      "Epoch 4/10\n",
      "12948/12948 [==============================] - 45s 3ms/sample - loss: 0.3289 - acc: 0.8692\n",
      "Epoch 5/10\n",
      "12948/12948 [==============================] - 37s 3ms/sample - loss: 0.2612 - acc: 0.8950\n",
      "Epoch 6/10\n",
      "12948/12948 [==============================] - 38s 3ms/sample - loss: 0.2258 - acc: 0.9072\n",
      "Epoch 7/10\n",
      "12948/12948 [==============================] - 44s 3ms/sample - loss: 0.1932 - acc: 0.9219\n",
      "Epoch 8/10\n",
      "12948/12948 [==============================] - 45s 4ms/sample - loss: 0.1724 - acc: 0.9288\n",
      "Epoch 9/10\n",
      "12948/12948 [==============================] - 43s 3ms/sample - loss: 0.1541 - acc: 0.9377\n",
      "Epoch 10/10\n",
      "12948/12948 [==============================] - 44s 3ms/sample - loss: 0.1435 - acc: 0.9386\n",
      "CPU times: user 17min 19s, sys: 2min 23s, total: 19min 43s\n",
      "Wall time: 7min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7c600cc50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train = np.concatenate([X_train_speaker, X_val_speaker], axis=0)\n",
    "y_train = np.concatenate([y_train_speaker, y_val_speaker], axis=0)\n",
    "model = cnn_models.custom_cnn(8, input_shape=input_shape)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.90      0.95        30\n",
      "      alinda       1.00      1.00      1.00        30\n",
      "        gian       0.97      1.00      0.98        30\n",
      "     jackson       0.91      1.00      0.95        30\n",
      "      khaled       1.00      0.87      0.93        30\n",
      "     nicolas       1.00      1.00      1.00        30\n",
      "        theo       0.88      1.00      0.94        30\n",
      "    yweweler       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.97       240\n",
      "   macro avg       0.97      0.97      0.97       240\n",
      "weighted avg       0.97      0.97      0.97       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_nn = np.argmax(y_test_speaker, axis=1)\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(y_test_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/speaker_recognition.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6hWHr2CAJbx"
   },
   "source": [
    "## Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digit.shape\n",
    "X_train_digit_2d = X_train_digit.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_digit.shape\n",
    "X_val_digit_2d = X_val_digit.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ew0HbFTlAJby"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.75       438\n",
      "           1       0.57      0.73      0.64       456\n",
      "           2       0.67      0.62      0.65       455\n",
      "           3       0.60      0.52      0.56       428\n",
      "           4       0.79      0.65      0.72       485\n",
      "           5       0.73      0.73      0.73       464\n",
      "           6       0.63      0.62      0.62       442\n",
      "           7       0.52      0.64      0.58       490\n",
      "           8       0.70      0.73      0.71       499\n",
      "           9       0.76      0.66      0.71       459\n",
      "\n",
      "    accuracy                           0.67      4616\n",
      "   macro avg       0.68      0.66      0.67      4616\n",
      "weighted avg       0.68      0.67      0.67      4616\n",
      "\n",
      "CPU times: user 10min 31s, sys: 12.6 s, total: 10min 43s\n",
      "Wall time: 13min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Switch to LinearSVC because SVC with RBF kernel takes a lot of time\n",
    "clf1 = LinearSVC(class_weight='balanced')\n",
    "clf1 = clf1.fit(X_train_digit_2d, y_train_digit)\n",
    "y_pred = clf1.predict(X_val_digit_2d)\n",
    "print(classification_report(y_val_digit, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gP6JS1xLAJb1"
   },
   "outputs": [],
   "source": [
    "X_train_digit = X_train_digit.reshape(X_train_digit.shape[0], X_train_digit.shape[1], X_train_digit.shape[2], 1)\n",
    "X_val_digit = X_val_digit.reshape(X_val_digit.shape[0], X_val_digit.shape[1], X_val_digit.shape[2], 1)\n",
    "X_test_digit = X_test_digit.reshape(X_test_digit.shape[0], X_test_digit.shape[1], X_test_digit.shape[2], 1)\n",
    "y_train_digit = tf.keras.utils.to_categorical(y_train_digit, 10)\n",
    "y_test_digit = tf.keras.utils.to_categorical(y_test_digit, 10)\n",
    "y_val_digit = tf.keras.utils.to_categorical(y_val_digit, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBDON2ZdAJb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 57, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (X_train_digit.shape[1], X_train_digit.shape[2], 1)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-NVkJ-QAJb7"
   },
   "source": [
    "#### Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XC3UZAcOAJb8",
    "outputId": "bc153d1f-f02e-430a-d369-6260bf7fe004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               38500     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 78,420\n",
      "Trainable params: 77,928\n",
      "Non-trainable params: 492\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPg3NJywAJb9",
    "outputId": "0f871699-0dad-45e3-c8f8-1af666ddf316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18462 samples, validate on 4616 samples\n",
      "Epoch 1/10\n",
      "18462/18462 [==============================] - 96s 5ms/sample - loss: 1.6812 - acc: 0.4126 - val_loss: 1.1362 - val_acc: 0.6237\n",
      "Epoch 2/10\n",
      "18462/18462 [==============================] - 89s 5ms/sample - loss: 1.1379 - acc: 0.6070 - val_loss: 0.8891 - val_acc: 0.7075\n",
      "Epoch 3/10\n",
      "18462/18462 [==============================] - 87s 5ms/sample - loss: 0.9713 - acc: 0.6669 - val_loss: 0.7421 - val_acc: 0.7517\n",
      "Epoch 4/10\n",
      "18462/18462 [==============================] - 166s 9ms/sample - loss: 0.8552 - acc: 0.7072 - val_loss: 0.7762 - val_acc: 0.7416\n",
      "Epoch 5/10\n",
      "18462/18462 [==============================] - 348s 19ms/sample - loss: 0.7833 - acc: 0.7358 - val_loss: 0.6693 - val_acc: 0.7734\n",
      "Epoch 6/10\n",
      "18462/18462 [==============================] - 209s 11ms/sample - loss: 0.7318 - acc: 0.7509 - val_loss: 0.5528 - val_acc: 0.8226\n",
      "Epoch 7/10\n",
      "18462/18462 [==============================] - 172s 9ms/sample - loss: 0.6905 - acc: 0.7656 - val_loss: 0.6270 - val_acc: 0.7808\n",
      "Epoch 8/10\n",
      "18462/18462 [==============================] - 82s 4ms/sample - loss: 0.6662 - acc: 0.7708 - val_loss: 0.6243 - val_acc: 0.7801\n",
      "Epoch 9/10\n",
      "18462/18462 [==============================] - 90s 5ms/sample - loss: 0.6371 - acc: 0.7884 - val_loss: 0.5264 - val_acc: 0.8234\n",
      "Epoch 10/10\n",
      "18462/18462 [==============================] - 93s 5ms/sample - loss: 0.6145 - acc: 0.7928 - val_loss: 0.5672 - val_acc: 0.8055\n",
      "CPU times: user 34min 25s, sys: 6min 47s, total: 41min 12s\n",
      "Wall time: 23min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd71312ca50>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit, y_train_digit,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digit, y_val_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8W5ebLFOAJb_",
    "outputId": "4cc55fb9-de41-4c1c-819a-bf0ddee91d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       438\n",
      "           1       0.59      0.93      0.72       456\n",
      "           2       0.98      0.57      0.72       455\n",
      "           3       0.68      0.84      0.75       428\n",
      "           4       0.90      0.80      0.84       485\n",
      "           5       0.86      0.74      0.80       464\n",
      "           6       0.90      0.81      0.85       442\n",
      "           7       0.97      0.72      0.82       490\n",
      "           8       0.92      0.83      0.87       499\n",
      "           9       0.73      0.90      0.80       459\n",
      "\n",
      "    accuracy                           0.81      4616\n",
      "   macro avg       0.83      0.81      0.81      4616\n",
      "weighted avg       0.84      0.81      0.81      4616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val = np.argmax(y_val_digit, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val_digit)\n",
    "print(classification_report(Y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNe34g3rAJcB"
   },
   "source": [
    "#### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVvhmAq_AJcB",
    "outputId": "ce6e89d0-9672-4dd1-f7fe-0b579280555f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 608,234\n",
      "Trainable params: 608,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejqqynFOAJcD",
    "outputId": "bcf3bdb5-8986-486f-a849-084d955340ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18462 samples, validate on 4616 samples\n",
      "Epoch 1/10\n",
      "18462/18462 [==============================] - 67s 4ms/sample - loss: 1.5261 - acc: 0.4572 - val_loss: 1.1146 - val_acc: 0.6098\n",
      "Epoch 2/10\n",
      "18462/18462 [==============================] - 65s 4ms/sample - loss: 1.0347 - acc: 0.6393 - val_loss: 0.8179 - val_acc: 0.7179\n",
      "Epoch 3/10\n",
      "18462/18462 [==============================] - 66s 4ms/sample - loss: 0.8470 - acc: 0.6988 - val_loss: 0.7932 - val_acc: 0.7240\n",
      "Epoch 4/10\n",
      "18462/18462 [==============================] - 66s 4ms/sample - loss: 0.7316 - acc: 0.7415 - val_loss: 0.6625 - val_acc: 0.7727\n",
      "Epoch 5/10\n",
      "18462/18462 [==============================] - 65s 4ms/sample - loss: 0.6629 - acc: 0.7638 - val_loss: 0.6325 - val_acc: 0.7886\n",
      "Epoch 6/10\n",
      "18462/18462 [==============================] - 66s 4ms/sample - loss: 0.6123 - acc: 0.7825 - val_loss: 0.5447 - val_acc: 0.8078\n",
      "Epoch 7/10\n",
      "18462/18462 [==============================] - 66s 4ms/sample - loss: 0.5566 - acc: 0.8056 - val_loss: 0.4839 - val_acc: 0.8343\n",
      "Epoch 8/10\n",
      "18462/18462 [==============================] - 65s 4ms/sample - loss: 0.5271 - acc: 0.8142 - val_loss: 0.5239 - val_acc: 0.8094\n",
      "Epoch 9/10\n",
      "18462/18462 [==============================] - 65s 4ms/sample - loss: 0.5008 - acc: 0.8266 - val_loss: 0.4583 - val_acc: 0.8471\n",
      "Epoch 10/10\n",
      "18462/18462 [==============================] - 64s 3ms/sample - loss: 0.4722 - acc: 0.8322 - val_loss: 0.4273 - val_acc: 0.8549\n",
      "CPU times: user 26min 16s, sys: 3min 26s, total: 29min 43s\n",
      "Wall time: 10min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd714a06ed0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit, y_train_digit,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digit, y_val_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3px-T1QRAJcF",
    "outputId": "9b7ed3c6-e597-4a11-a9c3-ec4517e58ed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       438\n",
      "           1       0.75      0.87      0.81       456\n",
      "           2       0.81      0.86      0.83       455\n",
      "           3       0.82      0.71      0.76       428\n",
      "           4       0.94      0.87      0.90       485\n",
      "           5       0.88      0.86      0.87       464\n",
      "           6       0.92      0.81      0.87       442\n",
      "           7       0.94      0.85      0.89       490\n",
      "           8       0.90      0.88      0.89       499\n",
      "           9       0.80      0.89      0.84       459\n",
      "\n",
      "    accuracy                           0.85      4616\n",
      "   macro avg       0.86      0.85      0.85      4616\n",
      "weighted avg       0.86      0.85      0.86      4616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_digit)\n",
    "print(classification_report(Y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model\n",
    "Based on F1-Score the best model is once again the custom paper architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 608,234\n",
      "Trainable params: 608,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "23078/23078 [==============================] - 92s 4ms/sample - loss: 1.4399 - acc: 0.4895\n",
      "Epoch 2/10\n",
      "23078/23078 [==============================] - 83s 4ms/sample - loss: 0.9641 - acc: 0.6614\n",
      "Epoch 3/10\n",
      "23078/23078 [==============================] - 83s 4ms/sample - loss: 0.7928 - acc: 0.7196\n",
      "Epoch 4/10\n",
      "23078/23078 [==============================] - 84s 4ms/sample - loss: 0.6848 - acc: 0.7585\n",
      "Epoch 5/10\n",
      "23078/23078 [==============================] - 84s 4ms/sample - loss: 0.6145 - acc: 0.7829\n",
      "Epoch 6/10\n",
      "23078/23078 [==============================] - 83s 4ms/sample - loss: 0.5636 - acc: 0.8001\n",
      "Epoch 7/10\n",
      "23078/23078 [==============================] - 83s 4ms/sample - loss: 0.5209 - acc: 0.8158\n",
      "Epoch 8/10\n",
      "23078/23078 [==============================] - 84s 4ms/sample - loss: 0.4850 - acc: 0.8307\n",
      "Epoch 9/10\n",
      "23078/23078 [==============================] - 83s 4ms/sample - loss: 0.4509 - acc: 0.8411\n",
      "Epoch 10/10\n",
      "23078/23078 [==============================] - 85s 4ms/sample - loss: 0.4256 - acc: 0.8510\n",
      "CPU times: user 30min 45s, sys: 4min 9s, total: 34min 54s\n",
      "Wall time: 14min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7164eaa90>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train = np.concatenate([X_train_digit, X_val_digit], axis=0)\n",
    "y_train = np.concatenate([y_train_digit, y_val_digit], axis=0)\n",
    "model = cnn_models.custom_cnn(10, input_shape=input_shape)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        30\n",
      "           1       0.97      0.93      0.95        30\n",
      "           2       0.97      1.00      0.98        30\n",
      "           3       0.97      0.93      0.95        30\n",
      "           4       0.97      1.00      0.98        30\n",
      "           5       0.78      0.93      0.85        30\n",
      "           6       0.94      1.00      0.97        30\n",
      "           7       0.90      0.93      0.92        30\n",
      "           8       0.97      0.93      0.95        30\n",
      "           9       0.96      0.77      0.85        30\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_nn = np.argmax(y_test_digit, axis=1)\n",
    "y_pred = model.predict_classes(X_test_digit)\n",
    "print(classification_report(y_test_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/digit_recognition.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTzZ1yR6AJcG"
   },
   "source": [
    "# Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WxSYVrOAJcH"
   },
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "from scipy.io import wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SyhhZ8dAJcL"
   },
   "outputs": [],
   "source": [
    "def pad_zeros_single_rec(rec, max_y):\n",
    "    rec = np.array(rec)\n",
    "    diff_in_y = max_y - rec.shape[0]\n",
    "    if diff_in_y > 0:\n",
    "        half_diff = int(diff_in_y/2)\n",
    "        remaining_diff = diff_in_y-half_diff\n",
    "        v = np.pad(rec, (half_diff, remaining_diff), 'constant', constant_values=0)\n",
    "        return v\n",
    "    else:\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUyrZr67AJcN"
   },
   "outputs": [],
   "source": [
    "def create_recording(duration, rec_rate, name = \"test.wav\", output_dir = \"test/\"):\n",
    "    print(\"Ready in 3...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"2...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"1...\")\n",
    "    time.sleep(1)\n",
    "    print(\"Go.\")\n",
    "    rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "    print(\"Playing the recording.\")\n",
    "    sd.play(rec, rec_rate)\n",
    "\n",
    "    # after hearing the recording, decide whether to record it again or continue to next number\n",
    "    # if you type anything, record again\n",
    "    # if you press enter, save current recording & go to next number\n",
    "    ok = input(\"OK?\")\n",
    "    if ok == \"\":\n",
    "        librosa.output.write_wav(output_dir+name, rec, rec_rate)\n",
    "        return rec\n",
    "    ipd.clear_output(wait=True)\n",
    "    create_recording(duration, rec_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QBcrjAzAJcO"
   },
   "outputs": [],
   "source": [
    "def trim_audio(file, input_dir=\"test/\", output_dir=\"test/\", db=-48):\n",
    "\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"There should be an input \\\"{input_dir}\\\" directory.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # create output directory if not there yet\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    temp1 = output_dir+\"temp1.wav\"\n",
    "    temp2 = output_dir+\"temp2.wav\"\n",
    "    temp3 = output_dir+\"temp3.wav\"\n",
    " \n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_dir+file, \"-af\", f\"silenceremove=1:0:{db}dB\", temp1])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp1, \"-af\", \"areverse\", temp2])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp2, \"-af\", f\"silenceremove=1:0.1:{db}dB\", temp3])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp3, \"-af\", \"areverse\", output_dir+file])\n",
    "    \n",
    "    os.remove(temp1)\n",
    "    os.remove(temp2)\n",
    "    os.remove(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkZPGYwUAJcQ"
   },
   "outputs": [],
   "source": [
    "def test_NN(nn, max_y, target_names, answer = None, duration=2, rec_rate=8000, directory = \"test/\", filename = \"test.wav\"):\n",
    "    create_recording(duration, rec_rate, filename, directory)   \n",
    "    ipd.clear_output()\n",
    "    trim_audio(filename, directory, directory)\n",
    "    # _, rec = wav.read(directory + \"/\" + filename)\n",
    "    rec, _ = librosa.core.load(directory + \"/\" + filename, sr = rec_rate)\n",
    "    rec = pad_zeros_single_rec(rec, max_y)\n",
    "    # sd.play(rec, rec_rate)\n",
    "    rec = data_preparation.compute_spectrogram(rec, normalize=True)\n",
    "    rec = rec[np.newaxis,:,:,np.newaxis]\n",
    "    preds = nn.predict_classes(rec)\n",
    "    print(\"Model prediction: {}\".format(target_names[preds[0]]))\n",
    "    if answer is not None:\n",
    "        print(f\"Correct answer {answer}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VP6Hng1sAJcT"
   },
   "outputs": [],
   "source": [
    "max_y = len(data_augm_pad_recordings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-M4mw6KAJcW"
   },
   "outputs": [],
   "source": [
    "pred = test_NN(model, max_y, target_names, answer = \"gian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9GkS5ZFAJcY"
   },
   "source": [
    "# TO DO:\n",
    "- [x] Set random seed\n",
    "- [x] Use only original recordings in test set of augmented scenario\n",
    "- [x] Use proper validation set for picking best models and params\n",
    "- [x] Data augmentation also for digit recognition\n",
    "- [ ] Evaluate each best model on test set, after training it on x_train + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ubpdv577AJcY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classifiers-Spectrogram_based.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041ee309cd2a4523b8cbb817a7133aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8db829965d284a9b848aa89f1d6e1a7e",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8f16c91328fb4555af28b4fa2522f1b6",
      "value": 2000
     }
    },
    "0471feee5a704241bc959bf9f25cf86b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f5badcb0b1e4938901d1ccebf26bc1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6532c85805db453f8a76edaf34996c0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74521556c16e4badb587537f36771810": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_041ee309cd2a4523b8cbb817a7133aeb",
       "IPY_MODEL_ab519d0c6d6241c5afbc76dbde2306fd"
      ],
      "layout": "IPY_MODEL_5f5badcb0b1e4938901d1ccebf26bc1f"
     }
    },
    "8db829965d284a9b848aa89f1d6e1a7e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f16c91328fb4555af28b4fa2522f1b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a9b4078544ee4fc4b203252a8539169c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ab519d0c6d6241c5afbc76dbde2306fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c29d5436c6514002b1380c6dfb229f76",
      "placeholder": "â",
      "style": "IPY_MODEL_eef3bdb92f1e43eb9241be66f3360fbc",
      "value": " 2000/2000 [57:14&lt;00:00,  1.72s/it]"
     }
    },
    "b20e330bbd0541b9ad6e8897ba359fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bce824cee09446879776ce8440927c32",
       "IPY_MODEL_d877478de1de4e2a9e67d33302b19075"
      ],
      "layout": "IPY_MODEL_6532c85805db453f8a76edaf34996c0c"
     }
    },
    "b365514386b341d6896420c06f2a9a86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bce824cee09446879776ce8440927c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b365514386b341d6896420c06f2a9a86",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a9b4078544ee4fc4b203252a8539169c",
      "value": 400
     }
    },
    "c29d5436c6514002b1380c6dfb229f76": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d877478de1de4e2a9e67d33302b19075": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f110b274d39141b892be18de60d7fd3b",
      "placeholder": "â",
      "style": "IPY_MODEL_0471feee5a704241bc959bf9f25cf86b",
      "value": " 400/400 [01:40&lt;00:00,  3.97it/s]"
     }
    },
    "eef3bdb92f1e43eb9241be66f3360fbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f110b274d39141b892be18de60d7fd3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
