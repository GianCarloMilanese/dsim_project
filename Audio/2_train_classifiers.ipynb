{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCH=32\n",
    "EPOCHS=100\n",
    "PATIENCE=10\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import data_augmentation\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "## No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdd_dir=\"./recordings/\"\n",
    "our_recs_dir=\"./preprocessed_recs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./recordings/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed94db126cd74fd8886418fc53c44482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ./preprocessed_recs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d493b42786ec49a89d9ae91e308da5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=401.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much does input recordings vary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 18262\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite a huge difference! Let's find out the 10 longest recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18262, 17567, 9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get their indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "first_length=18262\n",
    "second_length=17567\n",
    "index_first = a.index(first_length)\n",
    "index_second = a.index(second_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest track is associated with speaker theo, digit 9\n",
      "Second longest track is associated with speaker theo, digit 7\n"
     ]
    }
   ],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir])\n",
    "print(\"Longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_first],labels_digits[index_first]))\n",
    "print(\"Second longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_second],labels_digits[index_second]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problem is with theo, which has 500 recordings, digit 9 and 7, which respectively have 200 recordings. We can safely delete them and saving to pad many thousands of 0s (there will be (18262 - 9015) less zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "max_track_length=9015 # it will be useful later on\n",
    "print(\"Before: {}\".format(len(recordings)))\n",
    "recordings=np.delete(recordings,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(recordings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_speakers)))\n",
    "labels_speakers=np.delete(labels_speakers,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_speakers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_digits)))\n",
    "labels_digits=np.delete(labels_digits,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_digits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now double check to see if everything went well. Now the longest recording will be around 9 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356, 7147, 7038]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though variability is reduced, it is still there: for this reason we will pad zeros at start and end of recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they will have the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9015 9015\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create balancede train, validation and test sets. For digits it's not a huge problem (only 7 and 9, because of the previous operation, have 1 recordings less, however our 4 speakers (ale, alinda, gian, khaled) have 100 recordings, while the other 4 have 500 recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preparation.balanced_train_val_test_split(pad_recordings, labels_digits)\n",
    "X_train_digits = X[0]\n",
    "y_train_digits = y[0]\n",
    "X_val_digits = X[1]\n",
    "y_val_digits = y[1] \n",
    "X_test_digits = X[2]\n",
    "y_test_digits = y[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preparation.balanced_train_val_test_split(pad_recordings, labels_speakers)\n",
    "X_train_speakers = X[0]\n",
    "y_train_speakers = y[0]\n",
    "X_val_speakers = X[1]\n",
    "y_val_speakers = y[1] \n",
    "X_test_speakers = X[2]\n",
    "y_test_speakers = y[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits\n",
    "## Spectrograms - No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.3 s, sys: 393 ms, total: 23.6 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_train_digits])\n",
    "X_val_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_val_digits])\n",
    "X_test_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.1 s, sys: 351 ms, total: 23.5 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_train_digits])\n",
    "X_val_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_val_digits])\n",
    "X_test_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digits_spects.shape\n",
    "X_train_digits_spects_2d = X_train_digits_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.75 s, sys: 67.3 ms, total: 8.81 s\n",
      "Wall time: 9.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train_digits_spects_2d, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digits_spects.shape\n",
    "X_val_digits_spects_2d = X_val_digits_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29        48\n",
      "           1       0.69      0.23      0.34        48\n",
      "           2       0.62      0.17      0.26        48\n",
      "           3       0.56      0.19      0.28        48\n",
      "           4       0.13      0.50      0.21        48\n",
      "           5       0.64      0.19      0.29        48\n",
      "           6       0.13      0.52      0.20        48\n",
      "           7       0.70      0.15      0.24        48\n",
      "           8       0.80      0.08      0.15        48\n",
      "           9       0.93      0.27      0.42        48\n",
      "\n",
      "    accuracy                           0.25       480\n",
      "   macro avg       0.62      0.25      0.27       480\n",
      "weighted avg       0.62      0.25      0.27       480\n",
      "\n",
      "CPU times: user 1.75 s, sys: 18.7 ms, total: 1.77 s\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val_digits_spects_2d)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digits_spects_norm.shape\n",
    "X_train_digits_spects_norm_2d = X_train_digits_spects_norm.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.11 s, sys: 32.9 ms, total: 4.14 s\n",
      "Wall time: 4.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_spects_norm_2d, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digits_spects_norm.shape\n",
    "X_val_digits_spects_norm_2d = X_val_digits_spects_norm.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        48\n",
      "           1       0.90      0.90      0.90        48\n",
      "           2       0.87      0.94      0.90        48\n",
      "           3       0.96      0.90      0.92        48\n",
      "           4       1.00      0.85      0.92        48\n",
      "           5       0.93      0.88      0.90        48\n",
      "           6       0.85      0.92      0.88        48\n",
      "           7       0.87      0.98      0.92        48\n",
      "           8       0.90      0.90      0.90        48\n",
      "           9       0.91      0.85      0.88        48\n",
      "\n",
      "    accuracy                           0.91       480\n",
      "   macro avg       0.91      0.91      0.91       480\n",
      "weighted avg       0.91      0.91      0.91       480\n",
      "\n",
      "CPU times: user 1.52 s, sys: 16.9 ms, total: 1.54 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_digits_spects_norm_2d)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized spectrograms lead to better performances, therefore let's use this representation as default\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, input_shape, _ = data_preparation.prepare_data_nn(X_train_digits_spects_norm, X_val_digits_spects_norm, X_test_digits_spects_norm, y_train_digits, y_val_digits, y_test_digits, number_mode=True)\n",
    "\n",
    "X_train_digits_spects_norm_nn  = X_data[0]\n",
    "y_train_digits_nn = y_data[0]\n",
    "X_val_digits_spects_norm_nn  = X_data[1]\n",
    "y_val_digits_nn = y_data[1]\n",
    "X_test_digits_spects_norm_nn = X_data[2]\n",
    "y_test_digits_nn  = y_data[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,033,066\n",
      "Trainable params: 1,033,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 5s 3ms/sample - loss: 1.9174 - accuracy: 0.3510 - val_loss: 1.6236 - val_accuracy: 0.4604\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 1.3686 - accuracy: 0.5601 - val_loss: 0.9706 - val_accuracy: 0.7708\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 1.0282 - accuracy: 0.6916 - val_loss: 0.7945 - val_accuracy: 0.7750\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.8044 - accuracy: 0.7406 - val_loss: 0.6505 - val_accuracy: 0.8188\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.6677 - accuracy: 0.7790 - val_loss: 0.6628 - val_accuracy: 0.7979\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.5816 - accuracy: 0.8175 - val_loss: 0.7843 - val_accuracy: 0.8125\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.4884 - accuracy: 0.8490 - val_loss: 0.8742 - val_accuracy: 0.7042\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.4590 - accuracy: 0.8434 - val_loss: 0.5060 - val_accuracy: 0.8604\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3911 - accuracy: 0.8881 - val_loss: 0.4629 - val_accuracy: 0.8875\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3546 - accuracy: 0.8930 - val_loss: 0.3984 - val_accuracy: 0.8875\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3255 - accuracy: 0.9049 - val_loss: 0.3661 - val_accuracy: 0.9104\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2901 - accuracy: 0.9091 - val_loss: 0.3485 - val_accuracy: 0.9104\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2604 - accuracy: 0.9203 - val_loss: 0.3924 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2512 - accuracy: 0.9217 - val_loss: 0.3981 - val_accuracy: 0.9021\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2187 - accuracy: 0.9322 - val_loss: 0.3432 - val_accuracy: 0.9271\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1929 - accuracy: 0.9427 - val_loss: 0.3648 - val_accuracy: 0.9083\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2243 - accuracy: 0.9378 - val_loss: 0.3112 - val_accuracy: 0.9250\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1935 - accuracy: 0.9364 - val_loss: 0.3379 - val_accuracy: 0.9250\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1707 - accuracy: 0.9497 - val_loss: 0.3103 - val_accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1666 - accuracy: 0.9469 - val_loss: 0.3232 - val_accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1803 - accuracy: 0.9427 - val_loss: 0.3912 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1563 - accuracy: 0.9559 - val_loss: 0.3334 - val_accuracy: 0.9208\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1458 - accuracy: 0.9559 - val_loss: 0.3332 - val_accuracy: 0.9292\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1662 - accuracy: 0.9503 - val_loss: 0.3916 - val_accuracy: 0.9021\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1602 - accuracy: 0.9510 - val_loss: 0.3365 - val_accuracy: 0.9312\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1373 - accuracy: 0.9587 - val_loss: 0.3064 - val_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1281 - accuracy: 0.9566 - val_loss: 0.4461 - val_accuracy: 0.8938\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1178 - accuracy: 0.9678 - val_loss: 0.3189 - val_accuracy: 0.9312\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1074 - accuracy: 0.9699 - val_loss: 0.3576 - val_accuracy: 0.9250\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1225 - accuracy: 0.9594 - val_loss: 0.3374 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0988 - accuracy: 0.9734 - val_loss: 0.3076 - val_accuracy: 0.9417\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1023 - accuracy: 0.9699 - val_loss: 0.2945 - val_accuracy: 0.9458\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0998 - accuracy: 0.9741 - val_loss: 0.3093 - val_accuracy: 0.9375\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1019 - accuracy: 0.9678 - val_loss: 0.3300 - val_accuracy: 0.9396\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0891 - accuracy: 0.9734 - val_loss: 0.3032 - val_accuracy: 0.9458\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0687 - accuracy: 0.9797 - val_loss: 0.2842 - val_accuracy: 0.9417\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0841 - accuracy: 0.9776 - val_loss: 0.3330 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0760 - accuracy: 0.9783 - val_loss: 0.3004 - val_accuracy: 0.9479\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0825 - accuracy: 0.9741 - val_loss: 0.3155 - val_accuracy: 0.9292\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0663 - accuracy: 0.9853 - val_loss: 0.3460 - val_accuracy: 0.9396\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0730 - accuracy: 0.9769 - val_loss: 0.3130 - val_accuracy: 0.9500\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0726 - accuracy: 0.9811 - val_loss: 0.3445 - val_accuracy: 0.9292\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0653 - accuracy: 0.9839 - val_loss: 0.3782 - val_accuracy: 0.9187\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0716 - accuracy: 0.9776 - val_loss: 0.3093 - val_accuracy: 0.9479\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0649 - accuracy: 0.9811 - val_loss: 0.3263 - val_accuracy: 0.9396\n",
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0635 - accuracy: 0.9846 - val_loss: 0.3071 - val_accuracy: 0.9458\n",
      "CPU times: user 3min 27s, sys: 1min 26s, total: 4min 53s\n",
      "Wall time: 2min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f81a054fc50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10)\n",
    "model.fit(X_train_digits_spects_norm_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_norm_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        48\n",
      "           1       0.87      1.00      0.93        48\n",
      "           2       0.96      0.94      0.95        48\n",
      "           3       0.94      0.94      0.94        48\n",
      "           4       0.98      0.96      0.97        48\n",
      "           5       1.00      0.94      0.97        48\n",
      "           6       0.88      0.94      0.91        48\n",
      "           7       0.98      0.98      0.98        48\n",
      "           8       0.94      0.92      0.93        48\n",
      "           9       0.95      0.83      0.89        48\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.94      0.94      0.94       480\n",
      "weighted avg       0.94      0.94      0.94       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_norm_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 127, 17, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,033,450\n",
      "Trainable params: 1,033,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 6s 4ms/sample - loss: 1.1098 - accuracy: 0.6483 - val_loss: 1.6680 - val_accuracy: 0.5938\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.4727 - accuracy: 0.8776 - val_loss: 1.5970 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.3098 - accuracy: 0.9378 - val_loss: 1.3810 - val_accuracy: 0.5958\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2314 - accuracy: 0.9594 - val_loss: 1.2962 - val_accuracy: 0.5917\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1736 - accuracy: 0.9727 - val_loss: 1.1695 - val_accuracy: 0.6271\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1541 - accuracy: 0.9741 - val_loss: 1.0491 - val_accuracy: 0.6833\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1195 - accuracy: 0.9881 - val_loss: 0.8411 - val_accuracy: 0.7625\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1063 - accuracy: 0.9895 - val_loss: 0.7585 - val_accuracy: 0.7958\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0987 - accuracy: 0.9888 - val_loss: 0.5663 - val_accuracy: 0.8646\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0788 - accuracy: 0.9958 - val_loss: 0.5301 - val_accuracy: 0.8500\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0738 - accuracy: 0.9951 - val_loss: 0.4532 - val_accuracy: 0.8938\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0626 - accuracy: 0.9958 - val_loss: 0.3572 - val_accuracy: 0.9146\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0542 - accuracy: 0.9972 - val_loss: 0.3090 - val_accuracy: 0.9396\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0531 - accuracy: 0.9993 - val_loss: 0.3085 - val_accuracy: 0.9271\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0488 - accuracy: 0.9979 - val_loss: 0.2900 - val_accuracy: 0.9354\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0444 - accuracy: 0.9979 - val_loss: 0.2948 - val_accuracy: 0.9354\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9458\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9521\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0323 - accuracy: 0.9986 - val_loss: 0.3017 - val_accuracy: 0.9458\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9521\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0263 - accuracy: 0.9993 - val_loss: 0.2849 - val_accuracy: 0.9438\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0288 - accuracy: 0.9993 - val_loss: 0.2796 - val_accuracy: 0.9563\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9521\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0246 - accuracy: 0.9993 - val_loss: 0.2741 - val_accuracy: 0.9563\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9563\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9563\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0231 - accuracy: 0.9993 - val_loss: 0.2796 - val_accuracy: 0.9500\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9479\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9542\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9521\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9542\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9583\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9583\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9583\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9521\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9604\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9542\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0139 - accuracy: 0.9993 - val_loss: 0.2752 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9542\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9583\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9583\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9563\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9563\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9604\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9583\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9583\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9563\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9583\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9542\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9542\n",
      "CPU times: user 4min 40s, sys: 2min 11s, total: 6min 51s\n",
      "Wall time: 3min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f818706c5d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_spects_norm_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_norm_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        48\n",
      "           1       0.96      0.94      0.95        48\n",
      "           2       0.96      0.94      0.95        48\n",
      "           3       0.96      0.98      0.97        48\n",
      "           4       1.00      0.96      0.98        48\n",
      "           5       0.94      0.96      0.95        48\n",
      "           6       0.94      0.96      0.95        48\n",
      "           7       1.00      0.94      0.97        48\n",
      "           8       0.98      1.00      0.99        48\n",
      "           9       0.88      0.94      0.91        48\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_norm_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try with MFCCs\n",
    "## MFCC - No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 353 ms, total: 22.8 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc= np.array([data_preparation.mfcc(x, flatten=True) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "scaler_normal = StandardScaler()\n",
    "X_train_digits_mfcc_scaled = scaler_normal.fit_transform(X_train_digits_mfcc)\n",
    "X_val_digits_mfcc_scaled =  scaler_normal.transform(X_val_digits_mfcc)\n",
    "X_test_digits_mfcc_scaled =  scaler_normal.transform(X_test_digits_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 722 ms, sys: 12 ms, total: 734 ms\n",
      "Wall time: 818 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_mfcc_scaled, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        48\n",
      "           1       0.98      0.98      0.98        48\n",
      "           2       1.00      1.00      1.00        48\n",
      "           3       0.96      0.96      0.96        48\n",
      "           4       1.00      0.88      0.93        48\n",
      "           5       1.00      0.92      0.96        48\n",
      "           6       0.69      0.92      0.79        48\n",
      "           7       1.00      0.96      0.98        48\n",
      "           8       0.92      0.94      0.93        48\n",
      "           9       0.98      0.94      0.96        48\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.95      0.94      0.94       480\n",
      "weighted avg       0.95      0.94      0.94       480\n",
      "\n",
      "CPU times: user 244 ms, sys: 5.28 ms, total: 249 ms\n",
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_digits_mfcc_scaled)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar results of the best Spectrograms model. Let's now use CNNs with MFCC\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 s, sys: 360 ms, total: 22.9 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc= np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430, 20, 18)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_digits_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digits_mfcc, X_val_digits_mfcc, X_test_digits_mfcc, y_train_digits, y_val_digits, y_test_digits, number_mode=True)\n",
    "\n",
    "X_train_digits_mfcc_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_mfcc_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_mfcc_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start to train the models, let's start with the simpler one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,330\n",
      "Trainable params: 148,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 21556014486623.8633 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 1s 692us/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 1s 686us/sample - loss: 2.3027 - accuracy: 0.0944 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 1s 661us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 1s 648us/sample - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 1s 665us/sample - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 1s 740us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 1s 855us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 1s 713us/sample - loss: 2.3027 - accuracy: 0.0944 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 1s 706us/sample - loss: 2.3027 - accuracy: 0.0923 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 1s 715us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 1s 673us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 1s 780us/sample - loss: 2.3027 - accuracy: 0.0846 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 1s 653us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 1s 650us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 1s 671us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 1s 660us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 1s 629us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 1s 632us/sample - loss: 2.3027 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 1s 653us/sample - loss: 2.3027 - accuracy: 0.0888 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 1s 776us/sample - loss: 2.3027 - accuracy: 0.0958 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 1s 675us/sample - loss: 2.3027 - accuracy: 0.0867 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 1s 651us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 1s 650us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 1s 644us/sample - loss: 2.3027 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 1s 653us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 1s 647us/sample - loss: 2.3027 - accuracy: 0.0867 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 1s 637us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 1s 681us/sample - loss: 2.3027 - accuracy: 0.0804 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 1s 659us/sample - loss: 2.3027 - accuracy: 0.0755 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 1s 611us/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 1s 698us/sample - loss: 2.3027 - accuracy: 0.0867 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 1s 612us/sample - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 1s 627us/sample - loss: 2.3027 - accuracy: 0.0888 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 1s 653us/sample - loss: 2.3027 - accuracy: 0.0874 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 1s 641us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 1s 659us/sample - loss: 2.3027 - accuracy: 0.0762 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 1s 616us/sample - loss: 2.3027 - accuracy: 0.0888 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 1s 659us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 1s 687us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 1s 613us/sample - loss: 2.3027 - accuracy: 0.0818 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 1s 707us/sample - loss: 2.3027 - accuracy: 0.0783 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 1s 627us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 1s 649us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 1s 676us/sample - loss: 2.3027 - accuracy: 0.0958 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 1s 691us/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430/1430 [==============================] - 1s 636us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 1s 612us/sample - loss: 2.3027 - accuracy: 0.0790 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 1s 589us/sample - loss: 2.3027 - accuracy: 0.0818 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 1s 586us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 1s 600us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 1s 601us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 1s 603us/sample - loss: 2.3027 - accuracy: 0.0874 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 1s 696us/sample - loss: 2.3027 - accuracy: 0.0790 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "1430/1430 [==============================] - 1s 601us/sample - loss: 2.3027 - accuracy: 0.0755 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 56/100\n",
      "1430/1430 [==============================] - 1s 580us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 57/100\n",
      "1430/1430 [==============================] - 1s 601us/sample - loss: 2.3027 - accuracy: 0.0874 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "1430/1430 [==============================] - 1s 615us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 59/100\n",
      "1430/1430 [==============================] - 1s 590us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "1430/1430 [==============================] - 1s 605us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "1430/1430 [==============================] - 1s 570us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 62/100\n",
      "1430/1430 [==============================] - 1s 593us/sample - loss: 2.3027 - accuracy: 0.0923 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 63/100\n",
      "1430/1430 [==============================] - 1s 613us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 64/100\n",
      "1430/1430 [==============================] - 1s 609us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 65/100\n",
      "1430/1430 [==============================] - 1s 602us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 66/100\n",
      "1430/1430 [==============================] - 1s 607us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 67/100\n",
      "1430/1430 [==============================] - 1s 595us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 68/100\n",
      "1430/1430 [==============================] - 1s 605us/sample - loss: 2.3027 - accuracy: 0.0720 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 69/100\n",
      "1430/1430 [==============================] - 1s 593us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 70/100\n",
      "1430/1430 [==============================] - 1s 647us/sample - loss: 2.3027 - accuracy: 0.0797 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 71/100\n",
      "1430/1430 [==============================] - 1s 585us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 72/100\n",
      "1430/1430 [==============================] - 1s 597us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 73/100\n",
      "1430/1430 [==============================] - 1s 595us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 74/100\n",
      "1430/1430 [==============================] - 1s 612us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 75/100\n",
      "1430/1430 [==============================] - 1s 597us/sample - loss: 2.3027 - accuracy: 0.0923 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 76/100\n",
      "1430/1430 [==============================] - 1s 600us/sample - loss: 2.3027 - accuracy: 0.0790 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 77/100\n",
      "1430/1430 [==============================] - 1s 619us/sample - loss: 2.3027 - accuracy: 0.0846 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 78/100\n",
      "1430/1430 [==============================] - 1s 612us/sample - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 79/100\n",
      "1430/1430 [==============================] - 1s 603us/sample - loss: 2.3027 - accuracy: 0.0860 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 80/100\n",
      "1430/1430 [==============================] - 1s 588us/sample - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 81/100\n",
      "1430/1430 [==============================] - 1s 624us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 82/100\n",
      "1430/1430 [==============================] - 1s 603us/sample - loss: 2.3027 - accuracy: 0.0818 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "CPU times: user 1min 37s, sys: 54.9 s, total: 2min 32s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8189f80910>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        48\n",
      "           1       0.00      0.00      0.00        48\n",
      "           2       0.00      0.00      0.00        48\n",
      "           3       0.00      0.00      0.00        48\n",
      "           4       0.00      0.00      0.00        48\n",
      "           5       0.00      0.00      0.00        48\n",
      "           6       0.00      0.00      0.00        48\n",
      "           7       0.00      0.00      0.00        48\n",
      "           8       0.10      1.00      0.18        48\n",
      "           9       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.10       480\n",
      "   macro avg       0.01      0.10      0.02       480\n",
      "weighted avg       0.01      0.10      0.02       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really poor results, let's now use batch normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,714\n",
      "Trainable params: 148,522\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 1.2522 - accuracy: 0.5937 - val_loss: 3.5444 - val_accuracy: 0.4083\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 1s 805us/sample - loss: 0.7169 - accuracy: 0.7951 - val_loss: 1.1626 - val_accuracy: 0.6167\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 1s 830us/sample - loss: 0.5276 - accuracy: 0.8650 - val_loss: 0.5468 - val_accuracy: 0.8562\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 1s 804us/sample - loss: 0.4396 - accuracy: 0.8867 - val_loss: 0.5031 - val_accuracy: 0.8750\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 1s 822us/sample - loss: 0.3921 - accuracy: 0.9140 - val_loss: 0.4192 - val_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 1s 877us/sample - loss: 0.3155 - accuracy: 0.9294 - val_loss: 0.4369 - val_accuracy: 0.9042\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 1s 824us/sample - loss: 0.2809 - accuracy: 0.9455 - val_loss: 0.4165 - val_accuracy: 0.9021\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 1s 780us/sample - loss: 0.2710 - accuracy: 0.9441 - val_loss: 0.4441 - val_accuracy: 0.8833\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 1s 797us/sample - loss: 0.2774 - accuracy: 0.9420 - val_loss: 0.4018 - val_accuracy: 0.8979\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 1s 818us/sample - loss: 0.2256 - accuracy: 0.9573 - val_loss: 0.3165 - val_accuracy: 0.9167\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 1s 828us/sample - loss: 0.2163 - accuracy: 0.9671 - val_loss: 0.3378 - val_accuracy: 0.9167\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 1s 826us/sample - loss: 0.1964 - accuracy: 0.9608 - val_loss: 0.3073 - val_accuracy: 0.9083\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 1s 825us/sample - loss: 0.1874 - accuracy: 0.9629 - val_loss: 0.3715 - val_accuracy: 0.9021\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 1s 811us/sample - loss: 0.1909 - accuracy: 0.9657 - val_loss: 0.2944 - val_accuracy: 0.9292\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 1s 812us/sample - loss: 0.1727 - accuracy: 0.9664 - val_loss: 0.2911 - val_accuracy: 0.9146\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 1s 967us/sample - loss: 0.1649 - accuracy: 0.9678 - val_loss: 0.2859 - val_accuracy: 0.9271\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.1463 - accuracy: 0.9790 - val_loss: 0.2712 - val_accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.1360 - accuracy: 0.9769 - val_loss: 0.2633 - val_accuracy: 0.9292\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 1s 1ms/sample - loss: 0.1288 - accuracy: 0.9846 - val_loss: 0.2495 - val_accuracy: 0.9354\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 1s 866us/sample - loss: 0.1278 - accuracy: 0.9839 - val_loss: 0.2688 - val_accuracy: 0.9292\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 1s 821us/sample - loss: 0.1189 - accuracy: 0.9811 - val_loss: 0.2321 - val_accuracy: 0.9396\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 1s 860us/sample - loss: 0.1073 - accuracy: 0.9839 - val_loss: 0.2530 - val_accuracy: 0.9229\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 1s 855us/sample - loss: 0.1061 - accuracy: 0.9846 - val_loss: 0.2361 - val_accuracy: 0.9396\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.1002 - accuracy: 0.9846 - val_loss: 0.2850 - val_accuracy: 0.9271\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.0911 - accuracy: 0.9895 - val_loss: 0.2349 - val_accuracy: 0.9521\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0988 - accuracy: 0.9881 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 2s 2ms/sample - loss: 0.0826 - accuracy: 0.9923 - val_loss: 0.2425 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.0937 - accuracy: 0.9853 - val_loss: 0.2508 - val_accuracy: 0.9458\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 1s 926us/sample - loss: 0.0776 - accuracy: 0.9916 - val_loss: 0.2463 - val_accuracy: 0.9375\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 1s 974us/sample - loss: 0.0778 - accuracy: 0.9944 - val_loss: 0.2279 - val_accuracy: 0.9375\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 1s 821us/sample - loss: 0.0816 - accuracy: 0.9895 - val_loss: 0.2430 - val_accuracy: 0.9292\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 1s 835us/sample - loss: 0.0718 - accuracy: 0.9916 - val_loss: 0.2225 - val_accuracy: 0.9458\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 1s 938us/sample - loss: 0.0735 - accuracy: 0.9909 - val_loss: 0.2295 - val_accuracy: 0.9479\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 1s 855us/sample - loss: 0.0830 - accuracy: 0.9902 - val_loss: 0.2276 - val_accuracy: 0.9375\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 1s 945us/sample - loss: 0.0606 - accuracy: 0.9944 - val_loss: 0.2165 - val_accuracy: 0.9479\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 1s 912us/sample - loss: 0.0638 - accuracy: 0.9923 - val_loss: 0.2571 - val_accuracy: 0.9396\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 1s 897us/sample - loss: 0.0689 - accuracy: 0.9923 - val_loss: 0.2395 - val_accuracy: 0.9479\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 1s 813us/sample - loss: 0.0508 - accuracy: 0.9965 - val_loss: 0.2264 - val_accuracy: 0.9375\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 1s 799us/sample - loss: 0.0498 - accuracy: 0.9979 - val_loss: 0.2318 - val_accuracy: 0.9458\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 1s 920us/sample - loss: 0.0519 - accuracy: 0.9958 - val_loss: 0.2016 - val_accuracy: 0.9500\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 1s 797us/sample - loss: 0.0511 - accuracy: 0.9951 - val_loss: 0.2110 - val_accuracy: 0.9542\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 1s 810us/sample - loss: 0.0509 - accuracy: 0.9958 - val_loss: 0.2082 - val_accuracy: 0.9479\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 1s 824us/sample - loss: 0.0517 - accuracy: 0.9937 - val_loss: 0.2132 - val_accuracy: 0.9479\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 1s 799us/sample - loss: 0.0464 - accuracy: 0.9958 - val_loss: 0.2148 - val_accuracy: 0.9458\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 1s 803us/sample - loss: 0.0504 - accuracy: 0.9937 - val_loss: 0.2314 - val_accuracy: 0.9479\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430/1430 [==============================] - 1s 742us/sample - loss: 0.0459 - accuracy: 0.9972 - val_loss: 0.2176 - val_accuracy: 0.9479\n",
      "Epoch 47/100\n",
      "1430/1430 [==============================] - 1s 719us/sample - loss: 0.0414 - accuracy: 0.9930 - val_loss: 0.1988 - val_accuracy: 0.9521\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 1s 766us/sample - loss: 0.0409 - accuracy: 0.9944 - val_loss: 0.2124 - val_accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 1s 767us/sample - loss: 0.0429 - accuracy: 0.9965 - val_loss: 0.2060 - val_accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 1s 741us/sample - loss: 0.0384 - accuracy: 0.9986 - val_loss: 0.2049 - val_accuracy: 0.9458\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 1s 752us/sample - loss: 0.0487 - accuracy: 0.9923 - val_loss: 0.2110 - val_accuracy: 0.9521\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 1s 734us/sample - loss: 0.0378 - accuracy: 0.9986 - val_loss: 0.1910 - val_accuracy: 0.9542\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 1s 752us/sample - loss: 0.0384 - accuracy: 0.9972 - val_loss: 0.2527 - val_accuracy: 0.9375\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 1s 772us/sample - loss: 0.0384 - accuracy: 0.9972 - val_loss: 0.2168 - val_accuracy: 0.9500\n",
      "Epoch 55/100\n",
      "1430/1430 [==============================] - 1s 759us/sample - loss: 0.0397 - accuracy: 0.9958 - val_loss: 0.2040 - val_accuracy: 0.9438\n",
      "Epoch 56/100\n",
      "1430/1430 [==============================] - 1s 809us/sample - loss: 0.0404 - accuracy: 0.9972 - val_loss: 0.1913 - val_accuracy: 0.9583\n",
      "Epoch 57/100\n",
      "1430/1430 [==============================] - 1s 726us/sample - loss: 0.0317 - accuracy: 0.9986 - val_loss: 0.1914 - val_accuracy: 0.9563\n",
      "Epoch 58/100\n",
      "1430/1430 [==============================] - 1s 766us/sample - loss: 0.0351 - accuracy: 0.9972 - val_loss: 0.2108 - val_accuracy: 0.9521\n",
      "Epoch 59/100\n",
      "1430/1430 [==============================] - 1s 721us/sample - loss: 0.0320 - accuracy: 0.9972 - val_loss: 0.1898 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "1430/1430 [==============================] - 1s 722us/sample - loss: 0.0282 - accuracy: 0.9972 - val_loss: 0.1995 - val_accuracy: 0.9542\n",
      "Epoch 61/100\n",
      "1430/1430 [==============================] - 1s 808us/sample - loss: 0.0296 - accuracy: 0.9986 - val_loss: 0.2517 - val_accuracy: 0.9333\n",
      "Epoch 62/100\n",
      "1430/1430 [==============================] - 1s 799us/sample - loss: 0.0331 - accuracy: 0.9972 - val_loss: 0.1958 - val_accuracy: 0.9542\n",
      "Epoch 63/100\n",
      "1430/1430 [==============================] - 1s 905us/sample - loss: 0.0308 - accuracy: 0.9972 - val_loss: 0.2160 - val_accuracy: 0.9479\n",
      "Epoch 64/100\n",
      "1430/1430 [==============================] - 1s 776us/sample - loss: 0.0369 - accuracy: 0.9937 - val_loss: 0.1918 - val_accuracy: 0.9583\n",
      "Epoch 65/100\n",
      "1430/1430 [==============================] - 1s 828us/sample - loss: 0.0303 - accuracy: 0.9979 - val_loss: 0.2015 - val_accuracy: 0.9583\n",
      "Epoch 66/100\n",
      "1430/1430 [==============================] - 1s 852us/sample - loss: 0.0283 - accuracy: 0.9986 - val_loss: 0.1959 - val_accuracy: 0.9563\n",
      "Epoch 67/100\n",
      "1430/1430 [==============================] - 1s 862us/sample - loss: 0.0256 - accuracy: 0.9986 - val_loss: 0.1998 - val_accuracy: 0.9521\n",
      "Epoch 68/100\n",
      "1430/1430 [==============================] - 1s 867us/sample - loss: 0.0288 - accuracy: 0.9965 - val_loss: 0.2444 - val_accuracy: 0.9396\n",
      "Epoch 69/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.0270 - accuracy: 0.9986 - val_loss: 0.2397 - val_accuracy: 0.9417\n",
      "CPU times: user 1min 45s, sys: 41.5 s, total: 2min 26s\n",
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f818c49f350>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10,\n",
    "                                batch_normalisation=True)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        48\n",
      "           1       0.98      1.00      0.99        48\n",
      "           2       0.92      1.00      0.96        48\n",
      "           3       0.96      0.98      0.97        48\n",
      "           4       1.00      0.98      0.99        48\n",
      "           5       0.96      0.94      0.95        48\n",
      "           6       0.96      0.94      0.95        48\n",
      "           7       0.98      0.98      0.98        48\n",
      "           8       0.96      0.96      0.96        48\n",
      "           9       0.96      0.92      0.94        48\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best combo so far is \"CNN + MFCCs\".\n",
    "\n",
    "Batch normalisation lead to similar results on spectrograms, however on MFCC it works way better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n",
      "CPU times: user 5min 32s, sys: 13 s, total: 5min 45s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                                                    y_type= ['digit', 'digit'],\n",
    "                                                    n_category_test=15,\n",
    "                                                    include_pitch=True,\n",
    "                                                    max_length=max_track_length,\n",
    "                                                    recordings_source=[False, True],\n",
    "                                                    transform_function=\"mfcc\")\n",
    "X_train_digit_mfcc = X[0]\n",
    "y_train_digit_mfcc = y[0]\n",
    "X_val_digit_mfcc = X[1]\n",
    "y_val_digit_mfcc = y[1]\n",
    "X_test_digit_mfcc = X[2]\n",
    "y_test_digit_mfcc  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724 575\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_digit_mfcc, X_val_digit_mfcc]),\n",
    "                         np.concatenate([y_train_digit_mfcc, y_val_digit_mfcc]))\n",
    "\n",
    "X_train_digit = X[0]\n",
    "y_train_digit = y[0]\n",
    "X_val_digit = X[1]\n",
    "y_val_digit = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digit, X_val_digit, X_test_digit_mfcc, y_train_digit, y_val_digit, y_test_digit_mfcc, number_mode=True)\n",
    "X_train_digits_mfcc_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_mfcc_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_mfcc_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,714\n",
      "Trainable params: 148,522\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 17240 samples, validate on 5750 samples\n",
      "Epoch 1/100\n",
      "17240/17240 [==============================] - 16s 943us/sample - loss: 1.0633 - accuracy: 0.6489 - val_loss: 0.7819 - val_accuracy: 0.7501\n",
      "Epoch 2/100\n",
      "17240/17240 [==============================] - 13s 759us/sample - loss: 0.7437 - accuracy: 0.7578 - val_loss: 0.6766 - val_accuracy: 0.7852\n",
      "Epoch 3/100\n",
      "17240/17240 [==============================] - 13s 730us/sample - loss: 0.6421 - accuracy: 0.7907 - val_loss: 0.6062 - val_accuracy: 0.8031\n",
      "Epoch 4/100\n",
      "17240/17240 [==============================] - 12s 709us/sample - loss: 0.5956 - accuracy: 0.8075 - val_loss: 0.5070 - val_accuracy: 0.8428\n",
      "Epoch 5/100\n",
      "17240/17240 [==============================] - 12s 696us/sample - loss: 0.5549 - accuracy: 0.8187 - val_loss: 0.4978 - val_accuracy: 0.8417\n",
      "Epoch 6/100\n",
      "17240/17240 [==============================] - 12s 710us/sample - loss: 0.5346 - accuracy: 0.8296 - val_loss: 0.4743 - val_accuracy: 0.8471\n",
      "Epoch 7/100\n",
      "17240/17240 [==============================] - 12s 709us/sample - loss: 0.5174 - accuracy: 0.8304 - val_loss: 0.5735 - val_accuracy: 0.7983\n",
      "Epoch 8/100\n",
      "17240/17240 [==============================] - 14s 813us/sample - loss: 0.5087 - accuracy: 0.8339 - val_loss: 0.4781 - val_accuracy: 0.8390\n",
      "Epoch 9/100\n",
      "17240/17240 [==============================] - 11s 661us/sample - loss: 0.5026 - accuracy: 0.8331 - val_loss: 0.6470 - val_accuracy: 0.7807\n",
      "Epoch 10/100\n",
      "17240/17240 [==============================] - 11s 655us/sample - loss: 0.4749 - accuracy: 0.8446 - val_loss: 0.4549 - val_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "17240/17240 [==============================] - 11s 641us/sample - loss: 0.4807 - accuracy: 0.8432 - val_loss: 0.4589 - val_accuracy: 0.8457\n",
      "Epoch 12/100\n",
      "17240/17240 [==============================] - 14s 813us/sample - loss: 0.4550 - accuracy: 0.8498 - val_loss: 0.4396 - val_accuracy: 0.8550\n",
      "Epoch 13/100\n",
      "17240/17240 [==============================] - 13s 747us/sample - loss: 0.4409 - accuracy: 0.8535 - val_loss: 0.4425 - val_accuracy: 0.8550\n",
      "Epoch 14/100\n",
      "17240/17240 [==============================] - 13s 728us/sample - loss: 0.4453 - accuracy: 0.8499 - val_loss: 0.3828 - val_accuracy: 0.8763\n",
      "Epoch 15/100\n",
      "17240/17240 [==============================] - 12s 696us/sample - loss: 0.4389 - accuracy: 0.8563 - val_loss: 0.4470 - val_accuracy: 0.8548\n",
      "Epoch 16/100\n",
      "17240/17240 [==============================] - 13s 746us/sample - loss: 0.4397 - accuracy: 0.8546 - val_loss: 0.3735 - val_accuracy: 0.8805\n",
      "Epoch 17/100\n",
      "17240/17240 [==============================] - 13s 727us/sample - loss: 0.4288 - accuracy: 0.8567 - val_loss: 0.4227 - val_accuracy: 0.8574\n",
      "Epoch 18/100\n",
      "17240/17240 [==============================] - 12s 723us/sample - loss: 0.4247 - accuracy: 0.8583 - val_loss: 0.3699 - val_accuracy: 0.8838\n",
      "Epoch 19/100\n",
      "17240/17240 [==============================] - 13s 738us/sample - loss: 0.4104 - accuracy: 0.8628 - val_loss: 0.3904 - val_accuracy: 0.8703\n",
      "Epoch 20/100\n",
      "17240/17240 [==============================] - 12s 683us/sample - loss: 0.4063 - accuracy: 0.8662 - val_loss: 0.4098 - val_accuracy: 0.8621\n",
      "Epoch 21/100\n",
      "17240/17240 [==============================] - 12s 694us/sample - loss: 0.4000 - accuracy: 0.8676 - val_loss: 0.3730 - val_accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "17240/17240 [==============================] - 12s 673us/sample - loss: 0.3812 - accuracy: 0.8749 - val_loss: 0.3622 - val_accuracy: 0.8741\n",
      "Epoch 23/100\n",
      "17240/17240 [==============================] - 12s 679us/sample - loss: 0.3809 - accuracy: 0.8733 - val_loss: 0.3694 - val_accuracy: 0.8793\n",
      "Epoch 24/100\n",
      "17240/17240 [==============================] - 12s 675us/sample - loss: 0.3914 - accuracy: 0.8709 - val_loss: 0.3566 - val_accuracy: 0.8840\n",
      "Epoch 25/100\n",
      "17240/17240 [==============================] - 12s 688us/sample - loss: 0.3759 - accuracy: 0.8763 - val_loss: 0.3603 - val_accuracy: 0.8831\n",
      "Epoch 26/100\n",
      "17240/17240 [==============================] - 12s 690us/sample - loss: 0.3794 - accuracy: 0.8735 - val_loss: 0.3711 - val_accuracy: 0.8758\n",
      "Epoch 27/100\n",
      "17240/17240 [==============================] - 14s 823us/sample - loss: 0.3675 - accuracy: 0.8775 - val_loss: 0.4220 - val_accuracy: 0.8576\n",
      "Epoch 28/100\n",
      "17240/17240 [==============================] - 14s 803us/sample - loss: 0.3585 - accuracy: 0.8788 - val_loss: 0.3286 - val_accuracy: 0.8904\n",
      "Epoch 29/100\n",
      "17240/17240 [==============================] - 19s 1ms/sample - loss: 0.3595 - accuracy: 0.8787 - val_loss: 0.3269 - val_accuracy: 0.8915\n",
      "Epoch 30/100\n",
      "17240/17240 [==============================] - 15s 865us/sample - loss: 0.3530 - accuracy: 0.8812 - val_loss: 0.3348 - val_accuracy: 0.8868\n",
      "Epoch 31/100\n",
      "17240/17240 [==============================] - 15s 885us/sample - loss: 0.3568 - accuracy: 0.8770 - val_loss: 0.3545 - val_accuracy: 0.8812\n",
      "Epoch 32/100\n",
      "17240/17240 [==============================] - 15s 880us/sample - loss: 0.3462 - accuracy: 0.8838 - val_loss: 0.3128 - val_accuracy: 0.8957\n",
      "Epoch 33/100\n",
      "17240/17240 [==============================] - 15s 860us/sample - loss: 0.3391 - accuracy: 0.8865 - val_loss: 0.3459 - val_accuracy: 0.8765\n",
      "Epoch 34/100\n",
      "17240/17240 [==============================] - 15s 877us/sample - loss: 0.3361 - accuracy: 0.8893 - val_loss: 0.3303 - val_accuracy: 0.8864\n",
      "Epoch 35/100\n",
      "17240/17240 [==============================] - 16s 907us/sample - loss: 0.3430 - accuracy: 0.8878 - val_loss: 0.3663 - val_accuracy: 0.8715\n",
      "Epoch 36/100\n",
      "17240/17240 [==============================] - 16s 949us/sample - loss: 0.3222 - accuracy: 0.8905 - val_loss: 0.3261 - val_accuracy: 0.8901\n",
      "Epoch 37/100\n",
      "17240/17240 [==============================] - 15s 889us/sample - loss: 0.3224 - accuracy: 0.8908 - val_loss: 0.3540 - val_accuracy: 0.8817\n",
      "Epoch 38/100\n",
      "17240/17240 [==============================] - 14s 837us/sample - loss: 0.3226 - accuracy: 0.8884 - val_loss: 0.3168 - val_accuracy: 0.8878\n",
      "Epoch 39/100\n",
      "17240/17240 [==============================] - 14s 795us/sample - loss: 0.3119 - accuracy: 0.8969 - val_loss: 0.3549 - val_accuracy: 0.8793\n",
      "Epoch 40/100\n",
      "17240/17240 [==============================] - 18s 1ms/sample - loss: 0.3176 - accuracy: 0.8916 - val_loss: 0.3042 - val_accuracy: 0.8993\n",
      "Epoch 41/100\n",
      "17240/17240 [==============================] - 15s 853us/sample - loss: 0.3127 - accuracy: 0.8957 - val_loss: 0.3097 - val_accuracy: 0.8967\n",
      "Epoch 42/100\n",
      "17240/17240 [==============================] - 12s 677us/sample - loss: 0.2994 - accuracy: 0.8982 - val_loss: 0.3164 - val_accuracy: 0.8901\n",
      "Epoch 43/100\n",
      "17240/17240 [==============================] - 14s 832us/sample - loss: 0.3115 - accuracy: 0.8964 - val_loss: 0.3084 - val_accuracy: 0.8967\n",
      "Epoch 44/100\n",
      "17240/17240 [==============================] - 15s 867us/sample - loss: 0.3089 - accuracy: 0.8951 - val_loss: 0.3046 - val_accuracy: 0.8970\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17240/17240 [==============================] - 13s 734us/sample - loss: 0.3015 - accuracy: 0.8985 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 46/100\n",
      "17240/17240 [==============================] - 13s 768us/sample - loss: 0.3075 - accuracy: 0.8972 - val_loss: 0.3281 - val_accuracy: 0.8908\n",
      "Epoch 47/100\n",
      "17240/17240 [==============================] - 14s 830us/sample - loss: 0.3028 - accuracy: 0.8979 - val_loss: 0.2939 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "17240/17240 [==============================] - 13s 725us/sample - loss: 0.3037 - accuracy: 0.8972 - val_loss: 0.3088 - val_accuracy: 0.8957\n",
      "Epoch 49/100\n",
      "17240/17240 [==============================] - 13s 728us/sample - loss: 0.2931 - accuracy: 0.9020 - val_loss: 0.3345 - val_accuracy: 0.8896\n",
      "Epoch 50/100\n",
      "17240/17240 [==============================] - 11s 613us/sample - loss: 0.3002 - accuracy: 0.8997 - val_loss: 0.3322 - val_accuracy: 0.8882\n",
      "Epoch 51/100\n",
      "17240/17240 [==============================] - 11s 642us/sample - loss: 0.2910 - accuracy: 0.9020 - val_loss: 0.3095 - val_accuracy: 0.8939\n",
      "Epoch 52/100\n",
      "17240/17240 [==============================] - 11s 637us/sample - loss: 0.2876 - accuracy: 0.9042 - val_loss: 0.2900 - val_accuracy: 0.9003\n",
      "Epoch 53/100\n",
      "17240/17240 [==============================] - 11s 634us/sample - loss: 0.2846 - accuracy: 0.9037 - val_loss: 0.2876 - val_accuracy: 0.9042\n",
      "Epoch 54/100\n",
      "17240/17240 [==============================] - 12s 707us/sample - loss: 0.2840 - accuracy: 0.9031 - val_loss: 0.2964 - val_accuracy: 0.9012\n",
      "Epoch 55/100\n",
      "17240/17240 [==============================] - 11s 629us/sample - loss: 0.2803 - accuracy: 0.9053 - val_loss: 0.2900 - val_accuracy: 0.9030\n",
      "Epoch 56/100\n",
      "17240/17240 [==============================] - 11s 616us/sample - loss: 0.2859 - accuracy: 0.9009 - val_loss: 0.3020 - val_accuracy: 0.8963\n",
      "Epoch 57/100\n",
      "17240/17240 [==============================] - 11s 632us/sample - loss: 0.2727 - accuracy: 0.9112 - val_loss: 0.2973 - val_accuracy: 0.8977\n",
      "Epoch 58/100\n",
      "17240/17240 [==============================] - 11s 662us/sample - loss: 0.2831 - accuracy: 0.9060 - val_loss: 0.3337 - val_accuracy: 0.8847\n",
      "Epoch 59/100\n",
      "17240/17240 [==============================] - 11s 619us/sample - loss: 0.2755 - accuracy: 0.9068 - val_loss: 0.2779 - val_accuracy: 0.9052\n",
      "Epoch 60/100\n",
      "17240/17240 [==============================] - 10s 586us/sample - loss: 0.2659 - accuracy: 0.9097 - val_loss: 0.2829 - val_accuracy: 0.9049\n",
      "Epoch 61/100\n",
      "17240/17240 [==============================] - 11s 639us/sample - loss: 0.2748 - accuracy: 0.9075 - val_loss: 0.3258 - val_accuracy: 0.8920\n",
      "Epoch 62/100\n",
      "17240/17240 [==============================] - 10s 592us/sample - loss: 0.2722 - accuracy: 0.9084 - val_loss: 0.2905 - val_accuracy: 0.9009\n",
      "Epoch 63/100\n",
      "17240/17240 [==============================] - 11s 624us/sample - loss: 0.2766 - accuracy: 0.9080 - val_loss: 0.3288 - val_accuracy: 0.8899\n",
      "Epoch 64/100\n",
      "17240/17240 [==============================] - 10s 600us/sample - loss: 0.2713 - accuracy: 0.9069 - val_loss: 0.3197 - val_accuracy: 0.8943\n",
      "Epoch 65/100\n",
      "17240/17240 [==============================] - 10s 595us/sample - loss: 0.2700 - accuracy: 0.9099 - val_loss: 0.2994 - val_accuracy: 0.8976\n",
      "Epoch 66/100\n",
      "17240/17240 [==============================] - 10s 553us/sample - loss: 0.2626 - accuracy: 0.9127 - val_loss: 0.3198 - val_accuracy: 0.8906\n",
      "Epoch 67/100\n",
      "17240/17240 [==============================] - 9s 544us/sample - loss: 0.2730 - accuracy: 0.9059 - val_loss: 0.2979 - val_accuracy: 0.9002\n",
      "Epoch 68/100\n",
      "17240/17240 [==============================] - 9s 527us/sample - loss: 0.2630 - accuracy: 0.9080 - val_loss: 0.2727 - val_accuracy: 0.9071\n",
      "Epoch 69/100\n",
      "17240/17240 [==============================] - 9s 541us/sample - loss: 0.2472 - accuracy: 0.9146 - val_loss: 0.3009 - val_accuracy: 0.9014\n",
      "Epoch 70/100\n",
      "17240/17240 [==============================] - 9s 536us/sample - loss: 0.2513 - accuracy: 0.9134 - val_loss: 0.2914 - val_accuracy: 0.9007\n",
      "Epoch 71/100\n",
      "17240/17240 [==============================] - 9s 533us/sample - loss: 0.2546 - accuracy: 0.9155 - val_loss: 0.2750 - val_accuracy: 0.9087\n",
      "Epoch 72/100\n",
      "17240/17240 [==============================] - 10s 564us/sample - loss: 0.2477 - accuracy: 0.9190 - val_loss: 0.3041 - val_accuracy: 0.8981\n",
      "Epoch 73/100\n",
      "17240/17240 [==============================] - 10s 552us/sample - loss: 0.2487 - accuracy: 0.9184 - val_loss: 0.2695 - val_accuracy: 0.9104\n",
      "Epoch 74/100\n",
      "17240/17240 [==============================] - 9s 542us/sample - loss: 0.2444 - accuracy: 0.9176 - val_loss: 0.2871 - val_accuracy: 0.8998\n",
      "Epoch 75/100\n",
      "17240/17240 [==============================] - 9s 535us/sample - loss: 0.2492 - accuracy: 0.9150 - val_loss: 0.3134 - val_accuracy: 0.8923\n",
      "Epoch 76/100\n",
      "17240/17240 [==============================] - 10s 552us/sample - loss: 0.2378 - accuracy: 0.9180 - val_loss: 0.2871 - val_accuracy: 0.9033\n",
      "Epoch 77/100\n",
      "17240/17240 [==============================] - 9s 530us/sample - loss: 0.2421 - accuracy: 0.9187 - val_loss: 0.2717 - val_accuracy: 0.9094\n",
      "Epoch 78/100\n",
      "17240/17240 [==============================] - 10s 578us/sample - loss: 0.2475 - accuracy: 0.9152 - val_loss: 0.2794 - val_accuracy: 0.9066\n",
      "Epoch 79/100\n",
      "17240/17240 [==============================] - 9s 525us/sample - loss: 0.2413 - accuracy: 0.9179 - val_loss: 0.2685 - val_accuracy: 0.9097\n",
      "Epoch 80/100\n",
      "17240/17240 [==============================] - 11s 627us/sample - loss: 0.2361 - accuracy: 0.9175 - val_loss: 0.2784 - val_accuracy: 0.9063\n",
      "Epoch 81/100\n",
      "17240/17240 [==============================] - 10s 552us/sample - loss: 0.2286 - accuracy: 0.9233 - val_loss: 0.3134 - val_accuracy: 0.8950\n",
      "Epoch 82/100\n",
      "17240/17240 [==============================] - 9s 535us/sample - loss: 0.2411 - accuracy: 0.9183 - val_loss: 0.2866 - val_accuracy: 0.9068\n",
      "Epoch 83/100\n",
      "17240/17240 [==============================] - 9s 531us/sample - loss: 0.2451 - accuracy: 0.9160 - val_loss: 0.2811 - val_accuracy: 0.9089\n",
      "Epoch 84/100\n",
      "17240/17240 [==============================] - 9s 540us/sample - loss: 0.2421 - accuracy: 0.9190 - val_loss: 0.2751 - val_accuracy: 0.9071\n",
      "Epoch 85/100\n",
      "17240/17240 [==============================] - 13s 731us/sample - loss: 0.2367 - accuracy: 0.9197 - val_loss: 0.2733 - val_accuracy: 0.9099\n",
      "Epoch 86/100\n",
      "17240/17240 [==============================] - 13s 772us/sample - loss: 0.2282 - accuracy: 0.9212 - val_loss: 0.2792 - val_accuracy: 0.9002\n",
      "Epoch 87/100\n",
      "17240/17240 [==============================] - 10s 597us/sample - loss: 0.2327 - accuracy: 0.9194 - val_loss: 0.2810 - val_accuracy: 0.9056\n",
      "Epoch 88/100\n",
      "17240/17240 [==============================] - 10s 575us/sample - loss: 0.2277 - accuracy: 0.9233 - val_loss: 0.2761 - val_accuracy: 0.9090\n",
      "Epoch 89/100\n",
      "17240/17240 [==============================] - 10s 571us/sample - loss: 0.2351 - accuracy: 0.9206 - val_loss: 0.2827 - val_accuracy: 0.9049\n",
      "CPU times: user 25min 48s, sys: 16min 7s, total: 41min 55s\n",
      "Wall time: 17min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f819e8ab890>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       575\n",
      "           1       0.91      0.93      0.92       575\n",
      "           2       0.89      0.91      0.90       575\n",
      "           3       0.91      0.86      0.88       575\n",
      "           4       0.95      0.91      0.93       575\n",
      "           5       0.96      0.91      0.93       575\n",
      "           6       0.94      0.86      0.89       575\n",
      "           7       0.85      0.94      0.89       575\n",
      "           8       0.89      0.93      0.91       575\n",
      "           9       0.90      0.90      0.90       575\n",
      "\n",
      "    accuracy                           0.91      5750\n",
      "   macro avg       0.91      0.91      0.91      5750\n",
      "weighted avg       0.91      0.91      0.91      5750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation, in the MFCC scenario, did not lead to any improvement! Let's see what happens in the spectrograms scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrograms - Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n"
     ]
    }
   ],
   "source": [
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=max_track_length,\n",
    "                             recordings_source=[False, True])\n",
    "\n",
    "X_train_digit = X[0]\n",
    "y_train_digit = y[0]\n",
    "X_val_digit = X[1]\n",
    "y_val_digit = y[1]\n",
    "X_test_digit = X[2]\n",
    "y_test_digit  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724 575\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_digit, X_val_digit]),\n",
    "                         np.concatenate([y_train_digit, y_val_digit]))\n",
    "\n",
    "X_train_digit = X[0]\n",
    "y_train_digit = y[0]\n",
    "X_val_digit = X[1]\n",
    "y_val_digit = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digit, X_val_digit, X_test_digit_mfcc, y_train_digit, y_val_digit, y_test_digit_mfcc, number_mode=True)\n",
    "\n",
    "X_train_digits_spects_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_spects_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_spects_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 127, 17, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,033,450\n",
      "Trainable params: 1,033,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 17240 samples, validate on 5750 samples\n",
      "Epoch 1/100\n",
      "17240/17240 [==============================] - 46s 3ms/sample - loss: 1.0789 - accuracy: 0.6415 - val_loss: 0.8444 - val_accuracy: 0.7247\n",
      "Epoch 2/100\n",
      "17240/17240 [==============================] - 38s 2ms/sample - loss: 0.7081 - accuracy: 0.7722 - val_loss: 0.5658 - val_accuracy: 0.8190\n",
      "Epoch 3/100\n",
      "17240/17240 [==============================] - 39s 2ms/sample - loss: 0.5787 - accuracy: 0.8100 - val_loss: 0.5150 - val_accuracy: 0.8343\n",
      "Epoch 4/100\n",
      "17240/17240 [==============================] - 37s 2ms/sample - loss: 0.5119 - accuracy: 0.8382 - val_loss: 0.5074 - val_accuracy: 0.8358\n",
      "Epoch 5/100\n",
      "17240/17240 [==============================] - 46s 3ms/sample - loss: 0.4557 - accuracy: 0.8570 - val_loss: 0.4584 - val_accuracy: 0.8581\n",
      "Epoch 6/100\n",
      "17240/17240 [==============================] - 44s 3ms/sample - loss: 0.4196 - accuracy: 0.8659 - val_loss: 0.4662 - val_accuracy: 0.8506\n",
      "Epoch 7/100\n",
      "17240/17240 [==============================] - 38s 2ms/sample - loss: 0.3996 - accuracy: 0.8729 - val_loss: 0.4415 - val_accuracy: 0.8616\n",
      "Epoch 8/100\n",
      "17240/17240 [==============================] - 41s 2ms/sample - loss: 0.3671 - accuracy: 0.8821 - val_loss: 0.4153 - val_accuracy: 0.8628\n",
      "Epoch 9/100\n",
      "17240/17240 [==============================] - 41s 2ms/sample - loss: 0.3549 - accuracy: 0.8860 - val_loss: 0.9817 - val_accuracy: 0.8134\n",
      "Epoch 10/100\n",
      "17240/17240 [==============================] - 48s 3ms/sample - loss: 0.3359 - accuracy: 0.8921 - val_loss: 0.3993 - val_accuracy: 0.8706\n",
      "Epoch 11/100\n",
      "17240/17240 [==============================] - 40s 2ms/sample - loss: 0.3193 - accuracy: 0.8955 - val_loss: 0.4695 - val_accuracy: 0.8503\n",
      "Epoch 12/100\n",
      "17240/17240 [==============================] - 45s 3ms/sample - loss: 0.2951 - accuracy: 0.9046 - val_loss: 0.3495 - val_accuracy: 0.8864\n",
      "Epoch 13/100\n",
      "17240/17240 [==============================] - 45s 3ms/sample - loss: 0.2664 - accuracy: 0.9141 - val_loss: 0.3427 - val_accuracy: 0.8913\n",
      "Epoch 14/100\n",
      "17240/17240 [==============================] - 40s 2ms/sample - loss: 0.2650 - accuracy: 0.9146 - val_loss: 0.3976 - val_accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "17240/17240 [==============================] - 41s 2ms/sample - loss: 0.2465 - accuracy: 0.9180 - val_loss: 0.3788 - val_accuracy: 0.8784\n",
      "Epoch 16/100\n",
      "17240/17240 [==============================] - 39s 2ms/sample - loss: 0.2340 - accuracy: 0.9253 - val_loss: 0.4158 - val_accuracy: 0.8668\n",
      "Epoch 17/100\n",
      "17240/17240 [==============================] - 39s 2ms/sample - loss: 0.2288 - accuracy: 0.9277 - val_loss: 0.3444 - val_accuracy: 0.8880\n",
      "Epoch 18/100\n",
      "17240/17240 [==============================] - 42s 2ms/sample - loss: 0.2164 - accuracy: 0.9298 - val_loss: 0.3698 - val_accuracy: 0.8837\n",
      "Epoch 19/100\n",
      "17240/17240 [==============================] - 41s 2ms/sample - loss: 0.2032 - accuracy: 0.9338 - val_loss: 0.3686 - val_accuracy: 0.8845\n",
      "Epoch 20/100\n",
      "17240/17240 [==============================] - 36s 2ms/sample - loss: 0.1977 - accuracy: 0.9346 - val_loss: 0.4044 - val_accuracy: 0.8770\n",
      "Epoch 21/100\n",
      "17240/17240 [==============================] - 38s 2ms/sample - loss: 0.1865 - accuracy: 0.9398 - val_loss: 0.3715 - val_accuracy: 0.8837\n",
      "Epoch 22/100\n",
      "17240/17240 [==============================] - 46s 3ms/sample - loss: 0.1744 - accuracy: 0.9429 - val_loss: 0.3510 - val_accuracy: 0.8837\n",
      "Epoch 23/100\n",
      "17240/17240 [==============================] - 39s 2ms/sample - loss: 0.1626 - accuracy: 0.9489 - val_loss: 0.4169 - val_accuracy: 0.8722\n",
      "CPU times: user 26min 11s, sys: 15min 49s, total: 42min\n",
      "Wall time: 15min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80e28e7710>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_spects_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       575\n",
      "           1       0.81      0.94      0.87       575\n",
      "           2       0.93      0.83      0.88       575\n",
      "           3       0.80      0.90      0.85       575\n",
      "           4       0.95      0.87      0.91       575\n",
      "           5       0.88      0.96      0.92       575\n",
      "           6       0.86      0.89      0.87       575\n",
      "           7       0.94      0.83      0.88       575\n",
      "           8       0.86      0.94      0.90       575\n",
      "           9       0.96      0.86      0.91       575\n",
      "\n",
      "    accuracy                           0.89      5750\n",
      "   macro avg       0.90      0.89      0.89      5750\n",
      "weighted avg       0.90      0.89      0.89      5750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are worse than the normal scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINO QUI - Best model\n",
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preparation.balanced_train_val_test_split(pad_recordings, labels_digits)\n",
    "X_train_digits = X[0]\n",
    "y_train_digits = y[0]\n",
    "X_val_digits = X[1]\n",
    "y_val_digits = y[1] \n",
    "X_test_digits = X[2]\n",
    "y_test_digits = y[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 310 ms, total: 23.2 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_digits])\n",
    "\n",
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digits_mfcc,\n",
    "                                                       X_val_digits_mfcc,\n",
    "                                                       X_test_digits_mfcc,\n",
    "                                                       y_train_digits,\n",
    "                                                       y_val_digits,\n",
    "                                                       y_test_digits,\n",
    "                                                       number_mode=True)\n",
    "\n",
    "X_train_digits_mfcc_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_mfcc_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_mfcc_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digits_best = np.concatenate([X_train_digits_mfcc_nn, X_val_digits_mfcc_nn])\n",
    "y_train_digits_best = np.concatenate([y_train_digits_nn, y_val_digits_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,714\n",
      "Trainable params: 148,522\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1910 samples\n",
      "Epoch 1/59\n",
      "1910/1910 [==============================] - 4s 2ms/sample - loss: 1.1927 - accuracy: 0.6225\n",
      "Epoch 2/59\n",
      "1910/1910 [==============================] - 1s 635us/sample - loss: 0.6044 - accuracy: 0.8513\n",
      "Epoch 3/59\n",
      "1910/1910 [==============================] - 1s 675us/sample - loss: 0.4636 - accuracy: 0.8880\n",
      "Epoch 4/59\n",
      "1910/1910 [==============================] - 1s 623us/sample - loss: 0.3888 - accuracy: 0.9099\n",
      "Epoch 5/59\n",
      "1910/1910 [==============================] - 1s 691us/sample - loss: 0.3222 - accuracy: 0.9267\n",
      "Epoch 6/59\n",
      "1910/1910 [==============================] - 1s 622us/sample - loss: 0.2873 - accuracy: 0.9340\n",
      "Epoch 7/59\n",
      "1910/1910 [==============================] - 1s 625us/sample - loss: 0.2444 - accuracy: 0.9529\n",
      "Epoch 8/59\n",
      "1910/1910 [==============================] - 1s 641us/sample - loss: 0.2230 - accuracy: 0.9555\n",
      "Epoch 9/59\n",
      "1910/1910 [==============================] - 1s 711us/sample - loss: 0.1985 - accuracy: 0.9602\n",
      "Epoch 10/59\n",
      "1910/1910 [==============================] - 1s 662us/sample - loss: 0.1803 - accuracy: 0.9654\n",
      "Epoch 11/59\n",
      "1910/1910 [==============================] - 1s 682us/sample - loss: 0.1752 - accuracy: 0.9670\n",
      "Epoch 12/59\n",
      "1910/1910 [==============================] - 1s 618us/sample - loss: 0.1675 - accuracy: 0.9665\n",
      "Epoch 13/59\n",
      "1910/1910 [==============================] - 1s 610us/sample - loss: 0.1548 - accuracy: 0.9702\n",
      "Epoch 14/59\n",
      "1910/1910 [==============================] - 1s 632us/sample - loss: 0.1392 - accuracy: 0.9712\n",
      "Epoch 15/59\n",
      "1910/1910 [==============================] - 1s 616us/sample - loss: 0.1180 - accuracy: 0.9822\n",
      "Epoch 16/59\n",
      "1910/1910 [==============================] - 1s 632us/sample - loss: 0.1154 - accuracy: 0.9827\n",
      "Epoch 17/59\n",
      "1910/1910 [==============================] - 1s 661us/sample - loss: 0.1055 - accuracy: 0.9822\n",
      "Epoch 18/59\n",
      "1910/1910 [==============================] - 1s 735us/sample - loss: 0.1018 - accuracy: 0.9827\n",
      "Epoch 19/59\n",
      "1910/1910 [==============================] - 1s 755us/sample - loss: 0.0990 - accuracy: 0.9843\n",
      "Epoch 20/59\n",
      "1910/1910 [==============================] - 1s 657us/sample - loss: 0.1059 - accuracy: 0.9796\n",
      "Epoch 21/59\n",
      "1910/1910 [==============================] - 1s 612us/sample - loss: 0.0885 - accuracy: 0.9874\n",
      "Epoch 22/59\n",
      "1910/1910 [==============================] - 1s 709us/sample - loss: 0.0861 - accuracy: 0.9880\n",
      "Epoch 23/59\n",
      "1910/1910 [==============================] - 1s 721us/sample - loss: 0.0861 - accuracy: 0.9874\n",
      "Epoch 24/59\n",
      "1910/1910 [==============================] - 1s 693us/sample - loss: 0.0746 - accuracy: 0.9911\n",
      "Epoch 25/59\n",
      "1910/1910 [==============================] - 1s 606us/sample - loss: 0.0841 - accuracy: 0.9859\n",
      "Epoch 26/59\n",
      "1910/1910 [==============================] - 1s 647us/sample - loss: 0.0688 - accuracy: 0.9932\n",
      "Epoch 27/59\n",
      "1910/1910 [==============================] - 1s 676us/sample - loss: 0.0761 - accuracy: 0.9864\n",
      "Epoch 28/59\n",
      "1910/1910 [==============================] - 1s 658us/sample - loss: 0.0635 - accuracy: 0.9916\n",
      "Epoch 29/59\n",
      "1910/1910 [==============================] - 1s 641us/sample - loss: 0.0659 - accuracy: 0.9942\n",
      "Epoch 30/59\n",
      "1910/1910 [==============================] - 1s 665us/sample - loss: 0.0633 - accuracy: 0.9911\n",
      "Epoch 31/59\n",
      "1910/1910 [==============================] - 1s 629us/sample - loss: 0.0559 - accuracy: 0.9911\n",
      "Epoch 32/59\n",
      "1910/1910 [==============================] - 1s 647us/sample - loss: 0.0582 - accuracy: 0.9932\n",
      "Epoch 33/59\n",
      "1910/1910 [==============================] - 1s 661us/sample - loss: 0.0645 - accuracy: 0.9921\n",
      "Epoch 34/59\n",
      "1910/1910 [==============================] - 1s 642us/sample - loss: 0.0558 - accuracy: 0.9937\n",
      "Epoch 35/59\n",
      "1910/1910 [==============================] - 1s 668us/sample - loss: 0.0578 - accuracy: 0.9932\n",
      "Epoch 36/59\n",
      "1910/1910 [==============================] - 1s 648us/sample - loss: 0.0494 - accuracy: 0.9948\n",
      "Epoch 37/59\n",
      "1910/1910 [==============================] - 1s 690us/sample - loss: 0.0543 - accuracy: 0.9932\n",
      "Epoch 38/59\n",
      "1910/1910 [==============================] - 1s 667us/sample - loss: 0.0510 - accuracy: 0.9906\n",
      "Epoch 39/59\n",
      "1910/1910 [==============================] - 1s 681us/sample - loss: 0.0517 - accuracy: 0.9937\n",
      "Epoch 40/59\n",
      "1910/1910 [==============================] - 1s 597us/sample - loss: 0.0553 - accuracy: 0.9895\n",
      "Epoch 41/59\n",
      "1910/1910 [==============================] - 1s 622us/sample - loss: 0.0433 - accuracy: 0.9963\n",
      "Epoch 42/59\n",
      "1910/1910 [==============================] - 1s 593us/sample - loss: 0.0453 - accuracy: 0.9953\n",
      "Epoch 43/59\n",
      "1910/1910 [==============================] - 1s 712us/sample - loss: 0.0438 - accuracy: 0.9948\n",
      "Epoch 44/59\n",
      "1910/1910 [==============================] - 1s 732us/sample - loss: 0.0444 - accuracy: 0.9953\n",
      "Epoch 45/59\n",
      "1910/1910 [==============================] - 1s 683us/sample - loss: 0.0408 - accuracy: 0.9958\n",
      "Epoch 46/59\n",
      "1910/1910 [==============================] - 1s 661us/sample - loss: 0.0394 - accuracy: 0.9958\n",
      "Epoch 47/59\n",
      "1910/1910 [==============================] - 1s 651us/sample - loss: 0.0328 - accuracy: 0.9990\n",
      "Epoch 48/59\n",
      "1910/1910 [==============================] - 1s 610us/sample - loss: 0.0358 - accuracy: 0.9958\n",
      "Epoch 49/59\n",
      "1910/1910 [==============================] - 1s 595us/sample - loss: 0.0428 - accuracy: 0.9937\n",
      "Epoch 50/59\n",
      "1910/1910 [==============================] - 1s 624us/sample - loss: 0.0375 - accuracy: 0.9969\n",
      "Epoch 51/59\n",
      "1910/1910 [==============================] - 1s 761us/sample - loss: 0.0312 - accuracy: 0.9984\n",
      "Epoch 52/59\n",
      "1910/1910 [==============================] - 1s 637us/sample - loss: 0.0391 - accuracy: 0.9958\n",
      "Epoch 53/59\n",
      "1910/1910 [==============================] - 1s 656us/sample - loss: 0.0382 - accuracy: 0.9953\n",
      "Epoch 54/59\n",
      "1910/1910 [==============================] - 1s 756us/sample - loss: 0.0310 - accuracy: 0.9984\n",
      "Epoch 55/59\n",
      "1910/1910 [==============================] - 1s 686us/sample - loss: 0.0344 - accuracy: 0.9963\n",
      "Epoch 56/59\n",
      "1910/1910 [==============================] - 1s 643us/sample - loss: 0.0347 - accuracy: 0.9974\n",
      "Epoch 57/59\n",
      "1910/1910 [==============================] - 1s 700us/sample - loss: 0.0372 - accuracy: 0.9953\n",
      "Epoch 58/59\n",
      "1910/1910 [==============================] - 1s 622us/sample - loss: 0.0307 - accuracy: 0.9984\n",
      "Epoch 59/59\n",
      "1910/1910 [==============================] - 1s 688us/sample - loss: 0.0317 - accuracy: 0.9974\n",
      "CPU times: user 1min 32s, sys: 28.4 s, total: 2min 1s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f808af987d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10,\n",
    "                                batch_normalisation=True)\n",
    "model.fit(X_train_digits_best, y_train_digits_best,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=59,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn = np.argmax(y_test_digits_nn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test_digits_mfcc_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        49\n",
      "           1       1.00      0.98      0.99        49\n",
      "           2       1.00      0.98      0.99        49\n",
      "           3       0.91      0.98      0.94        49\n",
      "           4       0.96      0.98      0.97        49\n",
      "           5       0.98      0.98      0.98        49\n",
      "           6       1.00      0.92      0.96        49\n",
      "           7       0.96      0.94      0.95        48\n",
      "           8       0.96      1.00      0.98        49\n",
      "           9       1.00      0.96      0.98        48\n",
      "\n",
      "    accuracy                           0.97       488\n",
      "   macro avg       0.97      0.97      0.97       488\n",
      "weighted avg       0.97      0.97      0.97       488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/digits.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speakers\n",
    "## Std - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 s, sys: 436 ms, total: 23.2 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 ms, sys: 4.42 ms, total: 18 ms\n",
      "Wall time: 22.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaler_normal = StandardScaler()\n",
    "X_train_speakers_mfcc = scaler_normal.fit_transform(X_train_speakers_mfcc)\n",
    "X_val_speakers_mfcc =  scaler_normal.transform(X_val_speakers_mfcc)\n",
    "X_test_speakers_mfcc =  scaler_normal.transform(X_test_speakers_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_speakers_mfcc, y_train_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.95      0.97        20\n",
      "      alinda       1.00      0.95      0.97        20\n",
      "        gian       0.95      1.00      0.98        20\n",
      "     jackson       1.00      0.90      0.95        20\n",
      "      khaled       0.87      1.00      0.93        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       1.00      0.90      0.95        20\n",
      "    yweweler       0.91      1.00      0.95        20\n",
      "\n",
      "    accuracy                           0.96       160\n",
      "   macro avg       0.97      0.96      0.96       160\n",
      "weighted avg       0.97      0.96      0.96       160\n",
      "\n",
      "CPU times: user 36 ms, sys: 4.06 ms, total: 40.1 ms\n",
      "Wall time: 47.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_speakers_mfcc)\n",
    "print(classification_report(y_val_speakers, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.4 s, sys: 605 ms, total: 25 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.72 ms, sys: 4.97 ms, total: 10.7 ms\n",
      "Wall time: 12.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y, input_shape, target_names= data_preparation.prepare_data_nn(X_train_speakers_mfcc, X_val_speakers_mfcc, X_test_speakers_mfcc, y_train_speakers, y_val_speakers, y_test_speakers, number_mode=False)\n",
    "\n",
    "X_train_speakers_mfcc_nn = X[0]\n",
    "y_train_speakers_nn = y[0]\n",
    "X_val_speakers_mfcc_nn = X[1]\n",
    "y_val_speakers_nn = y[1]\n",
    "X_test_speakers_mfcc_nn = X[2]\n",
    "y_test_speakers_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 148,584\n",
      "Trainable params: 148,392\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 1.7035 - accuracy: 0.4354 - val_loss: 7.4132 - val_accuracy: 0.2937\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 0s 925us/sample - loss: 0.9496 - accuracy: 0.6833 - val_loss: 5.0327 - val_accuracy: 0.3000\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 0s 849us/sample - loss: 0.7363 - accuracy: 0.7792 - val_loss: 2.5728 - val_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 0s 844us/sample - loss: 0.5739 - accuracy: 0.8354 - val_loss: 2.1201 - val_accuracy: 0.4125\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 0s 832us/sample - loss: 0.4380 - accuracy: 0.8792 - val_loss: 1.1933 - val_accuracy: 0.6625\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 0s 898us/sample - loss: 0.3818 - accuracy: 0.9167 - val_loss: 1.0840 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 0s 975us/sample - loss: 0.3359 - accuracy: 0.9062 - val_loss: 0.7490 - val_accuracy: 0.7250\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 0s 938us/sample - loss: 0.2816 - accuracy: 0.9479 - val_loss: 0.5830 - val_accuracy: 0.7688\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.2408 - accuracy: 0.9604 - val_loss: 0.5504 - val_accuracy: 0.8062\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 0s 978us/sample - loss: 0.2324 - accuracy: 0.9625 - val_loss: 0.6163 - val_accuracy: 0.7250\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 0s 953us/sample - loss: 0.2088 - accuracy: 0.9583 - val_loss: 0.3713 - val_accuracy: 0.9187\n",
      "Epoch 12/100\n",
      "480/480 [==============================] - 0s 848us/sample - loss: 0.1817 - accuracy: 0.9812 - val_loss: 0.3581 - val_accuracy: 0.8938\n",
      "Epoch 13/100\n",
      "480/480 [==============================] - 0s 889us/sample - loss: 0.1847 - accuracy: 0.9583 - val_loss: 0.3053 - val_accuracy: 0.9062\n",
      "Epoch 14/100\n",
      "480/480 [==============================] - 0s 842us/sample - loss: 0.1408 - accuracy: 0.9917 - val_loss: 0.3201 - val_accuracy: 0.9312\n",
      "Epoch 15/100\n",
      "480/480 [==============================] - 0s 901us/sample - loss: 0.1415 - accuracy: 0.9792 - val_loss: 0.3025 - val_accuracy: 0.9187\n",
      "Epoch 16/100\n",
      "480/480 [==============================] - 0s 988us/sample - loss: 0.1342 - accuracy: 0.9854 - val_loss: 0.2343 - val_accuracy: 0.9375\n",
      "Epoch 17/100\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.1292 - accuracy: 0.9833 - val_loss: 0.2233 - val_accuracy: 0.9500\n",
      "Epoch 18/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.1265 - accuracy: 0.9812 - val_loss: 0.2063 - val_accuracy: 0.9438\n",
      "Epoch 19/100\n",
      "480/480 [==============================] - 0s 907us/sample - loss: 0.0972 - accuracy: 0.9917 - val_loss: 0.2122 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "480/480 [==============================] - 0s 869us/sample - loss: 0.1145 - accuracy: 0.9896 - val_loss: 0.2167 - val_accuracy: 0.9375\n",
      "Epoch 21/100\n",
      "480/480 [==============================] - 0s 878us/sample - loss: 0.1267 - accuracy: 0.9812 - val_loss: 0.1820 - val_accuracy: 0.9563\n",
      "Epoch 22/100\n",
      "480/480 [==============================] - 0s 858us/sample - loss: 0.0982 - accuracy: 0.9875 - val_loss: 0.2148 - val_accuracy: 0.9375\n",
      "Epoch 23/100\n",
      "480/480 [==============================] - 0s 972us/sample - loss: 0.0816 - accuracy: 0.9937 - val_loss: 0.1665 - val_accuracy: 0.9500\n",
      "Epoch 24/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0902 - accuracy: 0.9917 - val_loss: 0.2127 - val_accuracy: 0.9500\n",
      "Epoch 25/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0886 - accuracy: 0.9937 - val_loss: 0.1779 - val_accuracy: 0.9500\n",
      "Epoch 26/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0858 - accuracy: 0.9937 - val_loss: 0.1925 - val_accuracy: 0.9500\n",
      "Epoch 27/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0861 - accuracy: 0.9937 - val_loss: 0.1569 - val_accuracy: 0.9500\n",
      "Epoch 28/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0672 - accuracy: 0.9979 - val_loss: 0.1464 - val_accuracy: 0.9625\n",
      "Epoch 29/100\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.0689 - accuracy: 0.9937 - val_loss: 0.1469 - val_accuracy: 0.9625\n",
      "Epoch 30/100\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.0720 - accuracy: 0.9979 - val_loss: 0.1537 - val_accuracy: 0.9625\n",
      "Epoch 31/100\n",
      "480/480 [==============================] - 0s 970us/sample - loss: 0.0676 - accuracy: 0.9937 - val_loss: 0.1791 - val_accuracy: 0.9563\n",
      "Epoch 32/100\n",
      "480/480 [==============================] - 0s 930us/sample - loss: 0.0585 - accuracy: 0.9958 - val_loss: 0.1552 - val_accuracy: 0.9563\n",
      "Epoch 33/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0596 - accuracy: 0.9937 - val_loss: 0.1439 - val_accuracy: 0.9625\n",
      "Epoch 34/100\n",
      "480/480 [==============================] - 0s 838us/sample - loss: 0.0533 - accuracy: 0.9979 - val_loss: 0.1529 - val_accuracy: 0.9625\n",
      "Epoch 35/100\n",
      "480/480 [==============================] - 0s 838us/sample - loss: 0.0601 - accuracy: 0.9958 - val_loss: 0.1697 - val_accuracy: 0.9563\n",
      "Epoch 36/100\n",
      "480/480 [==============================] - 0s 831us/sample - loss: 0.0558 - accuracy: 0.9979 - val_loss: 0.1614 - val_accuracy: 0.9500\n",
      "Epoch 37/100\n",
      "480/480 [==============================] - 0s 864us/sample - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9625\n",
      "Epoch 38/100\n",
      "480/480 [==============================] - 0s 849us/sample - loss: 0.0519 - accuracy: 0.9979 - val_loss: 0.1198 - val_accuracy: 0.9688\n",
      "Epoch 39/100\n",
      "480/480 [==============================] - 0s 831us/sample - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9625\n",
      "Epoch 40/100\n",
      "480/480 [==============================] - 0s 839us/sample - loss: 0.0523 - accuracy: 0.9958 - val_loss: 0.1476 - val_accuracy: 0.9500\n",
      "Epoch 41/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0486 - accuracy: 0.9958 - val_loss: 0.1201 - val_accuracy: 0.9750\n",
      "Epoch 42/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0463 - accuracy: 0.9979 - val_loss: 0.1516 - val_accuracy: 0.9563\n",
      "Epoch 43/100\n",
      "480/480 [==============================] - 0s 999us/sample - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9563\n",
      "Epoch 44/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9625\n",
      "Epoch 45/100\n",
      "480/480 [==============================] - 0s 935us/sample - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9563\n",
      "Epoch 46/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "480/480 [==============================] - 0s 962us/sample - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9625\n",
      "Epoch 48/100\n",
      "480/480 [==============================] - 0s 953us/sample - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9750\n",
      "Epoch 49/100\n",
      "480/480 [==============================] - 0s 843us/sample - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9688\n",
      "Epoch 50/100\n",
      "480/480 [==============================] - 0s 929us/sample - loss: 0.0433 - accuracy: 0.9979 - val_loss: 0.1320 - val_accuracy: 0.9750\n",
      "Epoch 51/100\n",
      "480/480 [==============================] - 0s 971us/sample - loss: 0.0406 - accuracy: 0.9958 - val_loss: 0.1270 - val_accuracy: 0.9688\n",
      "Epoch 52/100\n",
      "480/480 [==============================] - 0s 929us/sample - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9625\n",
      "Epoch 53/100\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9688\n",
      "Epoch 54/100\n",
      "480/480 [==============================] - 0s 849us/sample - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9750\n",
      "Epoch 55/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9625\n",
      "Epoch 56/100\n",
      "480/480 [==============================] - 0s 984us/sample - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9625\n",
      "Epoch 57/100\n",
      "480/480 [==============================] - 0s 988us/sample - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9625\n",
      "Epoch 58/100\n",
      "480/480 [==============================] - 0s 911us/sample - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9563\n",
      "Epoch 59/100\n",
      "480/480 [==============================] - 0s 771us/sample - loss: 0.0348 - accuracy: 0.9958 - val_loss: 0.1128 - val_accuracy: 0.9812\n",
      "Epoch 60/100\n",
      "480/480 [==============================] - 0s 670us/sample - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9750\n",
      "Epoch 61/100\n",
      "480/480 [==============================] - 0s 855us/sample - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9688\n",
      "Epoch 62/100\n",
      "480/480 [==============================] - 0s 928us/sample - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9625\n",
      "Epoch 63/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9625\n",
      "CPU times: user 38.7 s, sys: 18 s, total: 56.6 s\n",
      "Wall time: 33 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f809cb03110>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)\n",
    "model.fit(X_train_speakers_mfcc_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "         callbacks=[callback],\n",
    "         validation_data=(X_val_speakers_mfcc_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get full performances on val set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.95      0.97        20\n",
      "      alinda       0.91      1.00      0.95        20\n",
      "        gian       1.00      0.95      0.97        20\n",
      "     jackson       1.00      0.95      0.97        20\n",
      "      khaled       1.00      1.00      1.00        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       0.95      0.90      0.92        20\n",
      "    yweweler       0.91      1.00      0.95        20\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.97      0.97      0.97       160\n",
      "weighted avg       0.97      0.97      0.97       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent performances! Let's now see what happens with spectrograms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Std - Spects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.2 s, sys: 268 ms, total: 21.5 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_train_speakers])\n",
    "X_val_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_val_speakers])\n",
    "X_test_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speakers_spects.shape\n",
    "X_train_speakers_spects_2d = X_train_speakers_spects.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_speakers_spects.shape\n",
    "X_val_speakers_spects_2d = X_val_speakers_spects.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_test_speakers_spects.shape\n",
    "X_test_speakers_spects_2d = X_test_speakers_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_speakers_spects_2d, y_train_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      0.95      0.95        20\n",
      "      alinda       1.00      0.95      0.97        20\n",
      "        gian       0.95      1.00      0.98        20\n",
      "     jackson       1.00      0.95      0.97        20\n",
      "      khaled       1.00      1.00      1.00        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       0.91      1.00      0.95        20\n",
      "    yweweler       0.95      0.90      0.92        20\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.97      0.97      0.97       160\n",
      "weighted avg       0.97      0.97      0.97       160\n",
      "\n",
      "CPU times: user 174 ms, sys: 12.1 ms, total: 186 ms\n",
      "Wall time: 213 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_speakers_spects_2d)\n",
    "print(classification_report(y_val_speakers, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances are at the level of MFCC\n",
    "### CNN - Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 419 ms, total: 19.3 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_train_speakers])\n",
    "X_val_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_val_speakers])\n",
    "X_test_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.9 ms, sys: 30 ms, total: 66.9 ms\n",
      "Wall time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speakers_spects, X_val_speakers_spects, X_test_speakers_spects, y_train_speakers, y_val_speakers, y_test_speakers, number_mode=False)\n",
    "\n",
    "X_train_speakers_spects_nn = X[0]\n",
    "y_train_speakers_nn = y[0]\n",
    "X_val_speakers_spects_nn = X[1]\n",
    "y_val_speakers_nn = y[1]\n",
    "X_test_speakers_spects_nn = X[2]\n",
    "y_test_speakers_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 67,744\n",
      "Trainable params: 67,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 2.0949 - accuracy: 0.1375 - val_loss: 2.0753 - val_accuracy: 0.1625\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0656 - accuracy: 0.1813 - val_loss: 2.0556 - val_accuracy: 0.1813\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0583 - accuracy: 0.1854 - val_loss: 2.0388 - val_accuracy: 0.2625\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0301 - accuracy: 0.2104 - val_loss: 2.0082 - val_accuracy: 0.2750\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0103 - accuracy: 0.2229 - val_loss: 1.9800 - val_accuracy: 0.3000\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.9888 - accuracy: 0.2354 - val_loss: 1.9532 - val_accuracy: 0.3250\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.9742 - accuracy: 0.2500 - val_loss: 1.9261 - val_accuracy: 0.3313\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.9568 - accuracy: 0.2521 - val_loss: 1.8923 - val_accuracy: 0.3063\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.9293 - accuracy: 0.2771 - val_loss: 1.8848 - val_accuracy: 0.3438\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8964 - accuracy: 0.2875 - val_loss: 1.8311 - val_accuracy: 0.3562\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8657 - accuracy: 0.3167 - val_loss: 1.7885 - val_accuracy: 0.3125\n",
      "Epoch 12/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8599 - accuracy: 0.2979 - val_loss: 1.7715 - val_accuracy: 0.2812\n",
      "Epoch 13/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8311 - accuracy: 0.3021 - val_loss: 1.7212 - val_accuracy: 0.3562\n",
      "Epoch 14/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7699 - accuracy: 0.3500 - val_loss: 1.6921 - val_accuracy: 0.3812\n",
      "Epoch 15/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7749 - accuracy: 0.3292 - val_loss: 1.6542 - val_accuracy: 0.4563\n",
      "Epoch 16/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.7363 - accuracy: 0.3500 - val_loss: 1.5937 - val_accuracy: 0.4375\n",
      "Epoch 17/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.7170 - accuracy: 0.3396 - val_loss: 1.6041 - val_accuracy: 0.3750\n",
      "Epoch 18/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.6423 - accuracy: 0.3500 - val_loss: 1.5201 - val_accuracy: 0.4187\n",
      "Epoch 19/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.6158 - accuracy: 0.4167 - val_loss: 1.4561 - val_accuracy: 0.4750\n",
      "Epoch 20/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.6146 - accuracy: 0.3854 - val_loss: 1.4502 - val_accuracy: 0.5437\n",
      "Epoch 21/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5354 - accuracy: 0.4458 - val_loss: 1.4311 - val_accuracy: 0.5312\n",
      "Epoch 22/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5515 - accuracy: 0.4000 - val_loss: 1.3461 - val_accuracy: 0.5625\n",
      "Epoch 23/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.4465 - accuracy: 0.4688 - val_loss: 1.2947 - val_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.4848 - accuracy: 0.4479 - val_loss: 1.4100 - val_accuracy: 0.4563\n",
      "Epoch 25/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.4432 - accuracy: 0.4604 - val_loss: 1.2158 - val_accuracy: 0.6375\n",
      "Epoch 26/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3280 - accuracy: 0.4771 - val_loss: 1.1784 - val_accuracy: 0.5688\n",
      "Epoch 27/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3817 - accuracy: 0.4938 - val_loss: 1.1510 - val_accuracy: 0.5938\n",
      "Epoch 28/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3484 - accuracy: 0.5333 - val_loss: 1.1502 - val_accuracy: 0.5938\n",
      "Epoch 29/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.2710 - accuracy: 0.5021 - val_loss: 1.0692 - val_accuracy: 0.6750\n",
      "Epoch 30/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.2759 - accuracy: 0.5229 - val_loss: 1.0428 - val_accuracy: 0.6687\n",
      "Epoch 31/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.2580 - accuracy: 0.5333 - val_loss: 1.0539 - val_accuracy: 0.6375\n",
      "Epoch 32/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1921 - accuracy: 0.5396 - val_loss: 0.9901 - val_accuracy: 0.6750\n",
      "Epoch 33/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1801 - accuracy: 0.5375 - val_loss: 1.0574 - val_accuracy: 0.6375\n",
      "Epoch 34/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1792 - accuracy: 0.5562 - val_loss: 0.9437 - val_accuracy: 0.6875\n",
      "Epoch 35/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0748 - accuracy: 0.6021 - val_loss: 0.8693 - val_accuracy: 0.7375\n",
      "Epoch 36/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1853 - accuracy: 0.5312 - val_loss: 0.9523 - val_accuracy: 0.6938\n",
      "Epoch 37/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0502 - accuracy: 0.6187 - val_loss: 0.8490 - val_accuracy: 0.7250\n",
      "Epoch 38/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9907 - accuracy: 0.6562 - val_loss: 0.7589 - val_accuracy: 0.7688\n",
      "Epoch 39/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1564 - accuracy: 0.5604 - val_loss: 0.7930 - val_accuracy: 0.8125\n",
      "Epoch 40/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9768 - accuracy: 0.6521 - val_loss: 1.2003 - val_accuracy: 0.5188\n",
      "Epoch 41/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.9990 - accuracy: 0.6250 - val_loss: 0.7845 - val_accuracy: 0.7563\n",
      "Epoch 42/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.9262 - accuracy: 0.6521 - val_loss: 0.9605 - val_accuracy: 0.6187\n",
      "Epoch 43/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.9768 - accuracy: 0.6604 - val_loss: 0.6623 - val_accuracy: 0.8375\n",
      "Epoch 44/100\n",
      "480/480 [==============================] - 2s 5ms/sample - loss: 0.9494 - accuracy: 0.6333 - val_loss: 0.6577 - val_accuracy: 0.8188\n",
      "Epoch 45/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.8698 - accuracy: 0.6875 - val_loss: 0.6350 - val_accuracy: 0.8062\n",
      "Epoch 46/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.8445 - accuracy: 0.6687 - val_loss: 0.6008 - val_accuracy: 0.8125\n",
      "Epoch 47/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.8353 - accuracy: 0.6667 - val_loss: 0.5736 - val_accuracy: 0.8375\n",
      "Epoch 48/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.7634 - accuracy: 0.7146 - val_loss: 0.5692 - val_accuracy: 0.8313\n",
      "Epoch 49/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.7898 - accuracy: 0.7146 - val_loss: 0.5588 - val_accuracy: 0.8125\n",
      "Epoch 50/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.7851 - accuracy: 0.7229 - val_loss: 0.5374 - val_accuracy: 0.8562\n",
      "Epoch 51/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.8087 - accuracy: 0.6979 - val_loss: 0.5684 - val_accuracy: 0.8313\n",
      "Epoch 52/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.7289 - accuracy: 0.7208 - val_loss: 0.5039 - val_accuracy: 0.8313\n",
      "Epoch 53/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.7330 - accuracy: 0.7312 - val_loss: 0.5060 - val_accuracy: 0.8687\n",
      "Epoch 54/100\n",
      "480/480 [==============================] - 2s 5ms/sample - loss: 0.6808 - accuracy: 0.7458 - val_loss: 0.4619 - val_accuracy: 0.8313\n",
      "Epoch 55/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.6734 - accuracy: 0.7437 - val_loss: 0.5265 - val_accuracy: 0.8250\n",
      "Epoch 56/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.7100 - accuracy: 0.7458 - val_loss: 0.4521 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.5930 - accuracy: 0.7875 - val_loss: 0.5017 - val_accuracy: 0.8562\n",
      "Epoch 58/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.6695 - accuracy: 0.7542 - val_loss: 1.0109 - val_accuracy: 0.6750\n",
      "Epoch 59/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.6226 - accuracy: 0.7917 - val_loss: 0.4252 - val_accuracy: 0.8625\n",
      "Epoch 60/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.6335 - accuracy: 0.7729 - val_loss: 0.4650 - val_accuracy: 0.8438\n",
      "Epoch 61/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.6084 - accuracy: 0.7750 - val_loss: 0.4296 - val_accuracy: 0.8500\n",
      "Epoch 62/100\n",
      "480/480 [==============================] - 2s 5ms/sample - loss: 0.5683 - accuracy: 0.8000 - val_loss: 0.4670 - val_accuracy: 0.8625\n",
      "Epoch 63/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.5348 - accuracy: 0.7979 - val_loss: 0.5307 - val_accuracy: 0.7875\n",
      "Epoch 64/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.6927 - accuracy: 0.7500 - val_loss: 0.3891 - val_accuracy: 0.8875\n",
      "Epoch 65/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.5108 - accuracy: 0.8354 - val_loss: 0.6223 - val_accuracy: 0.8125\n",
      "Epoch 66/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.5195 - accuracy: 0.8208 - val_loss: 0.4055 - val_accuracy: 0.8250\n",
      "Epoch 67/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4741 - accuracy: 0.8042 - val_loss: 0.3421 - val_accuracy: 0.8750\n",
      "Epoch 68/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.5393 - accuracy: 0.7896 - val_loss: 0.4341 - val_accuracy: 0.8313\n",
      "Epoch 69/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.5408 - accuracy: 0.8250 - val_loss: 1.3897 - val_accuracy: 0.5938\n",
      "Epoch 70/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.6028 - accuracy: 0.7937 - val_loss: 0.3073 - val_accuracy: 0.9062\n",
      "Epoch 71/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4285 - accuracy: 0.8375 - val_loss: 0.2759 - val_accuracy: 0.9250\n",
      "Epoch 72/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4214 - accuracy: 0.8521 - val_loss: 0.2891 - val_accuracy: 0.9062\n",
      "Epoch 73/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4224 - accuracy: 0.8583 - val_loss: 0.3973 - val_accuracy: 0.8438\n",
      "Epoch 74/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4285 - accuracy: 0.8521 - val_loss: 0.4612 - val_accuracy: 0.8250\n",
      "Epoch 75/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4119 - accuracy: 0.8500 - val_loss: 0.3401 - val_accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4170 - accuracy: 0.8438 - val_loss: 0.2620 - val_accuracy: 0.9250\n",
      "Epoch 77/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3584 - accuracy: 0.8708 - val_loss: 0.2753 - val_accuracy: 0.9125\n",
      "Epoch 78/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3635 - accuracy: 0.8833 - val_loss: 0.2634 - val_accuracy: 0.9375\n",
      "Epoch 79/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3553 - accuracy: 0.8792 - val_loss: 0.3028 - val_accuracy: 0.9125\n",
      "Epoch 80/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4229 - accuracy: 0.8458 - val_loss: 0.2712 - val_accuracy: 0.9187\n",
      "Epoch 81/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4115 - accuracy: 0.8375 - val_loss: 0.2503 - val_accuracy: 0.9187\n",
      "Epoch 82/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3555 - accuracy: 0.8854 - val_loss: 0.2605 - val_accuracy: 0.9125\n",
      "Epoch 83/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3463 - accuracy: 0.8771 - val_loss: 0.2141 - val_accuracy: 0.9438\n",
      "Epoch 84/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3317 - accuracy: 0.8708 - val_loss: 0.2170 - val_accuracy: 0.9438\n",
      "Epoch 85/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3227 - accuracy: 0.8854 - val_loss: 0.2202 - val_accuracy: 0.9438\n",
      "Epoch 86/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.3033 - accuracy: 0.9104 - val_loss: 0.1999 - val_accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2823 - accuracy: 0.8979 - val_loss: 0.2181 - val_accuracy: 0.9250\n",
      "Epoch 88/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3041 - accuracy: 0.8875 - val_loss: 0.1793 - val_accuracy: 0.9625\n",
      "Epoch 89/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3330 - accuracy: 0.8687 - val_loss: 0.2104 - val_accuracy: 0.9250\n",
      "Epoch 90/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2788 - accuracy: 0.9042 - val_loss: 0.2307 - val_accuracy: 0.9125\n",
      "Epoch 91/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2602 - accuracy: 0.9146 - val_loss: 0.1847 - val_accuracy: 0.9688\n",
      "Epoch 92/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2775 - accuracy: 0.8958 - val_loss: 0.1953 - val_accuracy: 0.9375\n",
      "Epoch 93/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2812 - accuracy: 0.9021 - val_loss: 0.1794 - val_accuracy: 0.9312\n",
      "Epoch 94/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2570 - accuracy: 0.9104 - val_loss: 0.2150 - val_accuracy: 0.9500\n",
      "Epoch 95/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2660 - accuracy: 0.8938 - val_loss: 0.2102 - val_accuracy: 0.9312\n",
      "Epoch 96/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2776 - accuracy: 0.8938 - val_loss: 0.2011 - val_accuracy: 0.9563\n",
      "Epoch 97/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2209 - accuracy: 0.9396 - val_loss: 0.1951 - val_accuracy: 0.9312\n",
      "Epoch 98/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3201 - accuracy: 0.9000 - val_loss: 0.1995 - val_accuracy: 0.9312\n",
      "CPU times: user 3min 7s, sys: 1min 29s, total: 4min 36s\n",
      "Wall time: 2min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80a3048450>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      1.00      1.00        20\n",
      "      alinda       1.00      0.95      0.98        21\n",
      "        gian       1.00      1.00      1.00        20\n",
      "     jackson       1.00      0.91      0.95        22\n",
      "      khaled       1.00      0.95      0.98        21\n",
      "     nicolas       0.85      1.00      0.92        17\n",
      "        theo       1.00      0.91      0.95        22\n",
      "    yweweler       0.85      1.00      0.92        17\n",
      "\n",
      "    accuracy                           0.96       160\n",
      "   macro avg       0.96      0.97      0.96       160\n",
      "weighted avg       0.97      0.96      0.96       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with the Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "480/480 [==============================] - 5s 10ms/sample - loss: 2.2696 - accuracy: 0.2208 - val_loss: 2.0117 - val_accuracy: 0.1375\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8373 - accuracy: 0.3562 - val_loss: 1.9834 - val_accuracy: 0.2750\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5934 - accuracy: 0.4313 - val_loss: 1.9903 - val_accuracy: 0.2562\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.4045 - accuracy: 0.4812 - val_loss: 2.1136 - val_accuracy: 0.1437\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.2342 - accuracy: 0.5521 - val_loss: 2.0679 - val_accuracy: 0.1688\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0244 - accuracy: 0.6958 - val_loss: 2.1188 - val_accuracy: 0.1437\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9932 - accuracy: 0.6917 - val_loss: 2.1358 - val_accuracy: 0.1437\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9020 - accuracy: 0.7250 - val_loss: 2.1982 - val_accuracy: 0.1437\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7526 - accuracy: 0.7917 - val_loss: 2.2969 - val_accuracy: 0.1312\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7425 - accuracy: 0.8000 - val_loss: 2.2651 - val_accuracy: 0.1500\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.6572 - accuracy: 0.8000 - val_loss: 2.1781 - val_accuracy: 0.1500\n",
      "Epoch 12/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.6547 - accuracy: 0.7917 - val_loss: 2.2560 - val_accuracy: 0.1500\n",
      "CPU times: user 28.4 s, sys: 16.9 s, total: 45.3 s\n",
      "Wall time: 20.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80afdf06d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.20      0.67      0.31         6\n",
      "      alinda       0.00      0.00      0.00         0\n",
      "        gian       0.35      0.15      0.21        48\n",
      "     jackson       0.55      0.48      0.51        23\n",
      "      khaled       0.25      0.26      0.26        19\n",
      "     nicolas       0.75      0.26      0.39        57\n",
      "        theo       0.10      1.00      0.18         2\n",
      "    yweweler       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.28       160\n",
      "   macro avg       0.28      0.35      0.23       160\n",
      "weighted avg       0.49      0.28      0.32       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 s, sys: 324 ms, total: 18.8 s\n",
      "Wall time: 9.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_train_speakers])\n",
    "X_val_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_val_speakers])\n",
    "X_test_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 127, 56, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 127, 56, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 63, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                3612736   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 3,613,800\n",
      "Trainable params: 3,613,608\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "480/480 [==============================] - 5s 10ms/sample - loss: 0.9840 - accuracy: 0.6833 - val_loss: 1.5258 - val_accuracy: 0.5562\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.3371 - accuracy: 0.9250 - val_loss: 1.5544 - val_accuracy: 0.5250\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.2070 - accuracy: 0.9604 - val_loss: 1.6564 - val_accuracy: 0.4938\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.1224 - accuracy: 0.9854 - val_loss: 1.7890 - val_accuracy: 0.4812\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0905 - accuracy: 0.9979 - val_loss: 1.7965 - val_accuracy: 0.4500\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0871 - accuracy: 0.9854 - val_loss: 1.8569 - val_accuracy: 0.4437\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0546 - accuracy: 1.0000 - val_loss: 1.8503 - val_accuracy: 0.4375\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.8297 - val_accuracy: 0.4187\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0470 - accuracy: 0.9979 - val_loss: 1.8310 - val_accuracy: 0.3875\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0412 - accuracy: 1.0000 - val_loss: 1.7744 - val_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0360 - accuracy: 0.9979 - val_loss: 1.7461 - val_accuracy: 0.4125\n",
      "CPU times: user 1min 12s, sys: 14.9 s, total: 1min 27s\n",
      "Wall time: 34.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80a0b70290>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      0.95      0.95        20\n",
      "      alinda       0.95      1.00      0.97        19\n",
      "        gian       0.55      0.92      0.69        12\n",
      "     jackson       0.55      1.00      0.71        11\n",
      "      khaled       1.00      0.22      0.37        89\n",
      "     nicolas       0.00      0.00      0.00         0\n",
      "        theo       0.45      1.00      0.62         9\n",
      "    yweweler       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56       160\n",
      "   macro avg       0.56      0.64      0.54       160\n",
      "weighted avg       0.89      0.56      0.57       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_preparation' from '/Users/kappa/repositories/dsim_project/Audio/data_preparation.py'>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(data_preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "9014 9014 2254 2254 120 120\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "2464 2464 616 616 120 120\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n",
      "CPU times: user 2min 22s, sys: 4.7 s, total: 2min 27s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                                                    y_type= ['speakers_default', 'speakers_us'],\n",
    "                                                    n_category_test=30,\n",
    "                                                    include_pitch=False,\n",
    "                                                    max_length=max_track_length,\n",
    "                                                    recordings_source=[False, True],\n",
    "                                                    transform_function=\"mfcc\")\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 193\n",
      "ale\n",
      "alinda\n",
      "gian\n",
      "jackson\n",
      "khaled\n",
      "nicolas\n",
      "theo\n",
      "yweweler\n",
      "CPU times: user 29.1 ms, sys: 14.2 ms, total: 43.3 ms\n",
      "Wall time: 45.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_speaker, X_val_speaker]),\n",
    "                         np.concatenate([y_train_speaker, y_val_speaker]))\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4616, 20, 18)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_speaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal = StandardScaler()\n",
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_scaled = scaler_normal.fit_transform(X_train_speaker.reshape((nsamples, nx * ny)))\n",
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_scaled =  scaler_normal.transform(X_val_speaker.reshape((nsamples, nx * ny)))\n",
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_scaled =  scaler_normal.transform(X_test_speaker.reshape((nsamples, nx * ny)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.38 s, sys: 31.4 ms, total: 4.41 s\n",
      "Wall time: 4.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker_normal.fit(X_train_speaker_scaled, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      0.98      0.97       186\n",
      "      alinda       0.92      0.98      0.95       182\n",
      "        gian       0.98      0.94      0.96       202\n",
      "     jackson       0.94      0.98      0.96       184\n",
      "      khaled       0.98      0.84      0.90       225\n",
      "     nicolas       0.96      0.97      0.97       191\n",
      "        theo       0.87      0.87      0.87       193\n",
      "    yweweler       0.86      0.92      0.89       181\n",
      "\n",
      "    accuracy                           0.93      1544\n",
      "   macro avg       0.93      0.94      0.93      1544\n",
      "weighted avg       0.93      0.93      0.93      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_speaker_normal.predict(X_val_speaker_scaled)\n",
    "print(classification_report(y_pred, y_val_speaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speaker, X_val_speaker, X_test_speaker, y_train_speaker, y_val_speaker, y_test_speaker, number_mode=False)\n",
    "\n",
    "X_train_speaker_nn = X[0]\n",
    "y_train_speaker_nn = y[0]\n",
    "X_val_speaker_nn = X[1]\n",
    "y_val_speaker_nn = y[1]\n",
    "X_test_speaker_nn = X[2]\n",
    "y_test_speaker_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 148,584\n",
      "Trainable params: 148,392\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4616 samples, validate on 1544 samples\n",
      "Epoch 1/100\n",
      "4616/4616 [==============================] - 7s 1ms/sample - loss: 1.0513 - accuracy: 0.6438 - val_loss: 1.3305 - val_accuracy: 0.5933\n",
      "Epoch 2/100\n",
      "4616/4616 [==============================] - 4s 772us/sample - loss: 0.5905 - accuracy: 0.8122 - val_loss: 0.5647 - val_accuracy: 0.7876\n",
      "Epoch 3/100\n",
      "4616/4616 [==============================] - 4s 889us/sample - loss: 0.4508 - accuracy: 0.8674 - val_loss: 0.5145 - val_accuracy: 0.8187\n",
      "Epoch 4/100\n",
      "4616/4616 [==============================] - 4s 800us/sample - loss: 0.3951 - accuracy: 0.8752 - val_loss: 0.3632 - val_accuracy: 0.8841\n",
      "Epoch 5/100\n",
      "4616/4616 [==============================] - 3s 747us/sample - loss: 0.3530 - accuracy: 0.8943 - val_loss: 0.5922 - val_accuracy: 0.7843\n",
      "Epoch 6/100\n",
      "4616/4616 [==============================] - 4s 815us/sample - loss: 0.3404 - accuracy: 0.8999 - val_loss: 0.3622 - val_accuracy: 0.8724\n",
      "Epoch 7/100\n",
      "4616/4616 [==============================] - 4s 831us/sample - loss: 0.3125 - accuracy: 0.9097 - val_loss: 0.3791 - val_accuracy: 0.8601\n",
      "Epoch 8/100\n",
      "4616/4616 [==============================] - 4s 762us/sample - loss: 0.2759 - accuracy: 0.9201 - val_loss: 0.2698 - val_accuracy: 0.9190\n",
      "Epoch 9/100\n",
      "4616/4616 [==============================] - 4s 793us/sample - loss: 0.2770 - accuracy: 0.9227 - val_loss: 0.2959 - val_accuracy: 0.8990\n",
      "Epoch 10/100\n",
      "4616/4616 [==============================] - 3s 671us/sample - loss: 0.2605 - accuracy: 0.9235 - val_loss: 0.2853 - val_accuracy: 0.9061\n",
      "Epoch 11/100\n",
      "4616/4616 [==============================] - 3s 719us/sample - loss: 0.2306 - accuracy: 0.9339 - val_loss: 0.2321 - val_accuracy: 0.9333\n",
      "Epoch 12/100\n",
      "4616/4616 [==============================] - 3s 724us/sample - loss: 0.2366 - accuracy: 0.9279 - val_loss: 0.2542 - val_accuracy: 0.9165\n",
      "Epoch 13/100\n",
      "4616/4616 [==============================] - 3s 686us/sample - loss: 0.2185 - accuracy: 0.9335 - val_loss: 0.2782 - val_accuracy: 0.9093\n",
      "Epoch 14/100\n",
      "4616/4616 [==============================] - 3s 694us/sample - loss: 0.2101 - accuracy: 0.9372 - val_loss: 0.2286 - val_accuracy: 0.9268\n",
      "Epoch 15/100\n",
      "4616/4616 [==============================] - 3s 683us/sample - loss: 0.1918 - accuracy: 0.9428 - val_loss: 0.2287 - val_accuracy: 0.9262\n",
      "Epoch 16/100\n",
      "4616/4616 [==============================] - 3s 713us/sample - loss: 0.1868 - accuracy: 0.9448 - val_loss: 0.2225 - val_accuracy: 0.9210\n",
      "Epoch 17/100\n",
      "4616/4616 [==============================] - 3s 730us/sample - loss: 0.1842 - accuracy: 0.9430 - val_loss: 0.1997 - val_accuracy: 0.9294\n",
      "Epoch 18/100\n",
      "4616/4616 [==============================] - 3s 751us/sample - loss: 0.1724 - accuracy: 0.9484 - val_loss: 0.1672 - val_accuracy: 0.9508\n",
      "Epoch 19/100\n",
      "4616/4616 [==============================] - 4s 841us/sample - loss: 0.1644 - accuracy: 0.9534 - val_loss: 0.2130 - val_accuracy: 0.9262\n",
      "Epoch 20/100\n",
      "4616/4616 [==============================] - 4s 776us/sample - loss: 0.1771 - accuracy: 0.9482 - val_loss: 0.2084 - val_accuracy: 0.9275\n",
      "Epoch 21/100\n",
      "4616/4616 [==============================] - 3s 682us/sample - loss: 0.1696 - accuracy: 0.9448 - val_loss: 0.1978 - val_accuracy: 0.9313\n",
      "Epoch 22/100\n",
      "4616/4616 [==============================] - 3s 669us/sample - loss: 0.1535 - accuracy: 0.9539 - val_loss: 0.2690 - val_accuracy: 0.9041\n",
      "Epoch 23/100\n",
      "4616/4616 [==============================] - 3s 665us/sample - loss: 0.1500 - accuracy: 0.9528 - val_loss: 0.2707 - val_accuracy: 0.9054\n",
      "Epoch 24/100\n",
      "4616/4616 [==============================] - 3s 685us/sample - loss: 0.1449 - accuracy: 0.9513 - val_loss: 0.1843 - val_accuracy: 0.9411\n",
      "Epoch 25/100\n",
      "4616/4616 [==============================] - 3s 698us/sample - loss: 0.1571 - accuracy: 0.9558 - val_loss: 0.2585 - val_accuracy: 0.9035\n",
      "Epoch 26/100\n",
      "4616/4616 [==============================] - 6s 1ms/sample - loss: 0.1418 - accuracy: 0.9593 - val_loss: 0.1753 - val_accuracy: 0.9404\n",
      "Epoch 27/100\n",
      "4616/4616 [==============================] - 12s 3ms/sample - loss: 0.1400 - accuracy: 0.9597 - val_loss: 0.1611 - val_accuracy: 0.9482\n",
      "Epoch 28/100\n",
      "4616/4616 [==============================] - 7s 2ms/sample - loss: 0.1436 - accuracy: 0.9582 - val_loss: 0.6525 - val_accuracy: 0.7830\n",
      "Epoch 29/100\n",
      "4616/4616 [==============================] - 5s 1ms/sample - loss: 0.1442 - accuracy: 0.9558 - val_loss: 0.2439 - val_accuracy: 0.9100\n",
      "Epoch 30/100\n",
      "4616/4616 [==============================] - 6s 1ms/sample - loss: 0.1359 - accuracy: 0.9595 - val_loss: 0.1957 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "4616/4616 [==============================] - 9s 2ms/sample - loss: 0.1420 - accuracy: 0.9597 - val_loss: 0.1866 - val_accuracy: 0.9281\n",
      "Epoch 32/100\n",
      "4616/4616 [==============================] - 7s 2ms/sample - loss: 0.1309 - accuracy: 0.9588 - val_loss: 0.2090 - val_accuracy: 0.9210\n",
      "Epoch 33/100\n",
      "4616/4616 [==============================] - 13s 3ms/sample - loss: 0.1343 - accuracy: 0.9558 - val_loss: 0.5710 - val_accuracy: 0.8219\n",
      "Epoch 34/100\n",
      "4616/4616 [==============================] - 9s 2ms/sample - loss: 0.1375 - accuracy: 0.9560 - val_loss: 0.5352 - val_accuracy: 0.8199\n",
      "Epoch 35/100\n",
      "4616/4616 [==============================] - 4s 939us/sample - loss: 0.1235 - accuracy: 0.9606 - val_loss: 0.1672 - val_accuracy: 0.9469\n",
      "Epoch 36/100\n",
      "4616/4616 [==============================] - 7s 1ms/sample - loss: 0.1299 - accuracy: 0.9591 - val_loss: 0.2369 - val_accuracy: 0.9028\n",
      "Epoch 37/100\n",
      "4616/4616 [==============================] - 5s 997us/sample - loss: 0.1148 - accuracy: 0.9632 - val_loss: 0.2931 - val_accuracy: 0.9003\n",
      "CPU times: user 2min 57s, sys: 1min 6s, total: 4min 3s\n",
      "Wall time: 2min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80bf3a74d0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker_nn, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker_nn, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      0.99      0.97       193\n",
      "      alinda       0.96      0.95      0.96       193\n",
      "        gian       0.96      0.93      0.94       193\n",
      "     jackson       0.98      0.99      0.99       193\n",
      "      khaled       0.97      0.99      0.98       193\n",
      "     nicolas       0.97      0.98      0.97       193\n",
      "        theo       0.89      0.87      0.88       193\n",
      "    yweweler       0.90      0.89      0.89       193\n",
      "\n",
      "    accuracy                           0.95      1544\n",
      "   macro avg       0.95      0.95      0.95      1544\n",
      "weighted avg       0.95      0.95      0.95      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - Spects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n",
      "CPU times: user 2min 30s, sys: 6.25 s, total: 2min 36s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                                                    y_type= ['speakers_default', 'speakers_us'],\n",
    "                                                    n_category_test=30,\n",
    "                                                    include_pitch=False,\n",
    "                                                    max_length=max_track_length,\n",
    "                                                    recordings_source=[False, True],\n",
    "                                                    transform_function=\"spectrogram\")\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 193\n",
      "ale\n",
      "alinda\n",
      "gian\n",
      "jackson\n",
      "khaled\n",
      "nicolas\n",
      "theo\n",
      "yweweler\n"
     ]
    }
   ],
   "source": [
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_speaker, X_val_speaker]),\n",
    "                                                 np.concatenate([y_train_speaker, y_val_speaker]))\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_2d = X_train_speaker.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_2d = X_val_speaker.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_2d = X_test_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 136 ms, total: 21.7 s\n",
      "Wall time: 23.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker.fit(X_train_speaker_2d, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.99      0.99      0.99       192\n",
      "      alinda       0.99      0.99      0.99       193\n",
      "        gian       0.99      0.99      0.99       193\n",
      "     jackson       0.99      0.99      0.99       193\n",
      "      khaled       1.00      0.97      0.99       198\n",
      "     nicolas       0.99      0.99      0.99       193\n",
      "        theo       0.83      0.88      0.86       182\n",
      "    yweweler       0.91      0.88      0.89       200\n",
      "\n",
      "    accuracy                           0.96      1544\n",
      "   macro avg       0.96      0.96      0.96      1544\n",
      "weighted avg       0.96      0.96      0.96      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_speaker.predict(X_val_speaker_2d)\n",
    "print(classification_report(y_pred, y_val_speaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speaker,\n",
    "                                                                   X_val_speaker,\n",
    "                                                                   X_test_speaker,\n",
    "                                                                   y_train_speaker,\n",
    "                                                                   y_val_speaker,\n",
    "                                                                   y_test_speaker,\n",
    "                                                                   number_mode=False)\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker_nn = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker_nn = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4616, 128, 18, 1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_speaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 127, 17, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 1,033,320\n",
      "Trainable params: 1,033,128\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4616 samples, validate on 1544 samples\n",
      "Epoch 1/100\n",
      "4616/4616 [==============================] - 14s 3ms/sample - loss: 0.6214 - accuracy: 0.8026 - val_loss: 1.3185 - val_accuracy: 0.5136\n",
      "Epoch 2/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.2292 - accuracy: 0.9350 - val_loss: 0.6883 - val_accuracy: 0.7992\n",
      "Epoch 3/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.1564 - accuracy: 0.9617 - val_loss: 0.3639 - val_accuracy: 0.9041\n",
      "Epoch 4/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.1239 - accuracy: 0.9716 - val_loss: 0.1871 - val_accuracy: 0.9469\n",
      "Epoch 5/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.1076 - accuracy: 0.9740 - val_loss: 0.0959 - val_accuracy: 0.9767\n",
      "Epoch 6/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0893 - accuracy: 0.9805 - val_loss: 0.0754 - val_accuracy: 0.9825\n",
      "Epoch 7/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0730 - accuracy: 0.9853 - val_loss: 0.2315 - val_accuracy: 0.9288\n",
      "Epoch 8/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0666 - accuracy: 0.9864 - val_loss: 0.1643 - val_accuracy: 0.9488\n",
      "Epoch 9/100\n",
      "4616/4616 [==============================] - 13s 3ms/sample - loss: 0.0627 - accuracy: 0.9872 - val_loss: 0.1764 - val_accuracy: 0.9404\n",
      "Epoch 10/100\n",
      "4616/4616 [==============================] - 13s 3ms/sample - loss: 0.0577 - accuracy: 0.9885 - val_loss: 0.0896 - val_accuracy: 0.9657\n",
      "Epoch 11/100\n",
      "4616/4616 [==============================] - 13s 3ms/sample - loss: 0.0432 - accuracy: 0.9937 - val_loss: 0.0545 - val_accuracy: 0.9858\n",
      "Epoch 12/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0350 - accuracy: 0.9957 - val_loss: 0.0650 - val_accuracy: 0.9812\n",
      "Epoch 13/100\n",
      "4616/4616 [==============================] - 12s 3ms/sample - loss: 0.0323 - accuracy: 0.9955 - val_loss: 0.0446 - val_accuracy: 0.9870\n",
      "Epoch 14/100\n",
      "4616/4616 [==============================] - 12s 3ms/sample - loss: 0.0310 - accuracy: 0.9959 - val_loss: 0.2054 - val_accuracy: 0.9365\n",
      "Epoch 15/100\n",
      "4616/4616 [==============================] - 12s 2ms/sample - loss: 0.0309 - accuracy: 0.9948 - val_loss: 0.1492 - val_accuracy: 0.9482\n",
      "Epoch 16/100\n",
      "4616/4616 [==============================] - 12s 3ms/sample - loss: 0.0274 - accuracy: 0.9968 - val_loss: 0.0647 - val_accuracy: 0.9760\n",
      "Epoch 17/100\n",
      "4616/4616 [==============================] - 12s 3ms/sample - loss: 0.0299 - accuracy: 0.9963 - val_loss: 0.0449 - val_accuracy: 0.9890\n",
      "Epoch 18/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0260 - accuracy: 0.9965 - val_loss: 0.0975 - val_accuracy: 0.9663\n",
      "Epoch 19/100\n",
      "4616/4616 [==============================] - 12s 3ms/sample - loss: 0.0256 - accuracy: 0.9965 - val_loss: 0.0774 - val_accuracy: 0.9767\n",
      "Epoch 20/100\n",
      "4616/4616 [==============================] - 13s 3ms/sample - loss: 0.0252 - accuracy: 0.9972 - val_loss: 0.0487 - val_accuracy: 0.9858\n",
      "Epoch 21/100\n",
      "4616/4616 [==============================] - 12s 3ms/sample - loss: 0.0230 - accuracy: 0.9974 - val_loss: 0.0533 - val_accuracy: 0.9877\n",
      "Epoch 22/100\n",
      "4616/4616 [==============================] - 12s 3ms/sample - loss: 0.0203 - accuracy: 0.9974 - val_loss: 0.0457 - val_accuracy: 0.9858\n",
      "Epoch 23/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0172 - accuracy: 0.9987 - val_loss: 0.0488 - val_accuracy: 0.9838\n",
      "CPU times: user 6min 2s, sys: 2min 34s, total: 8min 36s\n",
      "Wall time: 4min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7ffc2edcd0>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      1.00      1.00       193\n",
      "      alinda       1.00      0.99      1.00       194\n",
      "        gian       0.99      1.00      1.00       192\n",
      "     jackson       1.00      1.00      1.00       193\n",
      "      khaled       1.00      1.00      1.00       193\n",
      "     nicolas       1.00      1.00      1.00       193\n",
      "        theo       0.92      0.98      0.95       182\n",
      "    yweweler       0.98      0.93      0.95       204\n",
      "\n",
      "    accuracy                           0.99      1544\n",
      "   macro avg       0.99      0.99      0.99      1544\n",
      "weighted avg       0.99      0.99      0.99      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data_preparation' from '/Users/kappa/repositories/dsim_project/Audio/data_preparation.py'>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(data_preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n",
      "CPU times: user 2min 39s, sys: 9.82 s, total: 2min 49s\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                                                    y_type= ['speakers_default', 'speakers_us'],\n",
    "                                                    n_category_test=30,\n",
    "                                                    include_pitch=False,\n",
    "                                                    max_length=max_track_length,\n",
    "                                                    recordings_source=[False, True],\n",
    "                                                    transform_function=\"spectrogram\",\n",
    "                                                   paper_data=True)\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, target_names= data_preparation.prepare_data_nn(X_train_speaker,\n",
    "                                                                   X_val_speaker,\n",
    "                                                                   X_test_speaker,\n",
    "                                                                   y_train_speaker,\n",
    "                                                                   y_val_speaker,\n",
    "                                                                   y_test_speaker,\n",
    "                                                                   number_mode=False)\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker_nn = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker_nn = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "model = cnn_models.paper_architecture(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11478 samples, validate on 2870 samples\n",
      "Epoch 1/100\n",
      "11478/11478 [==============================] - 39s 3ms/sample - loss: 1.0939 - accuracy: 0.6147 - val_loss: 1.0364 - val_accuracy: 0.5798\n",
      "Epoch 2/100\n",
      "11478/11478 [==============================] - 37s 3ms/sample - loss: 0.6247 - accuracy: 0.7757 - val_loss: 0.6258 - val_accuracy: 0.7669\n",
      "Epoch 3/100\n",
      "11478/11478 [==============================] - 34s 3ms/sample - loss: 0.4920 - accuracy: 0.8230 - val_loss: 0.4013 - val_accuracy: 0.8456\n",
      "Epoch 4/100\n",
      "11478/11478 [==============================] - 34s 3ms/sample - loss: 0.3989 - accuracy: 0.8576 - val_loss: 0.2767 - val_accuracy: 0.9101\n",
      "Epoch 5/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.3422 - accuracy: 0.8804 - val_loss: 0.2676 - val_accuracy: 0.9111\n",
      "Epoch 6/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.2898 - accuracy: 0.8989 - val_loss: 0.6481 - val_accuracy: 0.7780\n",
      "Epoch 7/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.2638 - accuracy: 0.9081 - val_loss: 0.1921 - val_accuracy: 0.9401\n",
      "Epoch 8/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.2300 - accuracy: 0.9231 - val_loss: 0.1458 - val_accuracy: 0.9557\n",
      "Epoch 9/100\n",
      "11478/11478 [==============================] - 35s 3ms/sample - loss: 0.2145 - accuracy: 0.9250 - val_loss: 0.1177 - val_accuracy: 0.9589\n",
      "Epoch 10/100\n",
      "11478/11478 [==============================] - 36s 3ms/sample - loss: 0.1894 - accuracy: 0.9375 - val_loss: 0.1179 - val_accuracy: 0.9659\n",
      "Epoch 11/100\n",
      "11478/11478 [==============================] - 34s 3ms/sample - loss: 0.1811 - accuracy: 0.9378 - val_loss: 0.1388 - val_accuracy: 0.9467\n",
      "Epoch 12/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1647 - accuracy: 0.9475 - val_loss: 0.0956 - val_accuracy: 0.9693\n",
      "Epoch 13/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1560 - accuracy: 0.9496 - val_loss: 0.1411 - val_accuracy: 0.9519\n",
      "Epoch 14/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1615 - accuracy: 0.9463 - val_loss: 0.0927 - val_accuracy: 0.9714\n",
      "Epoch 15/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1464 - accuracy: 0.9514 - val_loss: 0.0834 - val_accuracy: 0.9711\n",
      "Epoch 16/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1342 - accuracy: 0.9558 - val_loss: 0.1058 - val_accuracy: 0.9648\n",
      "Epoch 17/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1247 - accuracy: 0.9584 - val_loss: 0.0554 - val_accuracy: 0.9812\n",
      "Epoch 18/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1194 - accuracy: 0.9591 - val_loss: 0.1456 - val_accuracy: 0.9415\n",
      "Epoch 19/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1141 - accuracy: 0.9602 - val_loss: 0.0535 - val_accuracy: 0.9829\n",
      "Epoch 20/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1067 - accuracy: 0.9649 - val_loss: 0.0546 - val_accuracy: 0.9812\n",
      "Epoch 21/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.1004 - accuracy: 0.9666 - val_loss: 0.0529 - val_accuracy: 0.9829\n",
      "Epoch 22/100\n",
      "11478/11478 [==============================] - 34s 3ms/sample - loss: 0.0943 - accuracy: 0.9683 - val_loss: 0.0504 - val_accuracy: 0.9833\n",
      "Epoch 23/100\n",
      "11478/11478 [==============================] - 41s 4ms/sample - loss: 0.0941 - accuracy: 0.9692 - val_loss: 0.0639 - val_accuracy: 0.9763\n",
      "Epoch 24/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.0863 - accuracy: 0.9726 - val_loss: 0.0479 - val_accuracy: 0.9826\n",
      "Epoch 25/100\n",
      "11478/11478 [==============================] - 34s 3ms/sample - loss: 0.0876 - accuracy: 0.9697 - val_loss: 0.0634 - val_accuracy: 0.9805\n",
      "Epoch 26/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.0785 - accuracy: 0.9728 - val_loss: 0.0468 - val_accuracy: 0.9861\n",
      "Epoch 27/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.0822 - accuracy: 0.9740 - val_loss: 0.0514 - val_accuracy: 0.9822\n",
      "Epoch 28/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.0709 - accuracy: 0.9772 - val_loss: 0.0997 - val_accuracy: 0.9617\n",
      "Epoch 29/100\n",
      "11478/11478 [==============================] - 43s 4ms/sample - loss: 0.0673 - accuracy: 0.9789 - val_loss: 0.0349 - val_accuracy: 0.9882\n",
      "Epoch 30/100\n",
      "11478/11478 [==============================] - 42s 4ms/sample - loss: 0.0704 - accuracy: 0.9776 - val_loss: 0.0689 - val_accuracy: 0.9746\n",
      "Epoch 31/100\n",
      "11478/11478 [==============================] - 37s 3ms/sample - loss: 0.0584 - accuracy: 0.9820 - val_loss: 0.0459 - val_accuracy: 0.9843\n",
      "Epoch 32/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0632 - accuracy: 0.9791 - val_loss: 0.0382 - val_accuracy: 0.9850\n",
      "Epoch 33/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0593 - accuracy: 0.9811 - val_loss: 0.0291 - val_accuracy: 0.9909\n",
      "Epoch 34/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0570 - accuracy: 0.9812 - val_loss: 0.0584 - val_accuracy: 0.9780\n",
      "Epoch 35/100\n",
      "11478/11478 [==============================] - 28s 2ms/sample - loss: 0.0603 - accuracy: 0.9799 - val_loss: 0.0559 - val_accuracy: 0.9780\n",
      "Epoch 36/100\n",
      "11478/11478 [==============================] - 28s 2ms/sample - loss: 0.0624 - accuracy: 0.9798 - val_loss: 0.0523 - val_accuracy: 0.9749\n",
      "Epoch 37/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.0555 - accuracy: 0.9817 - val_loss: 0.0457 - val_accuracy: 0.9812\n",
      "Epoch 38/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.0571 - accuracy: 0.9814 - val_loss: 0.0695 - val_accuracy: 0.9770\n",
      "Epoch 39/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.0535 - accuracy: 0.9831 - val_loss: 0.0503 - val_accuracy: 0.9829\n",
      "Epoch 40/100\n",
      "11478/11478 [==============================] - 37s 3ms/sample - loss: 0.0496 - accuracy: 0.9842 - val_loss: 0.0337 - val_accuracy: 0.9864\n",
      "Epoch 41/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0456 - accuracy: 0.9840 - val_loss: 0.0434 - val_accuracy: 0.9836\n",
      "Epoch 42/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.0460 - accuracy: 0.9860 - val_loss: 0.0380 - val_accuracy: 0.9857\n",
      "Epoch 43/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.0286 - val_accuracy: 0.9892\n",
      "Epoch 44/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.0405 - accuracy: 0.9867 - val_loss: 0.0278 - val_accuracy: 0.9899\n",
      "Epoch 45/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.0506 - accuracy: 0.9837 - val_loss: 0.0420 - val_accuracy: 0.9840\n",
      "Epoch 46/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.0368 - accuracy: 0.9885 - val_loss: 0.0261 - val_accuracy: 0.9899\n",
      "Epoch 47/100\n",
      "11478/11478 [==============================] - 44s 4ms/sample - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.0556 - val_accuracy: 0.9826\n",
      "Epoch 48/100\n",
      "11478/11478 [==============================] - 36s 3ms/sample - loss: 0.0450 - accuracy: 0.9840 - val_loss: 0.0358 - val_accuracy: 0.9857\n",
      "Epoch 49/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.0397 - accuracy: 0.9875 - val_loss: 0.0345 - val_accuracy: 0.9892\n",
      "Epoch 50/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.0378 - accuracy: 0.9875 - val_loss: 0.0427 - val_accuracy: 0.9843\n",
      "Epoch 51/100\n",
      "11478/11478 [==============================] - 35s 3ms/sample - loss: 0.0801 - accuracy: 0.9728 - val_loss: 0.0554 - val_accuracy: 0.9794\n",
      "Epoch 52/100\n",
      "11478/11478 [==============================] - 36s 3ms/sample - loss: 0.0460 - accuracy: 0.9858 - val_loss: 0.0405 - val_accuracy: 0.9850\n",
      "Epoch 53/100\n",
      "11478/11478 [==============================] - 34s 3ms/sample - loss: 0.0401 - accuracy: 0.9861 - val_loss: 0.0307 - val_accuracy: 0.9916\n",
      "Epoch 54/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0407 - val_accuracy: 0.9864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.0226 - val_accuracy: 0.9902\n",
      "Epoch 56/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0357 - accuracy: 0.9879 - val_loss: 0.0419 - val_accuracy: 0.9840\n",
      "Epoch 57/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0336 - accuracy: 0.9899 - val_loss: 0.0655 - val_accuracy: 0.9756\n",
      "Epoch 58/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0351 - accuracy: 0.9897 - val_loss: 0.0280 - val_accuracy: 0.9899\n",
      "Epoch 59/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.0328 - val_accuracy: 0.9850\n",
      "Epoch 60/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.0307 - accuracy: 0.9907 - val_loss: 0.0368 - val_accuracy: 0.9864\n",
      "Epoch 61/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.0292 - accuracy: 0.9916 - val_loss: 0.0316 - val_accuracy: 0.9889\n",
      "Epoch 62/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.0260 - accuracy: 0.9933 - val_loss: 0.0537 - val_accuracy: 0.9819\n",
      "Epoch 63/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0315 - accuracy: 0.9901 - val_loss: 0.0306 - val_accuracy: 0.9892\n",
      "Epoch 64/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.0424 - val_accuracy: 0.9871\n",
      "Epoch 65/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.0349 - accuracy: 0.9883 - val_loss: 0.0279 - val_accuracy: 0.9895\n",
      "CPU times: user 52min 40s, sys: 42min 16s, total: 1h 34min 57s\n",
      "Wall time: 35min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7ff2fa5890>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      1.00      1.00       134\n",
      "      alinda       1.00      1.00      1.00       172\n",
      "        gian       1.00      1.00      1.00       148\n",
      "     jackson       1.00      1.00      1.00       592\n",
      "      khaled       1.00      1.00      1.00       162\n",
      "     nicolas       1.00      1.00      1.00       568\n",
      "        theo       0.98      0.97      0.98       566\n",
      "    yweweler       0.97      0.98      0.97       528\n",
      "\n",
      "    accuracy                           0.99      2870\n",
      "   macro avg       0.99      0.99      0.99      2870\n",
      "weighted avg       0.99      0.99      0.99      2870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model\n",
    "The model with the best performances is the last one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speakers_best = np.concatenate([X_train_speaker, X_val_speaker])\n",
    "y_train_speakers_best = np.concatenate([y_train_speaker_nn, y_val_speaker_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14348 samples\n",
      "Epoch 1/55\n",
      "14348/14348 [==============================] - 43s 3ms/sample - loss: 1.1564 - accuracy: 0.5942\n",
      "Epoch 2/55\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.6672 - accuracy: 0.7638\n",
      "Epoch 3/55\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.4850 - accuracy: 0.8284\n",
      "Epoch 4/55\n",
      "14348/14348 [==============================] - 40s 3ms/sample - loss: 0.3829 - accuracy: 0.8681\n",
      "Epoch 5/55\n",
      "14348/14348 [==============================] - 39s 3ms/sample - loss: 0.3199 - accuracy: 0.8871\n",
      "Epoch 6/55\n",
      "14348/14348 [==============================] - 39s 3ms/sample - loss: 0.2799 - accuracy: 0.9046\n",
      "Epoch 7/55\n",
      "14348/14348 [==============================] - 34s 2ms/sample - loss: 0.2354 - accuracy: 0.9205\n",
      "Epoch 8/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.2187 - accuracy: 0.9235\n",
      "Epoch 9/55\n",
      "14348/14348 [==============================] - 45s 3ms/sample - loss: 0.2031 - accuracy: 0.9291\n",
      "Epoch 10/55\n",
      "14348/14348 [==============================] - 40s 3ms/sample - loss: 0.1766 - accuracy: 0.9403\n",
      "Epoch 11/55\n",
      "14348/14348 [==============================] - 47s 3ms/sample - loss: 0.1729 - accuracy: 0.9415\n",
      "Epoch 12/55\n",
      "14348/14348 [==============================] - 48s 3ms/sample - loss: 0.1507 - accuracy: 0.9491\n",
      "Epoch 13/55\n",
      "14348/14348 [==============================] - 35s 2ms/sample - loss: 0.1408 - accuracy: 0.9538\n",
      "Epoch 14/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.1378 - accuracy: 0.9506\n",
      "Epoch 15/55\n",
      "14348/14348 [==============================] - 44s 3ms/sample - loss: 0.1267 - accuracy: 0.9576\n",
      "Epoch 16/55\n",
      "14348/14348 [==============================] - 40s 3ms/sample - loss: 0.1224 - accuracy: 0.9581\n",
      "Epoch 17/55\n",
      "14348/14348 [==============================] - 39s 3ms/sample - loss: 0.1176 - accuracy: 0.9617\n",
      "Epoch 18/55\n",
      "14348/14348 [==============================] - 39s 3ms/sample - loss: 0.1053 - accuracy: 0.9651\n",
      "Epoch 19/55\n",
      "14348/14348 [==============================] - 36s 2ms/sample - loss: 0.1070 - accuracy: 0.9640\n",
      "Epoch 20/55\n",
      "14348/14348 [==============================] - 34s 2ms/sample - loss: 0.0945 - accuracy: 0.9693\n",
      "Epoch 21/55\n",
      "14348/14348 [==============================] - 35s 2ms/sample - loss: 0.0938 - accuracy: 0.9683\n",
      "Epoch 22/55\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.0877 - accuracy: 0.9711\n",
      "Epoch 23/55\n",
      "14348/14348 [==============================] - 35s 2ms/sample - loss: 0.0774 - accuracy: 0.9755\n",
      "Epoch 24/55\n",
      "14348/14348 [==============================] - 39s 3ms/sample - loss: 0.0796 - accuracy: 0.9727\n",
      "Epoch 25/55\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.0774 - accuracy: 0.9739\n",
      "Epoch 26/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0724 - accuracy: 0.9767\n",
      "Epoch 27/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0706 - accuracy: 0.9768\n",
      "Epoch 28/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0622 - accuracy: 0.9791\n",
      "Epoch 29/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0706 - accuracy: 0.9764\n",
      "Epoch 30/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0647 - accuracy: 0.9781\n",
      "Epoch 31/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0582 - accuracy: 0.9810\n",
      "Epoch 32/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0597 - accuracy: 0.9799\n",
      "Epoch 33/55\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.0635 - accuracy: 0.9785\n",
      "Epoch 34/55\n",
      "14348/14348 [==============================] - 36s 2ms/sample - loss: 0.0551 - accuracy: 0.9815\n",
      "Epoch 35/55\n",
      "14348/14348 [==============================] - 34s 2ms/sample - loss: 0.0621 - accuracy: 0.9803\n",
      "Epoch 36/55\n",
      "14348/14348 [==============================] - 34s 2ms/sample - loss: 0.0581 - accuracy: 0.9801\n",
      "Epoch 37/55\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.0477 - accuracy: 0.9853\n",
      "Epoch 38/55\n",
      "14348/14348 [==============================] - 35s 2ms/sample - loss: 0.0560 - accuracy: 0.9806\n",
      "Epoch 39/55\n",
      "14348/14348 [==============================] - 39s 3ms/sample - loss: 0.0525 - accuracy: 0.9821\n",
      "Epoch 40/55\n",
      "14348/14348 [==============================] - 36s 3ms/sample - loss: 0.0516 - accuracy: 0.9833\n",
      "Epoch 41/55\n",
      "14348/14348 [==============================] - 40s 3ms/sample - loss: 0.0553 - accuracy: 0.9822\n",
      "Epoch 42/55\n",
      "14348/14348 [==============================] - 34s 2ms/sample - loss: 0.0547 - accuracy: 0.9808\n",
      "Epoch 43/55\n",
      "14348/14348 [==============================] - 35s 2ms/sample - loss: 0.0487 - accuracy: 0.9852\n",
      "Epoch 44/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0423 - accuracy: 0.9856\n",
      "Epoch 45/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0434 - accuracy: 0.9849\n",
      "Epoch 46/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0435 - accuracy: 0.9859\n",
      "Epoch 47/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0496 - accuracy: 0.9841\n",
      "Epoch 48/55\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.0463 - accuracy: 0.9845\n",
      "Epoch 49/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0689 - accuracy: 0.9761\n",
      "Epoch 50/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0653 - accuracy: 0.9776\n",
      "Epoch 51/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0637 - accuracy: 0.9781\n",
      "Epoch 52/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0672 - accuracy: 0.9765\n",
      "Epoch 53/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0692 - accuracy: 0.9778\n",
      "Epoch 54/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0684 - accuracy: 0.9746\n",
      "Epoch 55/55\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0629 - accuracy: 0.9780\n",
      "CPU times: user 51min 6s, sys: 42min 39s, total: 1h 33min 46s\n",
      "Wall time: 34min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7fffc7b990>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.paper_architecture(num_classes=8, input_shape=input_shape, batch_normalisation=True)\n",
    "model.fit(X_train_speakers_best, y_train_speakers_best,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=55,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      1.00      1.00        30\n",
      "      alinda       1.00      0.97      0.98        30\n",
      "        gian       0.97      0.93      0.95        30\n",
      "     jackson       1.00      1.00      1.00        30\n",
      "      khaled       1.00      0.83      0.91        30\n",
      "     nicolas       1.00      1.00      1.00        30\n",
      "        theo       0.93      0.93      0.93        30\n",
      "    yweweler       0.81      1.00      0.90        30\n",
      "\n",
      "    accuracy                           0.96       240\n",
      "   macro avg       0.96      0.96      0.96       240\n",
      "weighted avg       0.96      0.96      0.96       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_test_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/speakers.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical representation of recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "test = pad_recordings[45]\n",
    "test_mfcc = librosa.feature.mfcc(test*1.0, sr=8000, n_mfcc=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from librosa.display import specshow\n",
    "plt.figure(figsize=(10, 4))\n",
    "specshow(test_mfcc, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "test_spect = data_preparation.compute_spectrogram(test)\n",
    "S_dB = librosa.power_to_db(test_spect, ref=np.max)\n",
    "librosa.display.specshow(S_dB, x_axis='time',\n",
    "                          y_axis='mel', sr=8000)\n",
    "plt.title('Mel-frequency spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "spectrogram = librosa.feature.melspectrogram(y=test,\n",
    "                                                 sr=8000,\n",
    "                                                 n_fft=1024,\n",
    "                                                 hop_length=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 57)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "S_dB = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "librosa.display.specshow(S_dB, x_axis='time',\n",
    "                          y_axis='mel', sr=8000)\n",
    "plt.title('Mel-frequency spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
