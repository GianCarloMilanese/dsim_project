{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCH=32\n",
    "EPOCHS=50\n",
    "PATIENCE=5\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import data_augmentation\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "## No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdd_dir=\"./recordings/\"\n",
    "our_recs_dir=\"./preprocessed_recs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./recordings/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72baac252154259bcc2a3ec276afac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ./preprocessed_recs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0850d1a874ad44d383275328c751d015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much does input recordings vary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 18262\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite a huge difference! Let's find out the 10 longest recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18262, 17567, 9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get their indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "first_length=18262\n",
    "second_length=17567\n",
    "index_first = a.index(first_length)\n",
    "index_second = a.index(second_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest track is associated with speaker theo, digit 9\n",
      "Second longest track is associated with speaker theo, digit 7\n"
     ]
    }
   ],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir])\n",
    "print(\"Longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_first],labels_digits[index_first]))\n",
    "print(\"Second longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_second],labels_digits[index_second]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problem is with theo, which has 500 recordings, digit 9 and 7, which respectively have 200 recordings. We can safely delete them and saving to pad many thousands of 0s (there will be (18262 - 9015) less zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "max_track_length=9015 # it will be useful later on\n",
    "print(\"Before: {}\".format(len(recordings)))\n",
    "recordings=np.delete(recordings,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(recordings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_speakers)))\n",
    "labels_speakers=np.delete(labels_speakers,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_speakers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_digits)))\n",
    "labels_digits=np.delete(labels_digits,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_digits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now double check to see if everything went well. Now the longest recording will be around 9 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356, 7147, 7038]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though variability is reduced, it is still there: for this reason we will pad zeros at start and end of recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_zeros >>>\n",
      "pad_zeros <<<\n"
     ]
    }
   ],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they will have the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9015 9015\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create balancede train, validation and test sets. For digits it's not a huge problem (only 7 and 9, because of the previous operation, have 1 recordings less, however our 4 speakers (ale, alinda, gian, khaled) have 100 recordings, while the other 4 have 500 recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 48 48\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X_train_digits, y_train_digits, X_val_digits, y_val_digits, X_test_digits, y_test_digits = data_preparation.balanced_train_val_test_split(pad_recordings, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 20 20\n",
      "ale\n",
      "alinda\n",
      "gian\n",
      "jackson\n",
      "khaled\n",
      "nicolas\n",
      "theo\n",
      "yweweler\n"
     ]
    }
   ],
   "source": [
    "X_train_speakers, y_train_speakers, X_val_speakers, y_val_speakers, X_test_speakers, y_test_speakers = data_preparation.balanced_train_val_test_split(pad_recordings, labels_speakers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits\n",
    "## Spectrograms - No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.4 s, sys: 245 ms, total: 17.6 s\n",
      "Wall time: 9.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_train_digits])\n",
    "X_val_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_val_digits])\n",
    "X_test_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 s, sys: 184 ms, total: 17.3 s\n",
      "Wall time: 8.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_train_digits])\n",
    "X_val_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_val_digits])\n",
    "X_test_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digits_spects.shape\n",
    "X_train_digits_spects_2d = X_train_digits_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.2 s, sys: 146 ms, total: 25.4 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train_digits_spects_2d, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digits_spects.shape\n",
    "X_val_digits_spects_2d = X_val_digits_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.25      0.37        48\n",
      "           1       0.71      0.31      0.43        48\n",
      "           2       0.53      0.19      0.28        48\n",
      "           3       0.56      0.21      0.30        48\n",
      "           4       0.21      0.40      0.28        48\n",
      "           5       0.71      0.42      0.53        48\n",
      "           6       0.34      0.31      0.33        48\n",
      "           7       0.53      0.21      0.30        48\n",
      "           8       0.80      0.25      0.38        48\n",
      "           9       0.21      0.92      0.34        48\n",
      "\n",
      "    accuracy                           0.35       480\n",
      "   macro avg       0.53      0.35      0.35       480\n",
      "weighted avg       0.53      0.35      0.35       480\n",
      "\n",
      "CPU times: user 5.28 s, sys: 45.8 ms, total: 5.32 s\n",
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val_digits_spects_2d)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digits_spects_norm.shape\n",
    "X_train_digits_spects_norm_2d = X_train_digits_spects_norm.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 141 ms, total: 14.6 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_spects_norm_2d, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digits_spects_norm.shape\n",
    "X_val_digits_spects_norm_2d = X_val_digits_spects_norm.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        48\n",
      "           1       0.91      0.88      0.89        48\n",
      "           2       0.66      0.96      0.78        48\n",
      "           3       0.91      0.60      0.72        48\n",
      "           4       1.00      0.83      0.91        48\n",
      "           5       0.91      0.88      0.89        48\n",
      "           6       0.69      0.83      0.75        48\n",
      "           7       0.81      0.92      0.86        48\n",
      "           8       0.88      0.79      0.84        48\n",
      "           9       0.88      0.79      0.84        48\n",
      "\n",
      "    accuracy                           0.84       480\n",
      "   macro avg       0.86      0.84      0.84       480\n",
      "weighted avg       0.86      0.84      0.84       480\n",
      "\n",
      "CPU times: user 4.66 s, sys: 49.5 ms, total: 4.71 s\n",
      "Wall time: 4.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_digits_spects_norm_2d)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized spectrograms lead to better performances, therefore let's use this representation as default\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digits_spects_norm_nn, X_val_digits_spects_norm_nn, X_test_digits_spects_norm_nn, y_train_digits_nn, y_val_digits_nn, y_test_digits_nn, input_shape, _ = data_preparation.prepare_data_nn(X_train_digits_spects_norm, X_val_digits_spects_norm, X_test_digits_spects_norm, y_train_digits, y_val_digits, y_test_digits, number_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 127, 56, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 63, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               7225472   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 7,226,922\n",
      "Trainable params: 7,226,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 1.9475 - accuracy: 0.3510 - val_loss: 1.4914 - val_accuracy: 0.5562\n",
      "Epoch 2/50\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 1.3172 - accuracy: 0.5895 - val_loss: 0.9205 - val_accuracy: 0.7917\n",
      "Epoch 3/50\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 0.9815 - accuracy: 0.7049 - val_loss: 0.7315 - val_accuracy: 0.8354\n",
      "Epoch 4/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.7935 - accuracy: 0.7650 - val_loss: 0.5837 - val_accuracy: 0.8542\n",
      "Epoch 5/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.6396 - accuracy: 0.8224 - val_loss: 0.4856 - val_accuracy: 0.8854\n",
      "Epoch 6/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.5656 - accuracy: 0.8273 - val_loss: 0.3836 - val_accuracy: 0.9042\n",
      "Epoch 7/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.4615 - accuracy: 0.8497 - val_loss: 0.3755 - val_accuracy: 0.9083\n",
      "Epoch 8/50\n",
      "1430/1430 [==============================] - 12s 8ms/sample - loss: 0.4187 - accuracy: 0.8853 - val_loss: 0.3190 - val_accuracy: 0.9042\n",
      "Epoch 9/50\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 0.4069 - accuracy: 0.8818 - val_loss: 0.2797 - val_accuracy: 0.9271\n",
      "Epoch 10/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.3313 - accuracy: 0.8951 - val_loss: 0.2712 - val_accuracy: 0.9312\n",
      "Epoch 11/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.3111 - accuracy: 0.9056 - val_loss: 0.2628 - val_accuracy: 0.9250\n",
      "Epoch 12/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.2803 - accuracy: 0.9203 - val_loss: 0.2323 - val_accuracy: 0.9354\n",
      "Epoch 13/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.2586 - accuracy: 0.9189 - val_loss: 0.2243 - val_accuracy: 0.9479\n",
      "Epoch 14/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.2291 - accuracy: 0.9343 - val_loss: 0.2005 - val_accuracy: 0.9479\n",
      "Epoch 15/50\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 0.2131 - accuracy: 0.9329 - val_loss: 0.2122 - val_accuracy: 0.9292\n",
      "Epoch 16/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.2045 - accuracy: 0.9448 - val_loss: 0.1815 - val_accuracy: 0.9563\n",
      "Epoch 17/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.1600 - accuracy: 0.9524 - val_loss: 0.1839 - val_accuracy: 0.9521\n",
      "Epoch 18/50\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 0.2203 - accuracy: 0.9287 - val_loss: 0.1865 - val_accuracy: 0.9563\n",
      "Epoch 19/50\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 0.1695 - accuracy: 0.9524 - val_loss: 0.1949 - val_accuracy: 0.9479\n",
      "Epoch 20/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.1675 - accuracy: 0.9510 - val_loss: 0.1825 - val_accuracy: 0.9563\n",
      "Epoch 21/50\n",
      "1430/1430 [==============================] - 8s 6ms/sample - loss: 0.1263 - accuracy: 0.9650 - val_loss: 0.2061 - val_accuracy: 0.9438\n",
      "CPU times: user 7min 21s, sys: 1min 20s, total: 8min 42s\n",
      "Wall time: 3min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faaa23ef910>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10)\n",
    "model.fit(X_train_digits_spects_norm_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_norm_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        48\n",
      "           1       1.00      0.92      0.96        48\n",
      "           2       0.92      0.96      0.94        48\n",
      "           3       0.94      0.98      0.96        48\n",
      "           4       0.98      1.00      0.99        48\n",
      "           5       0.98      0.98      0.98        48\n",
      "           6       0.93      0.88      0.90        48\n",
      "           7       0.96      0.98      0.97        48\n",
      "           8       0.94      0.94      0.94        48\n",
      "           9       0.96      0.96      0.96        48\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_norm_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 127, 56, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 127, 56, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 63, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               7225472   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 7,227,562\n",
      "Trainable params: 7,227,242\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/50\n",
      "1430/1430 [==============================] - 12s 8ms/sample - loss: 1.5569 - accuracy: 0.5154 - val_loss: 1.8422 - val_accuracy: 0.4667\n",
      "Epoch 2/50\n",
      "1430/1430 [==============================] - 11s 8ms/sample - loss: 0.7554 - accuracy: 0.7636 - val_loss: 1.7816 - val_accuracy: 0.3896\n",
      "Epoch 3/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.5617 - accuracy: 0.8371 - val_loss: 1.7304 - val_accuracy: 0.3646\n",
      "Epoch 4/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.4008 - accuracy: 0.8944 - val_loss: 1.5838 - val_accuracy: 0.4917\n",
      "Epoch 5/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.3045 - accuracy: 0.9231 - val_loss: 1.4488 - val_accuracy: 0.4521\n",
      "Epoch 6/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.2527 - accuracy: 0.9385 - val_loss: 1.2947 - val_accuracy: 0.5417\n",
      "Epoch 7/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.1942 - accuracy: 0.9622 - val_loss: 1.0436 - val_accuracy: 0.7083\n",
      "Epoch 8/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.1846 - accuracy: 0.9538 - val_loss: 0.8223 - val_accuracy: 0.8542\n",
      "Epoch 9/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.1847 - accuracy: 0.9559 - val_loss: 0.6349 - val_accuracy: 0.8979\n",
      "Epoch 10/50\n",
      "1430/1430 [==============================] - 13s 9ms/sample - loss: 0.1326 - accuracy: 0.9748 - val_loss: 0.5341 - val_accuracy: 0.9125\n",
      "Epoch 11/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0983 - accuracy: 0.9790 - val_loss: 0.4590 - val_accuracy: 0.9167\n",
      "Epoch 12/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0869 - accuracy: 0.9867 - val_loss: 0.3815 - val_accuracy: 0.9312\n",
      "Epoch 13/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0817 - accuracy: 0.9881 - val_loss: 0.3353 - val_accuracy: 0.9375\n",
      "Epoch 14/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0738 - accuracy: 0.9902 - val_loss: 0.3017 - val_accuracy: 0.9438\n",
      "Epoch 15/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.0703 - accuracy: 0.9923 - val_loss: 0.3415 - val_accuracy: 0.9271\n",
      "Epoch 16/50\n",
      "1430/1430 [==============================] - 11s 8ms/sample - loss: 0.0604 - accuracy: 0.9930 - val_loss: 0.2733 - val_accuracy: 0.9458\n",
      "Epoch 17/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0592 - accuracy: 0.9944 - val_loss: 0.2906 - val_accuracy: 0.9521\n",
      "Epoch 18/50\n",
      "1430/1430 [==============================] - 11s 8ms/sample - loss: 0.0502 - accuracy: 0.9944 - val_loss: 0.2753 - val_accuracy: 0.9500\n",
      "Epoch 19/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0437 - accuracy: 0.9951 - val_loss: 0.2598 - val_accuracy: 0.9479\n",
      "Epoch 20/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.0417 - accuracy: 0.9958 - val_loss: 0.2571 - val_accuracy: 0.9563\n",
      "Epoch 21/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.0341 - accuracy: 0.9986 - val_loss: 0.2723 - val_accuracy: 0.9542\n",
      "Epoch 22/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.0335 - accuracy: 0.9972 - val_loss: 0.2525 - val_accuracy: 0.9542\n",
      "Epoch 23/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.0345 - accuracy: 0.9965 - val_loss: 0.2415 - val_accuracy: 0.9604\n",
      "Epoch 24/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.0236 - accuracy: 0.9993 - val_loss: 0.2389 - val_accuracy: 0.9604\n",
      "Epoch 25/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0255 - accuracy: 0.9986 - val_loss: 0.2304 - val_accuracy: 0.9563\n",
      "Epoch 26/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.0296 - accuracy: 0.9986 - val_loss: 0.2242 - val_accuracy: 0.9542\n",
      "Epoch 27/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.0265 - accuracy: 0.9972 - val_loss: 0.2655 - val_accuracy: 0.9458\n",
      "Epoch 28/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.0290 - accuracy: 0.9965 - val_loss: 0.2199 - val_accuracy: 0.9500\n",
      "Epoch 29/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9500\n",
      "Epoch 30/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0199 - accuracy: 0.9993 - val_loss: 0.2235 - val_accuracy: 0.9500\n",
      "Epoch 31/50\n",
      "1430/1430 [==============================] - 12s 8ms/sample - loss: 0.0233 - accuracy: 0.9993 - val_loss: 0.2122 - val_accuracy: 0.9542\n",
      "Epoch 32/50\n",
      "1430/1430 [==============================] - 11s 8ms/sample - loss: 0.0181 - accuracy: 0.9979 - val_loss: 0.2061 - val_accuracy: 0.9563\n",
      "Epoch 33/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0191 - accuracy: 0.9993 - val_loss: 0.2084 - val_accuracy: 0.9542\n",
      "Epoch 34/50\n",
      "1430/1430 [==============================] - 11s 8ms/sample - loss: 0.0190 - accuracy: 0.9993 - val_loss: 0.2025 - val_accuracy: 0.9583\n",
      "Epoch 35/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9542\n",
      "Epoch 36/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.0155 - accuracy: 0.9993 - val_loss: 0.1941 - val_accuracy: 0.9563\n",
      "Epoch 37/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.0158 - accuracy: 0.9993 - val_loss: 0.2216 - val_accuracy: 0.9542\n",
      "Epoch 38/50\n",
      "1430/1430 [==============================] - 9s 7ms/sample - loss: 0.0161 - accuracy: 0.9993 - val_loss: 0.1881 - val_accuracy: 0.9563\n",
      "Epoch 39/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0180 - accuracy: 0.9979 - val_loss: 0.1899 - val_accuracy: 0.9542\n",
      "Epoch 40/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0167 - accuracy: 0.9993 - val_loss: 0.2073 - val_accuracy: 0.9542\n",
      "Epoch 41/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.0183 - accuracy: 0.9986 - val_loss: 0.2108 - val_accuracy: 0.9542\n",
      "Epoch 42/50\n",
      "1430/1430 [==============================] - 9s 6ms/sample - loss: 0.0140 - accuracy: 0.9993 - val_loss: 0.2146 - val_accuracy: 0.9563\n",
      "Epoch 43/50\n",
      "1430/1430 [==============================] - 10s 7ms/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9542\n",
      "CPU times: user 17min 49s, sys: 2min 47s, total: 20min 37s\n",
      "Wall time: 7min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa54b55110>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_spects_norm_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_norm_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        48\n",
      "           1       1.00      0.90      0.95        48\n",
      "           2       0.90      0.98      0.94        48\n",
      "           3       0.96      0.98      0.97        48\n",
      "           4       0.98      1.00      0.99        48\n",
      "           5       0.96      1.00      0.98        48\n",
      "           6       0.91      0.90      0.91        48\n",
      "           7       0.96      1.00      0.98        48\n",
      "           8       0.94      0.94      0.94        48\n",
      "           9       0.98      0.92      0.95        48\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_norm_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try with MFCCs\n",
    "## MFCC - No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 540 ms, total: 25.3 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc= np.array([data_preparation.mfcc(x, flatten=True) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 2 µs, total: 10 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "scaler_normal = StandardScaler()\n",
    "X_train_digits_mfcc_scaled = scaler_normal.fit_transform(X_train_digits_mfcc)\n",
    "X_val_digits_mfcc_scaled =  scaler_normal.transform(X_val_digits_mfcc)\n",
    "X_test_digits_mfcc_scaled =  scaler_normal.transform(X_test_digits_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.31 s, sys: 28.1 ms, total: 3.34 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_mfcc_scaled, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        48\n",
      "           1       0.94      0.92      0.93        48\n",
      "           2       0.94      0.96      0.95        48\n",
      "           3       0.95      0.85      0.90        48\n",
      "           4       1.00      0.94      0.97        48\n",
      "           5       1.00      0.96      0.98        48\n",
      "           6       0.72      0.88      0.79        48\n",
      "           7       1.00      0.96      0.98        48\n",
      "           8       0.88      0.92      0.90        48\n",
      "           9       0.94      0.92      0.93        48\n",
      "\n",
      "    accuracy                           0.93       480\n",
      "   macro avg       0.93      0.93      0.93       480\n",
      "weighted avg       0.93      0.93      0.93       480\n",
      "\n",
      "CPU times: user 1.08 s, sys: 9.61 ms, total: 1.09 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_digits_mfcc_scaled)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar results of the best Spectrograms model. Let's now use CNNs with MFCC\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 249 ms, total: 22.3 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc= np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430, 40, 40)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_digits_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digits_mfcc_nn, X_val_digits_mfcc_nn, X_test_digits_mfcc_nn, y_train_digits_nn, y_val_digits_nn, y_test_digits_nn, input_shape, _= data_preparation.prepare_data_nn(X_train_digits_mfcc, X_val_digits_mfcc, X_test_digits_mfcc, y_train_digits, y_val_digits, y_test_digits, number_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start to train the models, let's start with the simpler one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,480,234\n",
      "Trainable params: 1,480,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/50\n",
      "1430/1430 [==============================] - 5s 3ms/sample - loss: 154.7382 - accuracy: 0.0993 - val_loss: 2.2995 - val_accuracy: 0.1021\n",
      "Epoch 2/50\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 2.4240 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/50\n",
      "1430/1430 [==============================] - 2s 2ms/sample - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/50\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/50\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "CPU times: user 24.8 s, sys: 8.6 s, total: 33.4 s\n",
      "Wall time: 18.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa53f054d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        48\n",
      "           1       0.00      0.00      0.00        48\n",
      "           2       0.10      1.00      0.18        48\n",
      "           3       0.00      0.00      0.00        48\n",
      "           4       1.00      0.02      0.04        48\n",
      "           5       0.00      0.00      0.00        48\n",
      "           6       0.00      0.00      0.00        48\n",
      "           7       0.00      0.00      0.00        48\n",
      "           8       0.00      0.00      0.00        48\n",
      "           9       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.10       480\n",
      "   macro avg       0.11      0.10      0.02       480\n",
      "weighted avg       0.11      0.10      0.02       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really poor results, let's now use batch normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,480,874\n",
      "Trainable params: 1,480,554\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/50\n",
      "1430/1430 [==============================] - 6s 4ms/sample - loss: 1.0806 - accuracy: 0.6517 - val_loss: 1.7247 - val_accuracy: 0.6625\n",
      "Epoch 2/50\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.5094 - accuracy: 0.8559 - val_loss: 0.7144 - val_accuracy: 0.7604\n",
      "Epoch 3/50\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.4015 - accuracy: 0.8895 - val_loss: 0.4392 - val_accuracy: 0.8729\n",
      "Epoch 4/50\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3317 - accuracy: 0.9231 - val_loss: 0.2884 - val_accuracy: 0.9271\n",
      "Epoch 5/50\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.2870 - accuracy: 0.9294 - val_loss: 0.2472 - val_accuracy: 0.9375\n",
      "Epoch 6/50\n",
      "1430/1430 [==============================] - 5s 3ms/sample - loss: 0.2552 - accuracy: 0.9510 - val_loss: 0.4471 - val_accuracy: 0.8604\n",
      "Epoch 7/50\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.2102 - accuracy: 0.9594 - val_loss: 0.2187 - val_accuracy: 0.9625\n",
      "Epoch 8/50\n",
      "1430/1430 [==============================] - 5s 3ms/sample - loss: 0.2322 - accuracy: 0.9510 - val_loss: 0.2436 - val_accuracy: 0.9396\n",
      "Epoch 9/50\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.1978 - accuracy: 0.9685 - val_loss: 0.3279 - val_accuracy: 0.8958\n",
      "Epoch 10/50\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.1812 - accuracy: 0.9692 - val_loss: 0.2316 - val_accuracy: 0.9479\n",
      "Epoch 11/50\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1590 - accuracy: 0.9734 - val_loss: 0.2820 - val_accuracy: 0.9125\n",
      "Epoch 12/50\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1504 - accuracy: 0.9727 - val_loss: 0.2615 - val_accuracy: 0.9229\n",
      "CPU times: user 51.2 s, sys: 9.62 s, total: 1min\n",
      "Wall time: 48.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa531eb2d0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10,\n",
    "                                batch_normalisation=True)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        48\n",
      "           1       1.00      0.96      0.98        48\n",
      "           2       0.94      0.98      0.96        48\n",
      "           3       0.98      0.92      0.95        48\n",
      "           4       0.98      1.00      0.99        48\n",
      "           5       0.96      1.00      0.98        48\n",
      "           6       0.90      0.96      0.93        48\n",
      "           7       0.94      1.00      0.97        48\n",
      "           8       1.00      0.90      0.95        48\n",
      "           9       0.96      0.94      0.95        48\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"best model-data combo\" is now CNN + MFCC: f1-score is comparable, however the input data is smaller and therefore training is more efficient.\n",
    "\n",
    "Batch normalisation lead the same results on spectrograms, however on MFCC it works way better: let's use it by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "transform_recordings >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "transform_recordings <<<\n",
      "CPU times: user 5min 46s, sys: 14.5 s, total: 6min 1s\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digit_mfcc, y_train_digit_mfcc, X_val_digit_mfcc, y_val_digit_mfcc, X_test_digit_mfcc, y_test_digit_mfcc = data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=max_track_length,\n",
    "                             transform_function=\"mfcc\",\n",
    "                             load_stored_augm_recs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724 575\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X_train_digit, y_train_digit, X_val_digit, y_val_digit= data_preparation.balanced_train_val_split(np.concatenate([X_train_digit_mfcc, X_val_digit_mfcc]),\n",
    "                         np.concatenate([y_train_digit_mfcc, y_val_digit_mfcc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digits_mfcc_nn, X_val_digits_mfcc_nn, X_test_digits_mfcc_nn, y_train_digits_nn, y_val_digits_nn, y_test_digits_nn, input_shape, _= data_preparation.prepare_data_nn(X_train_digit, X_val_digit, X_test_digit_mfcc, y_train_digit, y_val_digit, y_test_digit_mfcc, number_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,480,874\n",
      "Trainable params: 1,480,554\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 17240 samples, validate on 5750 samples\n",
      "Epoch 1/50\n",
      "17240/17240 [==============================] - 38s 2ms/sample - loss: 1.2468 - accuracy: 0.5828 - val_loss: 1.2653 - val_accuracy: 0.6390\n",
      "Epoch 2/50\n",
      "17240/17240 [==============================] - 32s 2ms/sample - loss: 0.9433 - accuracy: 0.6900 - val_loss: 0.8310 - val_accuracy: 0.7221\n",
      "Epoch 3/50\n",
      "17240/17240 [==============================] - 32s 2ms/sample - loss: 0.8444 - accuracy: 0.7262 - val_loss: 0.7156 - val_accuracy: 0.7635\n",
      "Epoch 4/50\n",
      "17240/17240 [==============================] - 32s 2ms/sample - loss: 0.7945 - accuracy: 0.7439 - val_loss: 0.8517 - val_accuracy: 0.7237\n",
      "Epoch 5/50\n",
      "17240/17240 [==============================] - 32s 2ms/sample - loss: 0.7496 - accuracy: 0.7596 - val_loss: 0.5969 - val_accuracy: 0.8104\n",
      "Epoch 6/50\n",
      "17240/17240 [==============================] - 32s 2ms/sample - loss: 0.7257 - accuracy: 0.7593 - val_loss: 0.6438 - val_accuracy: 0.7950\n",
      "Epoch 7/50\n",
      "17240/17240 [==============================] - 31s 2ms/sample - loss: 0.7134 - accuracy: 0.7620 - val_loss: 0.6281 - val_accuracy: 0.7963\n",
      "Epoch 8/50\n",
      "17240/17240 [==============================] - 31s 2ms/sample - loss: 0.6905 - accuracy: 0.7749 - val_loss: 0.6130 - val_accuracy: 0.7941\n",
      "Epoch 9/50\n",
      "17240/17240 [==============================] - 32s 2ms/sample - loss: 0.6836 - accuracy: 0.7800 - val_loss: 0.5796 - val_accuracy: 0.8118\n",
      "Epoch 10/50\n",
      "17240/17240 [==============================] - 30s 2ms/sample - loss: 0.6744 - accuracy: 0.7791 - val_loss: 0.5605 - val_accuracy: 0.8163\n",
      "Epoch 11/50\n",
      "17240/17240 [==============================] - 31s 2ms/sample - loss: 0.6574 - accuracy: 0.7849 - val_loss: 0.5675 - val_accuracy: 0.8096\n",
      "Epoch 12/50\n",
      "17240/17240 [==============================] - 30s 2ms/sample - loss: 0.6411 - accuracy: 0.7874 - val_loss: 0.6037 - val_accuracy: 0.8035\n",
      "Epoch 13/50\n",
      "17240/17240 [==============================] - 31s 2ms/sample - loss: 0.6342 - accuracy: 0.7911 - val_loss: 0.5039 - val_accuracy: 0.8294\n",
      "Epoch 14/50\n",
      "17240/17240 [==============================] - 30s 2ms/sample - loss: 0.6223 - accuracy: 0.7958 - val_loss: 0.5147 - val_accuracy: 0.8245\n",
      "Epoch 15/50\n",
      "17240/17240 [==============================] - 33s 2ms/sample - loss: 0.6012 - accuracy: 0.8016 - val_loss: 0.5581 - val_accuracy: 0.8078\n",
      "Epoch 16/50\n",
      "17240/17240 [==============================] - 36s 2ms/sample - loss: 0.5965 - accuracy: 0.8024 - val_loss: 0.4998 - val_accuracy: 0.8327\n",
      "Epoch 17/50\n",
      "17240/17240 [==============================] - 31s 2ms/sample - loss: 0.5906 - accuracy: 0.8074 - val_loss: 0.4976 - val_accuracy: 0.8330\n",
      "Epoch 18/50\n",
      "17240/17240 [==============================] - 27s 2ms/sample - loss: 0.5855 - accuracy: 0.8080 - val_loss: 0.4908 - val_accuracy: 0.8336\n",
      "Epoch 19/50\n",
      "17240/17240 [==============================] - 35s 2ms/sample - loss: 0.5682 - accuracy: 0.8128 - val_loss: 0.5025 - val_accuracy: 0.8297\n",
      "Epoch 20/50\n",
      "17240/17240 [==============================] - 34s 2ms/sample - loss: 0.5755 - accuracy: 0.8093 - val_loss: 0.4939 - val_accuracy: 0.8271\n",
      "Epoch 21/50\n",
      "17240/17240 [==============================] - 28s 2ms/sample - loss: 0.5639 - accuracy: 0.8153 - val_loss: 0.5176 - val_accuracy: 0.8240\n",
      "Epoch 22/50\n",
      "17240/17240 [==============================] - 28s 2ms/sample - loss: 0.5668 - accuracy: 0.8095 - val_loss: 0.4645 - val_accuracy: 0.8410\n",
      "Epoch 23/50\n",
      "17240/17240 [==============================] - 28s 2ms/sample - loss: 0.5574 - accuracy: 0.8134 - val_loss: 0.5369 - val_accuracy: 0.8169\n",
      "Epoch 24/50\n",
      "17240/17240 [==============================] - 28s 2ms/sample - loss: 0.5626 - accuracy: 0.8161 - val_loss: 0.5361 - val_accuracy: 0.8242\n",
      "Epoch 25/50\n",
      "17240/17240 [==============================] - 28s 2ms/sample - loss: 0.5471 - accuracy: 0.8199 - val_loss: 0.4674 - val_accuracy: 0.8412\n",
      "Epoch 26/50\n",
      "17240/17240 [==============================] - 30s 2ms/sample - loss: 0.5407 - accuracy: 0.8219 - val_loss: 0.5003 - val_accuracy: 0.8306\n",
      "Epoch 27/50\n",
      "17240/17240 [==============================] - 49s 3ms/sample - loss: 0.5335 - accuracy: 0.8241 - val_loss: 0.4599 - val_accuracy: 0.8463\n",
      "Epoch 28/50\n",
      "17240/17240 [==============================] - 31s 2ms/sample - loss: 0.5332 - accuracy: 0.8241 - val_loss: 0.4835 - val_accuracy: 0.8381\n",
      "Epoch 29/50\n",
      "17240/17240 [==============================] - 28s 2ms/sample - loss: 0.5344 - accuracy: 0.8223 - val_loss: 0.4743 - val_accuracy: 0.8447\n",
      "Epoch 30/50\n",
      "17240/17240 [==============================] - 29s 2ms/sample - loss: 0.5111 - accuracy: 0.8292 - val_loss: 0.4699 - val_accuracy: 0.8438\n",
      "Epoch 31/50\n",
      "17240/17240 [==============================] - 28s 2ms/sample - loss: 0.5210 - accuracy: 0.8271 - val_loss: 0.4612 - val_accuracy: 0.8445\n",
      "Epoch 32/50\n",
      "17240/17240 [==============================] - 28s 2ms/sample - loss: 0.5189 - accuracy: 0.8304 - val_loss: 0.4844 - val_accuracy: 0.8299\n",
      "CPU times: user 30min 26s, sys: 19min 22s, total: 49min 49s\n",
      "Wall time: 16min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa5c1ac790>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86       575\n",
      "           1       0.83      0.84      0.84       575\n",
      "           2       0.88      0.83      0.85       575\n",
      "           3       0.88      0.78      0.82       575\n",
      "           4       0.92      0.84      0.88       575\n",
      "           5       0.85      0.91      0.88       575\n",
      "           6       0.76      0.86      0.81       575\n",
      "           7       0.88      0.79      0.83       575\n",
      "           8       0.86      0.79      0.83       575\n",
      "           9       0.84      0.89      0.86       575\n",
      "\n",
      "    accuracy                           0.85      5750\n",
      "   macro avg       0.85      0.85      0.85      5750\n",
      "weighted avg       0.85      0.85      0.85      5750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation, in the MFCC scenario, did not lead to any improvement! Let's see what happens in the spectrograms scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrograms - Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "transform_recordings >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "transform_recordings <<<\n",
      "CPU times: user 5min 2s, sys: 13.2 s, total: 5min 16s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digit, y_train_digit, X_val_digit, y_val_digit, X_test_digit, y_test_digit = data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=max_track_length,\n",
    "                                                                                                                                  load_stored_augm_recs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724 575\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X_train_digit, y_train_digit, X_val_digit, y_val_digit = data_preparation.balanced_train_val_split(np.concatenate([X_train_digit, X_val_digit]),\n",
    "                         np.concatenate([y_train_digit, y_val_digit]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digits_spects_nn, X_val_digits_spects_nn, X_test_digits_spects_nn, y_train_digits_nn, y_val_digits_nn, y_test_digits_nn, input_shape, _= data_preparation.prepare_data_nn(X_train_digit, X_val_digit, X_test_digit, y_train_digit, y_val_digit, y_test_digit, number_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 127, 56, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 127, 56, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 63, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               7225472   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 7,227,562\n",
      "Trainable params: 7,227,242\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 17240 samples, validate on 5750 samples\n",
      "Epoch 1/50\n",
      "17240/17240 [==============================] - 121s 7ms/sample - loss: 1.3827 - accuracy: 0.5428 - val_loss: 0.9861 - val_accuracy: 0.6563\n",
      "Epoch 2/50\n",
      "17240/17240 [==============================] - 114s 7ms/sample - loss: 0.9098 - accuracy: 0.6903 - val_loss: 0.6837 - val_accuracy: 0.7772\n",
      "Epoch 3/50\n",
      "17240/17240 [==============================] - 112s 7ms/sample - loss: 0.7685 - accuracy: 0.7429 - val_loss: 0.6187 - val_accuracy: 0.8035\n",
      "Epoch 4/50\n",
      "17240/17240 [==============================] - 113s 7ms/sample - loss: 0.6729 - accuracy: 0.7787 - val_loss: 0.5579 - val_accuracy: 0.8195\n",
      "Epoch 5/50\n",
      "17240/17240 [==============================] - 112s 7ms/sample - loss: 0.5964 - accuracy: 0.8046 - val_loss: 0.5645 - val_accuracy: 0.8157\n",
      "Epoch 6/50\n",
      "17240/17240 [==============================] - 111s 6ms/sample - loss: 0.5302 - accuracy: 0.8260 - val_loss: 0.5019 - val_accuracy: 0.8365\n",
      "Epoch 7/50\n",
      "17240/17240 [==============================] - 111s 6ms/sample - loss: 0.4903 - accuracy: 0.8392 - val_loss: 0.4980 - val_accuracy: 0.8388\n",
      "Epoch 8/50\n",
      "17240/17240 [==============================] - 112s 6ms/sample - loss: 0.4421 - accuracy: 0.8535 - val_loss: 0.4846 - val_accuracy: 0.8442\n",
      "Epoch 9/50\n",
      "17240/17240 [==============================] - 111s 6ms/sample - loss: 0.4061 - accuracy: 0.8655 - val_loss: 0.4525 - val_accuracy: 0.8517\n",
      "Epoch 10/50\n",
      "17240/17240 [==============================] - 112s 6ms/sample - loss: 0.3680 - accuracy: 0.8810 - val_loss: 0.4718 - val_accuracy: 0.8443\n",
      "Epoch 11/50\n",
      "17240/17240 [==============================] - 112s 7ms/sample - loss: 0.3432 - accuracy: 0.8892 - val_loss: 0.4584 - val_accuracy: 0.8473\n",
      "Epoch 12/50\n",
      "17240/17240 [==============================] - 111s 6ms/sample - loss: 0.3165 - accuracy: 0.8972 - val_loss: 0.4328 - val_accuracy: 0.8617\n",
      "Epoch 13/50\n",
      "17240/17240 [==============================] - 111s 6ms/sample - loss: 0.2873 - accuracy: 0.9084 - val_loss: 0.4637 - val_accuracy: 0.8510\n",
      "Epoch 14/50\n",
      "17240/17240 [==============================] - 112s 7ms/sample - loss: 0.2666 - accuracy: 0.9124 - val_loss: 0.4808 - val_accuracy: 0.8511\n",
      "Epoch 15/50\n",
      "17240/17240 [==============================] - 112s 6ms/sample - loss: 0.2514 - accuracy: 0.9149 - val_loss: 0.4476 - val_accuracy: 0.8565\n",
      "Epoch 16/50\n",
      "17240/17240 [==============================] - 111s 6ms/sample - loss: 0.2151 - accuracy: 0.9311 - val_loss: 0.4747 - val_accuracy: 0.8546\n",
      "Epoch 17/50\n",
      "17240/17240 [==============================] - 112s 6ms/sample - loss: 0.2124 - accuracy: 0.9302 - val_loss: 0.4910 - val_accuracy: 0.8485\n",
      "CPU times: user 1h 21min 51s, sys: 14min 40s, total: 1h 36min 31s\n",
      "Wall time: 31min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9b4d717d0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_spects_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       575\n",
      "           1       0.83      0.88      0.85       575\n",
      "           2       0.89      0.82      0.85       575\n",
      "           3       0.81      0.84      0.82       575\n",
      "           4       0.94      0.87      0.90       575\n",
      "           5       0.92      0.85      0.88       575\n",
      "           6       0.83      0.89      0.86       575\n",
      "           7       0.91      0.81      0.86       575\n",
      "           8       0.89      0.83      0.86       575\n",
      "           9       0.88      0.88      0.88       575\n",
      "\n",
      "    accuracy                           0.86      5750\n",
      "   macro avg       0.87      0.86      0.86      5750\n",
      "weighted avg       0.87      0.86      0.86      5750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are worse than the normal scenarios. Let's try to use a \"custom\" CNN architecture, that has less parameters than this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 608,234\n",
      "Trainable params: 608,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 17240 samples, validate on 5750 samples\n",
      "Epoch 1/50\n",
      "17240/17240 [==============================] - 64s 4ms/sample - loss: 1.6406 - accuracy: 0.4153 - val_loss: 1.1437 - val_accuracy: 0.5977\n",
      "Epoch 2/50\n",
      "17240/17240 [==============================] - 60s 4ms/sample - loss: 1.1020 - accuracy: 0.6121 - val_loss: 0.8780 - val_accuracy: 0.7089\n",
      "Epoch 3/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.9030 - accuracy: 0.6832 - val_loss: 0.6837 - val_accuracy: 0.7699\n",
      "Epoch 4/50\n",
      "17240/17240 [==============================] - 62s 4ms/sample - loss: 0.7804 - accuracy: 0.7260 - val_loss: 0.6492 - val_accuracy: 0.7739\n",
      "Epoch 5/50\n",
      "17240/17240 [==============================] - 63s 4ms/sample - loss: 0.6941 - accuracy: 0.7617 - val_loss: 0.5707 - val_accuracy: 0.7988\n",
      "Epoch 6/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.6434 - accuracy: 0.7744 - val_loss: 0.5152 - val_accuracy: 0.8259\n",
      "Epoch 7/50\n",
      "17240/17240 [==============================] - 59s 3ms/sample - loss: 0.5922 - accuracy: 0.7921 - val_loss: 0.5024 - val_accuracy: 0.8289\n",
      "Epoch 8/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.5519 - accuracy: 0.8067 - val_loss: 0.4515 - val_accuracy: 0.8450\n",
      "Epoch 9/50\n",
      "17240/17240 [==============================] - 60s 3ms/sample - loss: 0.5170 - accuracy: 0.8157 - val_loss: 0.4308 - val_accuracy: 0.8530\n",
      "Epoch 10/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.4920 - accuracy: 0.8270 - val_loss: 0.4817 - val_accuracy: 0.8275\n",
      "Epoch 11/50\n",
      "17240/17240 [==============================] - 62s 4ms/sample - loss: 0.4667 - accuracy: 0.8368 - val_loss: 0.3852 - val_accuracy: 0.8730\n",
      "Epoch 12/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.4544 - accuracy: 0.8382 - val_loss: 0.4022 - val_accuracy: 0.8609\n",
      "Epoch 13/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.4251 - accuracy: 0.8495 - val_loss: 0.3907 - val_accuracy: 0.8626\n",
      "Epoch 14/50\n",
      "17240/17240 [==============================] - 60s 3ms/sample - loss: 0.4154 - accuracy: 0.8538 - val_loss: 0.3924 - val_accuracy: 0.8593\n",
      "Epoch 15/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.3927 - accuracy: 0.8599 - val_loss: 0.3770 - val_accuracy: 0.8650\n",
      "Epoch 16/50\n",
      "17240/17240 [==============================] - 64s 4ms/sample - loss: 0.3774 - accuracy: 0.8673 - val_loss: 0.3527 - val_accuracy: 0.8729\n",
      "Epoch 17/50\n",
      "17240/17240 [==============================] - 62s 4ms/sample - loss: 0.3679 - accuracy: 0.8697 - val_loss: 0.3474 - val_accuracy: 0.8769\n",
      "Epoch 18/50\n",
      "17240/17240 [==============================] - 62s 4ms/sample - loss: 0.3542 - accuracy: 0.8758 - val_loss: 0.3180 - val_accuracy: 0.8896\n",
      "Epoch 19/50\n",
      "17240/17240 [==============================] - 67s 4ms/sample - loss: 0.3475 - accuracy: 0.8739 - val_loss: 0.3292 - val_accuracy: 0.8880\n",
      "Epoch 20/50\n",
      "17240/17240 [==============================] - 58s 3ms/sample - loss: 0.3346 - accuracy: 0.8831 - val_loss: 0.3132 - val_accuracy: 0.8880\n",
      "Epoch 21/50\n",
      "17240/17240 [==============================] - 56s 3ms/sample - loss: 0.3238 - accuracy: 0.8849 - val_loss: 0.3102 - val_accuracy: 0.8894\n",
      "Epoch 22/50\n",
      "17240/17240 [==============================] - 57s 3ms/sample - loss: 0.3076 - accuracy: 0.8951 - val_loss: 0.3214 - val_accuracy: 0.8885\n",
      "Epoch 23/50\n",
      "17240/17240 [==============================] - 58s 3ms/sample - loss: 0.2976 - accuracy: 0.8958 - val_loss: 0.3229 - val_accuracy: 0.8896\n",
      "Epoch 24/50\n",
      "17240/17240 [==============================] - 66s 4ms/sample - loss: 0.2918 - accuracy: 0.8965 - val_loss: 0.3197 - val_accuracy: 0.8856\n",
      "Epoch 25/50\n",
      "17240/17240 [==============================] - 62s 4ms/sample - loss: 0.2837 - accuracy: 0.9005 - val_loss: 0.2882 - val_accuracy: 0.9009\n",
      "Epoch 26/50\n",
      "17240/17240 [==============================] - 63s 4ms/sample - loss: 0.2825 - accuracy: 0.8993 - val_loss: 0.3148 - val_accuracy: 0.8911\n",
      "Epoch 27/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.2691 - accuracy: 0.9044 - val_loss: 0.2993 - val_accuracy: 0.8951\n",
      "Epoch 28/50\n",
      "17240/17240 [==============================] - 67s 4ms/sample - loss: 0.2645 - accuracy: 0.9072 - val_loss: 0.3119 - val_accuracy: 0.8894\n",
      "Epoch 29/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.2508 - accuracy: 0.9113 - val_loss: 0.3057 - val_accuracy: 0.8934\n",
      "Epoch 30/50\n",
      "17240/17240 [==============================] - 61s 4ms/sample - loss: 0.2492 - accuracy: 0.9106 - val_loss: 0.2973 - val_accuracy: 0.8953\n",
      "CPU times: user 1h 27s, sys: 31min 10s, total: 1h 31min 37s\n",
      "Wall time: 30min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faa5d1f7710>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.custom_cnn(input_shape=input_shape, num_classes=10)\n",
    "model.fit(X_train_digits_spects_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       575\n",
      "           1       0.90      0.90      0.90       575\n",
      "           2       0.92      0.85      0.88       575\n",
      "           3       0.80      0.90      0.85       575\n",
      "           4       0.94      0.91      0.93       575\n",
      "           5       0.93      0.91      0.92       575\n",
      "           6       0.89      0.86      0.87       575\n",
      "           7       0.93      0.91      0.92       575\n",
      "           8       0.90      0.92      0.91       575\n",
      "           9       0.93      0.90      0.92       575\n",
      "\n",
      "    accuracy                           0.90      5750\n",
      "   macro avg       0.90      0.90      0.90      5750\n",
      "weighted avg       0.90      0.90      0.90      5750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 48 48\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X_train_digits, y_train_digits, X_val_digits, y_val_digits, X_test_digits, y_test_digits = data_preparation.balanced_train_val_test_split(pad_recordings, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digits_mfcc_nn, X_val_digits_mfcc_nn, X_test_digits_mfcc_nn, y_train_digits_nn, y_val_digits_nn, y_test_digits_nn, input_shape, _= data_preparation.prepare_data_nn(X_train_digits_mfcc, X_val_digits_mfcc, X_test_digits_mfcc, y_train_digits, y_val_digits, y_test_digits, number_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digits_best = np.concatenate([X_train_digits_mfcc_nn, X_val_digits_mfcc_nn])\n",
    "y_train_digits_best = np.concatenate([y_train_digits_nn, y_val_digits_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,480,874\n",
      "Trainable params: 1,480,554\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1910 samples\n",
      "Epoch 1/7\n",
      "1910/1910 [==============================] - 5s 3ms/sample - loss: 0.9958 - accuracy: 0.6874\n",
      "Epoch 2/7\n",
      "1910/1910 [==============================] - 3s 2ms/sample - loss: 0.5132 - accuracy: 0.8613\n",
      "Epoch 3/7\n",
      "1910/1910 [==============================] - 3s 2ms/sample - loss: 0.3722 - accuracy: 0.8974\n",
      "Epoch 4/7\n",
      "1910/1910 [==============================] - 3s 2ms/sample - loss: 0.3029 - accuracy: 0.9277\n",
      "Epoch 5/7\n",
      "1910/1910 [==============================] - 3s 2ms/sample - loss: 0.2543 - accuracy: 0.9372\n",
      "Epoch 6/7\n",
      "1910/1910 [==============================] - 4s 2ms/sample - loss: 0.2179 - accuracy: 0.9550\n",
      "Epoch 7/7\n",
      "1910/1910 [==============================] - 3s 2ms/sample - loss: 0.1952 - accuracy: 0.9628\n",
      "CPU times: user 36 s, sys: 11.2 s, total: 47.2 s\n",
      "Wall time: 26.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa924235b10>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_best, y_train_digits_best,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=7,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn = np.argmax(y_test_digits_nn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test_digits_mfcc_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        49\n",
      "           1       0.96      0.98      0.97        49\n",
      "           2       0.94      0.92      0.93        49\n",
      "           3       0.98      0.84      0.90        49\n",
      "           4       0.96      0.96      0.96        49\n",
      "           5       1.00      0.96      0.98        49\n",
      "           6       0.86      0.98      0.91        49\n",
      "           7       0.87      0.94      0.90        48\n",
      "           8       0.94      0.90      0.92        49\n",
      "           9       0.92      0.98      0.95        48\n",
      "\n",
      "    accuracy                           0.94       488\n",
      "   macro avg       0.94      0.94      0.94       488\n",
      "weighted avg       0.94      0.94      0.94       488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/digits.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speakers\n",
    "## Std - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.2 s, sys: 319 ms, total: 23.6 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 77.7 ms, sys: 5.95 ms, total: 83.7 ms\n",
      "Wall time: 52 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaler_normal = StandardScaler()\n",
    "X_train_speakers_mfcc = scaler_normal.fit_transform(X_train_speakers_mfcc)\n",
    "X_val_speakers_mfcc =  scaler_normal.transform(X_val_speakers_mfcc)\n",
    "X_test_speakers_mfcc =  scaler_normal.transform(X_test_speakers_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_speakers_mfcc, y_train_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.90      0.95        20\n",
      "      alinda       1.00      1.00      1.00        20\n",
      "        gian       1.00      0.95      0.97        20\n",
      "     jackson       1.00      1.00      1.00        20\n",
      "      khaled       0.83      1.00      0.91        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       1.00      0.90      0.95        20\n",
      "    yweweler       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.97      0.97      0.97       160\n",
      "weighted avg       0.97      0.97      0.97       160\n",
      "\n",
      "CPU times: user 125 ms, sys: 2.04 ms, total: 127 ms\n",
      "Wall time: 126 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_speakers_mfcc)\n",
    "print(classification_report(y_val_speakers, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.1 s, sys: 258 ms, total: 22.4 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.91 ms, sys: 4.49 ms, total: 8.4 ms\n",
      "Wall time: 8.08 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc_nn, X_val_speakers_mfcc_nn, X_test_speakers_mfcc_nn, y_train_speakers_nn, y_val_speakers_nn, y_test_speakers_nn, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speakers_mfcc, X_val_speakers_mfcc, X_test_speakers_mfcc, y_train_speakers, y_val_speakers, y_test_speakers, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 1)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 1.2399 - accuracy: 0.5604 - val_loss: 7.6814 - val_accuracy: 0.3688\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.4917 - accuracy: 0.8667 - val_loss: 10.7005 - val_accuracy: 0.2313\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3814 - accuracy: 0.9062 - val_loss: 5.9727 - val_accuracy: 0.2562\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2411 - accuracy: 0.9625 - val_loss: 8.0990 - val_accuracy: 0.1625\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.1904 - accuracy: 0.9604 - val_loss: 4.0015 - val_accuracy: 0.2875\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1562 - accuracy: 0.9708 - val_loss: 4.0630 - val_accuracy: 0.2875\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.1308 - accuracy: 0.9833 - val_loss: 2.2558 - val_accuracy: 0.3750\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.1119 - accuracy: 0.9917 - val_loss: 1.5914 - val_accuracy: 0.5188\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0896 - accuracy: 0.9958 - val_loss: 0.8681 - val_accuracy: 0.6625\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.1005 - accuracy: 0.9854 - val_loss: 1.3468 - val_accuracy: 0.5188\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0815 - accuracy: 0.9896 - val_loss: 0.5625 - val_accuracy: 0.7063\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0808 - accuracy: 0.9833 - val_loss: 0.2140 - val_accuracy: 0.9625\n",
      "Epoch 13/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0714 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9750\n",
      "Epoch 14/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0604 - accuracy: 0.9958 - val_loss: 0.1248 - val_accuracy: 0.9750\n",
      "Epoch 15/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0611 - accuracy: 0.9937 - val_loss: 0.0770 - val_accuracy: 0.9937\n",
      "Epoch 16/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0466 - accuracy: 0.9979 - val_loss: 0.0882 - val_accuracy: 0.9937\n",
      "Epoch 17/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0534 - accuracy: 0.9958 - val_loss: 0.0918 - val_accuracy: 0.9812\n",
      "Epoch 18/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0542 - accuracy: 0.9958 - val_loss: 0.0652 - val_accuracy: 0.9937\n",
      "Epoch 19/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0515 - accuracy: 0.9937 - val_loss: 0.0603 - val_accuracy: 0.9937\n",
      "Epoch 20/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0572 - accuracy: 0.9958 - val_loss: 0.0592 - val_accuracy: 0.9937\n",
      "Epoch 21/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0375 - accuracy: 0.9979 - val_loss: 0.0776 - val_accuracy: 0.9812\n",
      "Epoch 22/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0402 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9937\n",
      "Epoch 23/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9937\n",
      "Epoch 24/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0354 - accuracy: 0.9979 - val_loss: 0.0550 - val_accuracy: 0.9937\n",
      "Epoch 25/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0347 - accuracy: 0.9979 - val_loss: 0.0490 - val_accuracy: 0.9937\n",
      "Epoch 26/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0324 - accuracy: 0.9979 - val_loss: 0.0520 - val_accuracy: 0.9875\n",
      "Epoch 27/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9812\n",
      "Epoch 28/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 0.9937\n",
      "Epoch 29/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0292 - accuracy: 0.9958 - val_loss: 0.0413 - val_accuracy: 0.9937\n",
      "Epoch 30/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0320 - accuracy: 0.9979 - val_loss: 0.0456 - val_accuracy: 0.9937\n",
      "Epoch 31/50\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0272 - accuracy: 0.9979 - val_loss: 0.0428 - val_accuracy: 0.9937\n",
      "Epoch 32/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9937\n",
      "Epoch 33/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9937\n",
      "Epoch 34/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9937\n",
      "CPU times: user 56 s, sys: 17.6 s, total: 1min 13s\n",
      "Wall time: 42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa93085a050>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)\n",
    "model.fit(X_train_speakers_mfcc_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "         callbacks=[callback],\n",
    "         validation_data=(X_val_speakers_mfcc_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get full performances on val set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      1.00      1.00        20\n",
      "      alinda       0.95      1.00      0.98        20\n",
      "        gian       1.00      0.95      0.97        20\n",
      "     jackson       1.00      1.00      1.00        20\n",
      "      khaled       1.00      1.00      1.00        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       1.00      1.00      1.00        20\n",
      "    yweweler       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           0.99       160\n",
      "   macro avg       0.99      0.99      0.99       160\n",
      "weighted avg       0.99      0.99      0.99       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent performances! Let's now see what happens with spectrograms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Std - Spects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 s, sys: 344 ms, total: 18.2 s\n",
      "Wall time: 9.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_train_speakers])\n",
    "X_val_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_val_speakers])\n",
    "X_test_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speakers_spects.shape\n",
    "X_train_speakers_spects_2d = X_train_speakers_spects.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_speakers_spects.shape\n",
    "X_val_speakers_spects_2d = X_val_speakers_spects.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_test_speakers_spects.shape\n",
    "X_test_speakers_spects_2d = X_test_speakers_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_speakers_spects_2d, y_train_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      0.90      0.92        20\n",
      "      alinda       1.00      1.00      1.00        20\n",
      "        gian       1.00      0.95      0.97        20\n",
      "     jackson       1.00      1.00      1.00        20\n",
      "      khaled       0.95      1.00      0.98        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       0.81      0.85      0.83        20\n",
      "    yweweler       0.90      0.90      0.90        20\n",
      "\n",
      "    accuracy                           0.95       160\n",
      "   macro avg       0.95      0.95      0.95       160\n",
      "weighted avg       0.95      0.95      0.95       160\n",
      "\n",
      "CPU times: user 539 ms, sys: 6.61 ms, total: 546 ms\n",
      "Wall time: 550 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_speakers_spects_2d)\n",
    "print(classification_report(y_val_speakers, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances are good but not at the level of MFCC: let's use the three different CNN architectures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speakers_spects_nn, X_val_speakers_spects_nn, X_test_speakers_spects_nn, y_train_speakers_nn, y_val_speakers_nn, y_test_speakers_nn, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speakers_spects, X_val_speakers_spects, X_test_speakers_spects, y_train_speakers, y_val_speakers, y_test_speakers, number_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 67,744\n",
      "Trainable params: 67,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 2.0844 - accuracy: 0.1167 - val_loss: 2.0549 - val_accuracy: 0.2188\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0660 - accuracy: 0.1583 - val_loss: 2.0395 - val_accuracy: 0.2000\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0444 - accuracy: 0.1521 - val_loss: 2.0225 - val_accuracy: 0.1875\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0426 - accuracy: 0.1583 - val_loss: 2.0068 - val_accuracy: 0.2000\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0170 - accuracy: 0.1917 - val_loss: 1.9829 - val_accuracy: 0.2313\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0073 - accuracy: 0.1813 - val_loss: 1.9637 - val_accuracy: 0.2688\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.9980 - accuracy: 0.2062 - val_loss: 1.9411 - val_accuracy: 0.3187\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.9885 - accuracy: 0.2146 - val_loss: 1.9194 - val_accuracy: 0.2875\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.9653 - accuracy: 0.2146 - val_loss: 1.8922 - val_accuracy: 0.3000\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.9408 - accuracy: 0.2438 - val_loss: 1.8820 - val_accuracy: 0.1937\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.9234 - accuracy: 0.2542 - val_loss: 1.8371 - val_accuracy: 0.3375\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.8916 - accuracy: 0.2688 - val_loss: 1.8110 - val_accuracy: 0.2625\n",
      "Epoch 13/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8745 - accuracy: 0.2937 - val_loss: 1.7775 - val_accuracy: 0.3375\n",
      "Epoch 14/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8304 - accuracy: 0.3146 - val_loss: 1.7355 - val_accuracy: 0.4313\n",
      "Epoch 15/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.7916 - accuracy: 0.3208 - val_loss: 1.7385 - val_accuracy: 0.3000\n",
      "Epoch 16/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7850 - accuracy: 0.3479 - val_loss: 1.6252 - val_accuracy: 0.4625\n",
      "Epoch 17/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7225 - accuracy: 0.3708 - val_loss: 1.6079 - val_accuracy: 0.4938\n",
      "Epoch 18/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.7064 - accuracy: 0.3375 - val_loss: 1.5878 - val_accuracy: 0.4125\n",
      "Epoch 19/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.6989 - accuracy: 0.3896 - val_loss: 1.5251 - val_accuracy: 0.4875\n",
      "Epoch 20/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.6243 - accuracy: 0.4062 - val_loss: 1.5245 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.6236 - accuracy: 0.4083 - val_loss: 1.4011 - val_accuracy: 0.5813\n",
      "Epoch 22/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5598 - accuracy: 0.4437 - val_loss: 1.3845 - val_accuracy: 0.6438\n",
      "Epoch 23/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.4844 - accuracy: 0.4729 - val_loss: 1.2791 - val_accuracy: 0.6500\n",
      "Epoch 24/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5621 - accuracy: 0.4146 - val_loss: 1.2673 - val_accuracy: 0.6375\n",
      "Epoch 25/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.4597 - accuracy: 0.4646 - val_loss: 1.3724 - val_accuracy: 0.4875\n",
      "Epoch 26/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.4393 - accuracy: 0.4771 - val_loss: 1.2036 - val_accuracy: 0.5750\n",
      "Epoch 27/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.4720 - accuracy: 0.4604 - val_loss: 1.1577 - val_accuracy: 0.7063\n",
      "Epoch 28/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3357 - accuracy: 0.5375 - val_loss: 1.1579 - val_accuracy: 0.5875\n",
      "Epoch 29/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3579 - accuracy: 0.5042 - val_loss: 1.0666 - val_accuracy: 0.6500\n",
      "Epoch 30/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.2381 - accuracy: 0.5688 - val_loss: 0.9705 - val_accuracy: 0.7250\n",
      "Epoch 31/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1872 - accuracy: 0.5917 - val_loss: 0.9114 - val_accuracy: 0.7312\n",
      "Epoch 32/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1676 - accuracy: 0.5729 - val_loss: 0.8607 - val_accuracy: 0.7688\n",
      "Epoch 33/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1587 - accuracy: 0.5813 - val_loss: 0.8500 - val_accuracy: 0.7437\n",
      "Epoch 34/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.0715 - accuracy: 0.6187 - val_loss: 0.9229 - val_accuracy: 0.6875\n",
      "Epoch 35/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 1.1622 - accuracy: 0.5562 - val_loss: 0.8889 - val_accuracy: 0.7188\n",
      "Epoch 36/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.0430 - accuracy: 0.6187 - val_loss: 0.7712 - val_accuracy: 0.7875\n",
      "Epoch 37/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.0282 - accuracy: 0.6208 - val_loss: 0.7325 - val_accuracy: 0.7750\n",
      "Epoch 38/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0651 - accuracy: 0.6187 - val_loss: 0.6818 - val_accuracy: 0.8313\n",
      "Epoch 39/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9560 - accuracy: 0.6562 - val_loss: 0.6727 - val_accuracy: 0.7688\n",
      "Epoch 40/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9425 - accuracy: 0.6625 - val_loss: 0.6479 - val_accuracy: 0.8125\n",
      "Epoch 41/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0478 - accuracy: 0.6229 - val_loss: 0.6734 - val_accuracy: 0.8250\n",
      "Epoch 42/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9206 - accuracy: 0.6646 - val_loss: 0.6397 - val_accuracy: 0.8062\n",
      "Epoch 43/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8554 - accuracy: 0.7146 - val_loss: 0.5905 - val_accuracy: 0.8188\n",
      "Epoch 44/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0114 - accuracy: 0.6313 - val_loss: 0.6389 - val_accuracy: 0.8000\n",
      "Epoch 45/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7946 - accuracy: 0.7271 - val_loss: 0.6695 - val_accuracy: 0.7750\n",
      "Epoch 46/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8577 - accuracy: 0.6875 - val_loss: 0.5866 - val_accuracy: 0.8313\n",
      "Epoch 47/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.8036 - accuracy: 0.7083 - val_loss: 0.5842 - val_accuracy: 0.8000\n",
      "Epoch 48/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.8090 - accuracy: 0.7125 - val_loss: 0.5019 - val_accuracy: 0.8938\n",
      "Epoch 49/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7613 - accuracy: 0.7104 - val_loss: 0.5040 - val_accuracy: 0.8625\n",
      "Epoch 50/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7779 - accuracy: 0.7188 - val_loss: 0.4966 - val_accuracy: 0.8375\n",
      "CPU times: user 1min 40s, sys: 56.3 s, total: 2min 37s\n",
      "Wall time: 1min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9423a4590>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.80      0.89        25\n",
      "      alinda       0.85      0.74      0.79        23\n",
      "        gian       0.55      1.00      0.71        11\n",
      "     jackson       0.90      1.00      0.95        18\n",
      "      khaled       0.95      0.90      0.93        21\n",
      "     nicolas       0.90      0.86      0.88        21\n",
      "        theo       0.65      0.87      0.74        15\n",
      "    yweweler       0.90      0.69      0.78        26\n",
      "\n",
      "    accuracy                           0.84       160\n",
      "   macro avg       0.84      0.86      0.83       160\n",
      "weighted avg       0.87      0.84      0.84       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with the Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 2.3114 - accuracy: 0.1917 - val_loss: 2.0066 - val_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7008 - accuracy: 0.3771 - val_loss: 1.8819 - val_accuracy: 0.4812\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5564 - accuracy: 0.4271 - val_loss: 1.8362 - val_accuracy: 0.3938\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.2898 - accuracy: 0.5208 - val_loss: 1.7929 - val_accuracy: 0.4500\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1370 - accuracy: 0.6062 - val_loss: 1.8261 - val_accuracy: 0.3625\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0083 - accuracy: 0.6646 - val_loss: 1.8153 - val_accuracy: 0.3562\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8819 - accuracy: 0.7104 - val_loss: 1.8767 - val_accuracy: 0.2250\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8652 - accuracy: 0.7333 - val_loss: 1.9084 - val_accuracy: 0.2000\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7942 - accuracy: 0.7500 - val_loss: 1.8865 - val_accuracy: 0.1937\n",
      "CPU times: user 25.6 s, sys: 22.2 s, total: 47.9 s\n",
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa943690a90>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.20      1.00      0.33         4\n",
      "      alinda       0.00      0.00      0.00         0\n",
      "        gian       0.75      0.30      0.43        50\n",
      "     jackson       0.45      0.82      0.58        11\n",
      "      khaled       0.80      0.48      0.60        33\n",
      "     nicolas       0.00      0.00      0.00         2\n",
      "        theo       0.40      0.89      0.55         9\n",
      "    yweweler       1.00      0.39      0.56        51\n",
      "\n",
      "    accuracy                           0.45       160\n",
      "   macro avg       0.45      0.49      0.38       160\n",
      "weighted avg       0.78      0.45      0.52       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 127, 56, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 127, 56, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 63, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 128)               7225472   \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 7,227,304\n",
      "Trainable params: 7,226,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 1.0804 - accuracy: 0.6604 - val_loss: 1.4463 - val_accuracy: 0.9000\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.3908 - accuracy: 0.9062 - val_loss: 1.5053 - val_accuracy: 0.6562\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.2770 - accuracy: 0.9250 - val_loss: 1.5952 - val_accuracy: 0.3938\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.1800 - accuracy: 0.9521 - val_loss: 1.6516 - val_accuracy: 0.3688\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.1178 - accuracy: 0.9771 - val_loss: 1.7115 - val_accuracy: 0.3688\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0997 - accuracy: 0.9792 - val_loss: 1.7418 - val_accuracy: 0.3250\n",
      "CPU times: user 54.8 s, sys: 6.58 s, total: 1min 1s\n",
      "Wall time: 19.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9459943d0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.85      1.00      0.92        17\n",
      "      alinda       0.95      1.00      0.97        19\n",
      "        gian       0.85      1.00      0.92        17\n",
      "     jackson       1.00      0.87      0.93        23\n",
      "      khaled       1.00      0.77      0.87        26\n",
      "     nicolas       0.90      1.00      0.95        18\n",
      "        theo       0.80      0.80      0.80        20\n",
      "    yweweler       0.85      0.85      0.85        20\n",
      "\n",
      "    accuracy                           0.90       160\n",
      "   macro avg       0.90      0.91      0.90       160\n",
      "weighted avg       0.91      0.90      0.90       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the CNN models, the last one is the one that looks better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "transform_recordings >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "transform_recordings <<<\n",
      "CPU times: user 3min 53s, sys: 9.34 s, total: 4min 3s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(\n",
    "    audio_dirs= [our_recs_dir, fsdd_dir],\n",
    "    y_type= ['speakers_us', 'speakers_default'],\n",
    "    n_category_test=30,\n",
    "    include_pitch=False,\n",
    "    max_length=17000,\n",
    "    transform_function=\"mfcc\",\n",
    "    load_stored_augm_recs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315 105\n",
      "ale\n",
      "alinda\n",
      "gian\n",
      "jackson\n",
      "khaled\n",
      "nicolas\n",
      "theo\n",
      "yweweler\n",
      "CPU times: user 45.9 ms, sys: 45.1 ms, total: 90.9 ms\n",
      "Wall time: 90.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker = data_preparation.balanced_train_val_split(np.concatenate([X_train_speaker, X_val_speaker]),\n",
    "                         np.concatenate([y_train_speaker, y_val_speaker]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520, 40, 40)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_speaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal = StandardScaler()\n",
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_scaled = scaler_normal.fit_transform(X_train_speaker.reshape((nsamples, nx * ny)))\n",
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_scaled =  scaler_normal.transform(X_val_speaker.reshape((nsamples, nx * ny)))\n",
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_scaled =  scaler_normal.transform(X_test_speaker.reshape((nsamples, nx * ny)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.26 s, sys: 63.4 ms, total: 8.32 s\n",
      "Wall time: 8.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker_normal.fit(X_train_speaker_scaled, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.88      0.98      0.92        94\n",
      "      alinda       0.91      0.94      0.93       102\n",
      "        gian       0.93      0.95      0.94       103\n",
      "     jackson       0.92      0.97      0.95       100\n",
      "      khaled       0.95      0.75      0.84       134\n",
      "     nicolas       0.95      0.95      0.95       105\n",
      "        theo       0.62      0.79      0.70        82\n",
      "    yweweler       0.84      0.73      0.78       120\n",
      "\n",
      "    accuracy                           0.88       840\n",
      "   macro avg       0.88      0.88      0.88       840\n",
      "weighted avg       0.88      0.88      0.88       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_speaker_normal.predict(X_val_speaker_scaled)\n",
    "print(classification_report(y_pred, y_val_speaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker_nn, X_val_speaker_nn, X_test_speaker, y_train_speaker_nn, y_val_speaker_nn, y_test_speaker_nn, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speaker, X_val_speaker, X_test_speaker, y_train_speaker, y_val_speaker, y_test_speaker, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 1)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2520 samples, validate on 840 samples\n",
      "Epoch 1/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 1.0889 - accuracy: 0.6218 - val_loss: 5.2176 - val_accuracy: 0.2881\n",
      "Epoch 2/50\n",
      "2520/2520 [==============================] - 4s 2ms/sample - loss: 0.6407 - accuracy: 0.7929 - val_loss: 2.4716 - val_accuracy: 0.3655\n",
      "Epoch 3/50\n",
      "2520/2520 [==============================] - 4s 2ms/sample - loss: 0.5377 - accuracy: 0.8349 - val_loss: 0.7903 - val_accuracy: 0.6940\n",
      "Epoch 4/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.4650 - accuracy: 0.8599 - val_loss: 0.9962 - val_accuracy: 0.6643\n",
      "Epoch 5/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.4336 - accuracy: 0.8651 - val_loss: 0.5721 - val_accuracy: 0.7845\n",
      "Epoch 6/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.4095 - accuracy: 0.8817 - val_loss: 0.4695 - val_accuracy: 0.8476\n",
      "Epoch 7/50\n",
      "2520/2520 [==============================] - 6s 2ms/sample - loss: 0.3757 - accuracy: 0.8897 - val_loss: 0.7307 - val_accuracy: 0.7429\n",
      "Epoch 8/50\n",
      "2520/2520 [==============================] - 6s 2ms/sample - loss: 0.3459 - accuracy: 0.9000 - val_loss: 0.6642 - val_accuracy: 0.7774\n",
      "Epoch 9/50\n",
      "2520/2520 [==============================] - 6s 2ms/sample - loss: 0.3511 - accuracy: 0.8933 - val_loss: 0.3746 - val_accuracy: 0.8881\n",
      "Epoch 10/50\n",
      "2520/2520 [==============================] - 6s 3ms/sample - loss: 0.3124 - accuracy: 0.9087 - val_loss: 0.4569 - val_accuracy: 0.8702\n",
      "Epoch 11/50\n",
      "2520/2520 [==============================] - 6s 2ms/sample - loss: 0.3046 - accuracy: 0.9147 - val_loss: 0.4192 - val_accuracy: 0.8821\n",
      "Epoch 12/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2904 - accuracy: 0.9159 - val_loss: 0.3168 - val_accuracy: 0.8988\n",
      "Epoch 13/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2676 - accuracy: 0.9250 - val_loss: 0.3817 - val_accuracy: 0.8750\n",
      "Epoch 14/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2564 - accuracy: 0.9274 - val_loss: 0.2971 - val_accuracy: 0.9024\n",
      "Epoch 15/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2511 - accuracy: 0.9310 - val_loss: 0.2889 - val_accuracy: 0.9071\n",
      "Epoch 16/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2289 - accuracy: 0.9325 - val_loss: 0.2687 - val_accuracy: 0.9119\n",
      "Epoch 17/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2341 - accuracy: 0.9373 - val_loss: 1.0219 - val_accuracy: 0.6750\n",
      "Epoch 18/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2576 - accuracy: 0.9234 - val_loss: 0.2921 - val_accuracy: 0.9071\n",
      "Epoch 19/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2325 - accuracy: 0.9341 - val_loss: 0.3283 - val_accuracy: 0.9048\n",
      "Epoch 20/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2191 - accuracy: 0.9365 - val_loss: 0.3200 - val_accuracy: 0.8952\n",
      "Epoch 21/50\n",
      "2520/2520 [==============================] - 5s 2ms/sample - loss: 0.2083 - accuracy: 0.9405 - val_loss: 0.3751 - val_accuracy: 0.8750\n",
      "CPU times: user 2min 51s, sys: 1min 19s, total: 4min 11s\n",
      "Wall time: 1min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa8c2ed76d0>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker_nn, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker_nn, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.96      1.00      0.98       105\n",
      "      alinda       0.95      0.97      0.96       105\n",
      "        gian       0.94      0.94      0.94       105\n",
      "     jackson       1.00      0.99      1.00       105\n",
      "      khaled       0.98      0.92      0.95       105\n",
      "     nicolas       0.89      0.98      0.93       105\n",
      "        theo       0.71      0.84      0.77       105\n",
      "    yweweler       0.89      0.65      0.75       105\n",
      "\n",
      "    accuracy                           0.91       840\n",
      "   macro avg       0.92      0.91      0.91       840\n",
      "weighted avg       0.92      0.91      0.91       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - Spects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "transform_recordings >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "transform_recordings <<<\n",
      "CPU times: user 3min 31s, sys: 9.36 s, total: 3min 41s\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(\n",
    "    audio_dirs= [our_recs_dir, fsdd_dir],\n",
    "    y_type= ['speakers_us', 'speakers_default'],\n",
    "    n_category_test=30,\n",
    "    include_pitch=False,\n",
    "    max_length=17000,\n",
    "    transform_function=\"spectrogram\",\n",
    "    load_stored_augm_recs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315 105\n",
      "ale\n",
      "alinda\n",
      "gian\n",
      "jackson\n",
      "khaled\n",
      "nicolas\n",
      "theo\n",
      "yweweler\n",
      "CPU times: user 167 ms, sys: 168 ms, total: 335 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker = data_preparation.balanced_train_val_split(np.concatenate([X_train_speaker, X_val_speaker]),\n",
    "                         np.concatenate([y_train_speaker, y_val_speaker]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_2d = X_train_speaker.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_2d = X_val_speaker.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_2d = X_test_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.5 s, sys: 369 ms, total: 33.8 s\n",
      "Wall time: 36.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker.fit(X_train_speaker_2d, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.93      0.91      0.92       108\n",
      "      alinda       0.91      0.97      0.94        99\n",
      "        gian       0.99      0.97      0.98       107\n",
      "     jackson       0.98      0.98      0.98       105\n",
      "      khaled       0.93      0.94      0.94       104\n",
      "     nicolas       0.95      0.92      0.93       109\n",
      "        theo       0.74      0.72      0.73       108\n",
      "    yweweler       0.72      0.76      0.74       100\n",
      "\n",
      "    accuracy                           0.90       840\n",
      "   macro avg       0.90      0.90      0.90       840\n",
      "weighted avg       0.90      0.90      0.90       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_speaker.predict(X_val_speaker_2d)\n",
    "print(classification_report(y_pred, y_val_speaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker, X_val_speaker, X_test_speaker, y_train_speaker_nn, y_val_speaker_nn, y_test_speaker_nn, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speaker, X_val_speaker, X_test_speaker, y_train_speaker, y_val_speaker, y_test_speaker, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520, 128, 57, 1)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_speaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 127, 56, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 127, 56, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 63, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 128)               7225472   \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 7,227,304\n",
      "Trainable params: 7,226,984\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2520 samples, validate on 840 samples\n",
      "Epoch 1/50\n",
      "2520/2520 [==============================] - 21s 8ms/sample - loss: 1.1486 - accuracy: 0.6222 - val_loss: 1.7398 - val_accuracy: 0.2405\n",
      "Epoch 2/50\n",
      "2520/2520 [==============================] - 22s 9ms/sample - loss: 0.4944 - accuracy: 0.8405 - val_loss: 1.7576 - val_accuracy: 0.3190\n",
      "Epoch 3/50\n",
      "2520/2520 [==============================] - 25s 10ms/sample - loss: 0.3206 - accuracy: 0.8976 - val_loss: 1.4508 - val_accuracy: 0.3893\n",
      "Epoch 4/50\n",
      "2520/2520 [==============================] - 18s 7ms/sample - loss: 0.2317 - accuracy: 0.9250 - val_loss: 1.1455 - val_accuracy: 0.5440\n",
      "Epoch 5/50\n",
      "2520/2520 [==============================] - 18s 7ms/sample - loss: 0.1959 - accuracy: 0.9409 - val_loss: 0.7091 - val_accuracy: 0.7440\n",
      "Epoch 6/50\n",
      "2520/2520 [==============================] - 17s 7ms/sample - loss: 0.1406 - accuracy: 0.9643 - val_loss: 0.5290 - val_accuracy: 0.8179\n",
      "Epoch 7/50\n",
      "2520/2520 [==============================] - 17s 7ms/sample - loss: 0.1717 - accuracy: 0.9548 - val_loss: 0.3712 - val_accuracy: 0.8798\n",
      "Epoch 8/50\n",
      "2520/2520 [==============================] - 17s 7ms/sample - loss: 0.1079 - accuracy: 0.9726 - val_loss: 0.4004 - val_accuracy: 0.8548\n",
      "Epoch 9/50\n",
      "2520/2520 [==============================] - 17s 7ms/sample - loss: 0.1166 - accuracy: 0.9698 - val_loss: 0.2048 - val_accuracy: 0.9321\n",
      "Epoch 10/50\n",
      "2520/2520 [==============================] - 19s 7ms/sample - loss: 0.0675 - accuracy: 0.9893 - val_loss: 0.1842 - val_accuracy: 0.9452\n",
      "Epoch 11/50\n",
      "2520/2520 [==============================] - 19s 7ms/sample - loss: 0.0569 - accuracy: 0.9933 - val_loss: 0.3355 - val_accuracy: 0.9048\n",
      "Epoch 12/50\n",
      "2520/2520 [==============================] - 16s 7ms/sample - loss: 0.0584 - accuracy: 0.9881 - val_loss: 0.1926 - val_accuracy: 0.9476\n",
      "Epoch 13/50\n",
      "2520/2520 [==============================] - 17s 7ms/sample - loss: 0.0485 - accuracy: 0.9937 - val_loss: 0.1743 - val_accuracy: 0.9452\n",
      "Epoch 14/50\n",
      "2520/2520 [==============================] - 18s 7ms/sample - loss: 0.0391 - accuracy: 0.9944 - val_loss: 0.1714 - val_accuracy: 0.9488\n",
      "Epoch 15/50\n",
      "2520/2520 [==============================] - 19s 7ms/sample - loss: 0.0365 - accuracy: 0.9960 - val_loss: 0.1748 - val_accuracy: 0.9429\n",
      "Epoch 16/50\n",
      "2520/2520 [==============================] - 16s 6ms/sample - loss: 0.0311 - accuracy: 0.9968 - val_loss: 0.1666 - val_accuracy: 0.9452\n",
      "Epoch 17/50\n",
      "2520/2520 [==============================] - 17s 7ms/sample - loss: 0.0270 - accuracy: 0.9980 - val_loss: 0.1737 - val_accuracy: 0.9417\n",
      "Epoch 18/50\n",
      "2520/2520 [==============================] - 19s 8ms/sample - loss: 0.0257 - accuracy: 0.9972 - val_loss: 0.1775 - val_accuracy: 0.9440\n",
      "Epoch 19/50\n",
      "2520/2520 [==============================] - 19s 8ms/sample - loss: 0.0246 - accuracy: 0.9988 - val_loss: 0.1856 - val_accuracy: 0.9464\n",
      "Epoch 20/50\n",
      "2520/2520 [==============================] - 19s 8ms/sample - loss: 0.0197 - accuracy: 0.9992 - val_loss: 0.1729 - val_accuracy: 0.9452\n",
      "Epoch 21/50\n",
      "2520/2520 [==============================] - 20s 8ms/sample - loss: 0.0209 - accuracy: 0.9976 - val_loss: 0.1838 - val_accuracy: 0.9452\n",
      "CPU times: user 15min 57s, sys: 2min 14s, total: 18min 12s\n",
      "Wall time: 6min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa8c6923e90>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.99      0.98      0.99       106\n",
      "      alinda       0.99      0.99      0.99       105\n",
      "        gian       1.00      0.99      1.00       106\n",
      "     jackson       0.99      1.00      1.00       104\n",
      "      khaled       1.00      0.98      0.99       107\n",
      "     nicolas       0.98      1.00      0.99       103\n",
      "        theo       0.80      0.79      0.80       106\n",
      "    yweweler       0.81      0.83      0.82       103\n",
      "\n",
      "    accuracy                           0.95       840\n",
      "   macro avg       0.95      0.95      0.95       840\n",
      "weighted avg       0.95      0.95      0.95       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "model = cnn_models.paper_architecture(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2520 samples, validate on 840 samples\n",
      "Epoch 1/50\n",
      "2520/2520 [==============================] - 14s 5ms/sample - loss: 1.8152 - accuracy: 0.3317 - val_loss: 1.9131 - val_accuracy: 0.2274\n",
      "Epoch 2/50\n",
      "2520/2520 [==============================] - 7s 3ms/sample - loss: 1.2912 - accuracy: 0.5163 - val_loss: 1.8492 - val_accuracy: 0.1940\n",
      "Epoch 3/50\n",
      "2520/2520 [==============================] - 8s 3ms/sample - loss: 1.0867 - accuracy: 0.6032 - val_loss: 1.6320 - val_accuracy: 0.3250\n",
      "Epoch 4/50\n",
      "2520/2520 [==============================] - 8s 3ms/sample - loss: 0.9213 - accuracy: 0.6782 - val_loss: 1.2181 - val_accuracy: 0.5202\n",
      "Epoch 5/50\n",
      "2520/2520 [==============================] - 8s 3ms/sample - loss: 0.7987 - accuracy: 0.7234 - val_loss: 0.9976 - val_accuracy: 0.6190\n",
      "Epoch 6/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.7169 - accuracy: 0.7583 - val_loss: 0.6695 - val_accuracy: 0.7881\n",
      "Epoch 7/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.6431 - accuracy: 0.7833 - val_loss: 0.5173 - val_accuracy: 0.8524\n",
      "Epoch 8/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.5724 - accuracy: 0.8135 - val_loss: 1.0112 - val_accuracy: 0.6536\n",
      "Epoch 9/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.5425 - accuracy: 0.8226 - val_loss: 0.4656 - val_accuracy: 0.8512\n",
      "Epoch 10/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.5049 - accuracy: 0.8258 - val_loss: 0.9488 - val_accuracy: 0.6679\n",
      "Epoch 11/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.4796 - accuracy: 0.8385 - val_loss: 0.3868 - val_accuracy: 0.8798\n",
      "Epoch 12/50\n",
      "2520/2520 [==============================] - 10s 4ms/sample - loss: 0.4450 - accuracy: 0.8464 - val_loss: 1.1617 - val_accuracy: 0.6202\n",
      "Epoch 13/50\n",
      "2520/2520 [==============================] - 10s 4ms/sample - loss: 0.4424 - accuracy: 0.8532 - val_loss: 0.4372 - val_accuracy: 0.8500\n",
      "Epoch 14/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.4145 - accuracy: 0.8571 - val_loss: 0.7987 - val_accuracy: 0.7333\n",
      "Epoch 15/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.3905 - accuracy: 0.8702 - val_loss: 0.3415 - val_accuracy: 0.8893\n",
      "Epoch 16/50\n",
      "2520/2520 [==============================] - 10s 4ms/sample - loss: 0.3862 - accuracy: 0.8675 - val_loss: 0.4177 - val_accuracy: 0.8667\n",
      "Epoch 17/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.3739 - accuracy: 0.8734 - val_loss: 0.5690 - val_accuracy: 0.7905\n",
      "Epoch 18/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.3650 - accuracy: 0.8758 - val_loss: 0.3439 - val_accuracy: 0.8798\n",
      "Epoch 19/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.3519 - accuracy: 0.8790 - val_loss: 0.2904 - val_accuracy: 0.9024\n",
      "Epoch 20/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.3336 - accuracy: 0.8869 - val_loss: 0.3981 - val_accuracy: 0.8619\n",
      "Epoch 21/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.3029 - accuracy: 0.8968 - val_loss: 0.3297 - val_accuracy: 0.9012\n",
      "Epoch 22/50\n",
      "2520/2520 [==============================] - 10s 4ms/sample - loss: 0.3071 - accuracy: 0.8996 - val_loss: 0.3860 - val_accuracy: 0.8643\n",
      "Epoch 23/50\n",
      "2520/2520 [==============================] - 8s 3ms/sample - loss: 0.3035 - accuracy: 0.8992 - val_loss: 0.3005 - val_accuracy: 0.8976\n",
      "Epoch 24/50\n",
      "2520/2520 [==============================] - 8s 3ms/sample - loss: 0.2631 - accuracy: 0.9131 - val_loss: 0.3797 - val_accuracy: 0.8714\n",
      "CPU times: user 4min 24s, sys: 2min 2s, total: 6min 26s\n",
      "Wall time: 4min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa89cf6e9d0>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.99      0.97      0.98       107\n",
      "      alinda       0.97      0.96      0.97       106\n",
      "        gian       0.96      0.99      0.98       102\n",
      "     jackson       0.99      0.87      0.93       119\n",
      "      khaled       0.92      0.99      0.96        98\n",
      "     nicolas       0.90      0.99      0.95        96\n",
      "        theo       0.80      0.71      0.75       119\n",
      "    yweweler       0.68      0.76      0.72        93\n",
      "\n",
      "    accuracy                           0.90       840\n",
      "   macro avg       0.90      0.91      0.90       840\n",
      "weighted avg       0.91      0.90      0.90       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 607,976\n",
      "Trainable params: 607,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "model = cnn_models.custom_cnn(num_classes=8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2520 samples, validate on 840 samples\n",
      "Epoch 1/50\n",
      "2520/2520 [==============================] - 10s 4ms/sample - loss: 1.9685 - accuracy: 0.2333 - val_loss: 1.8977 - val_accuracy: 0.2393\n",
      "Epoch 2/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 1.6658 - accuracy: 0.3722 - val_loss: 1.4796 - val_accuracy: 0.4881\n",
      "Epoch 3/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 1.4156 - accuracy: 0.4536 - val_loss: 1.7788 - val_accuracy: 0.2952\n",
      "Epoch 4/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 1.1699 - accuracy: 0.5663 - val_loss: 1.0941 - val_accuracy: 0.6238\n",
      "Epoch 5/50\n",
      "2520/2520 [==============================] - 10s 4ms/sample - loss: 0.9520 - accuracy: 0.6532 - val_loss: 1.3390 - val_accuracy: 0.5702\n",
      "Epoch 6/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.7836 - accuracy: 0.7262 - val_loss: 0.9528 - val_accuracy: 0.6738\n",
      "Epoch 7/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.6662 - accuracy: 0.7651 - val_loss: 0.5870 - val_accuracy: 0.8143\n",
      "Epoch 8/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.5441 - accuracy: 0.8032 - val_loss: 0.4323 - val_accuracy: 0.8643\n",
      "Epoch 9/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.4661 - accuracy: 0.8313 - val_loss: 0.5571 - val_accuracy: 0.7940\n",
      "Epoch 10/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.4028 - accuracy: 0.8560 - val_loss: 0.3076 - val_accuracy: 0.8976\n",
      "Epoch 11/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.3651 - accuracy: 0.8774 - val_loss: 0.2867 - val_accuracy: 0.9083\n",
      "Epoch 12/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.3153 - accuracy: 0.8833 - val_loss: 0.3330 - val_accuracy: 0.8857\n",
      "Epoch 13/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.2861 - accuracy: 0.9044 - val_loss: 0.2314 - val_accuracy: 0.9214\n",
      "Epoch 14/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.2622 - accuracy: 0.9087 - val_loss: 0.2209 - val_accuracy: 0.9262\n",
      "Epoch 15/50\n",
      "2520/2520 [==============================] - 13s 5ms/sample - loss: 0.2370 - accuracy: 0.9119 - val_loss: 0.1900 - val_accuracy: 0.9381\n",
      "Epoch 16/50\n",
      "2520/2520 [==============================] - 10s 4ms/sample - loss: 0.2404 - accuracy: 0.9091 - val_loss: 0.2113 - val_accuracy: 0.9143\n",
      "Epoch 17/50\n",
      "2520/2520 [==============================] - 13s 5ms/sample - loss: 0.2157 - accuracy: 0.9198 - val_loss: 0.1770 - val_accuracy: 0.9429\n",
      "Epoch 18/50\n",
      "2520/2520 [==============================] - 11s 4ms/sample - loss: 0.2112 - accuracy: 0.9206 - val_loss: 0.1742 - val_accuracy: 0.9405\n",
      "Epoch 19/50\n",
      "2520/2520 [==============================] - 14s 6ms/sample - loss: 0.1791 - accuracy: 0.9333 - val_loss: 0.1926 - val_accuracy: 0.9143\n",
      "Epoch 20/50\n",
      "2520/2520 [==============================] - 12s 5ms/sample - loss: 0.1780 - accuracy: 0.9357 - val_loss: 0.2204 - val_accuracy: 0.9298\n",
      "Epoch 21/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 0.1832 - accuracy: 0.9313 - val_loss: 0.1913 - val_accuracy: 0.9298\n",
      "Epoch 22/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 0.1705 - accuracy: 0.9329 - val_loss: 0.1645 - val_accuracy: 0.9464\n",
      "Epoch 23/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 0.1617 - accuracy: 0.9365 - val_loss: 0.1611 - val_accuracy: 0.9310\n",
      "Epoch 24/50\n",
      "2520/2520 [==============================] - 8s 3ms/sample - loss: 0.1502 - accuracy: 0.9381 - val_loss: 0.1852 - val_accuracy: 0.9369\n",
      "Epoch 25/50\n",
      "2520/2520 [==============================] - 8s 3ms/sample - loss: 0.1396 - accuracy: 0.9488 - val_loss: 0.1414 - val_accuracy: 0.9536\n",
      "Epoch 26/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.1340 - accuracy: 0.9460 - val_loss: 0.1472 - val_accuracy: 0.9548\n",
      "Epoch 27/50\n",
      "2520/2520 [==============================] - 10s 4ms/sample - loss: 0.1374 - accuracy: 0.9516 - val_loss: 0.1902 - val_accuracy: 0.9179\n",
      "Epoch 28/50\n",
      "2520/2520 [==============================] - 13s 5ms/sample - loss: 0.1222 - accuracy: 0.9516 - val_loss: 0.1671 - val_accuracy: 0.9417\n",
      "Epoch 29/50\n",
      "2520/2520 [==============================] - 13s 5ms/sample - loss: 0.1243 - accuracy: 0.9528 - val_loss: 0.1328 - val_accuracy: 0.9536\n",
      "Epoch 30/50\n",
      "2520/2520 [==============================] - 14s 5ms/sample - loss: 0.1005 - accuracy: 0.9611 - val_loss: 0.1263 - val_accuracy: 0.9548\n",
      "Epoch 31/50\n",
      "2520/2520 [==============================] - 12s 5ms/sample - loss: 0.1234 - accuracy: 0.9571 - val_loss: 0.2072 - val_accuracy: 0.9238\n",
      "Epoch 32/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 0.1101 - accuracy: 0.9567 - val_loss: 0.1331 - val_accuracy: 0.9488\n",
      "Epoch 33/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 0.0946 - accuracy: 0.9651 - val_loss: 0.1398 - val_accuracy: 0.9583\n",
      "Epoch 34/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 0.0999 - accuracy: 0.9643 - val_loss: 0.1276 - val_accuracy: 0.9548\n",
      "Epoch 35/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 0.0923 - accuracy: 0.9647 - val_loss: 0.1251 - val_accuracy: 0.9571\n",
      "Epoch 36/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 0.0824 - accuracy: 0.9730 - val_loss: 0.1161 - val_accuracy: 0.9607\n",
      "Epoch 37/50\n",
      "2520/2520 [==============================] - 12s 5ms/sample - loss: 0.0891 - accuracy: 0.9687 - val_loss: 0.1225 - val_accuracy: 0.9595\n",
      "Epoch 38/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.0832 - accuracy: 0.9694 - val_loss: 0.1173 - val_accuracy: 0.9631\n",
      "Epoch 39/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.0782 - accuracy: 0.9702 - val_loss: 0.1198 - val_accuracy: 0.9560\n",
      "Epoch 40/50\n",
      "2520/2520 [==============================] - 9s 3ms/sample - loss: 0.0833 - accuracy: 0.9706 - val_loss: 0.1364 - val_accuracy: 0.9452\n",
      "Epoch 41/50\n",
      "2520/2520 [==============================] - 9s 4ms/sample - loss: 0.0885 - accuracy: 0.9663 - val_loss: 0.1209 - val_accuracy: 0.9560\n",
      "CPU times: user 11min 36s, sys: 5min 1s, total: 16min 38s\n",
      "Wall time: 6min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa89f6224d0>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.98      0.99       107\n",
      "      alinda       0.98      0.99      0.99       104\n",
      "        gian       1.00      0.96      0.98       109\n",
      "     jackson       1.00      1.00      1.00       105\n",
      "      khaled       0.97      1.00      0.99       102\n",
      "     nicolas       0.99      0.97      0.98       107\n",
      "        theo       0.87      0.88      0.87       104\n",
      "    yweweler       0.88      0.90      0.89       102\n",
      "\n",
      "    accuracy                           0.96       840\n",
      "   macro avg       0.96      0.96      0.96       840\n",
      "weighted avg       0.96      0.96      0.96       840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.7 s, sys: 395 ms, total: 23.1 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_speakers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speakers_mfcc_nn = X_train_speakers_mfcc.reshape(X_train_speakers_mfcc.shape[0],\n",
    "                                                     X_train_speakers_mfcc.shape[1],\n",
    "                                                     X_train_speakers_mfcc.shape[2],\n",
    "                                                     1)\n",
    "X_val_speakers_mfcc_nn = X_val_speakers_mfcc.reshape(X_val_speakers_mfcc.shape[0],\n",
    "                                                 X_val_speakers_mfcc.shape[1],\n",
    "                                                 X_val_speakers_mfcc.shape[2],\n",
    "                                                 1)\n",
    "input_shape = (X_train_speakers_mfcc_nn.shape[1], X_train_speakers_mfcc_nn.shape[2], 1)\n",
    "enc, y_train_speakers_nn, target_names = data_preparation.transform_categorical_y(y_train_speakers)\n",
    "y_val_speakers_nn = enc.transform(y_val_speakers.reshape(-1, 1)).toarray()\n",
    "y_test_speakers_nn = enc.transform(y_test_speakers.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speakers_best = np.concatenate([X_train_speakers_mfcc_nn, X_val_speakers_mfcc_nn])\n",
    "y_train_speakers_best = np.concatenate([y_train_speakers_nn, y_val_speakers_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 640 samples\n",
      "Epoch 1/29\n",
      "640/640 [==============================] - 2s 4ms/sample - loss: 1.2200 - accuracy: 0.5797\n",
      "Epoch 2/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.5484 - accuracy: 0.8453\n",
      "Epoch 3/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.3639 - accuracy: 0.9047\n",
      "Epoch 4/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.3057 - accuracy: 0.9031\n",
      "Epoch 5/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.2443 - accuracy: 0.9422\n",
      "Epoch 6/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.1897 - accuracy: 0.9656\n",
      "Epoch 7/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.1594 - accuracy: 0.9719\n",
      "Epoch 8/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.1281 - accuracy: 0.9812\n",
      "Epoch 9/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.1090 - accuracy: 0.9906\n",
      "Epoch 10/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.1108 - accuracy: 0.9844\n",
      "Epoch 11/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0958 - accuracy: 0.9859\n",
      "Epoch 12/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.1006 - accuracy: 0.9859\n",
      "Epoch 13/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0841 - accuracy: 0.9906\n",
      "Epoch 14/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0743 - accuracy: 0.9922\n",
      "Epoch 15/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0777 - accuracy: 0.9937\n",
      "Epoch 16/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0703 - accuracy: 0.9937\n",
      "Epoch 17/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0618 - accuracy: 0.9937\n",
      "Epoch 18/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0521 - accuracy: 0.9984\n",
      "Epoch 19/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0542 - accuracy: 0.9984\n",
      "Epoch 20/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0458 - accuracy: 0.9953\n",
      "Epoch 21/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0493 - accuracy: 0.9953\n",
      "Epoch 22/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0594 - accuracy: 0.9953\n",
      "Epoch 23/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0535 - accuracy: 0.9969\n",
      "Epoch 24/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0414 - accuracy: 0.9953\n",
      "Epoch 25/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0434 - accuracy: 0.9984\n",
      "Epoch 26/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0445 - accuracy: 0.9969\n",
      "Epoch 27/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0355 - accuracy: 1.0000\n",
      "Epoch 28/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0411 - accuracy: 0.9984\n",
      "Epoch 29/29\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0403 - accuracy: 0.9969\n",
      "CPU times: user 50.8 s, sys: 19.2 s, total: 1min 10s\n",
      "Wall time: 35.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa948a0d8d0>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)\n",
    "model.fit(X_train_speakers_best, y_train_speakers_best,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=29,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_speakers_mfcc_nn = X_test_speakers_mfcc.reshape(X_test_speakers_mfcc.shape[0],\n",
    "                                                 X_test_speakers_mfcc.shape[1],\n",
    "                                                 X_test_speakers_mfcc.shape[2],\n",
    "                                                 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.95      0.97        20\n",
      "      alinda       0.87      1.00      0.93        20\n",
      "        gian       0.87      1.00      0.93        20\n",
      "     jackson       1.00      1.00      1.00       420\n",
      "      khaled       0.95      1.00      0.98        20\n",
      "     nicolas       1.00      1.00      1.00       420\n",
      "        theo       0.93      0.99      0.96       418\n",
      "    yweweler       1.00      0.93      0.96       420\n",
      "\n",
      "    accuracy                           0.98      1758\n",
      "   macro avg       0.95      0.98      0.97      1758\n",
      "weighted avg       0.98      0.98      0.98      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_test_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_test_speakers_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/speakers.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "- [X] Export train/val/test balanced split\n",
    "- [X] Double check all the trials\n",
    "- [X] Export in functions things like reshaping data for nn, evaluation blocks etc so that the notebook is more easy to read\n",
    "- [ ] Apply more times data augmentation on our recordings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
