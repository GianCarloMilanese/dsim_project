{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCH=32\n",
    "EPOCHS=100\n",
    "PATIENCE=10\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import data_augmentation\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "## No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdd_dir=\"./recordings/\"\n",
    "our_recs_dir=\"./preprocessed_recs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./recordings/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5098280b724c629e7bac1802a6b6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ./preprocessed_recs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f414a63cf19143ae99ace49ae85f9e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much does input recordings vary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 18262\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite a huge difference! Let's find out the 10 longest recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18262, 17567, 9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get their indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "first_length=18262\n",
    "second_length=17567\n",
    "index_first = a.index(first_length)\n",
    "index_second = a.index(second_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest track is associated with speaker theo, digit 9\n",
      "Second longest track is associated with speaker theo, digit 7\n"
     ]
    }
   ],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir])\n",
    "print(\"Longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_first],labels_digits[index_first]))\n",
    "print(\"Second longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_second],labels_digits[index_second]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problem is with theo, which has 500 recordings, digit 9 and 7, which respectively have 200 recordings. We can safely delete them and saving to pad many thousands of 0s (there will be (18262 - 9015) less zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "max_track_length=9015 # it will be useful later on\n",
    "print(\"Before: {}\".format(len(recordings)))\n",
    "recordings=np.delete(recordings,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(recordings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_speakers)))\n",
    "labels_speakers=np.delete(labels_speakers,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_speakers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_digits)))\n",
    "labels_digits=np.delete(labels_digits,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_digits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now double check to see if everything went well. Now the longest recording will be around 9 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356, 7147, 7038]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though variability is reduced, it is still there: for this reason we will pad zeros at start and end of recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they will have the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9015 9015\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create balancede train, validation and test sets. For digits it's not a huge problem (only 7 and 9, because of the previous operation, have 1 recordings less, however our 4 speakers (ale, alinda, gian, khaled) have 100 recordings, while the other 4 have 500 recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preparation.balanced_train_val_test_split(pad_recordings, labels_digits)\n",
    "X_train_digits = X[0]\n",
    "y_train_digits = y[0]\n",
    "X_val_digits = X[1]\n",
    "y_val_digits = y[1] \n",
    "X_test_digits = X[2]\n",
    "y_test_digits = y[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preparation.balanced_train_val_test_split(pad_recordings, labels_speakers)\n",
    "X_train_speakers = X[0]\n",
    "y_train_speakers = y[0]\n",
    "X_val_speakers = X[1]\n",
    "y_val_speakers = y[1] \n",
    "X_test_speakers = X[2]\n",
    "y_test_speakers = y[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits\n",
    "## Spectrograms - No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 s, sys: 298 ms, total: 22.5 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_train_digits])\n",
    "X_val_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_val_digits])\n",
    "X_test_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 s, sys: 213 ms, total: 20.5 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_train_digits])\n",
    "X_val_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_val_digits])\n",
    "X_test_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digits_spects.shape\n",
    "X_train_digits_spects_2d = X_train_digits_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.55 s, sys: 44.5 ms, total: 8.59 s\n",
      "Wall time: 8.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train_digits_spects_2d, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digits_spects.shape\n",
    "X_val_digits_spects_2d = X_val_digits_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29        48\n",
      "           1       0.69      0.23      0.34        48\n",
      "           2       0.62      0.17      0.26        48\n",
      "           3       0.56      0.19      0.28        48\n",
      "           4       0.13      0.50      0.21        48\n",
      "           5       0.64      0.19      0.29        48\n",
      "           6       0.13      0.52      0.20        48\n",
      "           7       0.70      0.15      0.24        48\n",
      "           8       0.80      0.08      0.15        48\n",
      "           9       0.93      0.27      0.42        48\n",
      "\n",
      "    accuracy                           0.25       480\n",
      "   macro avg       0.62      0.25      0.27       480\n",
      "weighted avg       0.62      0.25      0.27       480\n",
      "\n",
      "CPU times: user 1.71 s, sys: 13.2 ms, total: 1.72 s\n",
      "Wall time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val_digits_spects_2d)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digits_spects_norm.shape\n",
    "X_train_digits_spects_norm_2d = X_train_digits_spects_norm.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.12 s, sys: 30.7 ms, total: 4.15 s\n",
      "Wall time: 4.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_spects_norm_2d, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digits_spects_norm.shape\n",
    "X_val_digits_spects_norm_2d = X_val_digits_spects_norm.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        48\n",
      "           1       0.90      0.90      0.90        48\n",
      "           2       0.87      0.94      0.90        48\n",
      "           3       0.96      0.90      0.92        48\n",
      "           4       1.00      0.85      0.92        48\n",
      "           5       0.93      0.88      0.90        48\n",
      "           6       0.85      0.92      0.88        48\n",
      "           7       0.87      0.98      0.92        48\n",
      "           8       0.90      0.90      0.90        48\n",
      "           9       0.91      0.85      0.88        48\n",
      "\n",
      "    accuracy                           0.91       480\n",
      "   macro avg       0.91      0.91      0.91       480\n",
      "weighted avg       0.91      0.91      0.91       480\n",
      "\n",
      "CPU times: user 1.55 s, sys: 11.6 ms, total: 1.56 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_digits_spects_norm_2d)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized spectrograms lead to better performances, therefore let's use this representation as default\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, input_shape, _ = data_preparation.prepare_data_nn(X_train_digits_spects_norm, X_val_digits_spects_norm, X_test_digits_spects_norm, y_train_digits, y_val_digits, y_test_digits, number_mode=True)\n",
    "\n",
    "X_train_digits_spects_norm_nn  = X_data[0]\n",
    "y_train_digits_nn = y_data[0]\n",
    "X_val_digits_spects_norm_nn  = X_data[1]\n",
    "y_val_digits_nn = y_data[1]\n",
    "X_test_digits_spects_norm_nn = X_data[2]\n",
    "y_test_digits_nn  = y_data[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,033,066\n",
      "Trainable params: 1,033,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 5s 3ms/sample - loss: 1.9174 - accuracy: 0.3510 - val_loss: 1.6236 - val_accuracy: 0.4604\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 1.3686 - accuracy: 0.5601 - val_loss: 0.9706 - val_accuracy: 0.7708\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 1.0282 - accuracy: 0.6916 - val_loss: 0.7945 - val_accuracy: 0.7750\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.8044 - accuracy: 0.7406 - val_loss: 0.6505 - val_accuracy: 0.8188\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.6677 - accuracy: 0.7790 - val_loss: 0.6628 - val_accuracy: 0.7979\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.5816 - accuracy: 0.8175 - val_loss: 0.7843 - val_accuracy: 0.8125\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.4884 - accuracy: 0.8490 - val_loss: 0.8742 - val_accuracy: 0.7042\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.4590 - accuracy: 0.8434 - val_loss: 0.5060 - val_accuracy: 0.8604\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3911 - accuracy: 0.8881 - val_loss: 0.4629 - val_accuracy: 0.8875\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3546 - accuracy: 0.8930 - val_loss: 0.3984 - val_accuracy: 0.8875\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3255 - accuracy: 0.9049 - val_loss: 0.3661 - val_accuracy: 0.9104\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2901 - accuracy: 0.9091 - val_loss: 0.3485 - val_accuracy: 0.9104\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2604 - accuracy: 0.9203 - val_loss: 0.3924 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2512 - accuracy: 0.9217 - val_loss: 0.3981 - val_accuracy: 0.9021\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2187 - accuracy: 0.9322 - val_loss: 0.3432 - val_accuracy: 0.9271\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1929 - accuracy: 0.9427 - val_loss: 0.3648 - val_accuracy: 0.9083\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2243 - accuracy: 0.9378 - val_loss: 0.3112 - val_accuracy: 0.9250\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1935 - accuracy: 0.9364 - val_loss: 0.3379 - val_accuracy: 0.9250\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1707 - accuracy: 0.9497 - val_loss: 0.3103 - val_accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1666 - accuracy: 0.9469 - val_loss: 0.3232 - val_accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1803 - accuracy: 0.9427 - val_loss: 0.3912 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1563 - accuracy: 0.9559 - val_loss: 0.3334 - val_accuracy: 0.9208\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1458 - accuracy: 0.9559 - val_loss: 0.3332 - val_accuracy: 0.9292\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1662 - accuracy: 0.9503 - val_loss: 0.3916 - val_accuracy: 0.9021\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1602 - accuracy: 0.9510 - val_loss: 0.3365 - val_accuracy: 0.9312\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1373 - accuracy: 0.9587 - val_loss: 0.3064 - val_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1281 - accuracy: 0.9566 - val_loss: 0.4461 - val_accuracy: 0.8938\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1178 - accuracy: 0.9678 - val_loss: 0.3189 - val_accuracy: 0.9312\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1074 - accuracy: 0.9699 - val_loss: 0.3576 - val_accuracy: 0.9250\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1225 - accuracy: 0.9594 - val_loss: 0.3374 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0988 - accuracy: 0.9734 - val_loss: 0.3076 - val_accuracy: 0.9417\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1023 - accuracy: 0.9699 - val_loss: 0.2945 - val_accuracy: 0.9458\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0998 - accuracy: 0.9741 - val_loss: 0.3093 - val_accuracy: 0.9375\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1019 - accuracy: 0.9678 - val_loss: 0.3300 - val_accuracy: 0.9396\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0891 - accuracy: 0.9734 - val_loss: 0.3032 - val_accuracy: 0.9458\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0687 - accuracy: 0.9797 - val_loss: 0.2842 - val_accuracy: 0.9417\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0841 - accuracy: 0.9776 - val_loss: 0.3330 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0760 - accuracy: 0.9783 - val_loss: 0.3004 - val_accuracy: 0.9479\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0825 - accuracy: 0.9741 - val_loss: 0.3155 - val_accuracy: 0.9292\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0663 - accuracy: 0.9853 - val_loss: 0.3460 - val_accuracy: 0.9396\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0730 - accuracy: 0.9769 - val_loss: 0.3130 - val_accuracy: 0.9500\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0726 - accuracy: 0.9811 - val_loss: 0.3445 - val_accuracy: 0.9292\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0653 - accuracy: 0.9839 - val_loss: 0.3782 - val_accuracy: 0.9187\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0716 - accuracy: 0.9776 - val_loss: 0.3093 - val_accuracy: 0.9479\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0649 - accuracy: 0.9811 - val_loss: 0.3263 - val_accuracy: 0.9396\n",
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0635 - accuracy: 0.9846 - val_loss: 0.3071 - val_accuracy: 0.9458\n",
      "CPU times: user 3min 47s, sys: 2min 13s, total: 6min 1s\n",
      "Wall time: 2min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9210e46650>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10)\n",
    "model.fit(X_train_digits_spects_norm_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_norm_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        48\n",
      "           1       0.87      1.00      0.93        48\n",
      "           2       0.96      0.94      0.95        48\n",
      "           3       0.94      0.94      0.94        48\n",
      "           4       0.98      0.96      0.97        48\n",
      "           5       1.00      0.94      0.97        48\n",
      "           6       0.88      0.94      0.91        48\n",
      "           7       0.98      0.98      0.98        48\n",
      "           8       0.94      0.92      0.93        48\n",
      "           9       0.95      0.83      0.89        48\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.94      0.94      0.94       480\n",
      "weighted avg       0.94      0.94      0.94       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_norm_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 127, 17, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,033,450\n",
      "Trainable params: 1,033,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 5s 4ms/sample - loss: 1.1098 - accuracy: 0.6483 - val_loss: 1.6680 - val_accuracy: 0.5938\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.4727 - accuracy: 0.8776 - val_loss: 1.5970 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3098 - accuracy: 0.9378 - val_loss: 1.3810 - val_accuracy: 0.5958\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2314 - accuracy: 0.9594 - val_loss: 1.2962 - val_accuracy: 0.5917\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1736 - accuracy: 0.9727 - val_loss: 1.1695 - val_accuracy: 0.6271\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1541 - accuracy: 0.9741 - val_loss: 1.0491 - val_accuracy: 0.6833\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1195 - accuracy: 0.9881 - val_loss: 0.8411 - val_accuracy: 0.7625\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1063 - accuracy: 0.9895 - val_loss: 0.7585 - val_accuracy: 0.7958\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0987 - accuracy: 0.9888 - val_loss: 0.5663 - val_accuracy: 0.8646\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0788 - accuracy: 0.9958 - val_loss: 0.5301 - val_accuracy: 0.8500\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0738 - accuracy: 0.9951 - val_loss: 0.4532 - val_accuracy: 0.8938\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0626 - accuracy: 0.9958 - val_loss: 0.3572 - val_accuracy: 0.9146\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0542 - accuracy: 0.9972 - val_loss: 0.3090 - val_accuracy: 0.9396\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0531 - accuracy: 0.9993 - val_loss: 0.3085 - val_accuracy: 0.9271\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0488 - accuracy: 0.9979 - val_loss: 0.2900 - val_accuracy: 0.9354\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0444 - accuracy: 0.9979 - val_loss: 0.2948 - val_accuracy: 0.9354\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9458\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9521\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0323 - accuracy: 0.9986 - val_loss: 0.3017 - val_accuracy: 0.9458\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9521\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0263 - accuracy: 0.9993 - val_loss: 0.2849 - val_accuracy: 0.9438\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0288 - accuracy: 0.9993 - val_loss: 0.2796 - val_accuracy: 0.9563\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9521\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0246 - accuracy: 0.9993 - val_loss: 0.2741 - val_accuracy: 0.9563\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9563\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9563\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0231 - accuracy: 0.9993 - val_loss: 0.2796 - val_accuracy: 0.9500\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9479\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9542\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9521\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9542\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9583\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9583\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9583\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9521\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9604\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9542\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0139 - accuracy: 0.9993 - val_loss: 0.2752 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9542\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9583\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9583\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9563\n",
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9563\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9604\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9583\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9583\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9563\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9583\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9542\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9542\n",
      "CPU times: user 5min 28s, sys: 3min 35s, total: 9min 3s\n",
      "Wall time: 2min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91f7d3a290>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_spects_norm_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_norm_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        48\n",
      "           1       0.96      0.94      0.95        48\n",
      "           2       0.96      0.94      0.95        48\n",
      "           3       0.96      0.98      0.97        48\n",
      "           4       1.00      0.96      0.98        48\n",
      "           5       0.94      0.96      0.95        48\n",
      "           6       0.94      0.96      0.95        48\n",
      "           7       1.00      0.94      0.97        48\n",
      "           8       0.98      1.00      0.99        48\n",
      "           9       0.88      0.94      0.91        48\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_norm_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try with MFCCs\n",
    "## MFCC - No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.1 s, sys: 429 ms, total: 21.6 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc= np.array([data_preparation.mfcc(x, flatten=True) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "scaler_normal = StandardScaler()\n",
    "X_train_digits_mfcc_scaled = scaler_normal.fit_transform(X_train_digits_mfcc)\n",
    "X_val_digits_mfcc_scaled =  scaler_normal.transform(X_val_digits_mfcc)\n",
    "X_test_digits_mfcc_scaled =  scaler_normal.transform(X_test_digits_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 750 ms, sys: 9.88 ms, total: 760 ms\n",
      "Wall time: 621 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_mfcc_scaled, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        48\n",
      "           1       0.98      0.98      0.98        48\n",
      "           2       1.00      1.00      1.00        48\n",
      "           3       0.96      0.96      0.96        48\n",
      "           4       1.00      0.88      0.93        48\n",
      "           5       1.00      0.92      0.96        48\n",
      "           6       0.69      0.92      0.79        48\n",
      "           7       1.00      0.96      0.98        48\n",
      "           8       0.92      0.94      0.93        48\n",
      "           9       0.98      0.94      0.96        48\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.95      0.94      0.94       480\n",
      "weighted avg       0.95      0.94      0.94       480\n",
      "\n",
      "CPU times: user 215 ms, sys: 2.75 ms, total: 218 ms\n",
      "Wall time: 216 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_digits_mfcc_scaled)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar results of the best Spectrograms model. Let's now use CNNs with MFCC\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 252 ms, total: 21 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc= np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430, 20, 18)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_digits_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digits_mfcc, X_val_digits_mfcc, X_test_digits_mfcc, y_train_digits, y_val_digits, y_test_digits, number_mode=True)\n",
    "\n",
    "X_train_digits_mfcc_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_mfcc_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_mfcc_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start to train the predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,330\n",
      "Trainable params: 148,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 21556014486623.8633 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 1s 476us/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 1s 465us/sample - loss: 2.3027 - accuracy: 0.0944 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 1s 467us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 1s 462us/sample - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 1s 468us/sample - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 1s 493us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 1s 473us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 1s 469us/sample - loss: 2.3027 - accuracy: 0.0944 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 1s 471us/sample - loss: 2.3027 - accuracy: 0.0923 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 1s 465us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 1s 474us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 1s 471us/sample - loss: 2.3027 - accuracy: 0.0846 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 1s 467us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 1s 465us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 1s 469us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 1s 466us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 1s 465us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 1s 469us/sample - loss: 2.3027 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 1s 466us/sample - loss: 2.3027 - accuracy: 0.0888 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 1s 465us/sample - loss: 2.3027 - accuracy: 0.0958 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 1s 470us/sample - loss: 2.3027 - accuracy: 0.0867 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 1s 474us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 1s 468us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 1s 468us/sample - loss: 2.3027 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 1s 470us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 1s 513us/sample - loss: 2.3027 - accuracy: 0.0867 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 1s 465us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 1s 469us/sample - loss: 2.3027 - accuracy: 0.0804 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 1s 461us/sample - loss: 2.3027 - accuracy: 0.0755 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 1s 466us/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 1s 464us/sample - loss: 2.3027 - accuracy: 0.0867 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 1s 462us/sample - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 1s 580us/sample - loss: 2.3027 - accuracy: 0.0888 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 1s 465us/sample - loss: 2.3027 - accuracy: 0.0874 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 1s 466us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 1s 475us/sample - loss: 2.3027 - accuracy: 0.0762 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 1s 481us/sample - loss: 2.3027 - accuracy: 0.0888 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 1s 467us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 1s 465us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 1s 468us/sample - loss: 2.3027 - accuracy: 0.0818 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 1s 466us/sample - loss: 2.3027 - accuracy: 0.0783 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 1s 460us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 1s 468us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 1s 460us/sample - loss: 2.3027 - accuracy: 0.0958 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 1s 468us/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 47/100\n",
      "1430/1430 [==============================] - 1s 481us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 1s 762us/sample - loss: 2.3027 - accuracy: 0.0790 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 1s 644us/sample - loss: 2.3027 - accuracy: 0.0818 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 1s 474us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 1s 477us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 1s 672us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 1s 480us/sample - loss: 2.3027 - accuracy: 0.0874 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 1s 480us/sample - loss: 2.3027 - accuracy: 0.0790 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "1430/1430 [==============================] - 1s 472us/sample - loss: 2.3027 - accuracy: 0.0755 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 56/100\n",
      "1430/1430 [==============================] - 1s 478us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 57/100\n",
      "1430/1430 [==============================] - 1s 480us/sample - loss: 2.3027 - accuracy: 0.0874 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "1430/1430 [==============================] - 1s 474us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 59/100\n",
      "1430/1430 [==============================] - 1s 474us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "1430/1430 [==============================] - 1s 475us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "1430/1430 [==============================] - 1s 478us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 62/100\n",
      "1430/1430 [==============================] - 1s 471us/sample - loss: 2.3027 - accuracy: 0.0923 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 63/100\n",
      "1430/1430 [==============================] - 1s 480us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 64/100\n",
      "1430/1430 [==============================] - 1s 488us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 65/100\n",
      "1430/1430 [==============================] - 1s 621us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 66/100\n",
      "1430/1430 [==============================] - 1s 612us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 67/100\n",
      "1430/1430 [==============================] - 1s 474us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 68/100\n",
      "1430/1430 [==============================] - 1s 479us/sample - loss: 2.3027 - accuracy: 0.0720 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 69/100\n",
      "1430/1430 [==============================] - 1s 474us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 70/100\n",
      "1430/1430 [==============================] - 1s 480us/sample - loss: 2.3027 - accuracy: 0.0797 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 71/100\n",
      "1430/1430 [==============================] - 1s 715us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 72/100\n",
      "1430/1430 [==============================] - 1s 631us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 73/100\n",
      "1430/1430 [==============================] - 1s 614us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 74/100\n",
      "1430/1430 [==============================] - 1s 634us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 75/100\n",
      "1430/1430 [==============================] - 1s 527us/sample - loss: 2.3027 - accuracy: 0.0923 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 76/100\n",
      "1430/1430 [==============================] - 1s 725us/sample - loss: 2.3027 - accuracy: 0.0790 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 77/100\n",
      "1430/1430 [==============================] - 1s 574us/sample - loss: 2.3027 - accuracy: 0.0846 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 78/100\n",
      "1430/1430 [==============================] - 1s 639us/sample - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 79/100\n",
      "1430/1430 [==============================] - 1s 893us/sample - loss: 2.3027 - accuracy: 0.0860 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 80/100\n",
      "1430/1430 [==============================] - 1s 587us/sample - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 81/100\n",
      "1430/1430 [==============================] - 1s 576us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 82/100\n",
      "1430/1430 [==============================] - 1s 733us/sample - loss: 2.3027 - accuracy: 0.0818 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "CPU times: user 1min 47s, sys: 1min 34s, total: 3min 22s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91fb7aa310>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        48\n",
      "           1       0.00      0.00      0.00        48\n",
      "           2       0.00      0.00      0.00        48\n",
      "           3       0.00      0.00      0.00        48\n",
      "           4       0.00      0.00      0.00        48\n",
      "           5       0.00      0.00      0.00        48\n",
      "           6       0.00      0.00      0.00        48\n",
      "           7       0.00      0.00      0.00        48\n",
      "           8       0.10      1.00      0.18        48\n",
      "           9       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.10       480\n",
      "   macro avg       0.01      0.10      0.02       480\n",
      "weighted avg       0.01      0.10      0.02       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really poor results, let's now use batch normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,714\n",
      "Trainable params: 148,522\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 6s 4ms/sample - loss: 1.2522 - accuracy: 0.5937 - val_loss: 3.5444 - val_accuracy: 0.4083\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 1s 892us/sample - loss: 0.7169 - accuracy: 0.7951 - val_loss: 1.1626 - val_accuracy: 0.6167\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 1s 972us/sample - loss: 0.5276 - accuracy: 0.8650 - val_loss: 0.5468 - val_accuracy: 0.8562\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 1s 832us/sample - loss: 0.4396 - accuracy: 0.8867 - val_loss: 0.5031 - val_accuracy: 0.8750\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 1s 795us/sample - loss: 0.3921 - accuracy: 0.9140 - val_loss: 0.4192 - val_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 1s 1ms/sample - loss: 0.3155 - accuracy: 0.9294 - val_loss: 0.4369 - val_accuracy: 0.9042\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 1s 855us/sample - loss: 0.2809 - accuracy: 0.9455 - val_loss: 0.4165 - val_accuracy: 0.9021\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.2710 - accuracy: 0.9441 - val_loss: 0.4441 - val_accuracy: 0.8833\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 1s 1ms/sample - loss: 0.2774 - accuracy: 0.9420 - val_loss: 0.4018 - val_accuracy: 0.8979\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 1s 890us/sample - loss: 0.2256 - accuracy: 0.9573 - val_loss: 0.3165 - val_accuracy: 0.9167\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 1s 740us/sample - loss: 0.2163 - accuracy: 0.9671 - val_loss: 0.3378 - val_accuracy: 0.9167\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 1s 870us/sample - loss: 0.1964 - accuracy: 0.9608 - val_loss: 0.3073 - val_accuracy: 0.9083\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 1s 936us/sample - loss: 0.1874 - accuracy: 0.9629 - val_loss: 0.3715 - val_accuracy: 0.9021\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 1s 720us/sample - loss: 0.1909 - accuracy: 0.9657 - val_loss: 0.2944 - val_accuracy: 0.9292\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 1s 720us/sample - loss: 0.1727 - accuracy: 0.9664 - val_loss: 0.2911 - val_accuracy: 0.9146\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 1s 712us/sample - loss: 0.1649 - accuracy: 0.9678 - val_loss: 0.2859 - val_accuracy: 0.9271\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 1s 691us/sample - loss: 0.1463 - accuracy: 0.9790 - val_loss: 0.2712 - val_accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 1s 930us/sample - loss: 0.1360 - accuracy: 0.9769 - val_loss: 0.2633 - val_accuracy: 0.9292\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.1288 - accuracy: 0.9846 - val_loss: 0.2495 - val_accuracy: 0.9354\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 1s 992us/sample - loss: 0.1278 - accuracy: 0.9839 - val_loss: 0.2688 - val_accuracy: 0.9292\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 1s 888us/sample - loss: 0.1189 - accuracy: 0.9811 - val_loss: 0.2321 - val_accuracy: 0.9396\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 1s 715us/sample - loss: 0.1073 - accuracy: 0.9839 - val_loss: 0.2530 - val_accuracy: 0.9229\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 1s 782us/sample - loss: 0.1061 - accuracy: 0.9846 - val_loss: 0.2361 - val_accuracy: 0.9396\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 1s 764us/sample - loss: 0.1002 - accuracy: 0.9846 - val_loss: 0.2850 - val_accuracy: 0.9271\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 1s 846us/sample - loss: 0.0911 - accuracy: 0.9895 - val_loss: 0.2349 - val_accuracy: 0.9521\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 1s 727us/sample - loss: 0.0988 - accuracy: 0.9881 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 1s 694us/sample - loss: 0.0826 - accuracy: 0.9923 - val_loss: 0.2425 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 1s 723us/sample - loss: 0.0937 - accuracy: 0.9853 - val_loss: 0.2508 - val_accuracy: 0.9458\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 1s 782us/sample - loss: 0.0776 - accuracy: 0.9916 - val_loss: 0.2463 - val_accuracy: 0.9375\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 1s 969us/sample - loss: 0.0778 - accuracy: 0.9944 - val_loss: 0.2279 - val_accuracy: 0.9375\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 1s 891us/sample - loss: 0.0816 - accuracy: 0.9895 - val_loss: 0.2430 - val_accuracy: 0.9292\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 1s 972us/sample - loss: 0.0718 - accuracy: 0.9916 - val_loss: 0.2225 - val_accuracy: 0.9458\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 1s 918us/sample - loss: 0.0735 - accuracy: 0.9909 - val_loss: 0.2295 - val_accuracy: 0.9479\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 1s 872us/sample - loss: 0.0830 - accuracy: 0.9902 - val_loss: 0.2276 - val_accuracy: 0.9375\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 1s 772us/sample - loss: 0.0606 - accuracy: 0.9944 - val_loss: 0.2165 - val_accuracy: 0.9479\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 1s 932us/sample - loss: 0.0638 - accuracy: 0.9923 - val_loss: 0.2571 - val_accuracy: 0.9396\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 1s 787us/sample - loss: 0.0689 - accuracy: 0.9923 - val_loss: 0.2395 - val_accuracy: 0.9479\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 1s 724us/sample - loss: 0.0508 - accuracy: 0.9965 - val_loss: 0.2264 - val_accuracy: 0.9375\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 1s 705us/sample - loss: 0.0498 - accuracy: 0.9979 - val_loss: 0.2318 - val_accuracy: 0.9458\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 1s 803us/sample - loss: 0.0519 - accuracy: 0.9958 - val_loss: 0.2016 - val_accuracy: 0.9500\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 1s 760us/sample - loss: 0.0511 - accuracy: 0.9951 - val_loss: 0.2110 - val_accuracy: 0.9542\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 1s 719us/sample - loss: 0.0509 - accuracy: 0.9958 - val_loss: 0.2082 - val_accuracy: 0.9479\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 1s 776us/sample - loss: 0.0517 - accuracy: 0.9937 - val_loss: 0.2132 - val_accuracy: 0.9479\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 1s 774us/sample - loss: 0.0464 - accuracy: 0.9958 - val_loss: 0.2148 - val_accuracy: 0.9458\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 1s 763us/sample - loss: 0.0504 - accuracy: 0.9937 - val_loss: 0.2314 - val_accuracy: 0.9479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 1s 743us/sample - loss: 0.0459 - accuracy: 0.9972 - val_loss: 0.2176 - val_accuracy: 0.9479\n",
      "Epoch 47/100\n",
      "1430/1430 [==============================] - 1s 706us/sample - loss: 0.0414 - accuracy: 0.9930 - val_loss: 0.1988 - val_accuracy: 0.9521\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 1s 697us/sample - loss: 0.0409 - accuracy: 0.9944 - val_loss: 0.2124 - val_accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 1s 715us/sample - loss: 0.0429 - accuracy: 0.9965 - val_loss: 0.2060 - val_accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 1s 715us/sample - loss: 0.0384 - accuracy: 0.9986 - val_loss: 0.2049 - val_accuracy: 0.9458\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 1s 741us/sample - loss: 0.0487 - accuracy: 0.9923 - val_loss: 0.2110 - val_accuracy: 0.9521\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 1s 680us/sample - loss: 0.0378 - accuracy: 0.9986 - val_loss: 0.1910 - val_accuracy: 0.9542\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 1s 697us/sample - loss: 0.0384 - accuracy: 0.9972 - val_loss: 0.2527 - val_accuracy: 0.9375\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 1s 683us/sample - loss: 0.0384 - accuracy: 0.9972 - val_loss: 0.2168 - val_accuracy: 0.9500\n",
      "Epoch 55/100\n",
      "1430/1430 [==============================] - 1s 707us/sample - loss: 0.0397 - accuracy: 0.9958 - val_loss: 0.2040 - val_accuracy: 0.9438\n",
      "Epoch 56/100\n",
      "1430/1430 [==============================] - 1s 698us/sample - loss: 0.0404 - accuracy: 0.9972 - val_loss: 0.1913 - val_accuracy: 0.9583\n",
      "Epoch 57/100\n",
      "1430/1430 [==============================] - 1s 702us/sample - loss: 0.0317 - accuracy: 0.9986 - val_loss: 0.1914 - val_accuracy: 0.9563\n",
      "Epoch 58/100\n",
      "1430/1430 [==============================] - 1s 636us/sample - loss: 0.0351 - accuracy: 0.9972 - val_loss: 0.2108 - val_accuracy: 0.9521\n",
      "Epoch 59/100\n",
      "1430/1430 [==============================] - 1s 709us/sample - loss: 0.0320 - accuracy: 0.9972 - val_loss: 0.1898 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "1430/1430 [==============================] - 1s 650us/sample - loss: 0.0282 - accuracy: 0.9972 - val_loss: 0.1995 - val_accuracy: 0.9542\n",
      "Epoch 61/100\n",
      "1430/1430 [==============================] - 1s 702us/sample - loss: 0.0296 - accuracy: 0.9986 - val_loss: 0.2517 - val_accuracy: 0.9333\n",
      "Epoch 62/100\n",
      "1430/1430 [==============================] - 1s 712us/sample - loss: 0.0331 - accuracy: 0.9972 - val_loss: 0.1958 - val_accuracy: 0.9542\n",
      "Epoch 63/100\n",
      "1430/1430 [==============================] - 1s 721us/sample - loss: 0.0308 - accuracy: 0.9972 - val_loss: 0.2160 - val_accuracy: 0.9479\n",
      "Epoch 64/100\n",
      "1430/1430 [==============================] - 1s 674us/sample - loss: 0.0369 - accuracy: 0.9937 - val_loss: 0.1918 - val_accuracy: 0.9583\n",
      "Epoch 65/100\n",
      "1430/1430 [==============================] - 1s 682us/sample - loss: 0.0303 - accuracy: 0.9979 - val_loss: 0.2015 - val_accuracy: 0.9583\n",
      "Epoch 66/100\n",
      "1430/1430 [==============================] - 1s 710us/sample - loss: 0.0283 - accuracy: 0.9986 - val_loss: 0.1959 - val_accuracy: 0.9563\n",
      "Epoch 67/100\n",
      "1430/1430 [==============================] - 1s 654us/sample - loss: 0.0256 - accuracy: 0.9986 - val_loss: 0.1998 - val_accuracy: 0.9521\n",
      "Epoch 68/100\n",
      "1430/1430 [==============================] - 1s 726us/sample - loss: 0.0288 - accuracy: 0.9965 - val_loss: 0.2444 - val_accuracy: 0.9396\n",
      "Epoch 69/100\n",
      "1430/1430 [==============================] - 1s 688us/sample - loss: 0.0270 - accuracy: 0.9986 - val_loss: 0.2397 - val_accuracy: 0.9417\n",
      "CPU times: user 1min 41s, sys: 40.2 s, total: 2min 22s\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91fd80e710>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10,\n",
    "                                batch_normalisation=True)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        48\n",
      "           1       0.98      1.00      0.99        48\n",
      "           2       0.92      1.00      0.96        48\n",
      "           3       0.96      0.98      0.97        48\n",
      "           4       1.00      0.98      0.99        48\n",
      "           5       0.96      0.94      0.95        48\n",
      "           6       0.96      0.94      0.95        48\n",
      "           7       0.98      0.98      0.98        48\n",
      "           8       0.96      0.96      0.96        48\n",
      "           9       0.96      0.92      0.94        48\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best combo so far is \"CNN + MFCCs\", considering that its quicker to train.\n",
    "\n",
    "Batch normalisation lead to similar results on spectrograms, however on MFCC it works way better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n",
      "CPU times: user 6min, sys: 13.3 s, total: 6min 13s\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                                                    y_type= ['digit', 'digit'],\n",
    "                                                    n_category_test=15,\n",
    "                                                    include_pitch=True,\n",
    "                                                    max_length=max_track_length,\n",
    "                                                    recordings_source=[False, True],\n",
    "                                                    transform_function=\"mfcc\")\n",
    "X_train_digit_mfcc = X[0]\n",
    "y_train_digit_mfcc = y[0]\n",
    "X_val_digit_mfcc = X[1]\n",
    "y_val_digit_mfcc = y[1]\n",
    "X_test_digit_mfcc = X[2]\n",
    "y_test_digit_mfcc  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1911 638\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_digit_mfcc, X_val_digit_mfcc]),\n",
    "                         np.concatenate([y_train_digit_mfcc, y_val_digit_mfcc]))\n",
    "\n",
    "X_train_digit = X[0]\n",
    "y_train_digit = y[0]\n",
    "X_val_digit = X[1]\n",
    "y_val_digit = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "scaler_normal = StandardScaler()\n",
    "X_train_digits_mfcc_scaled = scaler_normal.fit_transform(X_train_digit.reshape((X_train_digit.shape[0],\n",
    "                                                                               X_train_digit.shape[1] * X_train_digit.shape[2])))\n",
    "X_val_digits_mfcc_scaled =  scaler_normal.transform(X_val_digit.reshape((X_val_digit.shape[0],\n",
    "                                                                               X_val_digit.shape[1] * X_val_digit.shape[2])))\n",
    "X_test_digits_mfcc_scaled =  scaler_normal.transform(X_test_digit_mfcc.reshape((X_test_digit_mfcc.shape[0],\n",
    "                                                                               X_test_digit_mfcc.shape[1] * X_test_digit_mfcc.shape[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 319 ms, total: 1min 19s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_mfcc_scaled, y_train_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 2 µs, total: 5 µs\n",
      "Wall time: 10 µs\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       638\n",
      "           1       0.88      0.92      0.90       638\n",
      "           2       0.88      0.85      0.87       638\n",
      "           3       0.85      0.83      0.84       638\n",
      "           4       0.97      0.87      0.92       638\n",
      "           5       0.95      0.91      0.93       638\n",
      "           6       0.76      0.88      0.82       638\n",
      "           7       0.93      0.88      0.90       638\n",
      "           8       0.89      0.89      0.89       638\n",
      "           9       0.83      0.91      0.87       638\n",
      "\n",
      "    accuracy                           0.89      6380\n",
      "   macro avg       0.89      0.89      0.89      6380\n",
      "weighted avg       0.89      0.89      0.89      6380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "y_pred = clf.predict(X_val_digits_mfcc_scaled)\n",
    "print(classification_report(y_val_digit, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digit, X_val_digit, X_test_digit_mfcc, y_train_digit, y_val_digit, y_test_digit_mfcc, number_mode=True)\n",
    "X_train_digits_mfcc_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_mfcc_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_mfcc_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,714\n",
      "Trainable params: 148,522\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19110 samples, validate on 6380 samples\n",
      "Epoch 1/100\n",
      "19110/19110 [==============================] - 20s 1ms/sample - loss: 1.1030 - accuracy: 0.6409 - val_loss: 0.8125 - val_accuracy: 0.7304\n",
      "Epoch 2/100\n",
      "19110/19110 [==============================] - 12s 636us/sample - loss: 0.7868 - accuracy: 0.7475 - val_loss: 0.8500 - val_accuracy: 0.7078\n",
      "Epoch 3/100\n",
      "19110/19110 [==============================] - 12s 603us/sample - loss: 0.6905 - accuracy: 0.7773 - val_loss: 0.5672 - val_accuracy: 0.8168\n",
      "Epoch 4/100\n",
      "19110/19110 [==============================] - 11s 579us/sample - loss: 0.6375 - accuracy: 0.7949 - val_loss: 0.5502 - val_accuracy: 0.8194\n",
      "Epoch 5/100\n",
      "19110/19110 [==============================] - 11s 574us/sample - loss: 0.5951 - accuracy: 0.8061 - val_loss: 0.5931 - val_accuracy: 0.8008\n",
      "Epoch 6/100\n",
      "19110/19110 [==============================] - 13s 660us/sample - loss: 0.5612 - accuracy: 0.8168 - val_loss: 0.6253 - val_accuracy: 0.7854\n",
      "Epoch 7/100\n",
      "19110/19110 [==============================] - 12s 626us/sample - loss: 0.5435 - accuracy: 0.8231 - val_loss: 0.4663 - val_accuracy: 0.8434\n",
      "Epoch 8/100\n",
      "19110/19110 [==============================] - 12s 626us/sample - loss: 0.5229 - accuracy: 0.8251 - val_loss: 0.4972 - val_accuracy: 0.8351\n",
      "Epoch 9/100\n",
      "19110/19110 [==============================] - 12s 630us/sample - loss: 0.4951 - accuracy: 0.8382 - val_loss: 2.0259 - val_accuracy: 0.5392\n",
      "Epoch 10/100\n",
      "19110/19110 [==============================] - 12s 631us/sample - loss: 0.4921 - accuracy: 0.8368 - val_loss: 0.5501 - val_accuracy: 0.8199\n",
      "Epoch 11/100\n",
      "19110/19110 [==============================] - 16s 838us/sample - loss: 0.4785 - accuracy: 0.8419 - val_loss: 0.4408 - val_accuracy: 0.8522\n",
      "Epoch 12/100\n",
      "19110/19110 [==============================] - 12s 621us/sample - loss: 0.4567 - accuracy: 0.8474 - val_loss: 0.6141 - val_accuracy: 0.7944\n",
      "Epoch 13/100\n",
      "19110/19110 [==============================] - 12s 613us/sample - loss: 0.4380 - accuracy: 0.8572 - val_loss: 3.1096 - val_accuracy: 0.4361\n",
      "Epoch 14/100\n",
      "19110/19110 [==============================] - 14s 712us/sample - loss: 0.4479 - accuracy: 0.8501 - val_loss: 0.4638 - val_accuracy: 0.8484\n",
      "Epoch 15/100\n",
      "19110/19110 [==============================] - 11s 558us/sample - loss: 0.4303 - accuracy: 0.8562 - val_loss: 0.4183 - val_accuracy: 0.8556\n",
      "Epoch 16/100\n",
      "19110/19110 [==============================] - 12s 610us/sample - loss: 0.4147 - accuracy: 0.8632 - val_loss: 0.3719 - val_accuracy: 0.8751\n",
      "Epoch 17/100\n",
      "19110/19110 [==============================] - 12s 617us/sample - loss: 0.3965 - accuracy: 0.8686 - val_loss: 0.4767 - val_accuracy: 0.8365\n",
      "Epoch 18/100\n",
      "19110/19110 [==============================] - 11s 577us/sample - loss: 0.4030 - accuracy: 0.8659 - val_loss: 0.3409 - val_accuracy: 0.8842\n",
      "Epoch 19/100\n",
      "19110/19110 [==============================] - 11s 588us/sample - loss: 0.3928 - accuracy: 0.8685 - val_loss: 0.3554 - val_accuracy: 0.8829\n",
      "Epoch 20/100\n",
      "19110/19110 [==============================] - 11s 585us/sample - loss: 0.3916 - accuracy: 0.8694 - val_loss: 0.3615 - val_accuracy: 0.8820\n",
      "Epoch 21/100\n",
      "19110/19110 [==============================] - 10s 532us/sample - loss: 0.3904 - accuracy: 0.8695 - val_loss: 0.5177 - val_accuracy: 0.8207\n",
      "Epoch 22/100\n",
      "19110/19110 [==============================] - 12s 615us/sample - loss: 0.3851 - accuracy: 0.8712 - val_loss: 1.1768 - val_accuracy: 0.7094\n",
      "Epoch 23/100\n",
      "19110/19110 [==============================] - 11s 556us/sample - loss: 0.3792 - accuracy: 0.8730 - val_loss: 0.9088 - val_accuracy: 0.7428\n",
      "Epoch 24/100\n",
      "19110/19110 [==============================] - 12s 603us/sample - loss: 0.3750 - accuracy: 0.8726 - val_loss: 0.6069 - val_accuracy: 0.8016\n",
      "Epoch 25/100\n",
      "19110/19110 [==============================] - 11s 551us/sample - loss: 0.3725 - accuracy: 0.8737 - val_loss: 0.4136 - val_accuracy: 0.8567\n",
      "Epoch 26/100\n",
      "19110/19110 [==============================] - 10s 529us/sample - loss: 0.3623 - accuracy: 0.8770 - val_loss: 0.3825 - val_accuracy: 0.8671\n",
      "Epoch 27/100\n",
      "19110/19110 [==============================] - 10s 542us/sample - loss: 0.3568 - accuracy: 0.8788 - val_loss: 0.4738 - val_accuracy: 0.8472\n",
      "Epoch 28/100\n",
      "19110/19110 [==============================] - 11s 583us/sample - loss: 0.3529 - accuracy: 0.8830 - val_loss: 0.3771 - val_accuracy: 0.8705\n",
      "CPU times: user 9min 19s, sys: 6min 57s, total: 16min 17s\n",
      "Wall time: 5min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91ea6b6090>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       638\n",
      "           1       0.90      0.91      0.90       638\n",
      "           2       0.95      0.76      0.85       638\n",
      "           3       0.72      0.94      0.81       638\n",
      "           4       0.88      0.93      0.90       638\n",
      "           5       0.89      0.89      0.89       638\n",
      "           6       0.90      0.88      0.89       638\n",
      "           7       0.95      0.80      0.87       638\n",
      "           8       0.91      0.87      0.89       638\n",
      "           9       0.90      0.89      0.90       638\n",
      "\n",
      "    accuracy                           0.88      6380\n",
      "   macro avg       0.89      0.88      0.88      6380\n",
      "weighted avg       0.89      0.88      0.88      6380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation, in the MFCC scenario, did not lead to any improvement! Let's see what happens in the spectrograms scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrograms - Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n"
     ]
    }
   ],
   "source": [
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=max_track_length,\n",
    "                             recordings_source=[False, True])\n",
    "\n",
    "X_train_digit = X[0]\n",
    "y_train_digit = y[0]\n",
    "X_val_digit = X[1]\n",
    "y_val_digit = y[1]\n",
    "X_test_digit = X[2]\n",
    "y_test_digit  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1911 638\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_digit, X_val_digit]),\n",
    "                         np.concatenate([y_train_digit, y_val_digit]))\n",
    "\n",
    "X_train_digit = X[0]\n",
    "y_train_digit = y[0]\n",
    "X_val_digit = X[1]\n",
    "y_val_digit = y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 23s, sys: 4.17 s, total: 8min 28s\n",
      "Wall time: 9min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nsamples, nx, ny = X_train_digit.shape\n",
    "X_train_digits_spects_norm_2d = X_train_digit.reshape((nsamples, nx * ny))\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_spects_norm_2d, y_train_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digit.shape\n",
    "X_val_digits_spects_norm_2d = X_val_digit.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       638\n",
      "           1       0.88      0.86      0.87       638\n",
      "           2       0.85      0.88      0.86       638\n",
      "           3       0.82      0.82      0.82       638\n",
      "           4       0.92      0.89      0.91       638\n",
      "           5       0.95      0.85      0.90       638\n",
      "           6       0.86      0.80      0.83       638\n",
      "           7       0.91      0.86      0.88       638\n",
      "           8       0.84      0.89      0.86       638\n",
      "           9       0.79      0.90      0.84       638\n",
      "\n",
      "    accuracy                           0.87      6380\n",
      "   macro avg       0.87      0.87      0.87      6380\n",
      "weighted avg       0.87      0.87      0.87      6380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_val_digits_spects_norm_2d)\n",
    "print(classification_report(y_val_digit, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digit, X_val_digit, X_test_digit_mfcc, y_train_digit, y_val_digit, y_test_digit_mfcc, number_mode=True)\n",
    "\n",
    "X_train_digits_spects_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_spects_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_spects_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 127, 17, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,033,450\n",
      "Trainable params: 1,033,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 19110 samples, validate on 6380 samples\n",
      "Epoch 1/100\n",
      "19110/19110 [==============================] - 48s 3ms/sample - loss: 1.1099 - accuracy: 0.6279 - val_loss: 1.0080 - val_accuracy: 0.6624\n",
      "Epoch 2/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.7199 - accuracy: 0.7666 - val_loss: 0.7804 - val_accuracy: 0.7475\n",
      "Epoch 3/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.6006 - accuracy: 0.8020 - val_loss: 0.7708 - val_accuracy: 0.7563\n",
      "Epoch 4/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.5323 - accuracy: 0.8294 - val_loss: 0.5116 - val_accuracy: 0.8313\n",
      "Epoch 5/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.4653 - accuracy: 0.8501 - val_loss: 0.8829 - val_accuracy: 0.7067\n",
      "Epoch 6/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.4337 - accuracy: 0.8585 - val_loss: 0.6936 - val_accuracy: 0.7788\n",
      "Epoch 7/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.3913 - accuracy: 0.8734 - val_loss: 0.5054 - val_accuracy: 0.8299\n",
      "Epoch 8/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.3649 - accuracy: 0.8814 - val_loss: 0.6611 - val_accuracy: 0.7813\n",
      "Epoch 9/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.3370 - accuracy: 0.8917 - val_loss: 0.4392 - val_accuracy: 0.8596\n",
      "Epoch 10/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.3293 - accuracy: 0.8944 - val_loss: 1.0125 - val_accuracy: 0.7160\n",
      "Epoch 11/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.2952 - accuracy: 0.9050 - val_loss: 0.4318 - val_accuracy: 0.8613\n",
      "Epoch 12/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.2654 - accuracy: 0.9152 - val_loss: 1.3437 - val_accuracy: 0.6666\n",
      "Epoch 13/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.2706 - accuracy: 0.9117 - val_loss: 0.4856 - val_accuracy: 0.8498\n",
      "Epoch 14/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.2522 - accuracy: 0.9169 - val_loss: 0.4391 - val_accuracy: 0.8679\n",
      "Epoch 15/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.2292 - accuracy: 0.9260 - val_loss: 0.4692 - val_accuracy: 0.8527\n",
      "Epoch 16/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.2140 - accuracy: 0.9299 - val_loss: 0.5643 - val_accuracy: 0.8306\n",
      "Epoch 17/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.2071 - accuracy: 0.9325 - val_loss: 0.7151 - val_accuracy: 0.7870\n",
      "Epoch 18/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.2119 - accuracy: 0.9305 - val_loss: 3.5994 - val_accuracy: 0.5560\n",
      "Epoch 19/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.2120 - accuracy: 0.9299 - val_loss: 0.3452 - val_accuracy: 0.8848\n",
      "Epoch 20/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.1833 - accuracy: 0.9398 - val_loss: 1.0688 - val_accuracy: 0.7292\n",
      "Epoch 21/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.1933 - accuracy: 0.9368 - val_loss: 0.3095 - val_accuracy: 0.8991\n",
      "Epoch 22/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.1691 - accuracy: 0.9452 - val_loss: 0.6056 - val_accuracy: 0.8114\n",
      "Epoch 23/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.1641 - accuracy: 0.9469 - val_loss: 0.5151 - val_accuracy: 0.8563\n",
      "Epoch 24/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.1526 - accuracy: 0.9503 - val_loss: 0.4428 - val_accuracy: 0.8542\n",
      "Epoch 25/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.1522 - accuracy: 0.9501 - val_loss: 0.6453 - val_accuracy: 0.8234\n",
      "Epoch 26/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.1452 - accuracy: 0.9515 - val_loss: 0.7921 - val_accuracy: 0.7864\n",
      "Epoch 27/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.1447 - accuracy: 0.9531 - val_loss: 0.4962 - val_accuracy: 0.8635\n",
      "Epoch 28/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.1364 - accuracy: 0.9539 - val_loss: 0.4453 - val_accuracy: 0.8734\n",
      "Epoch 29/100\n",
      "19110/19110 [==============================] - 45s 2ms/sample - loss: 0.1303 - accuracy: 0.9590 - val_loss: 0.9899 - val_accuracy: 0.7575\n",
      "Epoch 30/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.1310 - accuracy: 0.9567 - val_loss: 0.4502 - val_accuracy: 0.8688\n",
      "Epoch 31/100\n",
      "19110/19110 [==============================] - 44s 2ms/sample - loss: 0.1202 - accuracy: 0.9608 - val_loss: 0.3365 - val_accuracy: 0.8975\n",
      "CPU times: user 32min 59s, sys: 16min 38s, total: 49min 38s\n",
      "Wall time: 23min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91395f4710>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_spects_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       638\n",
      "           1       0.94      0.87      0.90       638\n",
      "           2       0.87      0.91      0.89       638\n",
      "           3       0.87      0.86      0.86       638\n",
      "           4       0.92      0.92      0.92       638\n",
      "           5       0.88      0.89      0.89       638\n",
      "           6       0.93      0.87      0.90       638\n",
      "           7       0.81      0.93      0.86       638\n",
      "           8       0.95      0.87      0.91       638\n",
      "           9       0.88      0.92      0.90       638\n",
      "\n",
      "    accuracy                           0.90      6380\n",
      "   macro avg       0.90      0.90      0.90      6380\n",
      "weighted avg       0.90      0.90      0.90      6380\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are worse than the normal scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model\n",
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preparation.balanced_train_val_test_split(pad_recordings, labels_digits)\n",
    "X_train_digits = X[0]\n",
    "y_train_digits = y[0]\n",
    "X_val_digits = X[1]\n",
    "y_val_digits = y[1] \n",
    "X_test_digits = X[2]\n",
    "y_test_digits = y[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 342 ms, total: 23.3 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_digits])\n",
    "\n",
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digits_mfcc,\n",
    "                                                       X_val_digits_mfcc,\n",
    "                                                       X_test_digits_mfcc,\n",
    "                                                       y_train_digits,\n",
    "                                                       y_val_digits,\n",
    "                                                       y_test_digits,\n",
    "                                                       number_mode=True)\n",
    "\n",
    "X_train_digits_mfcc_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_mfcc_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_mfcc_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digits_best = np.concatenate([X_train_digits_mfcc_nn, X_val_digits_mfcc_nn])\n",
    "y_train_digits_best = np.concatenate([y_train_digits_nn, y_val_digits_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,714\n",
      "Trainable params: 148,522\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1910 samples\n",
      "Epoch 1/59\n",
      "1910/1910 [==============================] - 3s 2ms/sample - loss: 1.1162 - accuracy: 0.6471\n",
      "Epoch 2/59\n",
      "1910/1910 [==============================] - 2s 786us/sample - loss: 0.5728 - accuracy: 0.8524\n",
      "Epoch 3/59\n",
      "1910/1910 [==============================] - 1s 672us/sample - loss: 0.4451 - accuracy: 0.8911\n",
      "Epoch 4/59\n",
      "1910/1910 [==============================] - 1s 722us/sample - loss: 0.3783 - accuracy: 0.9073\n",
      "Epoch 5/59\n",
      "1910/1910 [==============================] - 1s 678us/sample - loss: 0.3282 - accuracy: 0.9246\n",
      "Epoch 6/59\n",
      "1910/1910 [==============================] - 1s 634us/sample - loss: 0.3054 - accuracy: 0.9304\n",
      "Epoch 7/59\n",
      "1910/1910 [==============================] - 1s 643us/sample - loss: 0.2701 - accuracy: 0.9403\n",
      "Epoch 8/59\n",
      "1910/1910 [==============================] - 1s 636us/sample - loss: 0.2356 - accuracy: 0.9529\n",
      "Epoch 9/59\n",
      "1910/1910 [==============================] - 1s 653us/sample - loss: 0.2110 - accuracy: 0.9607\n",
      "Epoch 10/59\n",
      "1910/1910 [==============================] - 1s 630us/sample - loss: 0.1948 - accuracy: 0.9639\n",
      "Epoch 11/59\n",
      "1910/1910 [==============================] - 1s 619us/sample - loss: 0.1917 - accuracy: 0.9618\n",
      "Epoch 12/59\n",
      "1910/1910 [==============================] - 1s 649us/sample - loss: 0.1741 - accuracy: 0.9649\n",
      "Epoch 13/59\n",
      "1910/1910 [==============================] - 1s 635us/sample - loss: 0.1612 - accuracy: 0.9738\n",
      "Epoch 14/59\n",
      "1910/1910 [==============================] - 1s 626us/sample - loss: 0.1446 - accuracy: 0.9696\n",
      "Epoch 15/59\n",
      "1910/1910 [==============================] - 1s 712us/sample - loss: 0.1304 - accuracy: 0.9764\n",
      "Epoch 16/59\n",
      "1910/1910 [==============================] - 1s 601us/sample - loss: 0.1427 - accuracy: 0.9691\n",
      "Epoch 17/59\n",
      "1910/1910 [==============================] - 1s 743us/sample - loss: 0.1309 - accuracy: 0.9759\n",
      "Epoch 18/59\n",
      "1910/1910 [==============================] - 1s 761us/sample - loss: 0.1246 - accuracy: 0.9806\n",
      "Epoch 19/59\n",
      "1910/1910 [==============================] - 1s 608us/sample - loss: 0.1109 - accuracy: 0.9817\n",
      "Epoch 20/59\n",
      "1910/1910 [==============================] - 1s 649us/sample - loss: 0.1151 - accuracy: 0.9785\n",
      "Epoch 21/59\n",
      "1910/1910 [==============================] - 1s 627us/sample - loss: 0.1045 - accuracy: 0.9796\n",
      "Epoch 22/59\n",
      "1910/1910 [==============================] - 1s 604us/sample - loss: 0.1006 - accuracy: 0.9848\n",
      "Epoch 23/59\n",
      "1910/1910 [==============================] - 1s 708us/sample - loss: 0.0986 - accuracy: 0.9838\n",
      "Epoch 24/59\n",
      "1910/1910 [==============================] - 1s 623us/sample - loss: 0.0837 - accuracy: 0.9916\n",
      "Epoch 25/59\n",
      "1910/1910 [==============================] - 1s 636us/sample - loss: 0.0895 - accuracy: 0.9827\n",
      "Epoch 26/59\n",
      "1910/1910 [==============================] - 1s 589us/sample - loss: 0.0794 - accuracy: 0.9874\n",
      "Epoch 27/59\n",
      "1910/1910 [==============================] - 1s 763us/sample - loss: 0.0837 - accuracy: 0.9853\n",
      "Epoch 28/59\n",
      "1910/1910 [==============================] - 2s 949us/sample - loss: 0.0731 - accuracy: 0.9895\n",
      "Epoch 29/59\n",
      "1910/1910 [==============================] - 2s 928us/sample - loss: 0.0869 - accuracy: 0.9827\n",
      "Epoch 30/59\n",
      "1910/1910 [==============================] - 1s 621us/sample - loss: 0.0664 - accuracy: 0.9937\n",
      "Epoch 31/59\n",
      "1910/1910 [==============================] - 1s 595us/sample - loss: 0.0741 - accuracy: 0.9885\n",
      "Epoch 32/59\n",
      "1910/1910 [==============================] - 1s 612us/sample - loss: 0.0615 - accuracy: 0.9937\n",
      "Epoch 33/59\n",
      "1910/1910 [==============================] - 1s 711us/sample - loss: 0.0673 - accuracy: 0.9911\n",
      "Epoch 34/59\n",
      "1910/1910 [==============================] - 1s 619us/sample - loss: 0.0622 - accuracy: 0.9921\n",
      "Epoch 35/59\n",
      "1910/1910 [==============================] - 1s 630us/sample - loss: 0.0579 - accuracy: 0.9932\n",
      "Epoch 36/59\n",
      "1910/1910 [==============================] - 1s 620us/sample - loss: 0.0573 - accuracy: 0.9916\n",
      "Epoch 37/59\n",
      "1910/1910 [==============================] - 1s 636us/sample - loss: 0.0498 - accuracy: 0.9948\n",
      "Epoch 38/59\n",
      "1910/1910 [==============================] - 1s 638us/sample - loss: 0.0479 - accuracy: 0.9958\n",
      "Epoch 39/59\n",
      "1910/1910 [==============================] - 1s 669us/sample - loss: 0.0498 - accuracy: 0.9921\n",
      "Epoch 40/59\n",
      "1910/1910 [==============================] - 1s 633us/sample - loss: 0.0471 - accuracy: 0.9958\n",
      "Epoch 41/59\n",
      "1910/1910 [==============================] - 1s 571us/sample - loss: 0.0457 - accuracy: 0.9942\n",
      "Epoch 42/59\n",
      "1910/1910 [==============================] - 1s 564us/sample - loss: 0.0470 - accuracy: 0.9937\n",
      "Epoch 43/59\n",
      "1910/1910 [==============================] - 1s 604us/sample - loss: 0.0423 - accuracy: 0.9948\n",
      "Epoch 44/59\n",
      "1910/1910 [==============================] - 1s 613us/sample - loss: 0.0436 - accuracy: 0.9953\n",
      "Epoch 45/59\n",
      "1910/1910 [==============================] - 1s 622us/sample - loss: 0.0406 - accuracy: 0.9948\n",
      "Epoch 46/59\n",
      "1910/1910 [==============================] - 1s 589us/sample - loss: 0.0489 - accuracy: 0.9906\n",
      "Epoch 47/59\n",
      "1910/1910 [==============================] - 1s 593us/sample - loss: 0.0354 - accuracy: 0.9984\n",
      "Epoch 48/59\n",
      "1910/1910 [==============================] - 1s 576us/sample - loss: 0.0378 - accuracy: 0.9969\n",
      "Epoch 49/59\n",
      "1910/1910 [==============================] - 1s 641us/sample - loss: 0.0369 - accuracy: 0.9969\n",
      "Epoch 50/59\n",
      "1910/1910 [==============================] - 1s 654us/sample - loss: 0.0338 - accuracy: 0.9969\n",
      "Epoch 51/59\n",
      "1910/1910 [==============================] - 1s 676us/sample - loss: 0.0308 - accuracy: 0.9958\n",
      "Epoch 52/59\n",
      "1910/1910 [==============================] - 1s 620us/sample - loss: 0.0341 - accuracy: 0.9963\n",
      "Epoch 53/59\n",
      "1910/1910 [==============================] - 1s 725us/sample - loss: 0.0329 - accuracy: 0.9974\n",
      "Epoch 54/59\n",
      "1910/1910 [==============================] - 1s 676us/sample - loss: 0.0324 - accuracy: 0.9963\n",
      "Epoch 55/59\n",
      "1910/1910 [==============================] - 2s 793us/sample - loss: 0.0263 - accuracy: 0.9995\n",
      "Epoch 56/59\n",
      "1910/1910 [==============================] - 1s 664us/sample - loss: 0.0314 - accuracy: 0.9979\n",
      "Epoch 57/59\n",
      "1910/1910 [==============================] - 1s 509us/sample - loss: 0.0347 - accuracy: 0.9963\n",
      "Epoch 58/59\n",
      "1910/1910 [==============================] - 1s 504us/sample - loss: 0.0307 - accuracy: 0.9979\n",
      "Epoch 59/59\n",
      "1910/1910 [==============================] - 1s 507us/sample - loss: 0.0332 - accuracy: 0.9963\n",
      "CPU times: user 1min 32s, sys: 27.9 s, total: 2min\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f913c516d10>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10,\n",
    "                                batch_normalisation=True)\n",
    "model.fit(X_train_digits_best, y_train_digits_best,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=59,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn = np.argmax(y_test_digits_nn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test_digits_mfcc_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        49\n",
      "           1       1.00      1.00      1.00        49\n",
      "           2       0.98      0.96      0.97        49\n",
      "           3       0.98      1.00      0.99        49\n",
      "           4       1.00      1.00      1.00        49\n",
      "           5       0.98      0.98      0.98        49\n",
      "           6       0.94      0.96      0.95        49\n",
      "           7       0.96      0.96      0.96        48\n",
      "           8       0.98      0.94      0.96        49\n",
      "           9       0.96      0.98      0.97        48\n",
      "\n",
      "    accuracy                           0.98       488\n",
      "   macro avg       0.98      0.98      0.98       488\n",
      "weighted avg       0.98      0.98      0.98       488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./best_models/digits.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speakers\n",
    "## Std - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 579 ms, total: 26 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 ms, sys: 4.93 ms, total: 22.8 ms\n",
      "Wall time: 20.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaler_normal = StandardScaler()\n",
    "X_train_speakers_mfcc = scaler_normal.fit_transform(X_train_speakers_mfcc)\n",
    "X_val_speakers_mfcc =  scaler_normal.transform(X_val_speakers_mfcc)\n",
    "X_test_speakers_mfcc =  scaler_normal.transform(X_test_speakers_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_speakers_mfcc, y_train_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.95      0.97        20\n",
      "      alinda       1.00      0.95      0.97        20\n",
      "        gian       0.95      1.00      0.98        20\n",
      "     jackson       1.00      0.90      0.95        20\n",
      "      khaled       0.87      1.00      0.93        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       1.00      0.90      0.95        20\n",
      "    yweweler       0.91      1.00      0.95        20\n",
      "\n",
      "    accuracy                           0.96       160\n",
      "   macro avg       0.97      0.96      0.96       160\n",
      "weighted avg       0.97      0.96      0.96       160\n",
      "\n",
      "CPU times: user 30.6 ms, sys: 2.23 ms, total: 32.8 ms\n",
      "Wall time: 37.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_speakers_mfcc)\n",
    "print(classification_report(y_val_speakers, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.6 s, sys: 389 ms, total: 24 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 ms, sys: 1.95 ms, total: 15.1 ms\n",
      "Wall time: 9.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y, input_shape, target_names= data_preparation.prepare_data_nn(X_train_speakers_mfcc, X_val_speakers_mfcc, X_test_speakers_mfcc, y_train_speakers, y_val_speakers, y_test_speakers, number_mode=False)\n",
    "\n",
    "X_train_speakers_mfcc_nn = X[0]\n",
    "y_train_speakers_nn = y[0]\n",
    "X_val_speakers_mfcc_nn = X[1]\n",
    "y_val_speakers_nn = y[1]\n",
    "X_test_speakers_mfcc_nn = X[2]\n",
    "y_test_speakers_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 148,584\n",
      "Trainable params: 148,392\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 1.6878 - accuracy: 0.4021 - val_loss: 10.0686 - val_accuracy: 0.2375\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 0s 747us/sample - loss: 0.9089 - accuracy: 0.6917 - val_loss: 5.0205 - val_accuracy: 0.3000\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 0s 780us/sample - loss: 0.7186 - accuracy: 0.7583 - val_loss: 3.6707 - val_accuracy: 0.3688\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 0s 968us/sample - loss: 0.5493 - accuracy: 0.8521 - val_loss: 2.3445 - val_accuracy: 0.4250\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 0s 938us/sample - loss: 0.4826 - accuracy: 0.8896 - val_loss: 1.6991 - val_accuracy: 0.5312\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.4027 - accuracy: 0.8896 - val_loss: 1.5600 - val_accuracy: 0.5188\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.3161 - accuracy: 0.9312 - val_loss: 1.0543 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.2724 - accuracy: 0.9438 - val_loss: 0.9403 - val_accuracy: 0.6687\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.2587 - accuracy: 0.9500 - val_loss: 0.8130 - val_accuracy: 0.6938\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.2453 - accuracy: 0.9563 - val_loss: 0.5947 - val_accuracy: 0.7812\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 0s 967us/sample - loss: 0.1990 - accuracy: 0.9667 - val_loss: 0.4418 - val_accuracy: 0.8687\n",
      "Epoch 12/100\n",
      "480/480 [==============================] - 0s 796us/sample - loss: 0.2029 - accuracy: 0.9667 - val_loss: 0.3590 - val_accuracy: 0.8938\n",
      "Epoch 13/100\n",
      "480/480 [==============================] - 0s 791us/sample - loss: 0.1838 - accuracy: 0.9688 - val_loss: 0.3360 - val_accuracy: 0.9062\n",
      "Epoch 14/100\n",
      "480/480 [==============================] - 0s 826us/sample - loss: 0.1721 - accuracy: 0.9812 - val_loss: 0.2945 - val_accuracy: 0.9500\n",
      "Epoch 15/100\n",
      "480/480 [==============================] - 0s 722us/sample - loss: 0.1584 - accuracy: 0.9771 - val_loss: 0.3220 - val_accuracy: 0.8813\n",
      "Epoch 16/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.1354 - accuracy: 0.9875 - val_loss: 0.2353 - val_accuracy: 0.9500\n",
      "Epoch 17/100\n",
      "480/480 [==============================] - 0s 801us/sample - loss: 0.1326 - accuracy: 0.9917 - val_loss: 0.2436 - val_accuracy: 0.9312\n",
      "Epoch 18/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.1324 - accuracy: 0.9896 - val_loss: 0.2277 - val_accuracy: 0.9312\n",
      "Epoch 19/100\n",
      "480/480 [==============================] - 0s 816us/sample - loss: 0.1202 - accuracy: 0.9917 - val_loss: 0.2024 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "480/480 [==============================] - 0s 769us/sample - loss: 0.1119 - accuracy: 0.9937 - val_loss: 0.1849 - val_accuracy: 0.9563\n",
      "Epoch 21/100\n",
      "480/480 [==============================] - 0s 761us/sample - loss: 0.1115 - accuracy: 0.9875 - val_loss: 0.1788 - val_accuracy: 0.9625\n",
      "Epoch 22/100\n",
      "480/480 [==============================] - 0s 691us/sample - loss: 0.1024 - accuracy: 0.9917 - val_loss: 0.1884 - val_accuracy: 0.9625\n",
      "Epoch 23/100\n",
      "480/480 [==============================] - 0s 710us/sample - loss: 0.0943 - accuracy: 0.9958 - val_loss: 0.1589 - val_accuracy: 0.9688\n",
      "Epoch 24/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0999 - accuracy: 0.9917 - val_loss: 0.1554 - val_accuracy: 0.9625\n",
      "Epoch 25/100\n",
      "480/480 [==============================] - 0s 797us/sample - loss: 0.0924 - accuracy: 0.9937 - val_loss: 0.1538 - val_accuracy: 0.9625\n",
      "Epoch 26/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0871 - accuracy: 0.9958 - val_loss: 0.2008 - val_accuracy: 0.9250\n",
      "Epoch 27/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0819 - accuracy: 0.9958 - val_loss: 0.1548 - val_accuracy: 0.9625\n",
      "Epoch 28/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0762 - accuracy: 0.9958 - val_loss: 0.1409 - val_accuracy: 0.9625\n",
      "Epoch 29/100\n",
      "480/480 [==============================] - 0s 749us/sample - loss: 0.0732 - accuracy: 0.9979 - val_loss: 0.1421 - val_accuracy: 0.9750\n",
      "Epoch 30/100\n",
      "480/480 [==============================] - 0s 677us/sample - loss: 0.0718 - accuracy: 0.9958 - val_loss: 0.1423 - val_accuracy: 0.9812\n",
      "Epoch 31/100\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.0700 - accuracy: 0.9958 - val_loss: 0.1580 - val_accuracy: 0.9688\n",
      "Epoch 32/100\n",
      "480/480 [==============================] - 0s 758us/sample - loss: 0.0673 - accuracy: 0.9979 - val_loss: 0.1379 - val_accuracy: 0.9625\n",
      "Epoch 33/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.0683 - accuracy: 0.9958 - val_loss: 0.1528 - val_accuracy: 0.9563\n",
      "Epoch 34/100\n",
      "480/480 [==============================] - 0s 817us/sample - loss: 0.0621 - accuracy: 0.9979 - val_loss: 0.1455 - val_accuracy: 0.9625\n",
      "Epoch 35/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9500\n",
      "Epoch 36/100\n",
      "480/480 [==============================] - 0s 789us/sample - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9625\n",
      "Epoch 37/100\n",
      "480/480 [==============================] - 0s 766us/sample - loss: 0.0645 - accuracy: 0.9937 - val_loss: 0.1246 - val_accuracy: 0.9688\n",
      "Epoch 38/100\n",
      "480/480 [==============================] - 0s 717us/sample - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9438\n",
      "Epoch 39/100\n",
      "480/480 [==============================] - 0s 904us/sample - loss: 0.0565 - accuracy: 0.9937 - val_loss: 0.1309 - val_accuracy: 0.9625\n",
      "Epoch 40/100\n",
      "480/480 [==============================] - 0s 753us/sample - loss: 0.0636 - accuracy: 0.9979 - val_loss: 0.1141 - val_accuracy: 0.9750\n",
      "Epoch 41/100\n",
      "480/480 [==============================] - 0s 858us/sample - loss: 0.0514 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9750\n",
      "Epoch 42/100\n",
      "480/480 [==============================] - 0s 829us/sample - loss: 0.0612 - accuracy: 0.9958 - val_loss: 0.1612 - val_accuracy: 0.9375\n",
      "Epoch 43/100\n",
      "480/480 [==============================] - 0s 792us/sample - loss: 0.0605 - accuracy: 0.9979 - val_loss: 0.1884 - val_accuracy: 0.9187\n",
      "Epoch 44/100\n",
      "480/480 [==============================] - 0s 781us/sample - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9500\n",
      "Epoch 45/100\n",
      "480/480 [==============================] - 0s 764us/sample - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9563\n",
      "Epoch 46/100\n",
      "480/480 [==============================] - 0s 891us/sample - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "480/480 [==============================] - 0s 790us/sample - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 0.9563\n",
      "Epoch 48/100\n",
      "480/480 [==============================] - 0s 866us/sample - loss: 0.0463 - accuracy: 0.9979 - val_loss: 0.1534 - val_accuracy: 0.9438\n",
      "Epoch 49/100\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9688\n",
      "Epoch 50/100\n",
      "480/480 [==============================] - 0s 800us/sample - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9500\n",
      "Epoch 51/100\n",
      "480/480 [==============================] - 0s 724us/sample - loss: 0.0426 - accuracy: 0.9979 - val_loss: 0.1304 - val_accuracy: 0.9625\n",
      "Epoch 52/100\n",
      "480/480 [==============================] - 0s 769us/sample - loss: 0.0453 - accuracy: 0.9979 - val_loss: 0.1130 - val_accuracy: 0.9750\n",
      "Epoch 53/100\n",
      "480/480 [==============================] - 0s 688us/sample - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9750\n",
      "Epoch 54/100\n",
      "480/480 [==============================] - 0s 712us/sample - loss: 0.0352 - accuracy: 0.9979 - val_loss: 0.1021 - val_accuracy: 0.9750\n",
      "Epoch 55/100\n",
      "480/480 [==============================] - 0s 694us/sample - loss: 0.0353 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9563\n",
      "Epoch 56/100\n",
      "480/480 [==============================] - 0s 680us/sample - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9625\n",
      "Epoch 57/100\n",
      "480/480 [==============================] - 0s 701us/sample - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9688\n",
      "Epoch 58/100\n",
      "480/480 [==============================] - 0s 711us/sample - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9500\n",
      "Epoch 59/100\n",
      "480/480 [==============================] - 0s 728us/sample - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9750\n",
      "Epoch 60/100\n",
      "480/480 [==============================] - 0s 705us/sample - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9750\n",
      "Epoch 61/100\n",
      "480/480 [==============================] - 0s 708us/sample - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9750\n",
      "Epoch 62/100\n",
      "480/480 [==============================] - 0s 695us/sample - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9625\n",
      "Epoch 63/100\n",
      "480/480 [==============================] - 0s 676us/sample - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9688\n",
      "Epoch 64/100\n",
      "480/480 [==============================] - 0s 742us/sample - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9563\n",
      "CPU times: user 43.4 s, sys: 33.1 s, total: 1min 16s\n",
      "Wall time: 30.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90d13c77d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)\n",
    "model.fit(X_train_speakers_mfcc_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "         callbacks=[callback],\n",
    "         validation_data=(X_val_speakers_mfcc_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get full performances on val set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      1.00      0.98        20\n",
      "      alinda       0.95      0.95      0.95        20\n",
      "        gian       0.95      1.00      0.98        20\n",
      "     jackson       1.00      0.95      0.97        20\n",
      "      khaled       1.00      0.95      0.97        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       1.00      0.95      0.97        20\n",
      "    yweweler       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.98      0.97      0.97       160\n",
      "weighted avg       0.98      0.97      0.97       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent performances! Let's now see what happens with spectrograms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Std - Spects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.1 s, sys: 925 ms, total: 26.1 s\n",
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_train_speakers])\n",
    "X_val_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_val_speakers])\n",
    "X_test_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speakers_spects.shape\n",
    "X_train_speakers_spects_2d = X_train_speakers_spects.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_speakers_spects.shape\n",
    "X_val_speakers_spects_2d = X_val_speakers_spects.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_test_speakers_spects.shape\n",
    "X_test_speakers_spects_2d = X_test_speakers_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_speakers_spects_2d, y_train_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      0.95      0.95        20\n",
      "      alinda       1.00      0.95      0.97        20\n",
      "        gian       0.95      1.00      0.98        20\n",
      "     jackson       1.00      0.95      0.97        20\n",
      "      khaled       1.00      1.00      1.00        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       0.91      1.00      0.95        20\n",
      "    yweweler       0.95      0.90      0.92        20\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.97      0.97      0.97       160\n",
      "weighted avg       0.97      0.97      0.97       160\n",
      "\n",
      "CPU times: user 269 ms, sys: 7.72 ms, total: 277 ms\n",
      "Wall time: 345 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_speakers_spects_2d)\n",
    "print(classification_report(y_val_speakers, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances are at the level of MFCC\n",
    "### CNN - Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 814 ms, total: 24.7 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_train_speakers])\n",
    "X_val_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_val_speakers])\n",
    "X_test_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.2 ms, sys: 41.7 ms, total: 98.9 ms\n",
      "Wall time: 147 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speakers_spects, X_val_speakers_spects, X_test_speakers_spects, y_train_speakers, y_val_speakers, y_test_speakers, number_mode=False)\n",
    "\n",
    "X_train_speakers_spects_nn = X[0]\n",
    "y_train_speakers_nn = y[0]\n",
    "X_val_speakers_spects_nn = X[1]\n",
    "y_val_speakers_nn = y[1]\n",
    "X_test_speakers_spects_nn = X[2]\n",
    "y_test_speakers_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 67,744\n",
      "Trainable params: 67,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "480/480 [==============================] - 5s 11ms/sample - loss: 2.1125 - accuracy: 0.1187 - val_loss: 2.0614 - val_accuracy: 0.1688\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 2.0669 - accuracy: 0.1458 - val_loss: 2.0352 - val_accuracy: 0.1437\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 2.0321 - accuracy: 0.1646 - val_loss: 2.0196 - val_accuracy: 0.1562\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0311 - accuracy: 0.1500 - val_loss: 2.0021 - val_accuracy: 0.2188\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 2.0325 - accuracy: 0.1604 - val_loss: 1.9872 - val_accuracy: 0.2438\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0097 - accuracy: 0.1958 - val_loss: 1.9683 - val_accuracy: 0.2812\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.9760 - accuracy: 0.2188 - val_loss: 1.9415 - val_accuracy: 0.3063\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.9532 - accuracy: 0.2500 - val_loss: 1.9073 - val_accuracy: 0.3375\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.9309 - accuracy: 0.2417 - val_loss: 1.8873 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8984 - accuracy: 0.2896 - val_loss: 1.8208 - val_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8863 - accuracy: 0.2792 - val_loss: 1.7851 - val_accuracy: 0.4688\n",
      "Epoch 12/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8446 - accuracy: 0.2917 - val_loss: 1.7446 - val_accuracy: 0.4250\n",
      "Epoch 13/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7960 - accuracy: 0.3083 - val_loss: 1.6909 - val_accuracy: 0.5250\n",
      "Epoch 14/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7718 - accuracy: 0.3646 - val_loss: 1.6483 - val_accuracy: 0.4750\n",
      "Epoch 15/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7680 - accuracy: 0.3146 - val_loss: 1.6208 - val_accuracy: 0.5125\n",
      "Epoch 16/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.7116 - accuracy: 0.3292 - val_loss: 1.5453 - val_accuracy: 0.5250\n",
      "Epoch 17/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.6402 - accuracy: 0.3854 - val_loss: 1.4922 - val_accuracy: 0.5625\n",
      "Epoch 18/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.6330 - accuracy: 0.3875 - val_loss: 1.4357 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 1.5573 - accuracy: 0.4062 - val_loss: 1.4000 - val_accuracy: 0.5063\n",
      "Epoch 20/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 1.5654 - accuracy: 0.4333 - val_loss: 1.3335 - val_accuracy: 0.6187\n",
      "Epoch 21/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 1.4974 - accuracy: 0.4542 - val_loss: 1.2928 - val_accuracy: 0.6438\n",
      "Epoch 22/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 1.4624 - accuracy: 0.4812 - val_loss: 1.3418 - val_accuracy: 0.5562\n",
      "Epoch 23/100\n",
      "480/480 [==============================] - 2s 5ms/sample - loss: 1.3885 - accuracy: 0.4854 - val_loss: 1.1781 - val_accuracy: 0.6875\n",
      "Epoch 24/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3692 - accuracy: 0.4729 - val_loss: 1.1505 - val_accuracy: 0.6812\n",
      "Epoch 25/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.3586 - accuracy: 0.5021 - val_loss: 1.1476 - val_accuracy: 0.6938\n",
      "Epoch 26/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.2679 - accuracy: 0.5333 - val_loss: 1.2549 - val_accuracy: 0.5938\n",
      "Epoch 27/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.2969 - accuracy: 0.5354 - val_loss: 1.0054 - val_accuracy: 0.7375\n",
      "Epoch 28/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.2495 - accuracy: 0.5125 - val_loss: 0.9599 - val_accuracy: 0.7625\n",
      "Epoch 29/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.1536 - accuracy: 0.5917 - val_loss: 0.9027 - val_accuracy: 0.7437\n",
      "Epoch 30/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.1294 - accuracy: 0.5813 - val_loss: 0.8910 - val_accuracy: 0.7688\n",
      "Epoch 31/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.1319 - accuracy: 0.6167 - val_loss: 0.9664 - val_accuracy: 0.7188\n",
      "Epoch 32/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 1.0419 - accuracy: 0.6250 - val_loss: 0.7854 - val_accuracy: 0.7875\n",
      "Epoch 33/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0914 - accuracy: 0.6271 - val_loss: 0.8277 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0318 - accuracy: 0.6250 - val_loss: 0.7599 - val_accuracy: 0.8125\n",
      "Epoch 35/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.9659 - accuracy: 0.6458 - val_loss: 0.8986 - val_accuracy: 0.6938\n",
      "Epoch 36/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.0185 - accuracy: 0.6271 - val_loss: 0.8152 - val_accuracy: 0.7312\n",
      "Epoch 37/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9417 - accuracy: 0.6521 - val_loss: 0.6764 - val_accuracy: 0.8188\n",
      "Epoch 38/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9359 - accuracy: 0.6604 - val_loss: 0.6777 - val_accuracy: 0.8125\n",
      "Epoch 39/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8931 - accuracy: 0.6938 - val_loss: 0.6663 - val_accuracy: 0.8438\n",
      "Epoch 40/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.8598 - accuracy: 0.6917 - val_loss: 0.8966 - val_accuracy: 0.7437\n",
      "Epoch 41/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.8295 - accuracy: 0.7000 - val_loss: 0.5652 - val_accuracy: 0.8375\n",
      "Epoch 42/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.7908 - accuracy: 0.7208 - val_loss: 0.6381 - val_accuracy: 0.7875\n",
      "Epoch 43/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.7836 - accuracy: 0.7063 - val_loss: 0.5835 - val_accuracy: 0.8375\n",
      "Epoch 44/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.6953 - accuracy: 0.7625 - val_loss: 0.5358 - val_accuracy: 0.8500\n",
      "Epoch 45/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.7026 - accuracy: 0.7500 - val_loss: 0.5321 - val_accuracy: 0.8375\n",
      "Epoch 46/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.7396 - accuracy: 0.7479 - val_loss: 0.5225 - val_accuracy: 0.8687\n",
      "Epoch 47/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.7175 - accuracy: 0.7458 - val_loss: 0.4833 - val_accuracy: 0.8562\n",
      "Epoch 48/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.6790 - accuracy: 0.7250 - val_loss: 0.5337 - val_accuracy: 0.8500\n",
      "Epoch 49/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.6274 - accuracy: 0.7958 - val_loss: 0.4928 - val_accuracy: 0.8188\n",
      "Epoch 50/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.6397 - accuracy: 0.7750 - val_loss: 0.4567 - val_accuracy: 0.8438\n",
      "Epoch 51/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.6070 - accuracy: 0.7667 - val_loss: 0.4739 - val_accuracy: 0.8313\n",
      "Epoch 52/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.6054 - accuracy: 0.7729 - val_loss: 0.4476 - val_accuracy: 0.8687\n",
      "Epoch 53/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.6124 - accuracy: 0.7750 - val_loss: 0.4298 - val_accuracy: 0.9062\n",
      "Epoch 54/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.5923 - accuracy: 0.7833 - val_loss: 0.4272 - val_accuracy: 0.8687\n",
      "Epoch 55/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.5149 - accuracy: 0.8083 - val_loss: 0.3724 - val_accuracy: 0.8938\n",
      "Epoch 56/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.6132 - accuracy: 0.7875 - val_loss: 0.3645 - val_accuracy: 0.8938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.5493 - accuracy: 0.8042 - val_loss: 0.6004 - val_accuracy: 0.8000\n",
      "Epoch 58/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.5073 - accuracy: 0.8292 - val_loss: 0.4361 - val_accuracy: 0.8750\n",
      "Epoch 59/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4766 - accuracy: 0.8396 - val_loss: 0.4097 - val_accuracy: 0.9062\n",
      "Epoch 60/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.4842 - accuracy: 0.8292 - val_loss: 0.4234 - val_accuracy: 0.8562\n",
      "Epoch 61/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.5475 - accuracy: 0.8083 - val_loss: 0.3254 - val_accuracy: 0.9187\n",
      "Epoch 62/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.4810 - accuracy: 0.8250 - val_loss: 0.4261 - val_accuracy: 0.8562\n",
      "Epoch 63/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.4769 - accuracy: 0.8417 - val_loss: 0.3350 - val_accuracy: 0.9062\n",
      "Epoch 64/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.4533 - accuracy: 0.8458 - val_loss: 0.2830 - val_accuracy: 0.9438\n",
      "Epoch 65/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.4081 - accuracy: 0.8854 - val_loss: 0.3159 - val_accuracy: 0.8938\n",
      "Epoch 66/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4675 - accuracy: 0.8062 - val_loss: 0.2728 - val_accuracy: 0.9125\n",
      "Epoch 67/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3622 - accuracy: 0.8833 - val_loss: 0.2681 - val_accuracy: 0.9250\n",
      "Epoch 68/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.4952 - accuracy: 0.8250 - val_loss: 0.3021 - val_accuracy: 0.9438\n",
      "Epoch 69/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3813 - accuracy: 0.8813 - val_loss: 0.3378 - val_accuracy: 0.9125\n",
      "Epoch 70/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3561 - accuracy: 0.8562 - val_loss: 0.2471 - val_accuracy: 0.9312\n",
      "Epoch 71/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3773 - accuracy: 0.8729 - val_loss: 0.2560 - val_accuracy: 0.9312\n",
      "Epoch 72/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3805 - accuracy: 0.8708 - val_loss: 0.3252 - val_accuracy: 0.9250\n",
      "Epoch 73/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3636 - accuracy: 0.8854 - val_loss: 0.2778 - val_accuracy: 0.9312\n",
      "Epoch 74/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3377 - accuracy: 0.8896 - val_loss: 0.2982 - val_accuracy: 0.9312\n",
      "Epoch 75/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.3581 - accuracy: 0.8875 - val_loss: 0.2274 - val_accuracy: 0.9375\n",
      "Epoch 76/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3709 - accuracy: 0.8562 - val_loss: 0.2270 - val_accuracy: 0.9500\n",
      "Epoch 77/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3495 - accuracy: 0.8792 - val_loss: 0.2381 - val_accuracy: 0.9438\n",
      "Epoch 78/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3058 - accuracy: 0.9000 - val_loss: 0.2241 - val_accuracy: 0.9438\n",
      "Epoch 79/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.4164 - accuracy: 0.8521 - val_loss: 0.2150 - val_accuracy: 0.9500\n",
      "Epoch 80/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.2341 - accuracy: 0.9312 - val_loss: 0.2394 - val_accuracy: 0.9438\n",
      "Epoch 81/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3617 - accuracy: 0.8667 - val_loss: 0.2120 - val_accuracy: 0.9438\n",
      "Epoch 82/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3155 - accuracy: 0.9021 - val_loss: 0.2133 - val_accuracy: 0.9563\n",
      "Epoch 83/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3263 - accuracy: 0.8896 - val_loss: 0.1901 - val_accuracy: 0.9625\n",
      "Epoch 84/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.2859 - accuracy: 0.8938 - val_loss: 0.3204 - val_accuracy: 0.9000\n",
      "Epoch 85/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.2849 - accuracy: 0.9042 - val_loss: 0.2939 - val_accuracy: 0.9250\n",
      "Epoch 86/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.2829 - accuracy: 0.8917 - val_loss: 0.1842 - val_accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.2056 - accuracy: 0.9500 - val_loss: 0.2207 - val_accuracy: 0.9312\n",
      "Epoch 88/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3030 - accuracy: 0.8979 - val_loss: 0.3050 - val_accuracy: 0.8938\n",
      "Epoch 89/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.3044 - accuracy: 0.8875 - val_loss: 0.2159 - val_accuracy: 0.9250\n",
      "Epoch 90/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2428 - accuracy: 0.9229 - val_loss: 0.1803 - val_accuracy: 0.9500\n",
      "Epoch 91/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2332 - accuracy: 0.9250 - val_loss: 0.2078 - val_accuracy: 0.9438\n",
      "Epoch 92/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2309 - accuracy: 0.9250 - val_loss: 0.1772 - val_accuracy: 0.9500\n",
      "Epoch 93/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.2239 - accuracy: 0.9208 - val_loss: 0.1906 - val_accuracy: 0.9625\n",
      "Epoch 94/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2282 - accuracy: 0.9292 - val_loss: 0.2232 - val_accuracy: 0.9125\n",
      "Epoch 95/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1919 - accuracy: 0.9458 - val_loss: 0.1823 - val_accuracy: 0.9563\n",
      "Epoch 96/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.2073 - accuracy: 0.9229 - val_loss: 0.2120 - val_accuracy: 0.9438\n",
      "Epoch 97/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2375 - accuracy: 0.9104 - val_loss: 0.2130 - val_accuracy: 0.9438\n",
      "Epoch 98/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.2529 - accuracy: 0.9167 - val_loss: 0.2231 - val_accuracy: 0.9187\n",
      "Epoch 99/100\n",
      "480/480 [==============================] - 1s 2ms/sample - loss: 0.1700 - accuracy: 0.9542 - val_loss: 0.2691 - val_accuracy: 0.9187\n",
      "Epoch 100/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1937 - accuracy: 0.9396 - val_loss: 0.2218 - val_accuracy: 0.9438\n",
      "CPU times: user 4min 6s, sys: 2min 43s, total: 6min 49s\n",
      "Wall time: 2min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90cecc71d0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      1.00      1.00        20\n",
      "      alinda       1.00      0.95      0.98        21\n",
      "        gian       1.00      0.95      0.98        21\n",
      "     jackson       1.00      0.91      0.95        22\n",
      "      khaled       0.95      0.95      0.95        20\n",
      "     nicolas       0.75      1.00      0.86        15\n",
      "        theo       0.90      1.00      0.95        18\n",
      "    yweweler       0.95      0.83      0.88        23\n",
      "\n",
      "    accuracy                           0.94       160\n",
      "   macro avg       0.94      0.95      0.94       160\n",
      "weighted avg       0.95      0.94      0.94       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with the Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "480/480 [==============================] - 5s 10ms/sample - loss: 2.3782 - accuracy: 0.1771 - val_loss: 2.0621 - val_accuracy: 0.1562\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7357 - accuracy: 0.3729 - val_loss: 2.0303 - val_accuracy: 0.1750\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5230 - accuracy: 0.4187 - val_loss: 1.9694 - val_accuracy: 0.2250\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3219 - accuracy: 0.5167 - val_loss: 1.9572 - val_accuracy: 0.2562\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 1.1578 - accuracy: 0.6000 - val_loss: 1.9562 - val_accuracy: 0.2937\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 2s 5ms/sample - loss: 0.9723 - accuracy: 0.6708 - val_loss: 1.9634 - val_accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9074 - accuracy: 0.6896 - val_loss: 1.9640 - val_accuracy: 0.2625\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8274 - accuracy: 0.7271 - val_loss: 1.9662 - val_accuracy: 0.2500\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8055 - accuracy: 0.7312 - val_loss: 1.9455 - val_accuracy: 0.2562\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7403 - accuracy: 0.7771 - val_loss: 1.9981 - val_accuracy: 0.2500\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.6382 - accuracy: 0.8375 - val_loss: 2.0018 - val_accuracy: 0.2500\n",
      "Epoch 12/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.5917 - accuracy: 0.8438 - val_loss: 2.0372 - val_accuracy: 0.2500\n",
      "Epoch 13/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.5746 - accuracy: 0.8521 - val_loss: 1.9303 - val_accuracy: 0.2500\n",
      "Epoch 14/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.5619 - accuracy: 0.8354 - val_loss: 1.9522 - val_accuracy: 0.2562\n",
      "Epoch 15/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.5266 - accuracy: 0.8687 - val_loss: 1.9246 - val_accuracy: 0.2500\n",
      "Epoch 16/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4498 - accuracy: 0.8875 - val_loss: 1.9498 - val_accuracy: 0.2937\n",
      "Epoch 17/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.4510 - accuracy: 0.8917 - val_loss: 1.8528 - val_accuracy: 0.3063\n",
      "Epoch 18/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4112 - accuracy: 0.9083 - val_loss: 1.7841 - val_accuracy: 0.2688\n",
      "Epoch 19/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4142 - accuracy: 0.9187 - val_loss: 1.7099 - val_accuracy: 0.2500\n",
      "Epoch 20/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4171 - accuracy: 0.9021 - val_loss: 1.6827 - val_accuracy: 0.2688\n",
      "Epoch 21/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4042 - accuracy: 0.8792 - val_loss: 1.6238 - val_accuracy: 0.3187\n",
      "Epoch 22/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3721 - accuracy: 0.9167 - val_loss: 1.5611 - val_accuracy: 0.3375\n",
      "Epoch 23/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.3183 - accuracy: 0.9438 - val_loss: 1.4549 - val_accuracy: 0.3562\n",
      "Epoch 24/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.3170 - accuracy: 0.9438 - val_loss: 1.3801 - val_accuracy: 0.3812\n",
      "Epoch 25/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.3219 - accuracy: 0.9333 - val_loss: 1.1963 - val_accuracy: 0.4437\n",
      "Epoch 26/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.2963 - accuracy: 0.9229 - val_loss: 1.1566 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.2945 - accuracy: 0.9375 - val_loss: 0.9071 - val_accuracy: 0.6562\n",
      "Epoch 28/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.2711 - accuracy: 0.9354 - val_loss: 0.9683 - val_accuracy: 0.6000\n",
      "Epoch 29/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.2470 - accuracy: 0.9500 - val_loss: 1.1192 - val_accuracy: 0.5125\n",
      "Epoch 30/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2799 - accuracy: 0.9458 - val_loss: 0.7635 - val_accuracy: 0.7312\n",
      "Epoch 31/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2427 - accuracy: 0.9646 - val_loss: 0.6783 - val_accuracy: 0.7750\n",
      "Epoch 32/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2448 - accuracy: 0.9500 - val_loss: 0.7021 - val_accuracy: 0.7750\n",
      "Epoch 33/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2500 - accuracy: 0.9438 - val_loss: 0.5907 - val_accuracy: 0.8375\n",
      "Epoch 34/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2200 - accuracy: 0.9625 - val_loss: 0.5492 - val_accuracy: 0.8250\n",
      "Epoch 35/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2272 - accuracy: 0.9542 - val_loss: 0.6248 - val_accuracy: 0.8062\n",
      "Epoch 36/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.2250 - accuracy: 0.9646 - val_loss: 0.2796 - val_accuracy: 0.9625\n",
      "Epoch 37/100\n",
      "480/480 [==============================] - 2s 5ms/sample - loss: 0.2422 - accuracy: 0.9479 - val_loss: 0.3036 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1850 - accuracy: 0.9854 - val_loss: 0.2299 - val_accuracy: 0.9812\n",
      "Epoch 39/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1651 - accuracy: 0.9771 - val_loss: 0.2466 - val_accuracy: 0.9625\n",
      "Epoch 40/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2071 - accuracy: 0.9646 - val_loss: 0.2219 - val_accuracy: 0.9812\n",
      "Epoch 41/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1780 - accuracy: 0.9646 - val_loss: 0.2270 - val_accuracy: 0.9688\n",
      "Epoch 42/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1901 - accuracy: 0.9729 - val_loss: 0.1915 - val_accuracy: 0.9750\n",
      "Epoch 43/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1713 - accuracy: 0.9625 - val_loss: 0.2023 - val_accuracy: 0.9625\n",
      "Epoch 44/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1724 - accuracy: 0.9750 - val_loss: 0.2169 - val_accuracy: 0.9625\n",
      "Epoch 45/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1519 - accuracy: 0.9792 - val_loss: 0.2105 - val_accuracy: 0.9812\n",
      "Epoch 46/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1333 - accuracy: 0.9812 - val_loss: 0.1608 - val_accuracy: 0.9812\n",
      "Epoch 47/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1510 - accuracy: 0.9792 - val_loss: 0.1760 - val_accuracy: 0.9750\n",
      "Epoch 48/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1380 - accuracy: 0.9896 - val_loss: 0.1722 - val_accuracy: 0.9750\n",
      "Epoch 49/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1306 - accuracy: 0.9833 - val_loss: 0.1614 - val_accuracy: 0.9625\n",
      "Epoch 50/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1376 - accuracy: 0.9792 - val_loss: 0.1370 - val_accuracy: 0.9688\n",
      "Epoch 51/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1443 - accuracy: 0.9750 - val_loss: 0.1571 - val_accuracy: 0.9812\n",
      "Epoch 52/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1392 - accuracy: 0.9792 - val_loss: 0.1441 - val_accuracy: 0.9688\n",
      "Epoch 53/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1438 - accuracy: 0.9729 - val_loss: 0.1235 - val_accuracy: 0.9875\n",
      "Epoch 54/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1330 - accuracy: 0.9792 - val_loss: 0.1616 - val_accuracy: 0.9625\n",
      "Epoch 55/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1104 - accuracy: 0.9958 - val_loss: 0.1419 - val_accuracy: 0.9688\n",
      "Epoch 56/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1137 - accuracy: 0.9812 - val_loss: 0.1222 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1166 - accuracy: 0.9833 - val_loss: 0.1355 - val_accuracy: 0.9688\n",
      "Epoch 58/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1409 - accuracy: 0.9708 - val_loss: 0.2396 - val_accuracy: 0.9375\n",
      "Epoch 59/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1587 - accuracy: 0.9604 - val_loss: 0.1813 - val_accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1242 - accuracy: 0.9875 - val_loss: 0.1537 - val_accuracy: 0.9438\n",
      "Epoch 61/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1130 - accuracy: 0.9917 - val_loss: 0.1317 - val_accuracy: 0.9688\n",
      "Epoch 62/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1015 - accuracy: 0.9833 - val_loss: 0.1157 - val_accuracy: 0.9812\n",
      "Epoch 63/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0966 - accuracy: 0.9917 - val_loss: 0.1329 - val_accuracy: 0.9688\n",
      "Epoch 64/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1026 - accuracy: 0.9854 - val_loss: 0.2150 - val_accuracy: 0.9375\n",
      "Epoch 65/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0935 - accuracy: 0.9896 - val_loss: 0.1330 - val_accuracy: 0.9688\n",
      "Epoch 66/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0997 - accuracy: 0.9896 - val_loss: 0.1207 - val_accuracy: 0.9812\n",
      "Epoch 67/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0843 - accuracy: 0.9917 - val_loss: 0.1158 - val_accuracy: 0.9812\n",
      "Epoch 68/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.0928 - accuracy: 0.9875 - val_loss: 0.1017 - val_accuracy: 0.9812\n",
      "Epoch 69/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0972 - accuracy: 0.9771 - val_loss: 0.1037 - val_accuracy: 0.9750\n",
      "Epoch 70/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0927 - accuracy: 0.9833 - val_loss: 0.1153 - val_accuracy: 0.9625\n",
      "Epoch 71/100\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.0759 - accuracy: 0.9937 - val_loss: 0.1042 - val_accuracy: 0.9812\n",
      "Epoch 72/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0837 - accuracy: 0.9958 - val_loss: 0.1171 - val_accuracy: 0.9750\n",
      "Epoch 73/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0980 - accuracy: 0.9771 - val_loss: 0.1353 - val_accuracy: 0.9688\n",
      "Epoch 74/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0983 - accuracy: 0.9854 - val_loss: 0.1117 - val_accuracy: 0.9750\n",
      "Epoch 75/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0785 - accuracy: 0.9917 - val_loss: 0.1083 - val_accuracy: 0.9688\n",
      "Epoch 76/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.0802 - accuracy: 0.9958 - val_loss: 0.0980 - val_accuracy: 0.9688\n",
      "Epoch 77/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.0840 - accuracy: 0.9896 - val_loss: 0.0989 - val_accuracy: 0.9750\n",
      "Epoch 78/100\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.0846 - accuracy: 0.9896 - val_loss: 0.1050 - val_accuracy: 0.9750\n",
      "Epoch 79/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0816 - accuracy: 0.9896 - val_loss: 0.1345 - val_accuracy: 0.9625\n",
      "Epoch 80/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0785 - accuracy: 0.9937 - val_loss: 0.1094 - val_accuracy: 0.9750\n",
      "Epoch 81/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0719 - accuracy: 0.9958 - val_loss: 0.1036 - val_accuracy: 0.9812\n",
      "Epoch 82/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0771 - accuracy: 0.9875 - val_loss: 0.1240 - val_accuracy: 0.9625\n",
      "Epoch 83/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0640 - accuracy: 0.9958 - val_loss: 0.1125 - val_accuracy: 0.9688\n",
      "Epoch 84/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0674 - accuracy: 0.9958 - val_loss: 0.1002 - val_accuracy: 0.9812\n",
      "Epoch 85/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0766 - accuracy: 0.9854 - val_loss: 0.1023 - val_accuracy: 0.9875\n",
      "Epoch 86/100\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.0942 - accuracy: 0.9854 - val_loss: 0.1089 - val_accuracy: 0.9625\n",
      "CPU times: user 3min 43s, sys: 3min 14s, total: 6min 58s\n",
      "Wall time: 2min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f91006b4650>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.95      0.98        21\n",
      "      alinda       0.95      1.00      0.97        19\n",
      "        gian       0.95      0.95      0.95        20\n",
      "     jackson       0.95      1.00      0.97        19\n",
      "      khaled       1.00      1.00      1.00        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       0.95      0.95      0.95        20\n",
      "    yweweler       0.95      0.90      0.93        21\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.97      0.97      0.97       160\n",
      "weighted avg       0.97      0.97      0.97       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 666 ms, total: 20.5 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_train_speakers])\n",
    "X_val_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_val_speakers])\n",
    "X_test_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True, paper_data=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 127, 56, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 127, 56, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 63, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                3612736   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 3,613,800\n",
      "Trainable params: 3,613,608\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "480/480 [==============================] - 6s 13ms/sample - loss: 1.0218 - accuracy: 0.6771 - val_loss: 1.3753 - val_accuracy: 0.6187\n",
      "Epoch 2/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.4815 - accuracy: 0.8792 - val_loss: 1.3286 - val_accuracy: 0.8562\n",
      "Epoch 3/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.3482 - accuracy: 0.9208 - val_loss: 1.3577 - val_accuracy: 0.9312\n",
      "Epoch 4/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.2217 - accuracy: 0.9667 - val_loss: 1.3423 - val_accuracy: 0.8938\n",
      "Epoch 5/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.1768 - accuracy: 0.9812 - val_loss: 1.3139 - val_accuracy: 0.8875\n",
      "Epoch 6/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.1525 - accuracy: 0.9750 - val_loss: 1.3233 - val_accuracy: 0.8250\n",
      "Epoch 7/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.1251 - accuracy: 0.9917 - val_loss: 1.2633 - val_accuracy: 0.8188\n",
      "Epoch 8/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0957 - accuracy: 0.9958 - val_loss: 1.2025 - val_accuracy: 0.8625\n",
      "Epoch 9/100\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.0859 - accuracy: 0.9958 - val_loss: 1.1728 - val_accuracy: 0.8438\n",
      "Epoch 10/100\n",
      "480/480 [==============================] - 5s 9ms/sample - loss: 0.0836 - accuracy: 0.9937 - val_loss: 1.1377 - val_accuracy: 0.8375\n",
      "Epoch 11/100\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.0665 - accuracy: 0.9958 - val_loss: 1.0782 - val_accuracy: 0.8438\n",
      "Epoch 12/100\n",
      "480/480 [==============================] - 5s 10ms/sample - loss: 0.0768 - accuracy: 0.9958 - val_loss: 0.9929 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.9090 - val_accuracy: 0.9125\n",
      "Epoch 14/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0514 - accuracy: 0.9979 - val_loss: 0.8286 - val_accuracy: 0.9250\n",
      "Epoch 15/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.7767 - val_accuracy: 0.9500\n",
      "Epoch 16/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0460 - accuracy: 0.9979 - val_loss: 0.7142 - val_accuracy: 0.9375\n",
      "Epoch 17/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0500 - accuracy: 0.9979 - val_loss: 0.6381 - val_accuracy: 0.9500\n",
      "Epoch 18/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.5400 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9625\n",
      "Epoch 22/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9688\n",
      "Epoch 23/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9625\n",
      "Epoch 24/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9625\n",
      "Epoch 25/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9625\n",
      "Epoch 26/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0296 - accuracy: 0.9979 - val_loss: 0.2806 - val_accuracy: 0.9750\n",
      "Epoch 27/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9625\n",
      "Epoch 28/100\n",
      "480/480 [==============================] - 5s 9ms/sample - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9625\n",
      "Epoch 29/100\n",
      "480/480 [==============================] - 5s 9ms/sample - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9688\n",
      "Epoch 30/100\n",
      "480/480 [==============================] - 5s 10ms/sample - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9625\n",
      "Epoch 31/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9750\n",
      "Epoch 32/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 0.9750\n",
      "Epoch 33/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9688\n",
      "Epoch 34/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9688\n",
      "Epoch 35/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9750\n",
      "Epoch 36/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9750\n",
      "Epoch 37/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9875\n",
      "Epoch 38/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9875\n",
      "Epoch 39/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0208 - accuracy: 0.9979 - val_loss: 0.1156 - val_accuracy: 0.9750\n",
      "Epoch 40/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9812\n",
      "Epoch 41/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9875\n",
      "Epoch 42/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9875\n",
      "Epoch 43/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9750\n",
      "Epoch 44/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9812\n",
      "Epoch 45/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9750\n",
      "Epoch 46/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9875\n",
      "Epoch 47/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9812\n",
      "Epoch 48/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9812\n",
      "Epoch 49/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9812\n",
      "Epoch 50/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9812\n",
      "Epoch 51/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9750\n",
      "Epoch 52/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9812\n",
      "Epoch 53/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9812\n",
      "Epoch 54/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9812\n",
      "Epoch 55/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9812\n",
      "Epoch 56/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9812\n",
      "Epoch 58/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9875\n",
      "Epoch 59/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9875\n",
      "Epoch 60/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9812\n",
      "Epoch 61/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9875\n",
      "Epoch 62/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9875\n",
      "Epoch 63/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9812\n",
      "Epoch 64/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9875\n",
      "Epoch 65/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9875\n",
      "Epoch 66/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9812\n",
      "Epoch 67/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9812\n",
      "Epoch 68/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9812\n",
      "Epoch 69/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9875\n",
      "Epoch 70/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9812\n",
      "Epoch 71/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9812\n",
      "Epoch 72/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9812\n",
      "Epoch 73/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9812\n",
      "Epoch 74/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9875\n",
      "Epoch 75/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9875\n",
      "Epoch 76/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9812\n",
      "Epoch 77/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9812\n",
      "Epoch 78/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9875\n",
      "Epoch 79/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9875\n",
      "Epoch 80/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9875\n",
      "Epoch 81/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9812\n",
      "Epoch 82/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9812\n",
      "Epoch 83/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9812\n",
      "Epoch 84/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9812\n",
      "Epoch 85/100\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9812\n",
      "Epoch 86/100\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9812\n",
      "Epoch 87/100\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 0.9812\n",
      "Epoch 88/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9812\n",
      "Epoch 89/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9812\n",
      "Epoch 90/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9750\n",
      "Epoch 91/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9750\n",
      "Epoch 92/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9812\n",
      "Epoch 93/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9812\n",
      "Epoch 94/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9750\n",
      "Epoch 95/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9812\n",
      "Epoch 96/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9750\n",
      "Epoch 97/100\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9812\n",
      "Epoch 98/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9875\n",
      "Epoch 99/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9812\n",
      "Epoch 100/100\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9750\n",
      "CPU times: user 11min 37s, sys: 1min 52s, total: 13min 30s\n",
      "Wall time: 5min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90d6a69cd0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      1.00      0.97        19\n",
      "      alinda       1.00      1.00      1.00        20\n",
      "        gian       1.00      0.95      0.98        21\n",
      "     jackson       0.95      1.00      0.97        19\n",
      "      khaled       0.95      0.95      0.95        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       0.95      1.00      0.97        19\n",
      "    yweweler       1.00      0.91      0.95        22\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.97      0.98      0.98       160\n",
      "weighted avg       0.98      0.97      0.97       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n",
      "CPU times: user 2min 27s, sys: 6.32 s, total: 2min 33s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                                                    y_type= ['speakers_default', 'speakers_us'],\n",
    "                                                    n_category_test=30,\n",
    "                                                    include_pitch=False,\n",
    "                                                    max_length=max_track_length,\n",
    "                                                    recordings_source=[False, True],\n",
    "                                                    transform_function=\"mfcc\")\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 193\n",
      "ale\n",
      "alinda\n",
      "gian\n",
      "jackson\n",
      "khaled\n",
      "nicolas\n",
      "theo\n",
      "yweweler\n",
      "CPU times: user 35.5 ms, sys: 17.3 ms, total: 52.8 ms\n",
      "Wall time: 61.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_speaker, X_val_speaker]),\n",
    "                         np.concatenate([y_train_speaker, y_val_speaker]))\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4616, 20, 18)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_speaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal = StandardScaler()\n",
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_scaled = scaler_normal.fit_transform(X_train_speaker.reshape((nsamples, nx * ny)))\n",
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_scaled =  scaler_normal.transform(X_val_speaker.reshape((nsamples, nx * ny)))\n",
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_scaled =  scaler_normal.transform(X_test_speaker.reshape((nsamples, nx * ny)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.1 s, sys: 74.2 ms, total: 5.17 s\n",
      "Wall time: 5.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker_normal.fit(X_train_speaker_scaled, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.91      0.99      0.95       178\n",
      "      alinda       0.92      0.96      0.94       185\n",
      "        gian       0.96      0.95      0.95       195\n",
      "     jackson       0.92      0.98      0.95       181\n",
      "      khaled       1.00      0.80      0.89       240\n",
      "     nicolas       0.99      1.00      0.99       191\n",
      "        theo       0.82      0.89      0.85       177\n",
      "    yweweler       0.90      0.88      0.89       197\n",
      "\n",
      "    accuracy                           0.93      1544\n",
      "   macro avg       0.93      0.93      0.93      1544\n",
      "weighted avg       0.93      0.93      0.93      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_speaker_normal.predict(X_val_speaker_scaled)\n",
    "print(classification_report(y_pred, y_val_speaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speaker, X_val_speaker, X_test_speaker, y_train_speaker, y_val_speaker, y_test_speaker, number_mode=False)\n",
    "\n",
    "X_train_speaker_nn = X[0]\n",
    "y_train_speaker_nn = y[0]\n",
    "X_val_speaker_nn = X[1]\n",
    "y_val_speaker_nn = y[1]\n",
    "X_test_speaker_nn = X[2]\n",
    "y_test_speaker_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 148,584\n",
      "Trainable params: 148,392\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4616 samples, validate on 1544 samples\n",
      "Epoch 1/100\n",
      "4616/4616 [==============================] - 6s 1ms/sample - loss: 1.0359 - accuracy: 0.6393 - val_loss: 1.7434 - val_accuracy: 0.4119\n",
      "Epoch 2/100\n",
      "4616/4616 [==============================] - 3s 680us/sample - loss: 0.5408 - accuracy: 0.8315 - val_loss: 0.6701 - val_accuracy: 0.7668\n",
      "Epoch 3/100\n",
      "4616/4616 [==============================] - 3s 657us/sample - loss: 0.4336 - accuracy: 0.8614 - val_loss: 0.3845 - val_accuracy: 0.8905\n",
      "Epoch 4/100\n",
      "4616/4616 [==============================] - 3s 655us/sample - loss: 0.3620 - accuracy: 0.8897 - val_loss: 0.4597 - val_accuracy: 0.8465\n",
      "Epoch 5/100\n",
      "4616/4616 [==============================] - 3s 661us/sample - loss: 0.3203 - accuracy: 0.9021 - val_loss: 0.4745 - val_accuracy: 0.8316\n",
      "Epoch 6/100\n",
      "4616/4616 [==============================] - 3s 673us/sample - loss: 0.2995 - accuracy: 0.9084 - val_loss: 0.4501 - val_accuracy: 0.8543\n",
      "Epoch 7/100\n",
      "4616/4616 [==============================] - 3s 670us/sample - loss: 0.2783 - accuracy: 0.9146 - val_loss: 0.7424 - val_accuracy: 0.7416\n",
      "Epoch 8/100\n",
      "4616/4616 [==============================] - 3s 705us/sample - loss: 0.2615 - accuracy: 0.9227 - val_loss: 0.2433 - val_accuracy: 0.9346\n",
      "Epoch 9/100\n",
      "4616/4616 [==============================] - 3s 713us/sample - loss: 0.2462 - accuracy: 0.9268 - val_loss: 0.3310 - val_accuracy: 0.8834\n",
      "Epoch 10/100\n",
      "4616/4616 [==============================] - 3s 656us/sample - loss: 0.2337 - accuracy: 0.9283 - val_loss: 0.2632 - val_accuracy: 0.9275\n",
      "Epoch 11/100\n",
      "4616/4616 [==============================] - 3s 721us/sample - loss: 0.2220 - accuracy: 0.9307 - val_loss: 0.2390 - val_accuracy: 0.9216\n",
      "Epoch 12/100\n",
      "4616/4616 [==============================] - 3s 605us/sample - loss: 0.2135 - accuracy: 0.9337 - val_loss: 0.2134 - val_accuracy: 0.9404\n",
      "Epoch 13/100\n",
      "4616/4616 [==============================] - 3s 609us/sample - loss: 0.2153 - accuracy: 0.9328 - val_loss: 0.3434 - val_accuracy: 0.8744\n",
      "Epoch 14/100\n",
      "4616/4616 [==============================] - 3s 620us/sample - loss: 0.2106 - accuracy: 0.9328 - val_loss: 0.2406 - val_accuracy: 0.9255\n",
      "Epoch 15/100\n",
      "4616/4616 [==============================] - 3s 674us/sample - loss: 0.2010 - accuracy: 0.9365 - val_loss: 0.3480 - val_accuracy: 0.8834\n",
      "Epoch 16/100\n",
      "4616/4616 [==============================] - 3s 621us/sample - loss: 0.1976 - accuracy: 0.9361 - val_loss: 0.3711 - val_accuracy: 0.8789\n",
      "Epoch 17/100\n",
      "4616/4616 [==============================] - 3s 616us/sample - loss: 0.1955 - accuracy: 0.9404 - val_loss: 0.1939 - val_accuracy: 0.9404\n",
      "Epoch 18/100\n",
      "4616/4616 [==============================] - 3s 644us/sample - loss: 0.1869 - accuracy: 0.9396 - val_loss: 0.2055 - val_accuracy: 0.9365\n",
      "Epoch 19/100\n",
      "4616/4616 [==============================] - 3s 655us/sample - loss: 0.1850 - accuracy: 0.9422 - val_loss: 0.2777 - val_accuracy: 0.9139\n",
      "Epoch 20/100\n",
      "4616/4616 [==============================] - 3s 650us/sample - loss: 0.1770 - accuracy: 0.9426 - val_loss: 0.2193 - val_accuracy: 0.9333\n",
      "Epoch 21/100\n",
      "4616/4616 [==============================] - 3s 602us/sample - loss: 0.1721 - accuracy: 0.9458 - val_loss: 0.2749 - val_accuracy: 0.9022\n",
      "Epoch 22/100\n",
      "4616/4616 [==============================] - 3s 669us/sample - loss: 0.1710 - accuracy: 0.9439 - val_loss: 0.2029 - val_accuracy: 0.9346\n",
      "Epoch 23/100\n",
      "4616/4616 [==============================] - 3s 654us/sample - loss: 0.1654 - accuracy: 0.9465 - val_loss: 0.2599 - val_accuracy: 0.9171\n",
      "Epoch 24/100\n",
      "4616/4616 [==============================] - 3s 693us/sample - loss: 0.1671 - accuracy: 0.9428 - val_loss: 0.1963 - val_accuracy: 0.9365\n",
      "Epoch 25/100\n",
      "4616/4616 [==============================] - 3s 714us/sample - loss: 0.1541 - accuracy: 0.9510 - val_loss: 0.2307 - val_accuracy: 0.9158\n",
      "Epoch 26/100\n",
      "4616/4616 [==============================] - 3s 648us/sample - loss: 0.1575 - accuracy: 0.9497 - val_loss: 0.2166 - val_accuracy: 0.9359\n",
      "Epoch 27/100\n",
      "4616/4616 [==============================] - 3s 662us/sample - loss: 0.1553 - accuracy: 0.9482 - val_loss: 0.2188 - val_accuracy: 0.9223\n",
      "CPU times: user 2min 19s, sys: 1min 45s, total: 4min 4s\n",
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90b4528090>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker_nn, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker_nn, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.96      0.97      0.97       193\n",
      "      alinda       0.94      0.93      0.94       193\n",
      "        gian       0.95      0.94      0.95       193\n",
      "     jackson       0.99      0.97      0.98       193\n",
      "      khaled       0.95      0.98      0.97       193\n",
      "     nicolas       0.97      1.00      0.98       193\n",
      "        theo       0.89      0.83      0.86       193\n",
      "    yweweler       0.86      0.89      0.87       193\n",
      "\n",
      "    accuracy                           0.94      1544\n",
      "   macro avg       0.94      0.94      0.94      1544\n",
      "weighted avg       0.94      0.94      0.94      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - Spects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n",
      "CPU times: user 2min 26s, sys: 6.18 s, total: 2min 32s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                                                    y_type= ['speakers_default', 'speakers_us'],\n",
    "                                                    n_category_test=30,\n",
    "                                                    include_pitch=False,\n",
    "                                                    max_length=max_track_length,\n",
    "                                                    recordings_source=[False, True],\n",
    "                                                    transform_function=\"spectrogram\")\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 193\n",
      "ale\n",
      "alinda\n",
      "gian\n",
      "jackson\n",
      "khaled\n",
      "nicolas\n",
      "theo\n",
      "yweweler\n"
     ]
    }
   ],
   "source": [
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_speaker, X_val_speaker]),\n",
    "                                                 np.concatenate([y_train_speaker, y_val_speaker]))\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_2d = X_train_speaker.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_2d = X_val_speaker.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_2d = X_test_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 s, sys: 125 ms, total: 20.8 s\n",
      "Wall time: 21 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker.fit(X_train_speaker_2d, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.98      0.98      0.98       193\n",
      "      alinda       0.97      0.99      0.98       190\n",
      "        gian       0.99      0.97      0.98       196\n",
      "     jackson       0.99      0.99      0.99       194\n",
      "      khaled       0.98      0.97      0.98       194\n",
      "     nicolas       0.99      1.00      0.99       191\n",
      "        theo       0.87      0.89      0.88       188\n",
      "    yweweler       0.91      0.89      0.90       198\n",
      "\n",
      "    accuracy                           0.96      1544\n",
      "   macro avg       0.96      0.96      0.96      1544\n",
      "weighted avg       0.96      0.96      0.96      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_speaker.predict(X_val_speaker_2d)\n",
    "print(classification_report(y_pred, y_val_speaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speaker,\n",
    "                                                                   X_val_speaker,\n",
    "                                                                   X_test_speaker,\n",
    "                                                                   y_train_speaker,\n",
    "                                                                   y_val_speaker,\n",
    "                                                                   y_test_speaker,\n",
    "                                                                   number_mode=False)\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker_nn = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker_nn = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4616, 128, 18, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_speaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 127, 17, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 1,033,320\n",
      "Trainable params: 1,033,128\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4616 samples, validate on 1544 samples\n",
      "Epoch 1/100\n",
      "4616/4616 [==============================] - 13s 3ms/sample - loss: 0.6797 - accuracy: 0.7864 - val_loss: 1.2795 - val_accuracy: 0.4113\n",
      "Epoch 2/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.2754 - accuracy: 0.9272 - val_loss: 0.7939 - val_accuracy: 0.7124\n",
      "Epoch 3/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.1827 - accuracy: 0.9532 - val_loss: 0.3848 - val_accuracy: 0.8763\n",
      "Epoch 4/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.1401 - accuracy: 0.9688 - val_loss: 0.1873 - val_accuracy: 0.9540\n",
      "Epoch 5/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.1155 - accuracy: 0.9738 - val_loss: 0.1114 - val_accuracy: 0.9683\n",
      "Epoch 6/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0943 - accuracy: 0.9803 - val_loss: 0.0972 - val_accuracy: 0.9734\n",
      "Epoch 7/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0853 - accuracy: 0.9825 - val_loss: 0.2197 - val_accuracy: 0.9268\n",
      "Epoch 8/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0751 - accuracy: 0.9838 - val_loss: 0.3687 - val_accuracy: 0.8763\n",
      "Epoch 9/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0631 - accuracy: 0.9872 - val_loss: 0.1238 - val_accuracy: 0.9605\n",
      "Epoch 10/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0547 - accuracy: 0.9905 - val_loss: 0.0911 - val_accuracy: 0.9734\n",
      "Epoch 11/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0444 - accuracy: 0.9924 - val_loss: 0.0659 - val_accuracy: 0.9812\n",
      "Epoch 12/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0507 - accuracy: 0.9916 - val_loss: 0.0729 - val_accuracy: 0.9754\n",
      "Epoch 13/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0441 - accuracy: 0.9909 - val_loss: 0.0582 - val_accuracy: 0.9812\n",
      "Epoch 14/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0333 - accuracy: 0.9961 - val_loss: 0.0614 - val_accuracy: 0.9825\n",
      "Epoch 15/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0334 - accuracy: 0.9950 - val_loss: 0.0745 - val_accuracy: 0.9773\n",
      "Epoch 16/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0234 - accuracy: 0.9991 - val_loss: 0.0579 - val_accuracy: 0.9799\n",
      "Epoch 17/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0241 - accuracy: 0.9968 - val_loss: 0.0597 - val_accuracy: 0.9825\n",
      "Epoch 18/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0214 - accuracy: 0.9987 - val_loss: 0.0598 - val_accuracy: 0.9812\n",
      "Epoch 19/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0242 - accuracy: 0.9974 - val_loss: 0.0594 - val_accuracy: 0.9793\n",
      "Epoch 20/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0235 - accuracy: 0.9972 - val_loss: 0.1914 - val_accuracy: 0.9417\n",
      "Epoch 21/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0255 - accuracy: 0.9968 - val_loss: 0.0518 - val_accuracy: 0.9812\n",
      "Epoch 22/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0199 - accuracy: 0.9976 - val_loss: 0.0509 - val_accuracy: 0.9799\n",
      "Epoch 23/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0198 - accuracy: 0.9983 - val_loss: 0.0454 - val_accuracy: 0.9825\n",
      "Epoch 24/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.0613 - val_accuracy: 0.9780\n",
      "Epoch 25/100\n",
      "4616/4616 [==============================] - 10s 2ms/sample - loss: 0.0212 - accuracy: 0.9978 - val_loss: 0.2382 - val_accuracy: 0.9670\n",
      "Epoch 26/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0181 - accuracy: 0.9985 - val_loss: 0.0735 - val_accuracy: 0.9747\n",
      "Epoch 27/100\n",
      "4616/4616 [==============================] - 13s 3ms/sample - loss: 0.0192 - accuracy: 0.9976 - val_loss: 0.0652 - val_accuracy: 0.9812\n",
      "Epoch 28/100\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 0.0172 - accuracy: 0.9983 - val_loss: 0.0691 - val_accuracy: 0.9780\n",
      "Epoch 29/100\n",
      "4616/4616 [==============================] - 14s 3ms/sample - loss: 0.0164 - accuracy: 0.9991 - val_loss: 0.0515 - val_accuracy: 0.9825\n",
      "Epoch 30/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0140 - accuracy: 0.9994 - val_loss: 0.0508 - val_accuracy: 0.9812\n",
      "Epoch 31/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0169 - accuracy: 0.9983 - val_loss: 0.0661 - val_accuracy: 0.9799\n",
      "Epoch 32/100\n",
      "4616/4616 [==============================] - 11s 2ms/sample - loss: 0.0133 - accuracy: 0.9989 - val_loss: 0.0506 - val_accuracy: 0.9812\n",
      "Epoch 33/100\n",
      "4616/4616 [==============================] - 12s 3ms/sample - loss: 0.0132 - accuracy: 0.9994 - val_loss: 0.0668 - val_accuracy: 0.9722\n",
      "CPU times: user 10min 23s, sys: 7min 7s, total: 17min 31s\n",
      "Wall time: 5min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9084ac4cd0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.99      1.00       194\n",
      "      alinda       0.99      0.99      0.99       193\n",
      "        gian       0.99      0.99      0.99       193\n",
      "     jackson       1.00      1.00      1.00       193\n",
      "      khaled       0.99      1.00      1.00       192\n",
      "     nicolas       1.00      1.00      1.00       193\n",
      "        theo       0.92      0.96      0.94       186\n",
      "    yweweler       0.96      0.93      0.94       200\n",
      "\n",
      "    accuracy                           0.98      1544\n",
      "   macro avg       0.98      0.98      0.98      1544\n",
      "weighted avg       0.98      0.98      0.98      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n",
      "CPU times: user 1min 59s, sys: 5.36 s, total: 2min 5s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                                                    y_type= ['speakers_default', 'speakers_us'],\n",
    "                                                    n_category_test=30,\n",
    "                                                    include_pitch=False,\n",
    "                                                    max_length=max_track_length,\n",
    "                                                    recordings_source=[False, True],\n",
    "                                                    transform_function=\"spectrogram\",\n",
    "                                                   paper_data=True)\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, target_names= data_preparation.prepare_data_nn(X_train_speaker,\n",
    "                                                                   X_val_speaker,\n",
    "                                                                   X_test_speaker,\n",
    "                                                                   y_train_speaker,\n",
    "                                                                   y_val_speaker,\n",
    "                                                                   y_test_speaker,\n",
    "                                                                   number_mode=False)\n",
    "\n",
    "X_train_speaker = X[0]\n",
    "y_train_speaker_nn = y[0]\n",
    "X_val_speaker = X[1]\n",
    "y_val_speaker_nn = y[1]\n",
    "X_test_speaker = X[2]\n",
    "y_test_speaker_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "model = cnn_models.paper_architecture(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11478 samples, validate on 2870 samples\n",
      "Epoch 1/100\n",
      "11478/11478 [==============================] - 35s 3ms/sample - loss: 1.2100 - accuracy: 0.5777 - val_loss: 0.9732 - val_accuracy: 0.6777\n",
      "Epoch 2/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.6727 - accuracy: 0.7629 - val_loss: 0.5818 - val_accuracy: 0.7941\n",
      "Epoch 3/100\n",
      "11478/11478 [==============================] - 35s 3ms/sample - loss: 0.4942 - accuracy: 0.8300 - val_loss: 0.2793 - val_accuracy: 0.9139\n",
      "Epoch 4/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.3948 - accuracy: 0.8656 - val_loss: 0.4361 - val_accuracy: 0.8463\n",
      "Epoch 5/100\n",
      "11478/11478 [==============================] - 31s 3ms/sample - loss: 0.3220 - accuracy: 0.8915 - val_loss: 0.4866 - val_accuracy: 0.8038\n",
      "Epoch 6/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.2694 - accuracy: 0.9098 - val_loss: 0.3287 - val_accuracy: 0.8756\n",
      "Epoch 7/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.2401 - accuracy: 0.9194 - val_loss: 0.1254 - val_accuracy: 0.9641\n",
      "Epoch 8/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.2053 - accuracy: 0.9345 - val_loss: 0.1255 - val_accuracy: 0.9540\n",
      "Epoch 9/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.1797 - accuracy: 0.9394 - val_loss: 0.1410 - val_accuracy: 0.9488\n",
      "Epoch 10/100\n",
      "11478/11478 [==============================] - 33s 3ms/sample - loss: 0.1686 - accuracy: 0.9443 - val_loss: 0.1181 - val_accuracy: 0.9578\n",
      "Epoch 11/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.1694 - accuracy: 0.9438 - val_loss: 0.1346 - val_accuracy: 0.9495\n",
      "Epoch 12/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.1565 - accuracy: 0.9451 - val_loss: 0.1238 - val_accuracy: 0.9571\n",
      "Epoch 13/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.1444 - accuracy: 0.9521 - val_loss: 0.0616 - val_accuracy: 0.9812\n",
      "Epoch 14/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.1295 - accuracy: 0.9578 - val_loss: 0.0758 - val_accuracy: 0.9749\n",
      "Epoch 15/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.1251 - accuracy: 0.9574 - val_loss: 0.1407 - val_accuracy: 0.9519\n",
      "Epoch 16/100\n",
      "11478/11478 [==============================] - 32s 3ms/sample - loss: 0.1264 - accuracy: 0.9564 - val_loss: 0.0607 - val_accuracy: 0.9760\n",
      "Epoch 17/100\n",
      "11478/11478 [==============================] - 35s 3ms/sample - loss: 0.1121 - accuracy: 0.9631 - val_loss: 0.0643 - val_accuracy: 0.9787\n",
      "Epoch 18/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.1060 - accuracy: 0.9652 - val_loss: 0.0544 - val_accuracy: 0.9826\n",
      "Epoch 19/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0954 - accuracy: 0.9698 - val_loss: 0.0597 - val_accuracy: 0.9774\n",
      "Epoch 20/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0972 - accuracy: 0.9693 - val_loss: 0.0829 - val_accuracy: 0.9683\n",
      "Epoch 21/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0808 - accuracy: 0.9747 - val_loss: 0.0429 - val_accuracy: 0.9875\n",
      "Epoch 22/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0702 - accuracy: 0.9779 - val_loss: 0.0682 - val_accuracy: 0.9749\n",
      "Epoch 23/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0717 - accuracy: 0.9774 - val_loss: 0.0509 - val_accuracy: 0.9822\n",
      "Epoch 24/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0709 - accuracy: 0.9767 - val_loss: 0.0347 - val_accuracy: 0.9885\n",
      "Epoch 25/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0651 - accuracy: 0.9784 - val_loss: 0.0919 - val_accuracy: 0.9690\n",
      "Epoch 26/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0643 - accuracy: 0.9788 - val_loss: 0.0336 - val_accuracy: 0.9861\n",
      "Epoch 27/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0683 - accuracy: 0.9786 - val_loss: 0.0362 - val_accuracy: 0.9878\n",
      "Epoch 28/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0617 - accuracy: 0.9810 - val_loss: 0.0899 - val_accuracy: 0.9704\n",
      "Epoch 29/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0665 - accuracy: 0.9784 - val_loss: 0.0380 - val_accuracy: 0.9836\n",
      "Epoch 30/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0563 - accuracy: 0.9818 - val_loss: 0.0409 - val_accuracy: 0.9840\n",
      "Epoch 31/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0556 - accuracy: 0.9823 - val_loss: 0.0362 - val_accuracy: 0.9889\n",
      "Epoch 32/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0532 - accuracy: 0.9836 - val_loss: 0.0500 - val_accuracy: 0.9840\n",
      "Epoch 33/100\n",
      "11478/11478 [==============================] - 30s 3ms/sample - loss: 0.0444 - accuracy: 0.9875 - val_loss: 0.0350 - val_accuracy: 0.9871\n",
      "Epoch 34/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0422 - accuracy: 0.9875 - val_loss: 0.0308 - val_accuracy: 0.9889\n",
      "Epoch 35/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0428 - accuracy: 0.9874 - val_loss: 0.0457 - val_accuracy: 0.9857\n",
      "Epoch 36/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0475 - accuracy: 0.9848 - val_loss: 0.0681 - val_accuracy: 0.9753\n",
      "Epoch 37/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0644 - accuracy: 0.9799 - val_loss: 0.0345 - val_accuracy: 0.9864\n",
      "Epoch 38/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0466 - accuracy: 0.9853 - val_loss: 0.0410 - val_accuracy: 0.9857\n",
      "Epoch 39/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0456 - accuracy: 0.9858 - val_loss: 0.0310 - val_accuracy: 0.9871\n",
      "Epoch 40/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0493 - accuracy: 0.9841 - val_loss: 0.0356 - val_accuracy: 0.9843\n",
      "Epoch 41/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0466 - accuracy: 0.9844 - val_loss: 0.4085 - val_accuracy: 0.8662\n",
      "Epoch 42/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0647 - accuracy: 0.9780 - val_loss: 0.0395 - val_accuracy: 0.9871\n",
      "Epoch 43/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0663 - accuracy: 0.9773 - val_loss: 0.0865 - val_accuracy: 0.9704\n",
      "Epoch 44/100\n",
      "11478/11478 [==============================] - 29s 3ms/sample - loss: 0.0609 - accuracy: 0.9792 - val_loss: 0.0484 - val_accuracy: 0.9833\n",
      "CPU times: user 37min 55s, sys: 36min 35s, total: 1h 14min 31s\n",
      "Wall time: 22min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90d65b5550>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.99      0.99       140\n",
      "      alinda       0.99      0.99      0.99       167\n",
      "        gian       0.99      0.99      0.99       150\n",
      "     jackson       1.00      1.00      1.00       584\n",
      "      khaled       0.99      1.00      0.99       159\n",
      "     nicolas       1.00      1.00      1.00       574\n",
      "        theo       0.99      0.96      0.98       579\n",
      "    yweweler       0.96      0.99      0.98       517\n",
      "\n",
      "    accuracy                           0.99      2870\n",
      "   macro avg       0.99      0.99      0.99      2870\n",
      "weighted avg       0.99      0.99      0.99      2870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model\n",
    "The model with the best performances is the last one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speakers_best = np.concatenate([X_train_speaker, X_val_speaker])\n",
    "y_train_speakers_best = np.concatenate([y_train_speaker_nn, y_val_speaker_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 14348 samples\n",
      "Epoch 1/34\n",
      "14348/14348 [==============================] - 41s 3ms/sample - loss: 1.1606 - accuracy: 0.5931\n",
      "Epoch 2/34\n",
      "14348/14348 [==============================] - 39s 3ms/sample - loss: 0.6436 - accuracy: 0.7706\n",
      "Epoch 3/34\n",
      "14348/14348 [==============================] - 50s 4ms/sample - loss: 0.4640 - accuracy: 0.8373\n",
      "Epoch 4/34\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.3554 - accuracy: 0.8759\n",
      "Epoch 5/34\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.2937 - accuracy: 0.8976\n",
      "Epoch 6/34\n",
      "14348/14348 [==============================] - 36s 3ms/sample - loss: 0.2534 - accuracy: 0.9118\n",
      "Epoch 7/34\n",
      "14348/14348 [==============================] - 36s 2ms/sample - loss: 0.2224 - accuracy: 0.9227\n",
      "Epoch 8/34\n",
      "14348/14348 [==============================] - 36s 2ms/sample - loss: 0.1964 - accuracy: 0.9329\n",
      "Epoch 9/34\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.1774 - accuracy: 0.9378\n",
      "Epoch 10/34\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.1529 - accuracy: 0.9474\n",
      "Epoch 11/34\n",
      "14348/14348 [==============================] - 35s 2ms/sample - loss: 0.1593 - accuracy: 0.9444\n",
      "Epoch 12/34\n",
      "14348/14348 [==============================] - 35s 2ms/sample - loss: 0.1511 - accuracy: 0.9490\n",
      "Epoch 13/34\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.1437 - accuracy: 0.9507\n",
      "Epoch 14/34\n",
      "14348/14348 [==============================] - 47s 3ms/sample - loss: 0.1260 - accuracy: 0.9560\n",
      "Epoch 15/34\n",
      "14348/14348 [==============================] - 42s 3ms/sample - loss: 0.1172 - accuracy: 0.9606\n",
      "Epoch 16/34\n",
      "14348/14348 [==============================] - 36s 2ms/sample - loss: 0.1131 - accuracy: 0.9621\n",
      "Epoch 17/34\n",
      "14348/14348 [==============================] - 34s 2ms/sample - loss: 0.1027 - accuracy: 0.9646\n",
      "Epoch 18/34\n",
      "14348/14348 [==============================] - 34s 2ms/sample - loss: 0.0970 - accuracy: 0.9675\n",
      "Epoch 19/34\n",
      "14348/14348 [==============================] - 34s 2ms/sample - loss: 0.0957 - accuracy: 0.9683\n",
      "Epoch 20/34\n",
      "14348/14348 [==============================] - 36s 3ms/sample - loss: 0.0889 - accuracy: 0.9700\n",
      "Epoch 21/34\n",
      "14348/14348 [==============================] - 34s 2ms/sample - loss: 0.0786 - accuracy: 0.9737\n",
      "Epoch 22/34\n",
      "14348/14348 [==============================] - 36s 3ms/sample - loss: 0.0806 - accuracy: 0.9715\n",
      "Epoch 23/34\n",
      "14348/14348 [==============================] - 36s 3ms/sample - loss: 0.0741 - accuracy: 0.9751\n",
      "Epoch 24/34\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.0860 - accuracy: 0.9728\n",
      "Epoch 25/34\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0699 - accuracy: 0.9757\n",
      "Epoch 26/34\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.0709 - accuracy: 0.9778\n",
      "Epoch 27/34\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.0603 - accuracy: 0.9792\n",
      "Epoch 28/34\n",
      "14348/14348 [==============================] - 36s 3ms/sample - loss: 0.0638 - accuracy: 0.9797\n",
      "Epoch 29/34\n",
      "14348/14348 [==============================] - 36s 3ms/sample - loss: 0.0555 - accuracy: 0.9822\n",
      "Epoch 30/34\n",
      "14348/14348 [==============================] - 39s 3ms/sample - loss: 0.0559 - accuracy: 0.9813\n",
      "Epoch 31/34\n",
      "14348/14348 [==============================] - 40s 3ms/sample - loss: 0.0537 - accuracy: 0.9826\n",
      "Epoch 32/34\n",
      "14348/14348 [==============================] - 38s 3ms/sample - loss: 0.0525 - accuracy: 0.9827\n",
      "Epoch 33/34\n",
      "14348/14348 [==============================] - 37s 3ms/sample - loss: 0.0539 - accuracy: 0.9823\n",
      "Epoch 34/34\n",
      "14348/14348 [==============================] - 39s 3ms/sample - loss: 0.0520 - accuracy: 0.9836\n",
      "CPU times: user 31min 43s, sys: 27min 16s, total: 58min 59s\n",
      "Wall time: 21min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90114a0f90>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.paper_architecture(num_classes=8, input_shape=input_shape, batch_normalisation=True)\n",
    "model.fit(X_train_speakers_best, y_train_speakers_best,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=34,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.97      0.93      0.95        30\n",
      "      alinda       1.00      0.97      0.98        30\n",
      "        gian       1.00      0.97      0.98        30\n",
      "     jackson       0.97      1.00      0.98        30\n",
      "      khaled       0.94      1.00      0.97        30\n",
      "     nicolas       1.00      0.97      0.98        30\n",
      "        theo       0.94      1.00      0.97        30\n",
      "    yweweler       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.97       240\n",
      "   macro avg       0.98      0.98      0.98       240\n",
      "weighted avg       0.98      0.97      0.98       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_test_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./best_models/speakers.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
