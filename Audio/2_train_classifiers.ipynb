{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCH=32\n",
    "EPOCHS=100\n",
    "PATIENCE=10\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import data_augmentation\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "## No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdd_dir=\"./recordings/\"\n",
    "our_recs_dir=\"./preprocessed_recs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./recordings/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed94db126cd74fd8886418fc53c44482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2001.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ./preprocessed_recs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d493b42786ec49a89d9ae91e308da5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=401.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much does input recordings vary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 18262\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite a huge difference! Let's find out the 10 longest recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18262, 17567, 9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get their indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "first_length=18262\n",
    "second_length=17567\n",
    "index_first = a.index(first_length)\n",
    "index_second = a.index(second_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest track is associated with speaker theo, digit 9\n",
      "Second longest track is associated with speaker theo, digit 7\n"
     ]
    }
   ],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir])\n",
    "print(\"Longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_first],labels_digits[index_first]))\n",
    "print(\"Second longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_second],labels_digits[index_second]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problem is with theo, which has 500 recordings, digit 9 and 7, which respectively have 200 recordings. We can safely delete them and saving to pad many thousands of 0s (there will be (18262 - 9015) less zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "max_track_length=9015 # it will be useful later on\n",
    "print(\"Before: {}\".format(len(recordings)))\n",
    "recordings=np.delete(recordings,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(recordings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_speakers)))\n",
    "labels_speakers=np.delete(labels_speakers,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_speakers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_digits)))\n",
    "labels_digits=np.delete(labels_digits,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_digits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now double check to see if everything went well. Now the longest recording will be around 9 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356, 7147, 7038]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though variability is reduced, it is still there: for this reason we will pad zeros at start and end of recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they will have the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9015 9015\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create balancede train, validation and test sets. For digits it's not a huge problem (only 7 and 9, because of the previous operation, have 1 recordings less, however our 4 speakers (ale, alinda, gian, khaled) have 100 recordings, while the other 4 have 500 recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preparation.balanced_train_val_test_split(pad_recordings, labels_digits)\n",
    "X_train_digits = X[0]\n",
    "y_train_digits = y[0]\n",
    "X_val_digits = X[1]\n",
    "y_val_digits = y[1] \n",
    "X_test_digits = X[2]\n",
    "y_test_digits = y[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preparation.balanced_train_val_test_split(pad_recordings, labels_speakers)\n",
    "X_train_speakers = X[0]\n",
    "y_train_speakers = y[0]\n",
    "X_val_speakers = X[1]\n",
    "y_val_speakers = y[1] \n",
    "X_test_speakers = X[2]\n",
    "y_test_speakers = y[2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits\n",
    "## Spectrograms - No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.3 s, sys: 393 ms, total: 23.6 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_train_digits])\n",
    "X_val_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_val_digits])\n",
    "X_test_digits_spects = np.array([data_preparation.compute_spectrogram(x) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.1 s, sys: 351 ms, total: 23.5 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_train_digits])\n",
    "X_val_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_val_digits])\n",
    "X_test_digits_spects_norm = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digits_spects.shape\n",
    "X_train_digits_spects_2d = X_train_digits_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.75 s, sys: 67.3 ms, total: 8.81 s\n",
      "Wall time: 9.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train_digits_spects_2d, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digits_spects.shape\n",
    "X_val_digits_spects_2d = X_val_digits_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29        48\n",
      "           1       0.69      0.23      0.34        48\n",
      "           2       0.62      0.17      0.26        48\n",
      "           3       0.56      0.19      0.28        48\n",
      "           4       0.13      0.50      0.21        48\n",
      "           5       0.64      0.19      0.29        48\n",
      "           6       0.13      0.52      0.20        48\n",
      "           7       0.70      0.15      0.24        48\n",
      "           8       0.80      0.08      0.15        48\n",
      "           9       0.93      0.27      0.42        48\n",
      "\n",
      "    accuracy                           0.25       480\n",
      "   macro avg       0.62      0.25      0.27       480\n",
      "weighted avg       0.62      0.25      0.27       480\n",
      "\n",
      "CPU times: user 1.75 s, sys: 18.7 ms, total: 1.77 s\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val_digits_spects_2d)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digits_spects_norm.shape\n",
    "X_train_digits_spects_norm_2d = X_train_digits_spects_norm.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.11 s, sys: 32.9 ms, total: 4.14 s\n",
      "Wall time: 4.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_spects_norm_2d, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digits_spects_norm.shape\n",
    "X_val_digits_spects_norm_2d = X_val_digits_spects_norm.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        48\n",
      "           1       0.90      0.90      0.90        48\n",
      "           2       0.87      0.94      0.90        48\n",
      "           3       0.96      0.90      0.92        48\n",
      "           4       1.00      0.85      0.92        48\n",
      "           5       0.93      0.88      0.90        48\n",
      "           6       0.85      0.92      0.88        48\n",
      "           7       0.87      0.98      0.92        48\n",
      "           8       0.90      0.90      0.90        48\n",
      "           9       0.91      0.85      0.88        48\n",
      "\n",
      "    accuracy                           0.91       480\n",
      "   macro avg       0.91      0.91      0.91       480\n",
      "weighted avg       0.91      0.91      0.91       480\n",
      "\n",
      "CPU times: user 1.52 s, sys: 16.9 ms, total: 1.54 s\n",
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_digits_spects_norm_2d)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized spectrograms lead to better performances, therefore let's use this representation as default\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, input_shape, _ = data_preparation.prepare_data_nn(X_train_digits_spects_norm, X_val_digits_spects_norm, X_test_digits_spects_norm, y_train_digits, y_val_digits, y_test_digits, number_mode=True)\n",
    "\n",
    "X_train_digits_spects_norm_nn  = X_data[0]\n",
    "y_train_digits_nn = y_data[0]\n",
    "X_val_digits_spects_norm_nn  = X_data[1]\n",
    "y_val_digits_nn = y_data[1]\n",
    "X_test_digits_spects_norm_nn = X_data[2]\n",
    "y_test_digits_nn  = y_data[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,033,066\n",
      "Trainable params: 1,033,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 5s 3ms/sample - loss: 1.9174 - accuracy: 0.3510 - val_loss: 1.6236 - val_accuracy: 0.4604\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 1.3686 - accuracy: 0.5601 - val_loss: 0.9706 - val_accuracy: 0.7708\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 1.0282 - accuracy: 0.6916 - val_loss: 0.7945 - val_accuracy: 0.7750\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.8044 - accuracy: 0.7406 - val_loss: 0.6505 - val_accuracy: 0.8188\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.6677 - accuracy: 0.7790 - val_loss: 0.6628 - val_accuracy: 0.7979\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.5816 - accuracy: 0.8175 - val_loss: 0.7843 - val_accuracy: 0.8125\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.4884 - accuracy: 0.8490 - val_loss: 0.8742 - val_accuracy: 0.7042\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.4590 - accuracy: 0.8434 - val_loss: 0.5060 - val_accuracy: 0.8604\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3911 - accuracy: 0.8881 - val_loss: 0.4629 - val_accuracy: 0.8875\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3546 - accuracy: 0.8930 - val_loss: 0.3984 - val_accuracy: 0.8875\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.3255 - accuracy: 0.9049 - val_loss: 0.3661 - val_accuracy: 0.9104\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2901 - accuracy: 0.9091 - val_loss: 0.3485 - val_accuracy: 0.9104\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2604 - accuracy: 0.9203 - val_loss: 0.3924 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2512 - accuracy: 0.9217 - val_loss: 0.3981 - val_accuracy: 0.9021\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2187 - accuracy: 0.9322 - val_loss: 0.3432 - val_accuracy: 0.9271\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1929 - accuracy: 0.9427 - val_loss: 0.3648 - val_accuracy: 0.9083\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2243 - accuracy: 0.9378 - val_loss: 0.3112 - val_accuracy: 0.9250\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1935 - accuracy: 0.9364 - val_loss: 0.3379 - val_accuracy: 0.9250\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1707 - accuracy: 0.9497 - val_loss: 0.3103 - val_accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1666 - accuracy: 0.9469 - val_loss: 0.3232 - val_accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1803 - accuracy: 0.9427 - val_loss: 0.3912 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1563 - accuracy: 0.9559 - val_loss: 0.3334 - val_accuracy: 0.9208\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1458 - accuracy: 0.9559 - val_loss: 0.3332 - val_accuracy: 0.9292\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1662 - accuracy: 0.9503 - val_loss: 0.3916 - val_accuracy: 0.9021\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1602 - accuracy: 0.9510 - val_loss: 0.3365 - val_accuracy: 0.9312\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1373 - accuracy: 0.9587 - val_loss: 0.3064 - val_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1281 - accuracy: 0.9566 - val_loss: 0.4461 - val_accuracy: 0.8938\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1178 - accuracy: 0.9678 - val_loss: 0.3189 - val_accuracy: 0.9312\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1074 - accuracy: 0.9699 - val_loss: 0.3576 - val_accuracy: 0.9250\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1225 - accuracy: 0.9594 - val_loss: 0.3374 - val_accuracy: 0.9333\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0988 - accuracy: 0.9734 - val_loss: 0.3076 - val_accuracy: 0.9417\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1023 - accuracy: 0.9699 - val_loss: 0.2945 - val_accuracy: 0.9458\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0998 - accuracy: 0.9741 - val_loss: 0.3093 - val_accuracy: 0.9375\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1019 - accuracy: 0.9678 - val_loss: 0.3300 - val_accuracy: 0.9396\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0891 - accuracy: 0.9734 - val_loss: 0.3032 - val_accuracy: 0.9458\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0687 - accuracy: 0.9797 - val_loss: 0.2842 - val_accuracy: 0.9417\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0841 - accuracy: 0.9776 - val_loss: 0.3330 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0760 - accuracy: 0.9783 - val_loss: 0.3004 - val_accuracy: 0.9479\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0825 - accuracy: 0.9741 - val_loss: 0.3155 - val_accuracy: 0.9292\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0663 - accuracy: 0.9853 - val_loss: 0.3460 - val_accuracy: 0.9396\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0730 - accuracy: 0.9769 - val_loss: 0.3130 - val_accuracy: 0.9500\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0726 - accuracy: 0.9811 - val_loss: 0.3445 - val_accuracy: 0.9292\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0653 - accuracy: 0.9839 - val_loss: 0.3782 - val_accuracy: 0.9187\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0716 - accuracy: 0.9776 - val_loss: 0.3093 - val_accuracy: 0.9479\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0649 - accuracy: 0.9811 - val_loss: 0.3263 - val_accuracy: 0.9396\n",
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0635 - accuracy: 0.9846 - val_loss: 0.3071 - val_accuracy: 0.9458\n",
      "CPU times: user 3min 27s, sys: 1min 26s, total: 4min 53s\n",
      "Wall time: 2min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f81a054fc50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10)\n",
    "model.fit(X_train_digits_spects_norm_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_norm_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        48\n",
      "           1       0.87      1.00      0.93        48\n",
      "           2       0.96      0.94      0.95        48\n",
      "           3       0.94      0.94      0.94        48\n",
      "           4       0.98      0.96      0.97        48\n",
      "           5       1.00      0.94      0.97        48\n",
      "           6       0.88      0.94      0.91        48\n",
      "           7       0.98      0.98      0.98        48\n",
      "           8       0.94      0.92      0.93        48\n",
      "           9       0.95      0.83      0.89        48\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.94      0.94      0.94       480\n",
      "weighted avg       0.94      0.94      0.94       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_norm_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 127, 17, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,033,450\n",
      "Trainable params: 1,033,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 6s 4ms/sample - loss: 1.1098 - accuracy: 0.6483 - val_loss: 1.6680 - val_accuracy: 0.5938\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.4727 - accuracy: 0.8776 - val_loss: 1.5970 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.3098 - accuracy: 0.9378 - val_loss: 1.3810 - val_accuracy: 0.5958\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.2314 - accuracy: 0.9594 - val_loss: 1.2962 - val_accuracy: 0.5917\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1736 - accuracy: 0.9727 - val_loss: 1.1695 - val_accuracy: 0.6271\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1541 - accuracy: 0.9741 - val_loss: 1.0491 - val_accuracy: 0.6833\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1195 - accuracy: 0.9881 - val_loss: 0.8411 - val_accuracy: 0.7625\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.1063 - accuracy: 0.9895 - val_loss: 0.7585 - val_accuracy: 0.7958\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0987 - accuracy: 0.9888 - val_loss: 0.5663 - val_accuracy: 0.8646\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0788 - accuracy: 0.9958 - val_loss: 0.5301 - val_accuracy: 0.8500\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0738 - accuracy: 0.9951 - val_loss: 0.4532 - val_accuracy: 0.8938\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0626 - accuracy: 0.9958 - val_loss: 0.3572 - val_accuracy: 0.9146\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0542 - accuracy: 0.9972 - val_loss: 0.3090 - val_accuracy: 0.9396\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0531 - accuracy: 0.9993 - val_loss: 0.3085 - val_accuracy: 0.9271\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0488 - accuracy: 0.9979 - val_loss: 0.2900 - val_accuracy: 0.9354\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0444 - accuracy: 0.9979 - val_loss: 0.2948 - val_accuracy: 0.9354\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9458\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9521\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0323 - accuracy: 0.9986 - val_loss: 0.3017 - val_accuracy: 0.9458\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9521\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0263 - accuracy: 0.9993 - val_loss: 0.2849 - val_accuracy: 0.9438\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0288 - accuracy: 0.9993 - val_loss: 0.2796 - val_accuracy: 0.9563\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.2788 - val_accuracy: 0.9521\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0246 - accuracy: 0.9993 - val_loss: 0.2741 - val_accuracy: 0.9563\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9563\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9563\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0231 - accuracy: 0.9993 - val_loss: 0.2796 - val_accuracy: 0.9500\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9479\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9542\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9521\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9542\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9583\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9583\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9583\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9604\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.2731 - val_accuracy: 0.9521\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.9604\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9542\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0139 - accuracy: 0.9993 - val_loss: 0.2752 - val_accuracy: 0.9604\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2684 - val_accuracy: 0.9542\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9583\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.2618 - val_accuracy: 0.9583\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 4s 3ms/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9563\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.2689 - val_accuracy: 0.9604\n",
      "Epoch 47/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.9563\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9604\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9583\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.2705 - val_accuracy: 0.9583\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9563\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 4s 2ms/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9583\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9542\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9542\n",
      "CPU times: user 4min 40s, sys: 2min 11s, total: 6min 51s\n",
      "Wall time: 3min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f818706c5d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_spects_norm_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_norm_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        48\n",
      "           1       0.96      0.94      0.95        48\n",
      "           2       0.96      0.94      0.95        48\n",
      "           3       0.96      0.98      0.97        48\n",
      "           4       1.00      0.96      0.98        48\n",
      "           5       0.94      0.96      0.95        48\n",
      "           6       0.94      0.96      0.95        48\n",
      "           7       1.00      0.94      0.97        48\n",
      "           8       0.98      1.00      0.99        48\n",
      "           9       0.88      0.94      0.91        48\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_norm_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try with MFCCs\n",
    "## MFCC - No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 353 ms, total: 22.8 s\n",
      "Wall time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc= np.array([data_preparation.mfcc(x, flatten=True) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "scaler_normal = StandardScaler()\n",
    "X_train_digits_mfcc_scaled = scaler_normal.fit_transform(X_train_digits_mfcc)\n",
    "X_val_digits_mfcc_scaled =  scaler_normal.transform(X_val_digits_mfcc)\n",
    "X_test_digits_mfcc_scaled =  scaler_normal.transform(X_test_digits_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 722 ms, sys: 12 ms, total: 734 ms\n",
      "Wall time: 818 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_digits_mfcc_scaled, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        48\n",
      "           1       0.98      0.98      0.98        48\n",
      "           2       1.00      1.00      1.00        48\n",
      "           3       0.96      0.96      0.96        48\n",
      "           4       1.00      0.88      0.93        48\n",
      "           5       1.00      0.92      0.96        48\n",
      "           6       0.69      0.92      0.79        48\n",
      "           7       1.00      0.96      0.98        48\n",
      "           8       0.92      0.94      0.93        48\n",
      "           9       0.98      0.94      0.96        48\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.95      0.94      0.94       480\n",
      "weighted avg       0.95      0.94      0.94       480\n",
      "\n",
      "CPU times: user 244 ms, sys: 5.28 ms, total: 249 ms\n",
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_digits_mfcc_scaled)\n",
    "print(classification_report(y_val_digits, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar results of the best Spectrograms model. Let's now use CNNs with MFCC\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 s, sys: 360 ms, total: 22.9 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc= np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_digits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1430, 20, 18)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_digits_mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digits_mfcc, X_val_digits_mfcc, X_test_digits_mfcc, y_train_digits, y_val_digits, y_test_digits, number_mode=True)\n",
    "\n",
    "X_train_digits_mfcc_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_mfcc_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_mfcc_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start to train the models, let's start with the simpler one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,330\n",
      "Trainable params: 148,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 21556014486623.8633 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 1s 692us/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 1s 686us/sample - loss: 2.3027 - accuracy: 0.0944 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 1s 661us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 1s 648us/sample - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 1s 665us/sample - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 1s 740us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 1s 855us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 1s 713us/sample - loss: 2.3027 - accuracy: 0.0944 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 1s 706us/sample - loss: 2.3027 - accuracy: 0.0923 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 1s 715us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 1s 673us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 1s 780us/sample - loss: 2.3027 - accuracy: 0.0846 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 1s 653us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 1s 650us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 1s 671us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 1s 660us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 1s 629us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 1s 632us/sample - loss: 2.3027 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 1s 653us/sample - loss: 2.3027 - accuracy: 0.0888 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 1s 776us/sample - loss: 2.3027 - accuracy: 0.0958 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 1s 675us/sample - loss: 2.3027 - accuracy: 0.0867 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 1s 651us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 1s 650us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 1s 644us/sample - loss: 2.3027 - accuracy: 0.0951 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 1s 653us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 1s 647us/sample - loss: 2.3027 - accuracy: 0.0867 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 1s 637us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 1s 681us/sample - loss: 2.3027 - accuracy: 0.0804 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 1s 659us/sample - loss: 2.3027 - accuracy: 0.0755 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 1s 611us/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 1s 698us/sample - loss: 2.3027 - accuracy: 0.0867 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 1s 612us/sample - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 1s 627us/sample - loss: 2.3027 - accuracy: 0.0888 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 1s 653us/sample - loss: 2.3027 - accuracy: 0.0874 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 1s 641us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 1s 659us/sample - loss: 2.3027 - accuracy: 0.0762 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 1s 616us/sample - loss: 2.3027 - accuracy: 0.0888 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 1s 659us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 1s 687us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 1s 613us/sample - loss: 2.3027 - accuracy: 0.0818 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 1s 707us/sample - loss: 2.3027 - accuracy: 0.0783 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 1s 627us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 1s 649us/sample - loss: 2.3027 - accuracy: 0.0825 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 1s 676us/sample - loss: 2.3027 - accuracy: 0.0958 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 46/100\n",
      "1430/1430 [==============================] - 1s 691us/sample - loss: 2.3027 - accuracy: 0.0965 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430/1430 [==============================] - 1s 636us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 1s 612us/sample - loss: 2.3027 - accuracy: 0.0790 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 1s 589us/sample - loss: 2.3027 - accuracy: 0.0818 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 1s 586us/sample - loss: 2.3027 - accuracy: 0.0930 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 1s 600us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 1s 601us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 1s 603us/sample - loss: 2.3027 - accuracy: 0.0874 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 1s 696us/sample - loss: 2.3027 - accuracy: 0.0790 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "1430/1430 [==============================] - 1s 601us/sample - loss: 2.3027 - accuracy: 0.0755 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 56/100\n",
      "1430/1430 [==============================] - 1s 580us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 57/100\n",
      "1430/1430 [==============================] - 1s 601us/sample - loss: 2.3027 - accuracy: 0.0874 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "1430/1430 [==============================] - 1s 615us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 59/100\n",
      "1430/1430 [==============================] - 1s 590us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "1430/1430 [==============================] - 1s 605us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "1430/1430 [==============================] - 1s 570us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 62/100\n",
      "1430/1430 [==============================] - 1s 593us/sample - loss: 2.3027 - accuracy: 0.0923 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 63/100\n",
      "1430/1430 [==============================] - 1s 613us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 64/100\n",
      "1430/1430 [==============================] - 1s 609us/sample - loss: 2.3027 - accuracy: 0.0909 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 65/100\n",
      "1430/1430 [==============================] - 1s 602us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 66/100\n",
      "1430/1430 [==============================] - 1s 607us/sample - loss: 2.3027 - accuracy: 0.0881 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 67/100\n",
      "1430/1430 [==============================] - 1s 595us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 68/100\n",
      "1430/1430 [==============================] - 1s 605us/sample - loss: 2.3027 - accuracy: 0.0720 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 69/100\n",
      "1430/1430 [==============================] - 1s 593us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 70/100\n",
      "1430/1430 [==============================] - 1s 647us/sample - loss: 2.3027 - accuracy: 0.0797 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 71/100\n",
      "1430/1430 [==============================] - 1s 585us/sample - loss: 2.3027 - accuracy: 0.0916 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 72/100\n",
      "1430/1430 [==============================] - 1s 597us/sample - loss: 2.3027 - accuracy: 0.0937 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 73/100\n",
      "1430/1430 [==============================] - 1s 595us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 74/100\n",
      "1430/1430 [==============================] - 1s 612us/sample - loss: 2.3027 - accuracy: 0.0853 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 75/100\n",
      "1430/1430 [==============================] - 1s 597us/sample - loss: 2.3027 - accuracy: 0.0923 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 76/100\n",
      "1430/1430 [==============================] - 1s 600us/sample - loss: 2.3027 - accuracy: 0.0790 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 77/100\n",
      "1430/1430 [==============================] - 1s 619us/sample - loss: 2.3027 - accuracy: 0.0846 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 78/100\n",
      "1430/1430 [==============================] - 1s 612us/sample - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 79/100\n",
      "1430/1430 [==============================] - 1s 603us/sample - loss: 2.3027 - accuracy: 0.0860 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 80/100\n",
      "1430/1430 [==============================] - 1s 588us/sample - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 81/100\n",
      "1430/1430 [==============================] - 1s 624us/sample - loss: 2.3027 - accuracy: 0.0902 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 82/100\n",
      "1430/1430 [==============================] - 1s 603us/sample - loss: 2.3027 - accuracy: 0.0818 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "CPU times: user 1min 37s, sys: 54.9 s, total: 2min 32s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8189f80910>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        48\n",
      "           1       0.00      0.00      0.00        48\n",
      "           2       0.00      0.00      0.00        48\n",
      "           3       0.00      0.00      0.00        48\n",
      "           4       0.00      0.00      0.00        48\n",
      "           5       0.00      0.00      0.00        48\n",
      "           6       0.00      0.00      0.00        48\n",
      "           7       0.00      0.00      0.00        48\n",
      "           8       0.10      1.00      0.18        48\n",
      "           9       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.10       480\n",
      "   macro avg       0.01      0.10      0.02       480\n",
      "weighted avg       0.01      0.10      0.02       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really poor results, let's now use batch normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,714\n",
      "Trainable params: 148,522\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1430 samples, validate on 480 samples\n",
      "Epoch 1/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 1.2522 - accuracy: 0.5937 - val_loss: 3.5444 - val_accuracy: 0.4083\n",
      "Epoch 2/100\n",
      "1430/1430 [==============================] - 1s 805us/sample - loss: 0.7169 - accuracy: 0.7951 - val_loss: 1.1626 - val_accuracy: 0.6167\n",
      "Epoch 3/100\n",
      "1430/1430 [==============================] - 1s 830us/sample - loss: 0.5276 - accuracy: 0.8650 - val_loss: 0.5468 - val_accuracy: 0.8562\n",
      "Epoch 4/100\n",
      "1430/1430 [==============================] - 1s 804us/sample - loss: 0.4396 - accuracy: 0.8867 - val_loss: 0.5031 - val_accuracy: 0.8750\n",
      "Epoch 5/100\n",
      "1430/1430 [==============================] - 1s 822us/sample - loss: 0.3921 - accuracy: 0.9140 - val_loss: 0.4192 - val_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "1430/1430 [==============================] - 1s 877us/sample - loss: 0.3155 - accuracy: 0.9294 - val_loss: 0.4369 - val_accuracy: 0.9042\n",
      "Epoch 7/100\n",
      "1430/1430 [==============================] - 1s 824us/sample - loss: 0.2809 - accuracy: 0.9455 - val_loss: 0.4165 - val_accuracy: 0.9021\n",
      "Epoch 8/100\n",
      "1430/1430 [==============================] - 1s 780us/sample - loss: 0.2710 - accuracy: 0.9441 - val_loss: 0.4441 - val_accuracy: 0.8833\n",
      "Epoch 9/100\n",
      "1430/1430 [==============================] - 1s 797us/sample - loss: 0.2774 - accuracy: 0.9420 - val_loss: 0.4018 - val_accuracy: 0.8979\n",
      "Epoch 10/100\n",
      "1430/1430 [==============================] - 1s 818us/sample - loss: 0.2256 - accuracy: 0.9573 - val_loss: 0.3165 - val_accuracy: 0.9167\n",
      "Epoch 11/100\n",
      "1430/1430 [==============================] - 1s 828us/sample - loss: 0.2163 - accuracy: 0.9671 - val_loss: 0.3378 - val_accuracy: 0.9167\n",
      "Epoch 12/100\n",
      "1430/1430 [==============================] - 1s 826us/sample - loss: 0.1964 - accuracy: 0.9608 - val_loss: 0.3073 - val_accuracy: 0.9083\n",
      "Epoch 13/100\n",
      "1430/1430 [==============================] - 1s 825us/sample - loss: 0.1874 - accuracy: 0.9629 - val_loss: 0.3715 - val_accuracy: 0.9021\n",
      "Epoch 14/100\n",
      "1430/1430 [==============================] - 1s 811us/sample - loss: 0.1909 - accuracy: 0.9657 - val_loss: 0.2944 - val_accuracy: 0.9292\n",
      "Epoch 15/100\n",
      "1430/1430 [==============================] - 1s 812us/sample - loss: 0.1727 - accuracy: 0.9664 - val_loss: 0.2911 - val_accuracy: 0.9146\n",
      "Epoch 16/100\n",
      "1430/1430 [==============================] - 1s 967us/sample - loss: 0.1649 - accuracy: 0.9678 - val_loss: 0.2859 - val_accuracy: 0.9271\n",
      "Epoch 17/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.1463 - accuracy: 0.9790 - val_loss: 0.2712 - val_accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.1360 - accuracy: 0.9769 - val_loss: 0.2633 - val_accuracy: 0.9292\n",
      "Epoch 19/100\n",
      "1430/1430 [==============================] - 1s 1ms/sample - loss: 0.1288 - accuracy: 0.9846 - val_loss: 0.2495 - val_accuracy: 0.9354\n",
      "Epoch 20/100\n",
      "1430/1430 [==============================] - 1s 866us/sample - loss: 0.1278 - accuracy: 0.9839 - val_loss: 0.2688 - val_accuracy: 0.9292\n",
      "Epoch 21/100\n",
      "1430/1430 [==============================] - 1s 821us/sample - loss: 0.1189 - accuracy: 0.9811 - val_loss: 0.2321 - val_accuracy: 0.9396\n",
      "Epoch 22/100\n",
      "1430/1430 [==============================] - 1s 860us/sample - loss: 0.1073 - accuracy: 0.9839 - val_loss: 0.2530 - val_accuracy: 0.9229\n",
      "Epoch 23/100\n",
      "1430/1430 [==============================] - 1s 855us/sample - loss: 0.1061 - accuracy: 0.9846 - val_loss: 0.2361 - val_accuracy: 0.9396\n",
      "Epoch 24/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.1002 - accuracy: 0.9846 - val_loss: 0.2850 - val_accuracy: 0.9271\n",
      "Epoch 25/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.0911 - accuracy: 0.9895 - val_loss: 0.2349 - val_accuracy: 0.9521\n",
      "Epoch 26/100\n",
      "1430/1430 [==============================] - 3s 2ms/sample - loss: 0.0988 - accuracy: 0.9881 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 27/100\n",
      "1430/1430 [==============================] - 2s 2ms/sample - loss: 0.0826 - accuracy: 0.9923 - val_loss: 0.2425 - val_accuracy: 0.9333\n",
      "Epoch 28/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.0937 - accuracy: 0.9853 - val_loss: 0.2508 - val_accuracy: 0.9458\n",
      "Epoch 29/100\n",
      "1430/1430 [==============================] - 1s 926us/sample - loss: 0.0776 - accuracy: 0.9916 - val_loss: 0.2463 - val_accuracy: 0.9375\n",
      "Epoch 30/100\n",
      "1430/1430 [==============================] - 1s 974us/sample - loss: 0.0778 - accuracy: 0.9944 - val_loss: 0.2279 - val_accuracy: 0.9375\n",
      "Epoch 31/100\n",
      "1430/1430 [==============================] - 1s 821us/sample - loss: 0.0816 - accuracy: 0.9895 - val_loss: 0.2430 - val_accuracy: 0.9292\n",
      "Epoch 32/100\n",
      "1430/1430 [==============================] - 1s 835us/sample - loss: 0.0718 - accuracy: 0.9916 - val_loss: 0.2225 - val_accuracy: 0.9458\n",
      "Epoch 33/100\n",
      "1430/1430 [==============================] - 1s 938us/sample - loss: 0.0735 - accuracy: 0.9909 - val_loss: 0.2295 - val_accuracy: 0.9479\n",
      "Epoch 34/100\n",
      "1430/1430 [==============================] - 1s 855us/sample - loss: 0.0830 - accuracy: 0.9902 - val_loss: 0.2276 - val_accuracy: 0.9375\n",
      "Epoch 35/100\n",
      "1430/1430 [==============================] - 1s 945us/sample - loss: 0.0606 - accuracy: 0.9944 - val_loss: 0.2165 - val_accuracy: 0.9479\n",
      "Epoch 36/100\n",
      "1430/1430 [==============================] - 1s 912us/sample - loss: 0.0638 - accuracy: 0.9923 - val_loss: 0.2571 - val_accuracy: 0.9396\n",
      "Epoch 37/100\n",
      "1430/1430 [==============================] - 1s 897us/sample - loss: 0.0689 - accuracy: 0.9923 - val_loss: 0.2395 - val_accuracy: 0.9479\n",
      "Epoch 38/100\n",
      "1430/1430 [==============================] - 1s 813us/sample - loss: 0.0508 - accuracy: 0.9965 - val_loss: 0.2264 - val_accuracy: 0.9375\n",
      "Epoch 39/100\n",
      "1430/1430 [==============================] - 1s 799us/sample - loss: 0.0498 - accuracy: 0.9979 - val_loss: 0.2318 - val_accuracy: 0.9458\n",
      "Epoch 40/100\n",
      "1430/1430 [==============================] - 1s 920us/sample - loss: 0.0519 - accuracy: 0.9958 - val_loss: 0.2016 - val_accuracy: 0.9500\n",
      "Epoch 41/100\n",
      "1430/1430 [==============================] - 1s 797us/sample - loss: 0.0511 - accuracy: 0.9951 - val_loss: 0.2110 - val_accuracy: 0.9542\n",
      "Epoch 42/100\n",
      "1430/1430 [==============================] - 1s 810us/sample - loss: 0.0509 - accuracy: 0.9958 - val_loss: 0.2082 - val_accuracy: 0.9479\n",
      "Epoch 43/100\n",
      "1430/1430 [==============================] - 1s 824us/sample - loss: 0.0517 - accuracy: 0.9937 - val_loss: 0.2132 - val_accuracy: 0.9479\n",
      "Epoch 44/100\n",
      "1430/1430 [==============================] - 1s 799us/sample - loss: 0.0464 - accuracy: 0.9958 - val_loss: 0.2148 - val_accuracy: 0.9458\n",
      "Epoch 45/100\n",
      "1430/1430 [==============================] - 1s 803us/sample - loss: 0.0504 - accuracy: 0.9937 - val_loss: 0.2314 - val_accuracy: 0.9479\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430/1430 [==============================] - 1s 742us/sample - loss: 0.0459 - accuracy: 0.9972 - val_loss: 0.2176 - val_accuracy: 0.9479\n",
      "Epoch 47/100\n",
      "1430/1430 [==============================] - 1s 719us/sample - loss: 0.0414 - accuracy: 0.9930 - val_loss: 0.1988 - val_accuracy: 0.9521\n",
      "Epoch 48/100\n",
      "1430/1430 [==============================] - 1s 766us/sample - loss: 0.0409 - accuracy: 0.9944 - val_loss: 0.2124 - val_accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "1430/1430 [==============================] - 1s 767us/sample - loss: 0.0429 - accuracy: 0.9965 - val_loss: 0.2060 - val_accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "1430/1430 [==============================] - 1s 741us/sample - loss: 0.0384 - accuracy: 0.9986 - val_loss: 0.2049 - val_accuracy: 0.9458\n",
      "Epoch 51/100\n",
      "1430/1430 [==============================] - 1s 752us/sample - loss: 0.0487 - accuracy: 0.9923 - val_loss: 0.2110 - val_accuracy: 0.9521\n",
      "Epoch 52/100\n",
      "1430/1430 [==============================] - 1s 734us/sample - loss: 0.0378 - accuracy: 0.9986 - val_loss: 0.1910 - val_accuracy: 0.9542\n",
      "Epoch 53/100\n",
      "1430/1430 [==============================] - 1s 752us/sample - loss: 0.0384 - accuracy: 0.9972 - val_loss: 0.2527 - val_accuracy: 0.9375\n",
      "Epoch 54/100\n",
      "1430/1430 [==============================] - 1s 772us/sample - loss: 0.0384 - accuracy: 0.9972 - val_loss: 0.2168 - val_accuracy: 0.9500\n",
      "Epoch 55/100\n",
      "1430/1430 [==============================] - 1s 759us/sample - loss: 0.0397 - accuracy: 0.9958 - val_loss: 0.2040 - val_accuracy: 0.9438\n",
      "Epoch 56/100\n",
      "1430/1430 [==============================] - 1s 809us/sample - loss: 0.0404 - accuracy: 0.9972 - val_loss: 0.1913 - val_accuracy: 0.9583\n",
      "Epoch 57/100\n",
      "1430/1430 [==============================] - 1s 726us/sample - loss: 0.0317 - accuracy: 0.9986 - val_loss: 0.1914 - val_accuracy: 0.9563\n",
      "Epoch 58/100\n",
      "1430/1430 [==============================] - 1s 766us/sample - loss: 0.0351 - accuracy: 0.9972 - val_loss: 0.2108 - val_accuracy: 0.9521\n",
      "Epoch 59/100\n",
      "1430/1430 [==============================] - 1s 721us/sample - loss: 0.0320 - accuracy: 0.9972 - val_loss: 0.1898 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "1430/1430 [==============================] - 1s 722us/sample - loss: 0.0282 - accuracy: 0.9972 - val_loss: 0.1995 - val_accuracy: 0.9542\n",
      "Epoch 61/100\n",
      "1430/1430 [==============================] - 1s 808us/sample - loss: 0.0296 - accuracy: 0.9986 - val_loss: 0.2517 - val_accuracy: 0.9333\n",
      "Epoch 62/100\n",
      "1430/1430 [==============================] - 1s 799us/sample - loss: 0.0331 - accuracy: 0.9972 - val_loss: 0.1958 - val_accuracy: 0.9542\n",
      "Epoch 63/100\n",
      "1430/1430 [==============================] - 1s 905us/sample - loss: 0.0308 - accuracy: 0.9972 - val_loss: 0.2160 - val_accuracy: 0.9479\n",
      "Epoch 64/100\n",
      "1430/1430 [==============================] - 1s 776us/sample - loss: 0.0369 - accuracy: 0.9937 - val_loss: 0.1918 - val_accuracy: 0.9583\n",
      "Epoch 65/100\n",
      "1430/1430 [==============================] - 1s 828us/sample - loss: 0.0303 - accuracy: 0.9979 - val_loss: 0.2015 - val_accuracy: 0.9583\n",
      "Epoch 66/100\n",
      "1430/1430 [==============================] - 1s 852us/sample - loss: 0.0283 - accuracy: 0.9986 - val_loss: 0.1959 - val_accuracy: 0.9563\n",
      "Epoch 67/100\n",
      "1430/1430 [==============================] - 1s 862us/sample - loss: 0.0256 - accuracy: 0.9986 - val_loss: 0.1998 - val_accuracy: 0.9521\n",
      "Epoch 68/100\n",
      "1430/1430 [==============================] - 1s 867us/sample - loss: 0.0288 - accuracy: 0.9965 - val_loss: 0.2444 - val_accuracy: 0.9396\n",
      "Epoch 69/100\n",
      "1430/1430 [==============================] - 2s 1ms/sample - loss: 0.0270 - accuracy: 0.9986 - val_loss: 0.2397 - val_accuracy: 0.9417\n",
      "CPU times: user 1min 45s, sys: 41.5 s, total: 2min 26s\n",
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f818c49f350>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10,\n",
    "                                batch_normalisation=True)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        48\n",
      "           1       0.98      1.00      0.99        48\n",
      "           2       0.92      1.00      0.96        48\n",
      "           3       0.96      0.98      0.97        48\n",
      "           4       1.00      0.98      0.99        48\n",
      "           5       0.96      0.94      0.95        48\n",
      "           6       0.96      0.94      0.95        48\n",
      "           7       0.98      0.98      0.98        48\n",
      "           8       0.96      0.96      0.96        48\n",
      "           9       0.96      0.92      0.94        48\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.96      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best combo so far is \"CNN + MFCCs\".\n",
    "\n",
    "Batch normalisation lead to similar results on spectrograms, however on MFCC it works way better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n",
      "CPU times: user 5min 32s, sys: 13 s, total: 5min 45s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                                                    y_type= ['digit', 'digit'],\n",
    "                                                    n_category_test=15,\n",
    "                                                    include_pitch=True,\n",
    "                                                    max_length=max_track_length,\n",
    "                                                    recordings_source=[False, True],\n",
    "                                                    transform_function=\"mfcc\")\n",
    "X_train_digit_mfcc = X[0]\n",
    "y_train_digit_mfcc = y[0]\n",
    "X_val_digit_mfcc = X[1]\n",
    "y_val_digit_mfcc = y[1]\n",
    "X_test_digit_mfcc = X[2]\n",
    "y_test_digit_mfcc  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724 575\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_digit_mfcc, X_val_digit_mfcc]),\n",
    "                         np.concatenate([y_train_digit_mfcc, y_val_digit_mfcc]))\n",
    "\n",
    "X_train_digit = X[0]\n",
    "y_train_digit = y[0]\n",
    "X_val_digit = X[1]\n",
    "y_val_digit = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digit, X_val_digit, X_test_digit_mfcc, y_train_digit, y_val_digit, y_test_digit_mfcc, number_mode=True)\n",
    "X_train_digits_mfcc_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_mfcc_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_mfcc_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,714\n",
      "Trainable params: 148,522\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 17240 samples, validate on 5750 samples\n",
      "Epoch 1/100\n",
      "17240/17240 [==============================] - 16s 943us/sample - loss: 1.0633 - accuracy: 0.6489 - val_loss: 0.7819 - val_accuracy: 0.7501\n",
      "Epoch 2/100\n",
      "17240/17240 [==============================] - 13s 759us/sample - loss: 0.7437 - accuracy: 0.7578 - val_loss: 0.6766 - val_accuracy: 0.7852\n",
      "Epoch 3/100\n",
      "17240/17240 [==============================] - 13s 730us/sample - loss: 0.6421 - accuracy: 0.7907 - val_loss: 0.6062 - val_accuracy: 0.8031\n",
      "Epoch 4/100\n",
      "17240/17240 [==============================] - 12s 709us/sample - loss: 0.5956 - accuracy: 0.8075 - val_loss: 0.5070 - val_accuracy: 0.8428\n",
      "Epoch 5/100\n",
      "17240/17240 [==============================] - 12s 696us/sample - loss: 0.5549 - accuracy: 0.8187 - val_loss: 0.4978 - val_accuracy: 0.8417\n",
      "Epoch 6/100\n",
      "17240/17240 [==============================] - 12s 710us/sample - loss: 0.5346 - accuracy: 0.8296 - val_loss: 0.4743 - val_accuracy: 0.8471\n",
      "Epoch 7/100\n",
      "17240/17240 [==============================] - 12s 709us/sample - loss: 0.5174 - accuracy: 0.8304 - val_loss: 0.5735 - val_accuracy: 0.7983\n",
      "Epoch 8/100\n",
      "17240/17240 [==============================] - 14s 813us/sample - loss: 0.5087 - accuracy: 0.8339 - val_loss: 0.4781 - val_accuracy: 0.8390\n",
      "Epoch 9/100\n",
      "17240/17240 [==============================] - 11s 661us/sample - loss: 0.5026 - accuracy: 0.8331 - val_loss: 0.6470 - val_accuracy: 0.7807\n",
      "Epoch 10/100\n",
      "17240/17240 [==============================] - 11s 655us/sample - loss: 0.4749 - accuracy: 0.8446 - val_loss: 0.4549 - val_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "17240/17240 [==============================] - 11s 641us/sample - loss: 0.4807 - accuracy: 0.8432 - val_loss: 0.4589 - val_accuracy: 0.8457\n",
      "Epoch 12/100\n",
      "17240/17240 [==============================] - 14s 813us/sample - loss: 0.4550 - accuracy: 0.8498 - val_loss: 0.4396 - val_accuracy: 0.8550\n",
      "Epoch 13/100\n",
      "17240/17240 [==============================] - 13s 747us/sample - loss: 0.4409 - accuracy: 0.8535 - val_loss: 0.4425 - val_accuracy: 0.8550\n",
      "Epoch 14/100\n",
      "17240/17240 [==============================] - 13s 728us/sample - loss: 0.4453 - accuracy: 0.8499 - val_loss: 0.3828 - val_accuracy: 0.8763\n",
      "Epoch 15/100\n",
      "17240/17240 [==============================] - 12s 696us/sample - loss: 0.4389 - accuracy: 0.8563 - val_loss: 0.4470 - val_accuracy: 0.8548\n",
      "Epoch 16/100\n",
      "17240/17240 [==============================] - 13s 746us/sample - loss: 0.4397 - accuracy: 0.8546 - val_loss: 0.3735 - val_accuracy: 0.8805\n",
      "Epoch 17/100\n",
      "17240/17240 [==============================] - 13s 727us/sample - loss: 0.4288 - accuracy: 0.8567 - val_loss: 0.4227 - val_accuracy: 0.8574\n",
      "Epoch 18/100\n",
      "17240/17240 [==============================] - 12s 723us/sample - loss: 0.4247 - accuracy: 0.8583 - val_loss: 0.3699 - val_accuracy: 0.8838\n",
      "Epoch 19/100\n",
      "17240/17240 [==============================] - 13s 738us/sample - loss: 0.4104 - accuracy: 0.8628 - val_loss: 0.3904 - val_accuracy: 0.8703\n",
      "Epoch 20/100\n",
      "17240/17240 [==============================] - 12s 683us/sample - loss: 0.4063 - accuracy: 0.8662 - val_loss: 0.4098 - val_accuracy: 0.8621\n",
      "Epoch 21/100\n",
      "17240/17240 [==============================] - 12s 694us/sample - loss: 0.4000 - accuracy: 0.8676 - val_loss: 0.3730 - val_accuracy: 0.8800\n",
      "Epoch 22/100\n",
      "17240/17240 [==============================] - 12s 673us/sample - loss: 0.3812 - accuracy: 0.8749 - val_loss: 0.3622 - val_accuracy: 0.8741\n",
      "Epoch 23/100\n",
      "17240/17240 [==============================] - 12s 679us/sample - loss: 0.3809 - accuracy: 0.8733 - val_loss: 0.3694 - val_accuracy: 0.8793\n",
      "Epoch 24/100\n",
      "17240/17240 [==============================] - 12s 675us/sample - loss: 0.3914 - accuracy: 0.8709 - val_loss: 0.3566 - val_accuracy: 0.8840\n",
      "Epoch 25/100\n",
      "17240/17240 [==============================] - 12s 688us/sample - loss: 0.3759 - accuracy: 0.8763 - val_loss: 0.3603 - val_accuracy: 0.8831\n",
      "Epoch 26/100\n",
      "17240/17240 [==============================] - 12s 690us/sample - loss: 0.3794 - accuracy: 0.8735 - val_loss: 0.3711 - val_accuracy: 0.8758\n",
      "Epoch 27/100\n",
      "17240/17240 [==============================] - 14s 823us/sample - loss: 0.3675 - accuracy: 0.8775 - val_loss: 0.4220 - val_accuracy: 0.8576\n",
      "Epoch 28/100\n",
      "17240/17240 [==============================] - 14s 803us/sample - loss: 0.3585 - accuracy: 0.8788 - val_loss: 0.3286 - val_accuracy: 0.8904\n",
      "Epoch 29/100\n",
      "17240/17240 [==============================] - 19s 1ms/sample - loss: 0.3595 - accuracy: 0.8787 - val_loss: 0.3269 - val_accuracy: 0.8915\n",
      "Epoch 30/100\n",
      "17240/17240 [==============================] - 15s 865us/sample - loss: 0.3530 - accuracy: 0.8812 - val_loss: 0.3348 - val_accuracy: 0.8868\n",
      "Epoch 31/100\n",
      "17240/17240 [==============================] - 15s 885us/sample - loss: 0.3568 - accuracy: 0.8770 - val_loss: 0.3545 - val_accuracy: 0.8812\n",
      "Epoch 32/100\n",
      "17240/17240 [==============================] - 15s 880us/sample - loss: 0.3462 - accuracy: 0.8838 - val_loss: 0.3128 - val_accuracy: 0.8957\n",
      "Epoch 33/100\n",
      "17240/17240 [==============================] - 15s 860us/sample - loss: 0.3391 - accuracy: 0.8865 - val_loss: 0.3459 - val_accuracy: 0.8765\n",
      "Epoch 34/100\n",
      "17240/17240 [==============================] - 15s 877us/sample - loss: 0.3361 - accuracy: 0.8893 - val_loss: 0.3303 - val_accuracy: 0.8864\n",
      "Epoch 35/100\n",
      "17240/17240 [==============================] - 16s 907us/sample - loss: 0.3430 - accuracy: 0.8878 - val_loss: 0.3663 - val_accuracy: 0.8715\n",
      "Epoch 36/100\n",
      "17240/17240 [==============================] - 16s 949us/sample - loss: 0.3222 - accuracy: 0.8905 - val_loss: 0.3261 - val_accuracy: 0.8901\n",
      "Epoch 37/100\n",
      "17240/17240 [==============================] - 15s 889us/sample - loss: 0.3224 - accuracy: 0.8908 - val_loss: 0.3540 - val_accuracy: 0.8817\n",
      "Epoch 38/100\n",
      "17240/17240 [==============================] - 14s 837us/sample - loss: 0.3226 - accuracy: 0.8884 - val_loss: 0.3168 - val_accuracy: 0.8878\n",
      "Epoch 39/100\n",
      "17240/17240 [==============================] - 14s 795us/sample - loss: 0.3119 - accuracy: 0.8969 - val_loss: 0.3549 - val_accuracy: 0.8793\n",
      "Epoch 40/100\n",
      "17240/17240 [==============================] - 18s 1ms/sample - loss: 0.3176 - accuracy: 0.8916 - val_loss: 0.3042 - val_accuracy: 0.8993\n",
      "Epoch 41/100\n",
      "17240/17240 [==============================] - 15s 853us/sample - loss: 0.3127 - accuracy: 0.8957 - val_loss: 0.3097 - val_accuracy: 0.8967\n",
      "Epoch 42/100\n",
      "17240/17240 [==============================] - 12s 677us/sample - loss: 0.2994 - accuracy: 0.8982 - val_loss: 0.3164 - val_accuracy: 0.8901\n",
      "Epoch 43/100\n",
      "17240/17240 [==============================] - 14s 832us/sample - loss: 0.3115 - accuracy: 0.8964 - val_loss: 0.3084 - val_accuracy: 0.8967\n",
      "Epoch 44/100\n",
      "17240/17240 [==============================] - 15s 867us/sample - loss: 0.3089 - accuracy: 0.8951 - val_loss: 0.3046 - val_accuracy: 0.8970\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17240/17240 [==============================] - 13s 734us/sample - loss: 0.3015 - accuracy: 0.8985 - val_loss: 0.3025 - val_accuracy: 0.8932\n",
      "Epoch 46/100\n",
      "17240/17240 [==============================] - 13s 768us/sample - loss: 0.3075 - accuracy: 0.8972 - val_loss: 0.3281 - val_accuracy: 0.8908\n",
      "Epoch 47/100\n",
      "17240/17240 [==============================] - 14s 830us/sample - loss: 0.3028 - accuracy: 0.8979 - val_loss: 0.2939 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "17240/17240 [==============================] - 13s 725us/sample - loss: 0.3037 - accuracy: 0.8972 - val_loss: 0.3088 - val_accuracy: 0.8957\n",
      "Epoch 49/100\n",
      "17240/17240 [==============================] - 13s 728us/sample - loss: 0.2931 - accuracy: 0.9020 - val_loss: 0.3345 - val_accuracy: 0.8896\n",
      "Epoch 50/100\n",
      "17240/17240 [==============================] - 11s 613us/sample - loss: 0.3002 - accuracy: 0.8997 - val_loss: 0.3322 - val_accuracy: 0.8882\n",
      "Epoch 51/100\n",
      "17240/17240 [==============================] - 11s 642us/sample - loss: 0.2910 - accuracy: 0.9020 - val_loss: 0.3095 - val_accuracy: 0.8939\n",
      "Epoch 52/100\n",
      "17240/17240 [==============================] - 11s 637us/sample - loss: 0.2876 - accuracy: 0.9042 - val_loss: 0.2900 - val_accuracy: 0.9003\n",
      "Epoch 53/100\n",
      "17240/17240 [==============================] - 11s 634us/sample - loss: 0.2846 - accuracy: 0.9037 - val_loss: 0.2876 - val_accuracy: 0.9042\n",
      "Epoch 54/100\n",
      "17240/17240 [==============================] - 12s 707us/sample - loss: 0.2840 - accuracy: 0.9031 - val_loss: 0.2964 - val_accuracy: 0.9012\n",
      "Epoch 55/100\n",
      "17240/17240 [==============================] - 11s 629us/sample - loss: 0.2803 - accuracy: 0.9053 - val_loss: 0.2900 - val_accuracy: 0.9030\n",
      "Epoch 56/100\n",
      "17240/17240 [==============================] - 11s 616us/sample - loss: 0.2859 - accuracy: 0.9009 - val_loss: 0.3020 - val_accuracy: 0.8963\n",
      "Epoch 57/100\n",
      "17240/17240 [==============================] - 11s 632us/sample - loss: 0.2727 - accuracy: 0.9112 - val_loss: 0.2973 - val_accuracy: 0.8977\n",
      "Epoch 58/100\n",
      "17240/17240 [==============================] - 11s 662us/sample - loss: 0.2831 - accuracy: 0.9060 - val_loss: 0.3337 - val_accuracy: 0.8847\n",
      "Epoch 59/100\n",
      "17240/17240 [==============================] - 11s 619us/sample - loss: 0.2755 - accuracy: 0.9068 - val_loss: 0.2779 - val_accuracy: 0.9052\n",
      "Epoch 60/100\n",
      "17240/17240 [==============================] - 10s 586us/sample - loss: 0.2659 - accuracy: 0.9097 - val_loss: 0.2829 - val_accuracy: 0.9049\n",
      "Epoch 61/100\n",
      "17240/17240 [==============================] - 11s 639us/sample - loss: 0.2748 - accuracy: 0.9075 - val_loss: 0.3258 - val_accuracy: 0.8920\n",
      "Epoch 62/100\n",
      "17240/17240 [==============================] - 10s 592us/sample - loss: 0.2722 - accuracy: 0.9084 - val_loss: 0.2905 - val_accuracy: 0.9009\n",
      "Epoch 63/100\n",
      "17240/17240 [==============================] - 11s 624us/sample - loss: 0.2766 - accuracy: 0.9080 - val_loss: 0.3288 - val_accuracy: 0.8899\n",
      "Epoch 64/100\n",
      "17240/17240 [==============================] - 10s 600us/sample - loss: 0.2713 - accuracy: 0.9069 - val_loss: 0.3197 - val_accuracy: 0.8943\n",
      "Epoch 65/100\n",
      "17240/17240 [==============================] - 10s 595us/sample - loss: 0.2700 - accuracy: 0.9099 - val_loss: 0.2994 - val_accuracy: 0.8976\n",
      "Epoch 66/100\n",
      "17240/17240 [==============================] - 10s 553us/sample - loss: 0.2626 - accuracy: 0.9127 - val_loss: 0.3198 - val_accuracy: 0.8906\n",
      "Epoch 67/100\n",
      "17240/17240 [==============================] - 9s 544us/sample - loss: 0.2730 - accuracy: 0.9059 - val_loss: 0.2979 - val_accuracy: 0.9002\n",
      "Epoch 68/100\n",
      "17240/17240 [==============================] - 9s 527us/sample - loss: 0.2630 - accuracy: 0.9080 - val_loss: 0.2727 - val_accuracy: 0.9071\n",
      "Epoch 69/100\n",
      "17240/17240 [==============================] - 9s 541us/sample - loss: 0.2472 - accuracy: 0.9146 - val_loss: 0.3009 - val_accuracy: 0.9014\n",
      "Epoch 70/100\n",
      "17240/17240 [==============================] - 9s 536us/sample - loss: 0.2513 - accuracy: 0.9134 - val_loss: 0.2914 - val_accuracy: 0.9007\n",
      "Epoch 71/100\n",
      "17240/17240 [==============================] - 9s 533us/sample - loss: 0.2546 - accuracy: 0.9155 - val_loss: 0.2750 - val_accuracy: 0.9087\n",
      "Epoch 72/100\n",
      "17240/17240 [==============================] - 10s 564us/sample - loss: 0.2477 - accuracy: 0.9190 - val_loss: 0.3041 - val_accuracy: 0.8981\n",
      "Epoch 73/100\n",
      "17240/17240 [==============================] - 10s 552us/sample - loss: 0.2487 - accuracy: 0.9184 - val_loss: 0.2695 - val_accuracy: 0.9104\n",
      "Epoch 74/100\n",
      "17240/17240 [==============================] - 9s 542us/sample - loss: 0.2444 - accuracy: 0.9176 - val_loss: 0.2871 - val_accuracy: 0.8998\n",
      "Epoch 75/100\n",
      "17240/17240 [==============================] - 9s 535us/sample - loss: 0.2492 - accuracy: 0.9150 - val_loss: 0.3134 - val_accuracy: 0.8923\n",
      "Epoch 76/100\n",
      "17240/17240 [==============================] - 10s 552us/sample - loss: 0.2378 - accuracy: 0.9180 - val_loss: 0.2871 - val_accuracy: 0.9033\n",
      "Epoch 77/100\n",
      "17240/17240 [==============================] - 9s 530us/sample - loss: 0.2421 - accuracy: 0.9187 - val_loss: 0.2717 - val_accuracy: 0.9094\n",
      "Epoch 78/100\n",
      "17240/17240 [==============================] - 10s 578us/sample - loss: 0.2475 - accuracy: 0.9152 - val_loss: 0.2794 - val_accuracy: 0.9066\n",
      "Epoch 79/100\n",
      "17240/17240 [==============================] - 9s 525us/sample - loss: 0.2413 - accuracy: 0.9179 - val_loss: 0.2685 - val_accuracy: 0.9097\n",
      "Epoch 80/100\n",
      "17240/17240 [==============================] - 11s 627us/sample - loss: 0.2361 - accuracy: 0.9175 - val_loss: 0.2784 - val_accuracy: 0.9063\n",
      "Epoch 81/100\n",
      "17240/17240 [==============================] - 10s 552us/sample - loss: 0.2286 - accuracy: 0.9233 - val_loss: 0.3134 - val_accuracy: 0.8950\n",
      "Epoch 82/100\n",
      "17240/17240 [==============================] - 9s 535us/sample - loss: 0.2411 - accuracy: 0.9183 - val_loss: 0.2866 - val_accuracy: 0.9068\n",
      "Epoch 83/100\n",
      "17240/17240 [==============================] - 9s 531us/sample - loss: 0.2451 - accuracy: 0.9160 - val_loss: 0.2811 - val_accuracy: 0.9089\n",
      "Epoch 84/100\n",
      "17240/17240 [==============================] - 9s 540us/sample - loss: 0.2421 - accuracy: 0.9190 - val_loss: 0.2751 - val_accuracy: 0.9071\n",
      "Epoch 85/100\n",
      "17240/17240 [==============================] - 13s 731us/sample - loss: 0.2367 - accuracy: 0.9197 - val_loss: 0.2733 - val_accuracy: 0.9099\n",
      "Epoch 86/100\n",
      "17240/17240 [==============================] - 13s 772us/sample - loss: 0.2282 - accuracy: 0.9212 - val_loss: 0.2792 - val_accuracy: 0.9002\n",
      "Epoch 87/100\n",
      "17240/17240 [==============================] - 10s 597us/sample - loss: 0.2327 - accuracy: 0.9194 - val_loss: 0.2810 - val_accuracy: 0.9056\n",
      "Epoch 88/100\n",
      "17240/17240 [==============================] - 10s 575us/sample - loss: 0.2277 - accuracy: 0.9233 - val_loss: 0.2761 - val_accuracy: 0.9090\n",
      "Epoch 89/100\n",
      "17240/17240 [==============================] - 10s 571us/sample - loss: 0.2351 - accuracy: 0.9206 - val_loss: 0.2827 - val_accuracy: 0.9049\n",
      "CPU times: user 25min 48s, sys: 16min 7s, total: 41min 55s\n",
      "Wall time: 17min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f819e8ab890>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_mfcc_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_mfcc_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       575\n",
      "           1       0.91      0.93      0.92       575\n",
      "           2       0.89      0.91      0.90       575\n",
      "           3       0.91      0.86      0.88       575\n",
      "           4       0.95      0.91      0.93       575\n",
      "           5       0.96      0.91      0.93       575\n",
      "           6       0.94      0.86      0.89       575\n",
      "           7       0.85      0.94      0.89       575\n",
      "           8       0.89      0.93      0.91       575\n",
      "           9       0.90      0.90      0.90       575\n",
      "\n",
      "    accuracy                           0.91      5750\n",
      "   macro avg       0.91      0.91      0.91      5750\n",
      "weighted avg       0.91      0.91      0.91      5750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation, in the MFCC scenario, did not lead to any improvement! Let's see what happens in the spectrograms scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrograms - Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 9015, shape:(17567,)\n",
      "Max length: 9015, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "transform_recordings >>>\n",
      "transform_recordings <<<\n"
     ]
    }
   ],
   "source": [
    "X, y= data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=max_track_length,\n",
    "                             recordings_source=[False, True])\n",
    "\n",
    "X_train_digit = X[0]\n",
    "y_train_digit = y[0]\n",
    "X_val_digit = X[1]\n",
    "y_val_digit = y[1]\n",
    "X_test_digit = X[2]\n",
    "y_test_digit  = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724 575\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "X, y = data_preparation.balanced_train_val_split(np.concatenate([X_train_digit, X_val_digit]),\n",
    "                         np.concatenate([y_train_digit, y_val_digit]))\n",
    "\n",
    "X_train_digit = X[0]\n",
    "y_train_digit = y[0]\n",
    "X_val_digit = X[1]\n",
    "y_val_digit = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digit, X_val_digit, X_test_digit_mfcc, y_train_digit, y_val_digit, y_test_digit_mfcc, number_mode=True)\n",
    "\n",
    "X_train_digits_spects_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_spects_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_spects_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 127, 17, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 127, 17, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 63, 8, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16128)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                1032256   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,033,450\n",
      "Trainable params: 1,033,258\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 17240 samples, validate on 5750 samples\n",
      "Epoch 1/100\n",
      "17240/17240 [==============================] - 46s 3ms/sample - loss: 1.0789 - accuracy: 0.6415 - val_loss: 0.8444 - val_accuracy: 0.7247\n",
      "Epoch 2/100\n",
      "17240/17240 [==============================] - 38s 2ms/sample - loss: 0.7081 - accuracy: 0.7722 - val_loss: 0.5658 - val_accuracy: 0.8190\n",
      "Epoch 3/100\n",
      "17240/17240 [==============================] - 39s 2ms/sample - loss: 0.5787 - accuracy: 0.8100 - val_loss: 0.5150 - val_accuracy: 0.8343\n",
      "Epoch 4/100\n",
      "17240/17240 [==============================] - 37s 2ms/sample - loss: 0.5119 - accuracy: 0.8382 - val_loss: 0.5074 - val_accuracy: 0.8358\n",
      "Epoch 5/100\n",
      "17240/17240 [==============================] - 46s 3ms/sample - loss: 0.4557 - accuracy: 0.8570 - val_loss: 0.4584 - val_accuracy: 0.8581\n",
      "Epoch 6/100\n",
      "17240/17240 [==============================] - 44s 3ms/sample - loss: 0.4196 - accuracy: 0.8659 - val_loss: 0.4662 - val_accuracy: 0.8506\n",
      "Epoch 7/100\n",
      "17240/17240 [==============================] - 38s 2ms/sample - loss: 0.3996 - accuracy: 0.8729 - val_loss: 0.4415 - val_accuracy: 0.8616\n",
      "Epoch 8/100\n",
      "17240/17240 [==============================] - 41s 2ms/sample - loss: 0.3671 - accuracy: 0.8821 - val_loss: 0.4153 - val_accuracy: 0.8628\n",
      "Epoch 9/100\n",
      "17240/17240 [==============================] - 41s 2ms/sample - loss: 0.3549 - accuracy: 0.8860 - val_loss: 0.9817 - val_accuracy: 0.8134\n",
      "Epoch 10/100\n",
      "17240/17240 [==============================] - 48s 3ms/sample - loss: 0.3359 - accuracy: 0.8921 - val_loss: 0.3993 - val_accuracy: 0.8706\n",
      "Epoch 11/100\n",
      "17240/17240 [==============================] - 40s 2ms/sample - loss: 0.3193 - accuracy: 0.8955 - val_loss: 0.4695 - val_accuracy: 0.8503\n",
      "Epoch 12/100\n",
      "17240/17240 [==============================] - 45s 3ms/sample - loss: 0.2951 - accuracy: 0.9046 - val_loss: 0.3495 - val_accuracy: 0.8864\n",
      "Epoch 13/100\n",
      "17240/17240 [==============================] - 45s 3ms/sample - loss: 0.2664 - accuracy: 0.9141 - val_loss: 0.3427 - val_accuracy: 0.8913\n",
      "Epoch 14/100\n",
      "17240/17240 [==============================] - 40s 2ms/sample - loss: 0.2650 - accuracy: 0.9146 - val_loss: 0.3976 - val_accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "17240/17240 [==============================] - 41s 2ms/sample - loss: 0.2465 - accuracy: 0.9180 - val_loss: 0.3788 - val_accuracy: 0.8784\n",
      "Epoch 16/100\n",
      "17240/17240 [==============================] - 39s 2ms/sample - loss: 0.2340 - accuracy: 0.9253 - val_loss: 0.4158 - val_accuracy: 0.8668\n",
      "Epoch 17/100\n",
      "17240/17240 [==============================] - 39s 2ms/sample - loss: 0.2288 - accuracy: 0.9277 - val_loss: 0.3444 - val_accuracy: 0.8880\n",
      "Epoch 18/100\n",
      "17240/17240 [==============================] - 42s 2ms/sample - loss: 0.2164 - accuracy: 0.9298 - val_loss: 0.3698 - val_accuracy: 0.8837\n",
      "Epoch 19/100\n",
      "17240/17240 [==============================] - 41s 2ms/sample - loss: 0.2032 - accuracy: 0.9338 - val_loss: 0.3686 - val_accuracy: 0.8845\n",
      "Epoch 20/100\n",
      "17240/17240 [==============================] - 36s 2ms/sample - loss: 0.1977 - accuracy: 0.9346 - val_loss: 0.4044 - val_accuracy: 0.8770\n",
      "Epoch 21/100\n",
      "17240/17240 [==============================] - 38s 2ms/sample - loss: 0.1865 - accuracy: 0.9398 - val_loss: 0.3715 - val_accuracy: 0.8837\n",
      "Epoch 22/100\n",
      "17240/17240 [==============================] - 46s 3ms/sample - loss: 0.1744 - accuracy: 0.9429 - val_loss: 0.3510 - val_accuracy: 0.8837\n",
      "Epoch 23/100\n",
      "17240/17240 [==============================] - 39s 2ms/sample - loss: 0.1626 - accuracy: 0.9489 - val_loss: 0.4169 - val_accuracy: 0.8722\n",
      "CPU times: user 26min 11s, sys: 15min 49s, total: 42min\n",
      "Wall time: 15min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80e28e7710>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_digits_spects_nn, y_train_digits_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digits_spects_nn, y_val_digits_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       575\n",
      "           1       0.81      0.94      0.87       575\n",
      "           2       0.93      0.83      0.88       575\n",
      "           3       0.80      0.90      0.85       575\n",
      "           4       0.95      0.87      0.91       575\n",
      "           5       0.88      0.96      0.92       575\n",
      "           6       0.86      0.89      0.87       575\n",
      "           7       0.94      0.83      0.88       575\n",
      "           8       0.86      0.94      0.90       575\n",
      "           9       0.96      0.86      0.91       575\n",
      "\n",
      "    accuracy                           0.89      5750\n",
      "   macro avg       0.90      0.89      0.89      5750\n",
      "weighted avg       0.90      0.89      0.89      5750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digits_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digits_spects_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are worse than the normal scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINO QUI - Best model\n",
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data_preparation.balanced_train_val_test_split(pad_recordings, labels_digits)\n",
    "X_train_digits = X[0]\n",
    "y_train_digits = y[0]\n",
    "X_val_digits = X[1]\n",
    "y_val_digits = y[1] \n",
    "X_test_digits = X[2]\n",
    "y_test_digits = y[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 310 ms, total: 23.2 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_digits])\n",
    "X_val_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_digits])\n",
    "X_test_digits_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_digits])\n",
    "\n",
    "X, y, input_shape, _= data_preparation.prepare_data_nn(X_train_digits_mfcc,\n",
    "                                                       X_val_digits_mfcc,\n",
    "                                                       X_test_digits_mfcc,\n",
    "                                                       y_train_digits,\n",
    "                                                       y_val_digits,\n",
    "                                                       y_test_digits,\n",
    "                                                       number_mode=True)\n",
    "\n",
    "X_train_digits_mfcc_nn = X[0]\n",
    "y_train_digits_nn = y[0]\n",
    "X_val_digits_mfcc_nn = X[1]\n",
    "y_val_digits_nn = y[1]\n",
    "X_test_digits_mfcc_nn = X[2]\n",
    "y_test_digits_nn = y[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digits_best = np.concatenate([X_train_digits_mfcc_nn, X_val_digits_mfcc_nn])\n",
    "y_train_digits_best = np.concatenate([y_train_digits_nn, y_val_digits_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 148,714\n",
      "Trainable params: 148,522\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1910 samples\n",
      "Epoch 1/59\n",
      "1910/1910 [==============================] - 4s 2ms/sample - loss: 1.1927 - accuracy: 0.6225\n",
      "Epoch 2/59\n",
      "1910/1910 [==============================] - 1s 635us/sample - loss: 0.6044 - accuracy: 0.8513\n",
      "Epoch 3/59\n",
      "1910/1910 [==============================] - 1s 675us/sample - loss: 0.4636 - accuracy: 0.8880\n",
      "Epoch 4/59\n",
      "1910/1910 [==============================] - 1s 623us/sample - loss: 0.3888 - accuracy: 0.9099\n",
      "Epoch 5/59\n",
      "1910/1910 [==============================] - 1s 691us/sample - loss: 0.3222 - accuracy: 0.9267\n",
      "Epoch 6/59\n",
      "1910/1910 [==============================] - 1s 622us/sample - loss: 0.2873 - accuracy: 0.9340\n",
      "Epoch 7/59\n",
      "1910/1910 [==============================] - 1s 625us/sample - loss: 0.2444 - accuracy: 0.9529\n",
      "Epoch 8/59\n",
      "1910/1910 [==============================] - 1s 641us/sample - loss: 0.2230 - accuracy: 0.9555\n",
      "Epoch 9/59\n",
      "1910/1910 [==============================] - 1s 711us/sample - loss: 0.1985 - accuracy: 0.9602\n",
      "Epoch 10/59\n",
      "1910/1910 [==============================] - 1s 662us/sample - loss: 0.1803 - accuracy: 0.9654\n",
      "Epoch 11/59\n",
      "1910/1910 [==============================] - 1s 682us/sample - loss: 0.1752 - accuracy: 0.9670\n",
      "Epoch 12/59\n",
      "1910/1910 [==============================] - 1s 618us/sample - loss: 0.1675 - accuracy: 0.9665\n",
      "Epoch 13/59\n",
      "1910/1910 [==============================] - 1s 610us/sample - loss: 0.1548 - accuracy: 0.9702\n",
      "Epoch 14/59\n",
      "1910/1910 [==============================] - 1s 632us/sample - loss: 0.1392 - accuracy: 0.9712\n",
      "Epoch 15/59\n",
      "1910/1910 [==============================] - 1s 616us/sample - loss: 0.1180 - accuracy: 0.9822\n",
      "Epoch 16/59\n",
      "1910/1910 [==============================] - 1s 632us/sample - loss: 0.1154 - accuracy: 0.9827\n",
      "Epoch 17/59\n",
      "1910/1910 [==============================] - 1s 661us/sample - loss: 0.1055 - accuracy: 0.9822\n",
      "Epoch 18/59\n",
      "1910/1910 [==============================] - 1s 735us/sample - loss: 0.1018 - accuracy: 0.9827\n",
      "Epoch 19/59\n",
      "1910/1910 [==============================] - 1s 755us/sample - loss: 0.0990 - accuracy: 0.9843\n",
      "Epoch 20/59\n",
      "1910/1910 [==============================] - 1s 657us/sample - loss: 0.1059 - accuracy: 0.9796\n",
      "Epoch 21/59\n",
      "1910/1910 [==============================] - 1s 612us/sample - loss: 0.0885 - accuracy: 0.9874\n",
      "Epoch 22/59\n",
      "1910/1910 [==============================] - 1s 709us/sample - loss: 0.0861 - accuracy: 0.9880\n",
      "Epoch 23/59\n",
      "1910/1910 [==============================] - 1s 721us/sample - loss: 0.0861 - accuracy: 0.9874\n",
      "Epoch 24/59\n",
      "1910/1910 [==============================] - 1s 693us/sample - loss: 0.0746 - accuracy: 0.9911\n",
      "Epoch 25/59\n",
      "1910/1910 [==============================] - 1s 606us/sample - loss: 0.0841 - accuracy: 0.9859\n",
      "Epoch 26/59\n",
      "1910/1910 [==============================] - 1s 647us/sample - loss: 0.0688 - accuracy: 0.9932\n",
      "Epoch 27/59\n",
      "1910/1910 [==============================] - 1s 676us/sample - loss: 0.0761 - accuracy: 0.9864\n",
      "Epoch 28/59\n",
      "1910/1910 [==============================] - 1s 658us/sample - loss: 0.0635 - accuracy: 0.9916\n",
      "Epoch 29/59\n",
      "1910/1910 [==============================] - 1s 641us/sample - loss: 0.0659 - accuracy: 0.9942\n",
      "Epoch 30/59\n",
      "1910/1910 [==============================] - 1s 665us/sample - loss: 0.0633 - accuracy: 0.9911\n",
      "Epoch 31/59\n",
      "1910/1910 [==============================] - 1s 629us/sample - loss: 0.0559 - accuracy: 0.9911\n",
      "Epoch 32/59\n",
      "1910/1910 [==============================] - 1s 647us/sample - loss: 0.0582 - accuracy: 0.9932\n",
      "Epoch 33/59\n",
      "1910/1910 [==============================] - 1s 661us/sample - loss: 0.0645 - accuracy: 0.9921\n",
      "Epoch 34/59\n",
      "1910/1910 [==============================] - 1s 642us/sample - loss: 0.0558 - accuracy: 0.9937\n",
      "Epoch 35/59\n",
      "1910/1910 [==============================] - 1s 668us/sample - loss: 0.0578 - accuracy: 0.9932\n",
      "Epoch 36/59\n",
      "1910/1910 [==============================] - 1s 648us/sample - loss: 0.0494 - accuracy: 0.9948\n",
      "Epoch 37/59\n",
      "1910/1910 [==============================] - 1s 690us/sample - loss: 0.0543 - accuracy: 0.9932\n",
      "Epoch 38/59\n",
      "1910/1910 [==============================] - 1s 667us/sample - loss: 0.0510 - accuracy: 0.9906\n",
      "Epoch 39/59\n",
      "1910/1910 [==============================] - 1s 681us/sample - loss: 0.0517 - accuracy: 0.9937\n",
      "Epoch 40/59\n",
      "1910/1910 [==============================] - 1s 597us/sample - loss: 0.0553 - accuracy: 0.9895\n",
      "Epoch 41/59\n",
      "1910/1910 [==============================] - 1s 622us/sample - loss: 0.0433 - accuracy: 0.9963\n",
      "Epoch 42/59\n",
      "1910/1910 [==============================] - 1s 593us/sample - loss: 0.0453 - accuracy: 0.9953\n",
      "Epoch 43/59\n",
      "1910/1910 [==============================] - 1s 712us/sample - loss: 0.0438 - accuracy: 0.9948\n",
      "Epoch 44/59\n",
      "1910/1910 [==============================] - 1s 732us/sample - loss: 0.0444 - accuracy: 0.9953\n",
      "Epoch 45/59\n",
      "1910/1910 [==============================] - 1s 683us/sample - loss: 0.0408 - accuracy: 0.9958\n",
      "Epoch 46/59\n",
      "1910/1910 [==============================] - 1s 661us/sample - loss: 0.0394 - accuracy: 0.9958\n",
      "Epoch 47/59\n",
      "1910/1910 [==============================] - 1s 651us/sample - loss: 0.0328 - accuracy: 0.9990\n",
      "Epoch 48/59\n",
      "1910/1910 [==============================] - 1s 610us/sample - loss: 0.0358 - accuracy: 0.9958\n",
      "Epoch 49/59\n",
      "1910/1910 [==============================] - 1s 595us/sample - loss: 0.0428 - accuracy: 0.9937\n",
      "Epoch 50/59\n",
      "1910/1910 [==============================] - 1s 624us/sample - loss: 0.0375 - accuracy: 0.9969\n",
      "Epoch 51/59\n",
      "1910/1910 [==============================] - 1s 761us/sample - loss: 0.0312 - accuracy: 0.9984\n",
      "Epoch 52/59\n",
      "1910/1910 [==============================] - 1s 637us/sample - loss: 0.0391 - accuracy: 0.9958\n",
      "Epoch 53/59\n",
      "1910/1910 [==============================] - 1s 656us/sample - loss: 0.0382 - accuracy: 0.9953\n",
      "Epoch 54/59\n",
      "1910/1910 [==============================] - 1s 756us/sample - loss: 0.0310 - accuracy: 0.9984\n",
      "Epoch 55/59\n",
      "1910/1910 [==============================] - 1s 686us/sample - loss: 0.0344 - accuracy: 0.9963\n",
      "Epoch 56/59\n",
      "1910/1910 [==============================] - 1s 643us/sample - loss: 0.0347 - accuracy: 0.9974\n",
      "Epoch 57/59\n",
      "1910/1910 [==============================] - 1s 700us/sample - loss: 0.0372 - accuracy: 0.9953\n",
      "Epoch 58/59\n",
      "1910/1910 [==============================] - 1s 622us/sample - loss: 0.0307 - accuracy: 0.9984\n",
      "Epoch 59/59\n",
      "1910/1910 [==============================] - 1s 688us/sample - loss: 0.0317 - accuracy: 0.9974\n",
      "CPU times: user 1min 32s, sys: 28.4 s, total: 2min 1s\n",
      "Wall time: 1min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f808af987d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape,\n",
    "                                num_classes=10,\n",
    "                                batch_normalisation=True)\n",
    "model.fit(X_train_digits_best, y_train_digits_best,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=59,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nn = np.argmax(y_test_digits_nn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test_digits_mfcc_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        49\n",
      "           1       1.00      0.98      0.99        49\n",
      "           2       1.00      0.98      0.99        49\n",
      "           3       0.91      0.98      0.94        49\n",
      "           4       0.96      0.98      0.97        49\n",
      "           5       0.98      0.98      0.98        49\n",
      "           6       1.00      0.92      0.96        49\n",
      "           7       0.96      0.94      0.95        48\n",
      "           8       0.96      1.00      0.98        49\n",
      "           9       1.00      0.96      0.98        48\n",
      "\n",
      "    accuracy                           0.97       488\n",
      "   macro avg       0.97      0.97      0.97       488\n",
      "weighted avg       0.97      0.97      0.97       488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/digits.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speakers\n",
    "## Std - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 s, sys: 626 ms, total: 25.6 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.2 ms, sys: 7.11 ms, total: 24.3 ms\n",
      "Wall time: 27.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scaler_normal = StandardScaler()\n",
    "X_train_speakers_mfcc = scaler_normal.fit_transform(X_train_speakers_mfcc)\n",
    "X_val_speakers_mfcc =  scaler_normal.transform(X_val_speakers_mfcc)\n",
    "X_test_speakers_mfcc =  scaler_normal.transform(X_test_speakers_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_speakers_mfcc, y_train_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.95      0.97        20\n",
      "      alinda       1.00      0.95      0.97        20\n",
      "        gian       0.95      1.00      0.98        20\n",
      "     jackson       1.00      0.90      0.95        20\n",
      "      khaled       0.87      1.00      0.93        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       1.00      0.90      0.95        20\n",
      "    yweweler       0.91      1.00      0.95        20\n",
      "\n",
      "    accuracy                           0.96       160\n",
      "   macro avg       0.97      0.96      0.96       160\n",
      "weighted avg       0.97      0.96      0.96       160\n",
      "\n",
      "CPU times: user 33.8 ms, sys: 2.87 ms, total: 36.6 ms\n",
      "Wall time: 38.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_speakers_mfcc)\n",
    "print(classification_report(y_val_speakers, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.8 s, sys: 370 ms, total: 24.2 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 ms, sys: 3.83 ms, total: 15 ms\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc_nn, X_val_speakers_mfcc_nn, X_test_speakers_mfcc_nn, y_train_speakers_nn, y_val_speakers_nn, y_test_speakers_nn, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speakers_mfcc, X_val_speakers_mfcc, X_test_speakers_mfcc, y_train_speakers, y_val_speakers, y_test_speakers, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 148,584\n",
      "Trainable params: 148,392\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 2s 5ms/sample - loss: 1.9556 - accuracy: 0.3333 - val_loss: 5.3545 - val_accuracy: 0.3250\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 0s 844us/sample - loss: 1.0895 - accuracy: 0.6104 - val_loss: 3.5714 - val_accuracy: 0.3688\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 0s 995us/sample - loss: 0.9266 - accuracy: 0.6729 - val_loss: 2.0045 - val_accuracy: 0.5063\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 0s 928us/sample - loss: 0.7334 - accuracy: 0.7458 - val_loss: 1.6438 - val_accuracy: 0.5375\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 0s 979us/sample - loss: 0.6831 - accuracy: 0.7667 - val_loss: 1.1740 - val_accuracy: 0.6187\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 0s 917us/sample - loss: 0.5740 - accuracy: 0.8188 - val_loss: 0.5884 - val_accuracy: 0.8125\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 0s 997us/sample - loss: 0.5184 - accuracy: 0.8271 - val_loss: 0.7290 - val_accuracy: 0.7312\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 0s 913us/sample - loss: 0.4219 - accuracy: 0.8625 - val_loss: 0.6018 - val_accuracy: 0.7625\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.3563 - accuracy: 0.9021 - val_loss: 0.4525 - val_accuracy: 0.8813\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.3381 - accuracy: 0.9083 - val_loss: 0.5172 - val_accuracy: 0.8562\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.3400 - accuracy: 0.9208 - val_loss: 0.5211 - val_accuracy: 0.8188\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 0s 852us/sample - loss: 0.3069 - accuracy: 0.9312 - val_loss: 0.3732 - val_accuracy: 0.9000\n",
      "Epoch 13/50\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.2724 - accuracy: 0.9354 - val_loss: 0.3547 - val_accuracy: 0.9312\n",
      "Epoch 14/50\n",
      "480/480 [==============================] - 0s 919us/sample - loss: 0.2586 - accuracy: 0.9438 - val_loss: 0.3148 - val_accuracy: 0.9187\n",
      "Epoch 15/50\n",
      "480/480 [==============================] - 0s 969us/sample - loss: 0.2569 - accuracy: 0.9354 - val_loss: 0.2698 - val_accuracy: 0.9500\n",
      "Epoch 16/50\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.2350 - accuracy: 0.9500 - val_loss: 0.2488 - val_accuracy: 0.9500\n",
      "Epoch 17/50\n",
      "480/480 [==============================] - 0s 902us/sample - loss: 0.2127 - accuracy: 0.9521 - val_loss: 0.2970 - val_accuracy: 0.9125\n",
      "Epoch 18/50\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.2097 - accuracy: 0.9563 - val_loss: 0.2208 - val_accuracy: 0.9563\n",
      "Epoch 19/50\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.2082 - accuracy: 0.9604 - val_loss: 0.2622 - val_accuracy: 0.9000\n",
      "Epoch 20/50\n",
      "480/480 [==============================] - 0s 866us/sample - loss: 0.1772 - accuracy: 0.9688 - val_loss: 0.2053 - val_accuracy: 0.9500\n",
      "Epoch 21/50\n",
      "480/480 [==============================] - 0s 1ms/sample - loss: 0.1686 - accuracy: 0.9729 - val_loss: 0.1780 - val_accuracy: 0.9688\n",
      "Epoch 22/50\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.1753 - accuracy: 0.9646 - val_loss: 0.2414 - val_accuracy: 0.9312\n",
      "Epoch 23/50\n",
      "480/480 [==============================] - 0s 931us/sample - loss: 0.1762 - accuracy: 0.9625 - val_loss: 0.1912 - val_accuracy: 0.9688\n",
      "Epoch 24/50\n",
      "480/480 [==============================] - 0s 979us/sample - loss: 0.1437 - accuracy: 0.9792 - val_loss: 0.1813 - val_accuracy: 0.9438\n",
      "Epoch 25/50\n",
      "480/480 [==============================] - 0s 927us/sample - loss: 0.1689 - accuracy: 0.9750 - val_loss: 0.2090 - val_accuracy: 0.9375\n",
      "Epoch 26/50\n",
      "480/480 [==============================] - 1s 1ms/sample - loss: 0.1440 - accuracy: 0.9771 - val_loss: 0.2602 - val_accuracy: 0.9062\n",
      "CPU times: user 16.9 s, sys: 5.45 s, total: 22.3 s\n",
      "Wall time: 15.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9f47a3650>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)\n",
    "model.fit(X_train_speakers_mfcc_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "         callbacks=[callback],\n",
    "         validation_data=(X_val_speakers_mfcc_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get full performances on val set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      1.00      1.00        20\n",
      "      alinda       0.95      0.95      0.95        20\n",
      "        gian       0.95      1.00      0.98        20\n",
      "     jackson       1.00      0.95      0.97        20\n",
      "      khaled       1.00      1.00      1.00        20\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       1.00      0.85      0.92        20\n",
      "    yweweler       0.87      1.00      0.93        20\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.97      0.97      0.97       160\n",
      "weighted avg       0.97      0.97      0.97       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent performances! Let's now see what happens with spectrograms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Std - Spects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 417 ms, total: 20.4 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_train_speakers])\n",
    "X_val_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_val_speakers])\n",
    "X_test_speakers_spects = np.array([data_preparation.compute_spectrogram(x, normalize=True) for x in X_test_speakers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speakers_spects.shape\n",
    "X_train_speakers_spects_2d = X_train_speakers_spects.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_speakers_spects.shape\n",
    "X_val_speakers_spects_2d = X_val_speakers_spects.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_test_speakers_spects.shape\n",
    "X_test_speakers_spects_2d = X_test_speakers_spects.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf = clf.fit(X_train_speakers_spects_2d, y_train_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      0.90      0.92        20\n",
      "      alinda       1.00      0.95      0.97        20\n",
      "        gian       0.95      1.00      0.98        20\n",
      "     jackson       1.00      0.95      0.97        20\n",
      "      khaled       1.00      0.95      0.97        20\n",
      "     nicolas       0.95      1.00      0.98        20\n",
      "        theo       0.77      1.00      0.87        20\n",
      "    yweweler       1.00      0.80      0.89        20\n",
      "\n",
      "    accuracy                           0.94       160\n",
      "   macro avg       0.95      0.94      0.94       160\n",
      "weighted avg       0.95      0.94      0.94       160\n",
      "\n",
      "CPU times: user 591 ms, sys: 14.7 ms, total: 606 ms\n",
      "Wall time: 676 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf.predict(X_val_speakers_spects_2d)\n",
    "print(classification_report(y_val_speakers, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performances are good but not at the level of MFCC: let's use the three different CNN architectures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speakers_spects_nn, X_val_speakers_spects_nn, X_test_speakers_spects_nn, y_train_speakers_nn, y_val_speakers_nn, y_test_speakers_nn, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speakers_spects, X_val_speakers_spects, X_test_speakers_spects, y_train_speakers, y_val_speakers, y_test_speakers, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 67,744\n",
      "Trainable params: 67,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 2.1125 - accuracy: 0.1187 - val_loss: 2.0614 - val_accuracy: 0.1688\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0669 - accuracy: 0.1458 - val_loss: 2.0352 - val_accuracy: 0.1437\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0321 - accuracy: 0.1646 - val_loss: 2.0196 - val_accuracy: 0.1562\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0311 - accuracy: 0.1500 - val_loss: 2.0021 - val_accuracy: 0.2188\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0325 - accuracy: 0.1604 - val_loss: 1.9872 - val_accuracy: 0.2438\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 2.0097 - accuracy: 0.1958 - val_loss: 1.9683 - val_accuracy: 0.2812\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.9760 - accuracy: 0.2188 - val_loss: 1.9415 - val_accuracy: 0.3063\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.9532 - accuracy: 0.2500 - val_loss: 1.9073 - val_accuracy: 0.3375\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 1.9309 - accuracy: 0.2417 - val_loss: 1.8873 - val_accuracy: 0.4000\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.8984 - accuracy: 0.2896 - val_loss: 1.8208 - val_accuracy: 0.4000\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 1.8863 - accuracy: 0.2792 - val_loss: 1.7851 - val_accuracy: 0.4688\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.8446 - accuracy: 0.2917 - val_loss: 1.7446 - val_accuracy: 0.4250\n",
      "Epoch 13/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7960 - accuracy: 0.3083 - val_loss: 1.6909 - val_accuracy: 0.5250\n",
      "Epoch 14/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.7718 - accuracy: 0.3646 - val_loss: 1.6483 - val_accuracy: 0.4750\n",
      "Epoch 15/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7680 - accuracy: 0.3146 - val_loss: 1.6208 - val_accuracy: 0.5125\n",
      "Epoch 16/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.7116 - accuracy: 0.3292 - val_loss: 1.5453 - val_accuracy: 0.5250\n",
      "Epoch 17/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.6402 - accuracy: 0.3854 - val_loss: 1.4922 - val_accuracy: 0.5625\n",
      "Epoch 18/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.6330 - accuracy: 0.3875 - val_loss: 1.4357 - val_accuracy: 0.6000\n",
      "Epoch 19/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5573 - accuracy: 0.4062 - val_loss: 1.4000 - val_accuracy: 0.5063\n",
      "Epoch 20/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5654 - accuracy: 0.4333 - val_loss: 1.3335 - val_accuracy: 0.6187\n",
      "Epoch 21/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.4974 - accuracy: 0.4542 - val_loss: 1.2928 - val_accuracy: 0.6438\n",
      "Epoch 22/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.4624 - accuracy: 0.4812 - val_loss: 1.3418 - val_accuracy: 0.5562\n",
      "Epoch 23/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3885 - accuracy: 0.4854 - val_loss: 1.1781 - val_accuracy: 0.6875\n",
      "Epoch 24/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3692 - accuracy: 0.4729 - val_loss: 1.1505 - val_accuracy: 0.6812\n",
      "Epoch 25/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.3586 - accuracy: 0.5021 - val_loss: 1.1476 - val_accuracy: 0.6938\n",
      "Epoch 26/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.2679 - accuracy: 0.5333 - val_loss: 1.2549 - val_accuracy: 0.5938\n",
      "Epoch 27/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.2969 - accuracy: 0.5354 - val_loss: 1.0054 - val_accuracy: 0.7375\n",
      "Epoch 28/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.2495 - accuracy: 0.5125 - val_loss: 0.9599 - val_accuracy: 0.7625\n",
      "Epoch 29/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1536 - accuracy: 0.5917 - val_loss: 0.9027 - val_accuracy: 0.7437\n",
      "Epoch 30/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1294 - accuracy: 0.5813 - val_loss: 0.8910 - val_accuracy: 0.7688\n",
      "Epoch 31/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.1319 - accuracy: 0.6167 - val_loss: 0.9664 - val_accuracy: 0.7188\n",
      "Epoch 32/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0419 - accuracy: 0.6250 - val_loss: 0.7854 - val_accuracy: 0.7875\n",
      "Epoch 33/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0914 - accuracy: 0.6271 - val_loss: 0.8277 - val_accuracy: 0.7500\n",
      "Epoch 34/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0318 - accuracy: 0.6250 - val_loss: 0.7599 - val_accuracy: 0.8125\n",
      "Epoch 35/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9659 - accuracy: 0.6458 - val_loss: 0.8986 - val_accuracy: 0.6938\n",
      "Epoch 36/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.0185 - accuracy: 0.6271 - val_loss: 0.8152 - val_accuracy: 0.7312\n",
      "Epoch 37/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9417 - accuracy: 0.6521 - val_loss: 0.6764 - val_accuracy: 0.8188\n",
      "Epoch 38/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9359 - accuracy: 0.6604 - val_loss: 0.6777 - val_accuracy: 0.8125\n",
      "Epoch 39/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8931 - accuracy: 0.6938 - val_loss: 0.6663 - val_accuracy: 0.8438\n",
      "Epoch 40/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8598 - accuracy: 0.6917 - val_loss: 0.8966 - val_accuracy: 0.7437\n",
      "Epoch 41/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.8295 - accuracy: 0.7000 - val_loss: 0.5652 - val_accuracy: 0.8375\n",
      "Epoch 42/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.7908 - accuracy: 0.7208 - val_loss: 0.6381 - val_accuracy: 0.7875\n",
      "Epoch 43/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7836 - accuracy: 0.7063 - val_loss: 0.5835 - val_accuracy: 0.8375\n",
      "Epoch 44/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.6953 - accuracy: 0.7625 - val_loss: 0.5358 - val_accuracy: 0.8500\n",
      "Epoch 45/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7026 - accuracy: 0.7500 - val_loss: 0.5321 - val_accuracy: 0.8375\n",
      "Epoch 46/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7396 - accuracy: 0.7479 - val_loss: 0.5225 - val_accuracy: 0.8687\n",
      "Epoch 47/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.7175 - accuracy: 0.7458 - val_loss: 0.4833 - val_accuracy: 0.8562\n",
      "Epoch 48/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.6790 - accuracy: 0.7250 - val_loss: 0.5337 - val_accuracy: 0.8500\n",
      "Epoch 49/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.6274 - accuracy: 0.7958 - val_loss: 0.4928 - val_accuracy: 0.8188\n",
      "Epoch 50/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.6397 - accuracy: 0.7750 - val_loss: 0.4567 - val_accuracy: 0.8438\n",
      "CPU times: user 1min 29s, sys: 37.2 s, total: 2min 6s\n",
      "Wall time: 1min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9ef63ec90>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      1.00      0.97        19\n",
      "      alinda       1.00      0.87      0.93        23\n",
      "        gian       0.80      0.94      0.86        17\n",
      "     jackson       0.90      0.75      0.82        24\n",
      "      khaled       0.70      1.00      0.82        14\n",
      "     nicolas       0.85      0.81      0.83        21\n",
      "        theo       0.60      1.00      0.75        12\n",
      "    yweweler       0.95      0.63      0.76        30\n",
      "\n",
      "    accuracy                           0.84       160\n",
      "   macro avg       0.84      0.88      0.84       160\n",
      "weighted avg       0.87      0.84      0.84       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with the Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 5s 10ms/sample - loss: 2.3782 - accuracy: 0.1771 - val_loss: 2.0621 - val_accuracy: 0.1562\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.7357 - accuracy: 0.3729 - val_loss: 2.0303 - val_accuracy: 0.1750\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 1.5230 - accuracy: 0.4187 - val_loss: 1.9694 - val_accuracy: 0.2250\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.3219 - accuracy: 0.5167 - val_loss: 1.9572 - val_accuracy: 0.2562\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 1.1578 - accuracy: 0.6000 - val_loss: 1.9562 - val_accuracy: 0.2937\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.9723 - accuracy: 0.6708 - val_loss: 1.9634 - val_accuracy: 0.2500\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.9074 - accuracy: 0.6896 - val_loss: 1.9640 - val_accuracy: 0.2625\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.8274 - accuracy: 0.7271 - val_loss: 1.9662 - val_accuracy: 0.2500\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.8055 - accuracy: 0.7312 - val_loss: 1.9455 - val_accuracy: 0.2562\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.7403 - accuracy: 0.7771 - val_loss: 1.9981 - val_accuracy: 0.2500\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.6382 - accuracy: 0.8375 - val_loss: 2.0018 - val_accuracy: 0.2500\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.5917 - accuracy: 0.8438 - val_loss: 2.0372 - val_accuracy: 0.2500\n",
      "Epoch 13/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.5746 - accuracy: 0.8521 - val_loss: 1.9303 - val_accuracy: 0.2500\n",
      "Epoch 14/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.5619 - accuracy: 0.8354 - val_loss: 1.9522 - val_accuracy: 0.2562\n",
      "Epoch 15/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.5266 - accuracy: 0.8687 - val_loss: 1.9246 - val_accuracy: 0.2500\n",
      "Epoch 16/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.4498 - accuracy: 0.8875 - val_loss: 1.9498 - val_accuracy: 0.2937\n",
      "Epoch 17/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.4510 - accuracy: 0.8917 - val_loss: 1.8528 - val_accuracy: 0.3063\n",
      "Epoch 18/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.4112 - accuracy: 0.9083 - val_loss: 1.7841 - val_accuracy: 0.2688\n",
      "Epoch 19/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.4142 - accuracy: 0.9187 - val_loss: 1.7099 - val_accuracy: 0.2500\n",
      "Epoch 20/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.4171 - accuracy: 0.9021 - val_loss: 1.6827 - val_accuracy: 0.2688\n",
      "Epoch 21/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.4042 - accuracy: 0.8792 - val_loss: 1.6238 - val_accuracy: 0.3187\n",
      "Epoch 22/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.3721 - accuracy: 0.9167 - val_loss: 1.5611 - val_accuracy: 0.3375\n",
      "Epoch 23/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.3183 - accuracy: 0.9438 - val_loss: 1.4549 - val_accuracy: 0.3562\n",
      "Epoch 24/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.3170 - accuracy: 0.9438 - val_loss: 1.3801 - val_accuracy: 0.3812\n",
      "Epoch 25/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.3219 - accuracy: 0.9333 - val_loss: 1.1963 - val_accuracy: 0.4437\n",
      "Epoch 26/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.2963 - accuracy: 0.9229 - val_loss: 1.1566 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.2945 - accuracy: 0.9375 - val_loss: 0.9071 - val_accuracy: 0.6562\n",
      "Epoch 28/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.2711 - accuracy: 0.9354 - val_loss: 0.9683 - val_accuracy: 0.6000\n",
      "Epoch 29/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.2470 - accuracy: 0.9500 - val_loss: 1.1192 - val_accuracy: 0.5125\n",
      "Epoch 30/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.2799 - accuracy: 0.9458 - val_loss: 0.7635 - val_accuracy: 0.7312\n",
      "Epoch 31/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.2427 - accuracy: 0.9646 - val_loss: 0.6783 - val_accuracy: 0.7750\n",
      "Epoch 32/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.2448 - accuracy: 0.9500 - val_loss: 0.7021 - val_accuracy: 0.7750\n",
      "Epoch 33/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2500 - accuracy: 0.9438 - val_loss: 0.5907 - val_accuracy: 0.8375\n",
      "Epoch 34/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.2200 - accuracy: 0.9625 - val_loss: 0.5492 - val_accuracy: 0.8250\n",
      "Epoch 35/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.2272 - accuracy: 0.9542 - val_loss: 0.6248 - val_accuracy: 0.8062\n",
      "Epoch 36/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.2250 - accuracy: 0.9646 - val_loss: 0.2796 - val_accuracy: 0.9625\n",
      "Epoch 37/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.2422 - accuracy: 0.9479 - val_loss: 0.3036 - val_accuracy: 0.9500\n",
      "Epoch 38/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1850 - accuracy: 0.9854 - val_loss: 0.2299 - val_accuracy: 0.9812\n",
      "Epoch 39/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.1651 - accuracy: 0.9771 - val_loss: 0.2466 - val_accuracy: 0.9625\n",
      "Epoch 40/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.2071 - accuracy: 0.9646 - val_loss: 0.2219 - val_accuracy: 0.9812\n",
      "Epoch 41/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1780 - accuracy: 0.9646 - val_loss: 0.2270 - val_accuracy: 0.9688\n",
      "Epoch 42/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1901 - accuracy: 0.9729 - val_loss: 0.1915 - val_accuracy: 0.9750\n",
      "Epoch 43/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1713 - accuracy: 0.9625 - val_loss: 0.2023 - val_accuracy: 0.9625\n",
      "Epoch 44/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1724 - accuracy: 0.9750 - val_loss: 0.2169 - val_accuracy: 0.9625\n",
      "Epoch 45/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1519 - accuracy: 0.9792 - val_loss: 0.2105 - val_accuracy: 0.9812\n",
      "Epoch 46/50\n",
      "480/480 [==============================] - 2s 4ms/sample - loss: 0.1333 - accuracy: 0.9812 - val_loss: 0.1608 - val_accuracy: 0.9812\n",
      "Epoch 47/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1510 - accuracy: 0.9792 - val_loss: 0.1760 - val_accuracy: 0.9750\n",
      "Epoch 48/50\n",
      "480/480 [==============================] - 1s 3ms/sample - loss: 0.1380 - accuracy: 0.9896 - val_loss: 0.1722 - val_accuracy: 0.9750\n",
      "Epoch 49/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.1306 - accuracy: 0.9833 - val_loss: 0.1614 - val_accuracy: 0.9625\n",
      "Epoch 50/50\n",
      "480/480 [==============================] - 2s 3ms/sample - loss: 0.1376 - accuracy: 0.9792 - val_loss: 0.1370 - val_accuracy: 0.9688\n",
      "CPU times: user 1min 41s, sys: 44.4 s, total: 2min 25s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9fffa9390>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      1.00      1.00        20\n",
      "      alinda       1.00      1.00      1.00        20\n",
      "        gian       0.95      0.90      0.93        21\n",
      "     jackson       0.95      1.00      0.97        19\n",
      "      khaled       0.95      1.00      0.97        19\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       0.95      0.95      0.95        20\n",
      "    yweweler       0.95      0.90      0.93        21\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.97      0.97      0.97       160\n",
      "weighted avg       0.97      0.97      0.97       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 127, 56, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 127, 56, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 63, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                3612736   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 3,613,800\n",
      "Trainable params: 3,613,608\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 160 samples\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 6s 12ms/sample - loss: 1.4323 - accuracy: 0.5542 - val_loss: 1.3593 - val_accuracy: 0.4938\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.6567 - accuracy: 0.7833 - val_loss: 1.3085 - val_accuracy: 0.7000\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.4503 - accuracy: 0.8583 - val_loss: 1.2954 - val_accuracy: 0.7437\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.3527 - accuracy: 0.8917 - val_loss: 1.3069 - val_accuracy: 0.6938\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.2675 - accuracy: 0.9312 - val_loss: 1.3454 - val_accuracy: 0.6687\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.2456 - accuracy: 0.9438 - val_loss: 1.3477 - val_accuracy: 0.6062\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 4s 7ms/sample - loss: 0.2162 - accuracy: 0.9625 - val_loss: 1.2676 - val_accuracy: 0.6687\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.1815 - accuracy: 0.9729 - val_loss: 1.2732 - val_accuracy: 0.6000\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.1401 - accuracy: 0.9812 - val_loss: 1.2226 - val_accuracy: 0.6062\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.1247 - accuracy: 0.9854 - val_loss: 1.1680 - val_accuracy: 0.6750\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.1127 - accuracy: 0.9896 - val_loss: 1.1069 - val_accuracy: 0.7812\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.1157 - accuracy: 0.9833 - val_loss: 1.0303 - val_accuracy: 0.7750\n",
      "Epoch 13/50\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.1159 - accuracy: 0.9833 - val_loss: 1.0011 - val_accuracy: 0.8188\n",
      "Epoch 14/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.1068 - accuracy: 0.9917 - val_loss: 0.8527 - val_accuracy: 0.8813\n",
      "Epoch 15/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.1020 - accuracy: 0.9896 - val_loss: 0.7939 - val_accuracy: 0.9062\n",
      "Epoch 16/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0850 - accuracy: 0.9896 - val_loss: 0.7598 - val_accuracy: 0.9187\n",
      "Epoch 17/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0976 - accuracy: 0.9917 - val_loss: 0.7054 - val_accuracy: 0.9312\n",
      "Epoch 18/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0828 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.9438\n",
      "Epoch 19/50\n",
      "480/480 [==============================] - 4s 7ms/sample - loss: 0.0778 - accuracy: 0.9958 - val_loss: 0.5738 - val_accuracy: 0.9563\n",
      "Epoch 20/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0893 - accuracy: 0.9896 - val_loss: 0.5093 - val_accuracy: 0.9625\n",
      "Epoch 21/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0872 - accuracy: 0.9854 - val_loss: 0.4214 - val_accuracy: 0.9563\n",
      "Epoch 22/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0672 - accuracy: 0.9958 - val_loss: 0.3964 - val_accuracy: 0.9500\n",
      "Epoch 23/50\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.0751 - accuracy: 0.9937 - val_loss: 0.3482 - val_accuracy: 0.9438\n",
      "Epoch 24/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0634 - accuracy: 0.9958 - val_loss: 0.3544 - val_accuracy: 0.9563\n",
      "Epoch 25/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9563\n",
      "Epoch 26/50\n",
      "480/480 [==============================] - 4s 9ms/sample - loss: 0.0594 - accuracy: 0.9979 - val_loss: 0.2794 - val_accuracy: 0.9688\n",
      "Epoch 27/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0607 - accuracy: 0.9937 - val_loss: 0.2540 - val_accuracy: 0.9625\n",
      "Epoch 28/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0554 - accuracy: 0.9958 - val_loss: 0.2446 - val_accuracy: 0.9625\n",
      "Epoch 29/50\n",
      "480/480 [==============================] - 4s 7ms/sample - loss: 0.0573 - accuracy: 0.9958 - val_loss: 0.2250 - val_accuracy: 0.9750\n",
      "Epoch 30/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0548 - accuracy: 0.9979 - val_loss: 0.1974 - val_accuracy: 0.9688\n",
      "Epoch 31/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0637 - accuracy: 0.9958 - val_loss: 0.1908 - val_accuracy: 0.9688\n",
      "Epoch 32/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0599 - accuracy: 0.9917 - val_loss: 0.1784 - val_accuracy: 0.9688\n",
      "Epoch 33/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0400 - accuracy: 0.9979 - val_loss: 0.1678 - val_accuracy: 0.9688\n",
      "Epoch 34/50\n",
      "480/480 [==============================] - 4s 8ms/sample - loss: 0.0508 - accuracy: 0.9958 - val_loss: 0.1559 - val_accuracy: 0.9750\n",
      "Epoch 35/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0432 - accuracy: 0.9979 - val_loss: 0.1464 - val_accuracy: 0.9688\n",
      "Epoch 36/50\n",
      "480/480 [==============================] - 3s 7ms/sample - loss: 0.0535 - accuracy: 0.9979 - val_loss: 0.1450 - val_accuracy: 0.9812\n",
      "Epoch 37/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0538 - accuracy: 0.9979 - val_loss: 0.1428 - val_accuracy: 0.9563\n",
      "Epoch 38/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0427 - accuracy: 0.9979 - val_loss: 0.1284 - val_accuracy: 0.9688\n",
      "Epoch 39/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9750\n",
      "Epoch 40/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9750\n",
      "Epoch 41/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0434 - accuracy: 0.9958 - val_loss: 0.1206 - val_accuracy: 0.9625\n",
      "Epoch 42/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9750\n",
      "Epoch 43/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9625\n",
      "Epoch 44/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0390 - accuracy: 0.9979 - val_loss: 0.1094 - val_accuracy: 0.9688\n",
      "Epoch 45/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9812\n",
      "Epoch 46/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0362 - accuracy: 0.9979 - val_loss: 0.1098 - val_accuracy: 0.9812\n",
      "Epoch 47/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0358 - accuracy: 0.9979 - val_loss: 0.1083 - val_accuracy: 0.9812\n",
      "Epoch 48/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9750\n",
      "Epoch 49/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9750\n",
      "Epoch 50/50\n",
      "480/480 [==============================] - 3s 6ms/sample - loss: 0.0275 - accuracy: 0.9979 - val_loss: 0.1125 - val_accuracy: 0.9750\n",
      "CPU times: user 5min 28s, sys: 1min, total: 6min 29s\n",
      "Wall time: 2min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa20cde490>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speakers_spects_nn, y_train_speakers_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speakers_spects_nn, y_val_speakers_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      1.00      1.00        20\n",
      "      alinda       1.00      0.95      0.98        21\n",
      "        gian       1.00      0.95      0.98        21\n",
      "     jackson       0.95      1.00      0.97        19\n",
      "      khaled       0.95      1.00      0.97        19\n",
      "     nicolas       1.00      1.00      1.00        20\n",
      "        theo       0.95      1.00      0.97        19\n",
      "    yweweler       0.95      0.90      0.93        21\n",
      "\n",
      "    accuracy                           0.97       160\n",
      "   macro avg       0.97      0.98      0.98       160\n",
      "weighted avg       0.98      0.97      0.97       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speakers_spects_nn)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "transform_recordings >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "transform_recordings <<<\n",
      "CPU times: user 2min 28s, sys: 6.24 s, total: 2min 34s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(\n",
    "    audio_dirs= [our_recs_dir, fsdd_dir],\n",
    "    y_type= ['speakers_us', 'speakers_default'],\n",
    "    n_category_test=30,\n",
    "    include_pitch=False,\n",
    "    max_length=17000,\n",
    "    transform_function=\"mfcc\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 193\n",
      "ale\n",
      "alinda\n",
      "gian\n",
      "jackson\n",
      "khaled\n",
      "nicolas\n",
      "theo\n",
      "yweweler\n",
      "CPU times: user 35.4 ms, sys: 19.7 ms, total: 55.1 ms\n",
      "Wall time: 52.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker = data_preparation.balanced_train_val_split(np.concatenate([X_train_speaker, X_val_speaker]),\n",
    "                         np.concatenate([y_train_speaker, y_val_speaker]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4616, 20, 18)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_speaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal = StandardScaler()\n",
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_scaled = scaler_normal.fit_transform(X_train_speaker.reshape((nsamples, nx * ny)))\n",
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_scaled =  scaler_normal.transform(X_val_speaker.reshape((nsamples, nx * ny)))\n",
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_scaled =  scaler_normal.transform(X_test_speaker.reshape((nsamples, nx * ny)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.18 s, sys: 96.3 ms, total: 6.28 s\n",
      "Wall time: 7.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker_normal.fit(X_train_speaker_scaled, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.93      0.95      0.94       189\n",
      "      alinda       0.95      0.96      0.96       191\n",
      "        gian       0.95      0.98      0.97       188\n",
      "     jackson       0.91      0.98      0.95       179\n",
      "      khaled       0.99      0.83      0.90       231\n",
      "     nicolas       0.95      0.96      0.96       191\n",
      "        theo       0.78      0.82      0.80       184\n",
      "    yweweler       0.81      0.82      0.81       191\n",
      "\n",
      "    accuracy                           0.91      1544\n",
      "   macro avg       0.91      0.91      0.91      1544\n",
      "weighted avg       0.91      0.91      0.91      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_speaker_normal.predict(X_val_speaker_scaled)\n",
    "print(classification_report(y_pred, y_val_speaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker_nn, X_val_speaker_nn, X_test_speaker, y_train_speaker_nn, y_val_speaker_nn, y_test_speaker_nn, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speaker, X_val_speaker, X_test_speaker, y_train_speaker, y_val_speaker, y_test_speaker, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 19, 17, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 19, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 9, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 148,584\n",
      "Trainable params: 148,392\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4616 samples, validate on 1544 samples\n",
      "Epoch 1/50\n",
      "4616/4616 [==============================] - 9s 2ms/sample - loss: 1.4331 - accuracy: 0.4983 - val_loss: 1.6041 - val_accuracy: 0.4799\n",
      "Epoch 2/50\n",
      "4616/4616 [==============================] - 3s 641us/sample - loss: 0.8727 - accuracy: 0.6917 - val_loss: 0.8255 - val_accuracy: 0.6962\n",
      "Epoch 3/50\n",
      "4616/4616 [==============================] - 3s 621us/sample - loss: 0.7137 - accuracy: 0.7532 - val_loss: 0.4929 - val_accuracy: 0.8400\n",
      "Epoch 4/50\n",
      "4616/4616 [==============================] - 3s 602us/sample - loss: 0.6247 - accuracy: 0.7829 - val_loss: 0.4447 - val_accuracy: 0.8776\n",
      "Epoch 5/50\n",
      "4616/4616 [==============================] - 4s 765us/sample - loss: 0.5717 - accuracy: 0.7996 - val_loss: 0.3923 - val_accuracy: 0.8886\n",
      "Epoch 6/50\n",
      "4616/4616 [==============================] - 3s 650us/sample - loss: 0.5277 - accuracy: 0.8193 - val_loss: 0.4060 - val_accuracy: 0.8595\n",
      "Epoch 7/50\n",
      "4616/4616 [==============================] - 3s 648us/sample - loss: 0.4806 - accuracy: 0.8360 - val_loss: 0.3920 - val_accuracy: 0.8646\n",
      "Epoch 8/50\n",
      "4616/4616 [==============================] - 3s 651us/sample - loss: 0.4805 - accuracy: 0.8369 - val_loss: 0.3770 - val_accuracy: 0.8672\n",
      "Epoch 9/50\n",
      "4616/4616 [==============================] - 3s 647us/sample - loss: 0.4558 - accuracy: 0.8464 - val_loss: 0.3289 - val_accuracy: 0.8912\n",
      "Epoch 10/50\n",
      "4616/4616 [==============================] - 3s 722us/sample - loss: 0.4287 - accuracy: 0.8488 - val_loss: 0.5660 - val_accuracy: 0.7927\n",
      "Epoch 11/50\n",
      "4616/4616 [==============================] - 4s 800us/sample - loss: 0.4017 - accuracy: 0.8601 - val_loss: 0.3040 - val_accuracy: 0.8860\n",
      "Epoch 12/50\n",
      "4616/4616 [==============================] - 4s 785us/sample - loss: 0.4027 - accuracy: 0.8551 - val_loss: 0.2845 - val_accuracy: 0.9035\n",
      "Epoch 13/50\n",
      "4616/4616 [==============================] - 3s 712us/sample - loss: 0.3859 - accuracy: 0.8674 - val_loss: 0.4781 - val_accuracy: 0.8135\n",
      "Epoch 14/50\n",
      "4616/4616 [==============================] - 4s 900us/sample - loss: 0.3785 - accuracy: 0.8692 - val_loss: 0.2701 - val_accuracy: 0.9016\n",
      "Epoch 15/50\n",
      "4616/4616 [==============================] - 6s 1ms/sample - loss: 0.3684 - accuracy: 0.8698 - val_loss: 0.3372 - val_accuracy: 0.8705\n",
      "Epoch 16/50\n",
      "4616/4616 [==============================] - 4s 760us/sample - loss: 0.3571 - accuracy: 0.8785 - val_loss: 0.3055 - val_accuracy: 0.8834\n",
      "Epoch 17/50\n",
      "4616/4616 [==============================] - 3s 695us/sample - loss: 0.3696 - accuracy: 0.8711 - val_loss: 0.3962 - val_accuracy: 0.8271\n",
      "Epoch 18/50\n",
      "4616/4616 [==============================] - 4s 836us/sample - loss: 0.3491 - accuracy: 0.8782 - val_loss: 0.4831 - val_accuracy: 0.8400\n",
      "Epoch 19/50\n",
      "4616/4616 [==============================] - 3s 608us/sample - loss: 0.3583 - accuracy: 0.8709 - val_loss: 0.3773 - val_accuracy: 0.8595\n",
      "CPU times: user 1min 43s, sys: 1min 11s, total: 2min 54s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffa328d71d0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker_nn, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker_nn, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.97      0.94      0.95       193\n",
      "      alinda       0.86      0.96      0.91       193\n",
      "        gian       0.88      0.95      0.91       193\n",
      "     jackson       0.98      0.95      0.97       193\n",
      "      khaled       0.97      0.96      0.97       193\n",
      "     nicolas       0.94      0.96      0.95       193\n",
      "        theo       0.87      0.66      0.75       193\n",
      "    yweweler       0.75      0.83      0.79       193\n",
      "\n",
      "    accuracy                           0.90      1544\n",
      "   macro avg       0.90      0.90      0.90      1544\n",
      "weighted avg       0.90      0.90      0.90      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation - Spects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "transform_recordings >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "transform_recordings <<<\n",
      "CPU times: user 2min 9s, sys: 8.03 s, total: 2min 17s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(\n",
    "    audio_dirs= [our_recs_dir, fsdd_dir],\n",
    "    y_type= ['speakers_us', 'speakers_default'],\n",
    "    n_category_test=30,\n",
    "    include_pitch=False,\n",
    "    max_length=17000,\n",
    "    transform_function=\"spectrogram\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 193\n",
      "ale\n",
      "alinda\n",
      "gian\n",
      "jackson\n",
      "khaled\n",
      "nicolas\n",
      "theo\n",
      "yweweler\n",
      "CPU times: user 240 ms, sys: 261 ms, total: 502 ms\n",
      "Wall time: 563 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker = data_preparation.balanced_train_val_split(np.concatenate([X_train_speaker, X_val_speaker]),\n",
    "                         np.concatenate([y_train_speaker, y_val_speaker]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_2d = X_train_speaker.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_2d = X_val_speaker.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_2d = X_test_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 1.17 s, total: 1min 26s\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker.fit(X_train_speaker_2d, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.98      0.99      0.98       191\n",
      "      alinda       0.99      0.98      0.99       195\n",
      "        gian       1.00      0.99      1.00       194\n",
      "     jackson       0.98      0.98      0.98       194\n",
      "      khaled       0.98      0.97      0.97       195\n",
      "     nicolas       0.97      0.98      0.98       192\n",
      "        theo       0.73      0.72      0.73       195\n",
      "    yweweler       0.73      0.74      0.73       188\n",
      "\n",
      "    accuracy                           0.92      1544\n",
      "   macro avg       0.92      0.92      0.92      1544\n",
      "weighted avg       0.92      0.92      0.92      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf_speaker.predict(X_val_speaker_2d)\n",
    "print(classification_report(y_pred, y_val_speaker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker, X_val_speaker, X_test_speaker, y_train_speaker_nn, y_val_speaker_nn, y_test_speaker_nn, input_shape,  target_names= data_preparation.prepare_data_nn(X_train_speaker, X_val_speaker, X_test_speaker, y_train_speaker, y_val_speaker, y_test_speaker, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4616, 128, 57, 1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_speaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 127, 56, 32)       160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 127, 56, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 63, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                3612736   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 3,613,800\n",
      "Trainable params: 3,613,608\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4616 samples, validate on 1544 samples\n",
      "Epoch 1/50\n",
      "4616/4616 [==============================] - 37s 8ms/sample - loss: 1.1574 - accuracy: 0.6263 - val_loss: 1.4517 - val_accuracy: 0.4411\n",
      "Epoch 2/50\n",
      "4616/4616 [==============================] - 31s 7ms/sample - loss: 0.6108 - accuracy: 0.8154 - val_loss: 1.0813 - val_accuracy: 0.6665\n",
      "Epoch 3/50\n",
      "4616/4616 [==============================] - 32s 7ms/sample - loss: 0.4360 - accuracy: 0.8683 - val_loss: 0.5939 - val_accuracy: 0.8433\n",
      "Epoch 4/50\n",
      "4616/4616 [==============================] - 34s 7ms/sample - loss: 0.3353 - accuracy: 0.9060 - val_loss: 0.3403 - val_accuracy: 0.9035\n",
      "Epoch 5/50\n",
      "4616/4616 [==============================] - 36s 8ms/sample - loss: 0.2687 - accuracy: 0.9296 - val_loss: 0.2953 - val_accuracy: 0.9113\n",
      "Epoch 6/50\n",
      "4616/4616 [==============================] - 32s 7ms/sample - loss: 0.2192 - accuracy: 0.9391 - val_loss: 0.2135 - val_accuracy: 0.9262\n",
      "Epoch 7/50\n",
      "4616/4616 [==============================] - 28s 6ms/sample - loss: 0.1863 - accuracy: 0.9510 - val_loss: 0.2086 - val_accuracy: 0.9223\n",
      "Epoch 8/50\n",
      "4616/4616 [==============================] - 28s 6ms/sample - loss: 0.1607 - accuracy: 0.9591 - val_loss: 0.9184 - val_accuracy: 0.7021\n",
      "Epoch 9/50\n",
      "4616/4616 [==============================] - 29s 6ms/sample - loss: 0.1626 - accuracy: 0.9556 - val_loss: 0.1620 - val_accuracy: 0.9417\n",
      "Epoch 10/50\n",
      "4616/4616 [==============================] - 28s 6ms/sample - loss: 0.1273 - accuracy: 0.9697 - val_loss: 0.1702 - val_accuracy: 0.9365\n",
      "Epoch 11/50\n",
      "4616/4616 [==============================] - 34s 7ms/sample - loss: 0.1069 - accuracy: 0.9751 - val_loss: 0.1836 - val_accuracy: 0.9417\n",
      "Epoch 12/50\n",
      "4616/4616 [==============================] - 34s 7ms/sample - loss: 0.0990 - accuracy: 0.9790 - val_loss: 0.2665 - val_accuracy: 0.8944\n",
      "Epoch 13/50\n",
      "4616/4616 [==============================] - 31s 7ms/sample - loss: 0.0984 - accuracy: 0.9770 - val_loss: 0.1811 - val_accuracy: 0.9339\n",
      "Epoch 14/50\n",
      "4616/4616 [==============================] - 30s 7ms/sample - loss: 0.0800 - accuracy: 0.9831 - val_loss: 0.7527 - val_accuracy: 0.7882\n",
      "CPU times: user 14min 15s, sys: 3min 2s, total: 17min 17s\n",
      "Wall time: 7min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff951c0c590>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.98      0.99      0.99       191\n",
      "      alinda       1.00      0.99      0.99       195\n",
      "        gian       0.99      0.99      0.99       193\n",
      "     jackson       0.99      0.98      0.99       196\n",
      "      khaled       1.00      0.99      0.99       195\n",
      "     nicolas       0.98      1.00      0.99       189\n",
      "        theo       0.81      0.78      0.79       201\n",
      "    yweweler       0.77      0.81      0.79       184\n",
      "\n",
      "    accuracy                           0.94      1544\n",
      "   macro avg       0.94      0.94      0.94      1544\n",
      "weighted avg       0.94      0.94      0.94      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN - paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "model = cnn_models.paper_architecture(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4616 samples, validate on 1544 samples\n",
      "Epoch 1/50\n",
      "4616/4616 [==============================] - 20s 4ms/sample - loss: 1.7200 - accuracy: 0.3776 - val_loss: 1.7328 - val_accuracy: 0.3083\n",
      "Epoch 2/50\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 1.0940 - accuracy: 0.6166 - val_loss: 1.2473 - val_accuracy: 0.5551\n",
      "Epoch 3/50\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 0.8035 - accuracy: 0.7281 - val_loss: 1.0651 - val_accuracy: 0.5933\n",
      "Epoch 4/50\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 0.6583 - accuracy: 0.7795 - val_loss: 0.5106 - val_accuracy: 0.8238\n",
      "Epoch 5/50\n",
      "4616/4616 [==============================] - 14s 3ms/sample - loss: 0.5839 - accuracy: 0.7957 - val_loss: 0.7265 - val_accuracy: 0.7150\n",
      "Epoch 6/50\n",
      "4616/4616 [==============================] - 14s 3ms/sample - loss: 0.5080 - accuracy: 0.8260 - val_loss: 0.4839 - val_accuracy: 0.7966\n",
      "Epoch 7/50\n",
      "4616/4616 [==============================] - 16s 4ms/sample - loss: 0.4612 - accuracy: 0.8458 - val_loss: 0.3696 - val_accuracy: 0.8614\n",
      "Epoch 8/50\n",
      "4616/4616 [==============================] - 17s 4ms/sample - loss: 0.4091 - accuracy: 0.8607 - val_loss: 0.3270 - val_accuracy: 0.8938\n",
      "Epoch 9/50\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 0.3731 - accuracy: 0.8774 - val_loss: 0.2422 - val_accuracy: 0.9165\n",
      "Epoch 10/50\n",
      "4616/4616 [==============================] - 14s 3ms/sample - loss: 0.3400 - accuracy: 0.8856 - val_loss: 0.2839 - val_accuracy: 0.8957\n",
      "Epoch 11/50\n",
      "4616/4616 [==============================] - 17s 4ms/sample - loss: 0.3294 - accuracy: 0.8867 - val_loss: 0.9010 - val_accuracy: 0.6930\n",
      "Epoch 12/50\n",
      "4616/4616 [==============================] - 13s 3ms/sample - loss: 0.3112 - accuracy: 0.8941 - val_loss: 0.3566 - val_accuracy: 0.8549\n",
      "Epoch 13/50\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 0.2935 - accuracy: 0.8956 - val_loss: 0.2328 - val_accuracy: 0.9080\n",
      "Epoch 14/50\n",
      "4616/4616 [==============================] - 17s 4ms/sample - loss: 0.2766 - accuracy: 0.9023 - val_loss: 0.2329 - val_accuracy: 0.9100\n",
      "Epoch 15/50\n",
      "4616/4616 [==============================] - 14s 3ms/sample - loss: 0.2526 - accuracy: 0.9068 - val_loss: 0.1925 - val_accuracy: 0.9203\n",
      "Epoch 16/50\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 0.2435 - accuracy: 0.9112 - val_loss: 0.2001 - val_accuracy: 0.9275\n",
      "Epoch 17/50\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 0.2401 - accuracy: 0.9157 - val_loss: 1.3602 - val_accuracy: 0.6140\n",
      "Epoch 18/50\n",
      "4616/4616 [==============================] - 16s 3ms/sample - loss: 0.2435 - accuracy: 0.9120 - val_loss: 0.2422 - val_accuracy: 0.8899\n",
      "Epoch 19/50\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 0.2327 - accuracy: 0.9164 - val_loss: 0.3229 - val_accuracy: 0.8867\n",
      "Epoch 20/50\n",
      "4616/4616 [==============================] - 15s 3ms/sample - loss: 0.2257 - accuracy: 0.9211 - val_loss: 0.2206 - val_accuracy: 0.9158\n",
      "CPU times: user 6min 57s, sys: 5min 34s, total: 12min 31s\n",
      "Wall time: 5min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9f457c6d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.98      0.99      0.99       192\n",
      "      alinda       0.99      0.98      0.99       194\n",
      "        gian       1.00      0.99      0.99       195\n",
      "     jackson       0.96      0.99      0.98       186\n",
      "      khaled       1.00      0.95      0.97       204\n",
      "     nicolas       0.99      0.96      0.98       200\n",
      "        theo       0.52      0.89      0.66       112\n",
      "    yweweler       0.92      0.68      0.78       261\n",
      "\n",
      "    accuracy                           0.92      1544\n",
      "   macro avg       0.92      0.93      0.92      1544\n",
      "weighted avg       0.94      0.92      0.92      1544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(y_pred, y_nn, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.3 s, sys: 445 ms, total: 23.7 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_train_speakers])\n",
    "X_val_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_val_speakers])\n",
    "X_test_speakers_mfcc = np.array([data_preparation.mfcc(x, flatten=False) for x in X_test_speakers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speakers_mfcc_nn = X_train_speakers_mfcc.reshape(X_train_speakers_mfcc.shape[0],\n",
    "                                                     X_train_speakers_mfcc.shape[1],\n",
    "                                                     X_train_speakers_mfcc.shape[2],\n",
    "                                                     1)\n",
    "X_val_speakers_mfcc_nn = X_val_speakers_mfcc.reshape(X_val_speakers_mfcc.shape[0],\n",
    "                                                 X_val_speakers_mfcc.shape[1],\n",
    "                                                 X_val_speakers_mfcc.shape[2],\n",
    "                                                 1)\n",
    "input_shape = (X_train_speakers_mfcc_nn.shape[1], X_train_speakers_mfcc_nn.shape[2], 1)\n",
    "enc, y_train_speakers_nn, target_names = data_preparation.transform_categorical_y(y_train_speakers)\n",
    "y_val_speakers_nn = enc.transform(y_val_speakers.reshape(-1, 1)).toarray()\n",
    "y_test_speakers_nn = enc.transform(y_test_speakers.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speakers_best = np.concatenate([X_train_speakers_mfcc_nn, X_val_speakers_mfcc_nn])\n",
    "y_train_speakers_best = np.concatenate([y_train_speakers_nn, y_val_speakers_nn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 640 samples\n",
      "Epoch 1/22\n",
      "640/640 [==============================] - 5s 8ms/sample - loss: 1.0577 - accuracy: 0.6484\n",
      "Epoch 2/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.4477 - accuracy: 0.8891\n",
      "Epoch 3/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.3221 - accuracy: 0.9234\n",
      "Epoch 4/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.2449 - accuracy: 0.9375\n",
      "Epoch 5/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.1812 - accuracy: 0.9641\n",
      "Epoch 6/22\n",
      "640/640 [==============================] - 1s 1ms/sample - loss: 0.1484 - accuracy: 0.9734\n",
      "Epoch 7/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.1380 - accuracy: 0.9828\n",
      "Epoch 8/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.1310 - accuracy: 0.9750\n",
      "Epoch 9/22\n",
      "640/640 [==============================] - 1s 1ms/sample - loss: 0.0918 - accuracy: 0.9906\n",
      "Epoch 10/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0922 - accuracy: 0.9875\n",
      "Epoch 11/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0886 - accuracy: 0.9906\n",
      "Epoch 12/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0670 - accuracy: 0.9984\n",
      "Epoch 13/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0672 - accuracy: 0.9906\n",
      "Epoch 14/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0592 - accuracy: 0.9937\n",
      "Epoch 15/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0637 - accuracy: 0.9937\n",
      "Epoch 16/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0633 - accuracy: 0.9906\n",
      "Epoch 17/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0596 - accuracy: 0.9937\n",
      "Epoch 18/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0559 - accuracy: 0.9969\n",
      "Epoch 19/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0448 - accuracy: 0.9969\n",
      "Epoch 20/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0458 - accuracy: 0.9953\n",
      "Epoch 21/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0504 - accuracy: 0.9937\n",
      "Epoch 22/22\n",
      "640/640 [==============================] - 1s 2ms/sample - loss: 0.0526 - accuracy: 0.9891\n",
      "CPU times: user 38.1 s, sys: 2.96 s, total: 41 s\n",
      "Wall time: 30 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb35bcd03d0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)\n",
    "model.fit(X_train_speakers_best, y_train_speakers_best,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=22,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_speakers_mfcc_nn = X_test_speakers_mfcc.reshape(X_test_speakers_mfcc.shape[0],\n",
    "                                                 X_test_speakers_mfcc.shape[1],\n",
    "                                                 X_test_speakers_mfcc.shape[2],\n",
    "                                                 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.69      1.00      0.82        20\n",
      "      alinda       0.70      0.95      0.81        20\n",
      "        gian       0.59      1.00      0.74        20\n",
      "     jackson       1.00      1.00      1.00       420\n",
      "      khaled       0.83      1.00      0.91        20\n",
      "     nicolas       0.99      1.00      1.00       420\n",
      "        theo       0.97      0.96      0.96       418\n",
      "    yweweler       1.00      0.93      0.96       420\n",
      "\n",
      "    accuracy                           0.97      1758\n",
      "   macro avg       0.85      0.98      0.90      1758\n",
      "weighted avg       0.98      0.97      0.97      1758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_nn = np.argmax(y_test_speakers_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_test_speakers_mfcc_nn)\n",
    "print(classification_report(y_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/speakers.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "- [X] Export train/val/test balanced split\n",
    "- [X] Double check all the trials\n",
    "- [X] Export in functions things like reshaping data for nn, evaluation blocks etc so that the notebook is more easy to read\n",
    "- [X] Apply more times data augmentation on our recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pad_recordings[43]\n",
    "test_mfcc = librosa.feature.mfcc(test*1.0, sr=8000, n_mfcc=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from librosa.display import specshow\n",
    "plt.figure(figsize=(10, 4))\n",
    "specshow(test_mfcc, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApkAAAEYCAYAAAAXq+2yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9eZhtd1Xn/VlnrvHWnXLHTJCADKJoBGwjRtQWkLdptRUVkdAgjQ0O3dIGbF9xbKNtd9O+ot0RAwgq0EhDVBDRh6BpQQkYQDpARjLc3LluTafOvN4/zr5QqVTV+iY5VbnD+jxPPffWqXX2/u19ztl7nTV8l7k7SZIkSZIkSTJKSo/1ApIkSZIkSZJzj3QykyRJkiRJkpGTTmaSJEmSJEkyctLJTJIkSZIkSUZOOplJkiRJkiTJyEknM0mSJEmSJBk56WQmyTmOmV1lZvdt8Hczs7eY2ayZ/cNWri1JkiQ5d0knM0nOYMzsbjPrmNmuVY/fYmZuZpeMYDdXAt8BHHT3Z4xge8kGRE5/kiTJuUI6mUly5nMX8IOnfzGzrwbGRrj9i4G73X1prT+aWWWE+0oERn3Ozaw8yu0lSZIopJOZJGc+bwd+ZMXvLwX+YKWBmdXN7DfN7B4zO2Jm/8PMQkfUzF4OvBn4RjNbNLNfPB1pM7NrzOww8JbC9gVFBPWUmf2dmT1txXaebmafMrMFM3uXmb3TzH6l+NvVZnbTqv26mV0WrX3FWn7azI6a2QNm9rIV2xkzs/9iZl8yszkzu6l47M/N7MdX7fMzZvYv1zgHDTN7h5mdKI7tE2a2p/jbjWb2a2b2D8X2329mO1Y891nFuThlZp82s6tW/G1HUYZwqChFeJ+ZTQAfBPYX53vRzPab2S+Y2XuKdcwDVxfn5Y3F8w8V/6+v2P7PFOfjkJm9YtU5fauZ/a6ZfcDMloBvNbPvMrN/NLN5M7vXzH5hxbYuKZ7/suJvs2b2KjP7huK8nTKz347eT0mSJCtJJzNJznw+Dkyb2ZOKiNSLgHessvl14AnA1wKXAQeAn4827O6/D7wK+Ji7T7r7G4o/7QV2MIxyvtLMvg64Hvg3wE7gfwI3FI5QDXgfQ2d4B/C/gO99GMcXrX0vsK14/OXAm8xse/G33wS+Hvhnxb5/BhgAbwN++PQGzOxriud/YI39v7TY/oXFsb0KWF7x9x8B/jWwH+gBv1Vs8wDw58CvFPt+LfAnZra7eN7bgXHgKcAFwH8rosXPAw4V53vS3Q8V9i8E3gPMAH8I/EfgWcV5+RrgGcDPFft+LvDvgW8vztm3rHFcPwT8KjAF3AQsFccyA3wX8GNrON3PBC5n+B57Y7GGby+O4fvNbK39JEmSrEk6mUlydnA6mvkdwOeB+0//wcwM+FHg37n7SXdfAP4T8AOPYn8D4A3u3nb35WL7/9Pd/97d++7+NqDN0Al6FlAF3ujuXXd/D/AJZSfi2rvALxXb/gCwCDzRzEoMnb+fdPf7i3X9nbu3gfcDl5vZ5cU2XgK8y907ayyjy9C5vKzYxifdfX7F39/u7v9UOIj/L0Nnq8zQif2Au3/A3Qfu/mHgZuD5ZraPoTP5KnefLdb+0eB0fMzd31dsaxl4cXHcR939GPCLxXEAfD/wFnf/nLs3i7+t5v3u/n+K7bXc/UZ3/2zx+2eAP+ahzukvF7Z/ydAp/eNi//cDfws8PTiGJEmSL5NOZpKcHbydYWTqalalyoHdDCNmnyzSmqeAvygefxBm9uIVadoPbrC/Y+7eWvH7xcBPn95+sY8LGUb39gP3u7uvsP+SeFzK2k+4e2/F701gEtgFNIA7Vm+0cDTfDfxw4Yz+IMNzuBZvBz4EvLNIPf+GmVVX/P3eVcdVLfZ9MfB9q87JlcA+hufmpLvPSmfhofuB4XldeR6/VDx2+m8r7Vc/9yGPmdkzzewjZnbMzOYYRmx3rXrOkRX/X17j98kNjyBJkmQF6WQmyVmAu3+JYQPQ84H3rvrzcYYOwFPcfab42ebuD3EI3P0PV6Rpn7fRLlf9fi/wqyu2P+Pu4+7+x8ADwIEiKnmai1b8f4mhIwmAme19JGtfg+NAC3j8On9/G8No4LcBTXf/2FpGRZTxF939yQzT7i/gwTWwF646rm6x73sZRjlXnpMJd7+2+NsOM5tZa5frrHf144cYOrIr9306tf4AcHCdNa63vT8CbgAudPdtwP8A7CHPSpIkGRHpZCbJ2cPLgees7gJ39wHwe8B/M7MLYFgvaGbfOcJ9/x7wqiIaZmY2UTSSTAEfY1ir+BNmVjGz72FYP3iaTwNPMbOvNbMG8AujWHvx3OuB/1o0z5TN7BtPN8cUTuUA+C+sH8XEzL7VzL66SIHPM3Qi+ytMftjMnmxm48AvAe9x9z7Dutj/x8y+s9h3w4aNSgfd/QGGDT6/Y2bbzaxqZs8utncE2Glm24JD/GPg58xstw0lrH6er9Tivht4WVGnO45Qf8uwNvOku7fM7BkMI+NJkiSbRjqZSXKW4O53uPvN6/z5GuB24ONFd/JfAU8c4b5vZlg7+dvAbLGvq4u/dYDvKX6fZdg08t4Vz/0iQ+fsr4DbGDahjGrtrwU+y7AG9CTDJqKV17U/AL6ahzZKrWQvw4abeeBW4KOr7N8OvBU4zDA9/xPFcd3LsFnnZ4FjDKOX/2HF/l/C0GH9PHAU+KnieZ9n6EDeWaTZT6fAV/MrDGs8P1Mc46eKx3D3DzJsQPoIw3N3Okrb3uA4/y3wS2a2wNApffcGtkmSJI8ae3AZVZIkyaPHzN4K3OfuP/cYr+NHgFe6+5WP8Pk3Au9w9zePdGEjxsyeBPwTUF9Vv5okSfKYkZHMJEnOSYo08r8Frnus17IZmNl3m1mtkHP6deBP08FMkuRMIp3MJEnOOYqazmMM6x//6DFezmbxbxge4x0Ma0h/7LFdTpIkZyo2HA7xYTO7rfh3u/CcG83siuL/d5vZZ204kOOzZvZCab+ZLk+SJEmSJDn7seHUsavd/epVj/8Gw8a/a83sdcB2d78m2NaNwGvd/WYzuxu4wt2Pm9kTgb9094s3ej5kJDNJkiRJkuRc54UMZd0o/l1rxO6YDUcCf8bM3gWsN5p4mmGTZ0jlkaz0bMDMMkR7RhHL8RllYTPx96KSxdspWy20qRDbDO3i/Y1KjLBs8ZaqJcVG25+tK+n4YKuIgbAZZU99wagn7KwnZnAUK5esYkz6jIxmOyplYVMl4T2pnKPeIN5X90HKUutsh268IaAv2cXrHippBfsatEIb7d2WjJDj7v6QgRVbyXd+5zP8xIk5yfaTn/zi5xjqAp/mOnd/OPXmewppNdz9gdOScav4MYaawk8zs6cxVLRYyUcKPeTHMZw6FnLOOplDzvHDO4tQbnyVSlgiQrncCG3GaztDm22VtbSrH8xuj20AdjIV2lQFx3cg3GSmq/F7+sBEvK8L4tMIQKMUr6nv8Wvbin0D2oKTMbfWUMhVnBA2NNvW+mPaHi+8LzgZCmXhC1Rd+gI1Oidzuhbvb6wSr1tx/E+04tfkcH8+tDlZPhraAMz17w9tBsSvbbe/GNqcWvpCaJM9W1tNT51KtmmcODHH3//D/5RsK+Vvbbn7Fev93cz+HqgznMq1w8xuKf50jbt/SFzSsxlKo+HunzGzz6z6+7cW6fLHA39tZje6+4YfgPTCki1BiWSYcJOtlGLvqDzU4t54O4LNQHQeloWbQ084/jGLP46NcnyOlOhTTYxkzlTjc1AVHNHFXrzDU93YRnFo24N4O8vCegDKAyFKK7y2JeFL1mQ1dujGK6OJGgMsduPXtiOEjstC0qgvRI67wudtoRRHfZriJM++x5FME5x6JZKJ4Kwm5yEODEbz3nD3Z8L6NZnAETPbV0Qx9zHU7l1vVdG+7jCzI8CTgX/YyDadzGRLKD1oFPTaVCvxJMHJ2p7QZlv5QLydQTRsBSZ9IrQZ7i92WMfL8c1qQshhb6vFTsZMfKoZL2sXNsWBUJwaIYOP4D8h+EWS86RG++rCa6Icm1bmMJrtDMRSAGVbinOoOKLKdpSocbvUDG0WO4dDG4Bufzm06Q/i0HmnFzu1miOanH849LYsgn0D8FLg2uLf969h8zcMR/F+xMyeCjxtrQ0VqfZLgTAanE5mkiRJkiTJVuPA1in8XAu828xeDtwDfN8aNr8LvKVIk9/CQ6OUHzGzPlAFXufuR6KdppOZbAmVShw53F6/JLTZL0wbvMDjfdWEtLP62VciQtvqcSRzRugz2ivUUu4fi78Z76hpzRGT1diuJKSLl3pxePVIKz4BXY8vWS6IZqgpZeW1VSKZSiRPQaltbgv1ryrVUnwup7X+uJDtnfHQprT4+NBmuaKly+eHPRAbb6sT3kPp95ek/SXJQ/GRpcu/vEX3G4Eb13j8BPBtwXOXgR9Y52+XPJL1pJOZbAkDoW5RqX/qC9tpDWKbErHTU1G8B7TmiAsa8bb2NuKLzUw19iAUB3K6KnTQiDR78WVkoRvbdIX6R6URaULIuzd72murdVcrWxpNM46ylTGl7gAQvmdJVKS0e7ydrnCzbQuf/1JJqBcBur3YOcxmnGTTGbGTeaaRTmaSJEmSJMlWM8LGnzOVdDKTLUEpfHel8N9ivbkljxtxyi6kVIUuZYD5Trzu40pITEjzKlGzbf14PaWalr6tiQ1CEUtCtLMlRDK7Qne50jnfFyRZAZo9ofFFOEXCW4SGsCalu1x6q4l2SgSyLdQeCOpEzAp5/tlSnArveTveGZqaBdmwk2wqo0+Xn2mkk5kkSZIkSbLVuGP9c7skI53MZEvoKyLKrTtDm049lh2x0hNCm0lfb1rWV1BlbpToohIRU2oSlRUpskMqfWFNLSEsqEQgx8vxuptCRPBEd3Rakpo8UWwj6JUjlPZKmqSjZLYtvCbCqB4lIrrQj2uJW6W4jnK2GV9HAFrtWIydEQrbJ8maZCQzSbaGbi+enLFcOhnbNGKHdnEQT+lhEDuiAGVBA1RxMhSHpivcrE8JTTbjFe2jv3MsLk/Y34jTkzuFdPnRZtxd3OzH7fVTwslWfQelKVxJ8ysjE5X3iJKaVxxDgMPLsVOnTOqpCR3oimC9MjmpJJS5jNd2hTYA7e6x0GYw0FLvSfKIcPRvvGcp6WQmSZIkSZJsOVmTmSRbhiJz1OkthDZLg+OhTa0URyndZ0IbgGo/joouCSMTY0U+baxiiTjv2ihr4oYDYX/1cpzDViKH1VJ8sd3biKNvfY+P7WRHC2UqzTjTwuhNpVxgQZAubQr3I/WWtbMeX/6nhQlTU1WlGWk0WqoHmpeHNregZSCWqvGM805HiHYK4ymTZE2yu/zRYWb/DngFw1P5WeBlxe8/BTwe2O3uxwvb7cD1xeMt4F+7+z+Z2YXAHwB7GV4/r3P3/76Z605GjyIiPSqUTvZOKa7tPGFaqqwtdLMudWJH9PLqdGgzLUgATlXi49/TiNPgAHsm4xq4Wk3QLm0LYuyL8RjPZaH+U3FoFC1NdVsKSk1iR0i7K53zF02MbqykUm+6lXWiY0JNQb0lTCwAyqX4y0i1ujO06fbieeqDQXy9Sc5TznEFgxHJ8T4UMzsA/ARwhbs/FSgzVJL/P8C389CZlz8L3OLuTwN+BDjtSPaAn3b3JwHPAl5tZk/erHUnSZIkSZJsOu7Q62s/ZymbnS6vAGNm1gXGgUPu/o8A9tBv0U8Gfg3A3T9vZpeY2R53fwB4oHh8wcxuBQ4A/3eT156MEiFqoujWKVGDw3MfE/YVv/Unxy4NbQB21eMU3kBIBX9hSUgpduOIaHcmjva1BpOhDcC9QjNOQzg2EyKCSnf9qDrwlclBoEUgm/14j/NCx7uyr5qw7q4YGFkQ1r00Ip3QZaHz6XArzgjcXbo7tFkiLpcBqJXjyLnSjOiZLk8eMVmT+Yhx9/vN7DcZDmJfBv7S3f9yg6d8Gvge4CYzewZwMXCQFaVqZnYJ8HTg7zdp2clmMaLZzaNCmgHd1WYgH/X4+06rfiC0KQnSS61+fGM8shw7mXWhIxg0WaGGomkt1CQq9aYKynaOtrV9zQv+Q1+4R7QUD1JASV+rtyxpiEA7dvxGdYucJa63bnr8mVzsKtXN0OycCG2kcbjCteTMuvolZxTnuJO5meny7cALgUuB/cCEmf3wBk+5FthuZrcAPw78I8NU+entTQJ/AvyUu6+pUWNmrzSzm83s5hEdRpIkSZIkyehxsMFA+jlb2cx0+bcDd7n7MQAzey/wz4B3rGVcOI4vK2wNuKv4wcyqDB3MP3T39663Q3e/DriueE5+eTyDcOG7/KAfN5mMqpNT2U63F2tyAvSFon6lGakyFjcsVAdxs8KgGXfF913oIALmBM3NiUocOVU0QJXGF0XUXok+Lio5XqArROBrwsFJxy9EO1tC2LQ50CaIzBGngmdLceq5483QpuVxmUtX+Bz1Bd3KZTED0R/E1xsXIpnZXZ48cvyMy/KNms10Mu8BnmVm4wzT5d8GrBthNLMZoOnuHYYd6H/j7vOFw/n7wK3u/l83cb3JJqKklEpCjRRb6IiqH37FgewPOqFNWfg47iLuQD8wHjui++NSy+H+6vGxKXWCSra4JdQIKg6d4j8eV3LcQFMY+TZejl+3srBuJRWuOPRl4TwCzPfiRFbb4xR2axAPP1DmiXeEz3a3p9jEDi1kx3dyhnAWRykVNi1d7u5/D7wH+BRD+aIScJ2Z/YSZ3cew3vIzZvbm4ilPAj5nZp8Hngf8ZPH4NwEvAZ5jZrcUP8/frHUnSZIkSZJsOtld/uhw9zcAb1j18G8VP6ttPwY8pE3X3W9CaxhNzmDOtHS5hDh7sCwIu5eEbvaB0ELRFWz6QgR2SYhigdawIEWplYYVYWdzwst/z2JsdKh/Kt4QMC7MuJ8UXlslSql0YM/144jgbEk7tiN2R2jT7cepcAXlc6sMWugJ61E+jwC16nbJLqLTFRqIcjxlshYpxp4kSZIkSZJsCulkJsmj52ysyTRhPKOKCxFIZd3bhHGQO+pxlPJxk1r6ZacwzUeZ+LLUi8/lkXZ8OVKag/aOxU1NpWUtilUTQpA1QQ6qJ4RplQi0QmOgRfJmSvtDm2Y5bqJZ6seRvFY3rpNURjhKCJFllXI5bsYrCZHTjGQma5ONP0kyGix2MkwpERZuICZ0hCrrUen1hcYHwabTuDC0URpRXPhYL4jp8vYgdth6guPXVgS7JVHz+IKsdKAr6XvQnMPeIHbYla7wRaE5bM7i99Gc0BEOsNiPZ3cvdeNttQUHUlLTFD7bkvC50GQEMPD4M1Dy+EtdkjxiNildbmZfBbwF+DrgP7r7b67423MZTlQsA29292uDbV0C/Jm7P9XMrgLez1D5pwQcBX7I3de9mGxa40+SJEmSJEmyAQPXfh4eJxmO9f7NlQ+aWRl4E8Pm6icDP/gIxnT/rbt/bTEC/BPAqzcyzkhmsiWYEDksleKogTJ6sqNIkyjRTrHfrFrdGdrUhSaDmsVpt6qQmh3VeEKA7VVhZKTQHrQgpMsVyvXYpiGkuE91tEvfXDuOUraFSERPkLnqEr8nOxZHOxXdSoC2EF1Xpl4pEl7K53YohxztTNGt1CJDfaX0RkhzK1qaSbIm7tAb/funiCweNbPvWvWnZwC3u/udAGb2ToZDcx40ts7Mvh64HmgCN621j0Jecgq4faO1pJOZnFUoepMjY4Qp9UZlW2hzmX9taLO7Ed+ItwsZvrroZAqZZ/pC2lHRrlRKk5Qv9FL9rzjoryvs8GSvFdrMlmJnrVmKnb6lQVz/ONe+J7QB6PYUZ1RxDuOtaAMLhBGOQv1jraTV2yqOr9LN3hec9SRZFz1KuWvVNMPrigE0D4cDwL0rfr8PeOYadm8BftzdP2pm/3nV3765mMy4E1gCfnajHaaTmSRJkiRJsuU4iJF34Li7X/Eod7jWV8IHeblmtg2YcfePFg+9nWF6/TR/6+4vKGyvAX4DeNV6O0wnM9kSlLRTrx/r5I1qSkdJSM1J3e4iu8uXhTbbLe5knazGYaOqUGk9U9W6y3fX48hxvRxva6kXn+/7l+MQ7F1L8SVrWagXECVQmanH0eyG8D7Z3otf26P9qdDmeFkoOxHUBQBa1TgC1+zEjT8DIQIpTcUaUdq5VNJua7VKfL7r1TgD0WwLEdGepl2anGc4j6Te8iGY2auBHy1+fb67H1rH9D5gZYfpQWC1raFJJAPcwHDk97qkk5lsCYpTp4goKzcr99Gk5iplbfbimFBvWSc+tm01YaykUJP4VVOxQ3/xZFyPBjDVGI30SrMjvP4WX9e6Qif7RCW+6bfEARoL3Xh/yqTs5ogGdpQ9fo+MielihX5lRNI7Qrlltx9/bpXa7opQ2w3atUSZp57yRMmjYgTd5e7+JoYNPRGfAC43s0uB+4EfAH5o1bZOmdmcmV1ZDMN58QbbuxLYcKpDOplJkiRJkiRbzYgimasxs73AzcA0MDCznwKe7O7zZvYa4EMMJYyud/fPrbGJlwHXm1mzsF3J6ZpMA+aAV2y0lnQykzMGE3TyKuU4xaUl3YT0XT9u6ADoluJox/Fq3Iyx2N0b2jTKimB5HMk73NQEu+9djFPBJ4VO7ZPdOAK1LLxwpwSZxMPN+KI919HeJYpAuiLGrjQ1VYQmm6YQN13oHol3hib+35ZGPSqfk/jzVi7FJQUNIX1dL08L69EafypCJFNpRmy1R1Pmk5xr+KbMJXf3wwxT4Wv97QPAB4LnfxL4mhUP/ULx+I1A/CFcQTqZSZIkSZIkW43zcBp/zkrSyUy2BkknL7YpC/VWio0y5rEkjqerlOJCyW3EUcp940JNZi1e9x6hjnLPhFaT2ajH0a6uEKU8vhTXt969pERN433tbcR1lCc7Wt3eoWZ8vhe6wshQISXWsHhNU1wQ2nTKWtRMiWQqzTijavxRUNaj6H+q9IQopSJzlCRr84iE1s8q0slMtgbhJqM4dUq6rGyx06c0ELhraQzlJrtrsDu0OSD0GU1X431NVuMbY1XsLlfo9JQUfny+a6X4PVIRvogoIvpKkxHAmCDs3hQy7y0hX94UxiF2hNKMTn8xXhCw3D0Z2gwG8cEpXdq1ESk19ITmoI4gsg7iGNst3E5ynpJOZpIkSZIkSTJSNml2+ZlEOpnJGYMSyayU4nBfoxQX/ivp8vZAiwiVlZGZ4ojKiGkhAlkWpvk024KmDLDcje2WuvHr1urH56jVjyNCy/34PM4JzUGLoiSjornZG1EkQnmPdD1ushkraxJGyuekI8iB1UuToc24jUZWabk8F9o0+/FUJNCioqrmZkS3F0eNk/OUjGQmyaPHhDpJpbaxJKSmyoIo3zRx+rouiKOrNEb0UTsuOIftfnzTn6oKnhiwcyx2araPxTfrruBk7hTqJLctx6/JrQuxzZw4nbRSih2/MUGXc1L4IjIhnCNrx6L+d5Q+G9oA9InfA8rnrUL8uZ0cxGUukx6n1HtCbfNsORaQBzhud4U2zc6x0GZZEKxPkjXxzekuP5NIJzNJkiRJkuSxQNE3O4tJJzPZEvpCMf5C6/7QZn5we2ijjIPcPh5HhCbLcScvwCQ7Q5u6kC5URh0qE29agk5mu611Vx8X7IRgn0Tf4w0tCJ3sS0IqXGgIB6DVi28AJ9qC3qTQRNYVbGZLsU6mElkELc094TOhzfgg/rzVEd5HoyopEdYMUCrF14DjNWF6lNBAlSRrskli7GcS6WQmW0JZcPzq1fjmMPD4xtjtxbWU8637QpteTZOC6Qup58PCXOrb53eENkqX9owwvLxR1i5swqh0GuXRFK4v9OJ1378cH/+x1tbVUQLsrMclDN1BfKk91RGcVcGhKwni8ACLxPO0WxZ/ORwnXpMiNN8W0vezpdih65o25lGpb1Vk1RrV+HO7mLPLkzVJCaMkSZIkSZJkM8ju8iR59JjF0R6pu7wcj0Mcqyqp6dFp27UGsfjzA6U7QpuZZtw5P1WNj78haDuOiZHMmZqgAVqPu2ga5Xg7rX78+u+px2lXbcyl9vovCP1RXaE8YVFIuyulWd1u/PrXhKgpQF3Qk2143ES1qxKvabIqKDAIUfOlXpwRONLRxNG/VPqiZBdRFa5JJpQCOOd2RCtZg0yXJ0mSJEmSJCPHHXoZyUySLUHRrlSolOLIgtL0UBEiPQB94ihdT5jmcthifb99nQOhzY660BwkRDsBjrXjS8Sc0IxTF7Q7lS/0TUFL80QntlnoasffFhZ1qh2/b+c6cVPPQi8Om3aEUZAzQmQNYKISfwYaZUGeSSjcbcRvEQRJUmplYUMIo7OAbudxoc29pS+ENqe6XwptMkqZrIdnJDNJHj0lYS5zWdDJVGYgK2MeFdo+uvF83UHcRDQxtiu0UVKKyiWrJ3Spg9b4UxFHNEYoXfGzQpr7aNzPgYuyIYKPJZUnUIudIyWl3OnHn5GueGyKU9cXtqW8l5aVUgDBZpQNWwPhS63y5bArjvFMkjVJCaMkSZIkSZJkpGRNZpKMBheii/2BEDXoxUX9C83bpDVFlIRmJQCEhqVqJZ540vH42BTdRqXJQJUw2l2P07P7hKlAE1Xl9RfS/MJUnLZgs9DTLn2HW/F74HArDnf2PbYxIQZdFsRUK6LcpJLCrgllDrVSHBFUIvAtYWTovFDmcKKjpNSh1owbBL395NBmtnxnaNNLCaNkPdLJTJIzB2WWcLUS69Yp9Z8maPuBpu9Zq8RagsqoywvG4jVtq8YXLTXFfUqYS14XyhwUJ0u51i4Is9SVtPuioMkJcKyt1HfG2xkXrrSCvKkkIt8RSyF6QppuUvBYlUpqJSPYlObSC45oR6vtbveF0puspUw2E0+dzCRJkiRJkmQT8OwuT5JHj9KMozT1KFqaVta6S8PtiFqapVIcXauXp0Ob3YN4PKXSiKKwrRp3OwPsqMVhuqqQLl0UIqJH2kpqOk6FKtE+JWoISLHsmpALVlLhO2pKajq2USKCAKc6o4lSKgwUnUghoKO8bmNivUBLUCqY7MbXksn63tBmuR1PGEvOQzapJtPMXgxcU/y6CPyYu3+6+Ntzgf8OlIE3u/u1wbYuAf7M3Z9qZlcB7wfuYnh5PAr8kLsfXe/56WQmW9B2+O8AACAASURBVILkHApOnVKT2e3F3d6lUnzzaNTitDtASXBFJkpx5/gOIe1cEWryxoQxj5MVzclUaiknhLGaOy2u29whjGfcVYvFwZUUvzIDHkAogZUkfMaFGtgdgvD9eFl73RTaQlnBslDfOivUQM7Gev0Syv1YnUuvzJy/vfRPoc38UjqQyaNgc9LldwHf4u6zZvY84DrgmWZWBt4EfAdwH/AJM7vB3f/vw9j237r7CwDM7NeAVwNvWM84ncwkSZIkSZKtZpNqMt3971b8+nHgYPH/ZwC3u/udAGb2TuCFwIOcTDP7euB6oAnctNY+zMyAKeD2jday6U5m4TnfDNzv7i8ws0uBdwI7gE8BL3H3jpldzPCgdgMngR929/uKbVwEvBm4kGGA+fnufvdmrz0ZHaVSrJNZK8fNMfVKPFbOPW6g6Q1GFFoBapU4FV4mjtLVSnFkaUpo6lE42dE652eFEY0Hx+Mo5b7JpdBmYjp+TaaFEZYPLMXvo7uW4oioyq5aHF2cECLHdaHsQGHgWpRWKwWI17Q9/mjjxNHO4+143R3hhrykCG4CzUEcyZwsxSUsx4VrW5Ksi66TucvMbl7x+3Xufp3wvJcDHyz+fwC4d8Xf7gOeucZz3gL8uLt/1Mz+86q/fbOZ3QLsBJaAn91o51sRyfxJ4Fbg9J3414H/5u7vNLP/wfAE/C7wm8AfuPvbzOw5wK8BLyme8wfAr7r7h81sktGVCiVbhCRhJNiUhC5lRfi8043njff6sQ1As30ktJneFtdtTQhpV6VuT0m7bhPS4ADbarFTNybJE8Wv29JS7Pgeb8XTbO5eissOWmK6XLn+dwaxA6UEK8YbsSM6XonPtepkKp36C7342E4JE5/awvlWJJWUznl1ctiiCZJhpNB6snk4ILQinOa4u1/xcLZvZt/K0Me68vRD6yxj5XO2ATPu/tHiobcDz1thsjJdfg3wG8Cr1lvDiNoI1sbMDgLfxTAKeTq8+hzgPYXJ24B/Wfz/ycBfF///CMMQLmb2ZKDi7h8GcPdFd0FQMEmSJEmS5EzFGc4uV342wMxebWa3FD/7i8eextD3eqG7n55ZfB/DjPBpDgKHVm8ObXAcwA3Aszcy2OxI5huBn2GYt4dhePWUfyWsdR/D8C3Ap4HvZdj19N3AlJntBJ4AnDKz9wKXAn8FvM7dH/K138xeCbxyk44l2WSU7vJ2P067tjqrPzOPbF8qFaGbffDQt+tDmG3HNncsxh/Z/UIm+ICQvgaYmY6/z5Ur8bnsCDPQ+4txlLJi8b4uGo9F/eeE5iCAQ4IY+5xQeTEhdDy70IGtRCmVyOrQbjTapYrmqiAlKo2nXBI6seaFOfEATYujlMs+G9q0uydCmyRZj1Hcitz9TQwbeoAvlxi+l2E54hdXmH4CuLwoW7wf+AHgh1Zt65SZzZnZle5+E/DiDXZ9JXDHRmvbNCfTzF4AHHX3TxZt77BxqPa1wG+b2dXA3zA8Ab1ijd8MPB24B3gXcDXw+w/Z0LA+4bpi/+e2wmmSJEmSJGcvmzdW8ucZBvV+Z5hApufuV7h7z8xeA3yIoYTR9e7+uTWe/zLgejNrFrYrOV2TacAc8IqNFrKZkcxvAv6FmT0faDCsyXwjMGNmlSKa+eVQrbsfAr4HoKi7/F53nzOz+4B/XNEN9T7gWazhZCZnMptamfEgqpVYLqhejcc8lgXZJYCBUANWtTi82BImkCgSRso0m/sX4+YY0JpolGtkQ5DeUSJ5yljJrhDt64t1i3VBl7IRl4BSFb7zKk1WRwejqaMc7i8+B6eEEKQiGdQX3iOLQsPO0eV4QYc8ljADOMX9oc1S93hoY+r42SRZi03oMHH3V7CO8+fuHwA+EDz/k8DXrHjoF4rHbwTim+cKNs3JdPfXA68HKCKZr3X3F5vZ/wL+FcMO85cyFPbEzHYBJ32Yx3w9w05zGIZ3t5vZbnc/xrCmc2WHVXIWoGhgKk6dC52cvX6c4lWadcolrQNZGXU5W7k3tGlUL5f2F3FPM17PYSF9DZq+o6bLGdvMCHqbirPaF+aSK0LcoKWCx4Xjbwg2ioa4MgNc6cAGaJTjje0UTtOCMOpRcSAVt3+yGjvQ2zux2gPAUcE5rJbiEo6xWqxmsZCzy5O1cMfP8bGSWxde+grXAP/ezG5nGM49HZG8CviCmX0R2AP8KkBRe/la4K/N7LMMr0W/t9WLTpIkSZIkGSkD8ecsZUvE2IsQ643F/+9kKAi62uY9fKXrfPXfPgw8bfNWmGw2SnRxIKSwG9WZ0KYu6Fb2B3FzSFmYwAMwVdkT2jz1QZmHtTk4EX8cFZ3MGUHm6PLJWOYJ4KLphdBmciI+lwOhqaMtRFfnW/FroqTdG2JKWdGJVOWgIkZVCqBocoIWXV0QSi8UeSohaEpdmJlaFVL8rb6Wvp4eXBDaNC1u6un1tc9SkjwEB1dqSc5icuJPsiVUK5OhTb0cC61XhXGQjiB8LTiGY2LpSYO4bnGqEn/UlC+rzV58k91dj7fUFRwD0ByI+lic5q5NxmvqC2LcpePxBbnVVwTktdDAmKBLWRNS+B3BgTy6HJdnNAWnb0ksBVgQ3kuC4AE9wfFVttMWbrZdIbVYkhLvsHMQC603y/tDm14ldjKX4+9hyfnKWRylVEgnM0mSJEmS5DFghGp6ZyTpZCZbggnlv11BA3OpczTel9BkNF0/ENr00MIPUzwxtFFSgUpKUeFkR5mKpJUCzAtNNLuFDvSJihDtFCKCCiVZRzjmhJCeV7QrS0IDkbIdJcWtTNcB6At2SpRS6S5XmpGawsu/FIhSA5zsxWNOAe6wz4Q2y0LDjjKpLEnWxMlIZpKMgmoldkQalbjeUpkTPl6KtzNJLHNURZtJPDmIU/htQZ5oTnAOO0IpoSLP0xEvbE0h9TwrLOrgWGyzdzxOOyqO6FgpvumPoTkGE5X4NWkL4ucdIYWtjoOMUOWZFGqChJPy5UiSORIc0Z5gMy+IrAP0BYl45QurUt+dJGvxMMdKnpWkk5kkSZIkSbLVZCQzSUZDtxenwjuCBqaCleKC/rLw1q+6tp6uEBVb6MU2k9V4f0LWnZ7H0Z4p8ZP/+Mk4SrOrHtso+pYKSopXoSxE6AAm6/HMyHEhcrgsjLFUzlG1FHdOL6md80IIUpnQeFjITt86H6tL9IWQTlmILE66NmhgV+lxoc3dvY+HNs3WPdL+kmQtBqO5NJ6xpJOZJEmSJEmy1WQkM0lGQ7cf10mVe3Ekr1qOJ3AoDTtLFhf0LwhSSAD7/JLQZrwsaCAKF5v5jqKTGUeojgtyQQCNcvyaKJHMnVNxJKtej6O93W4cyZpbit8jp4SGHoATgqyQostZttHISp3sxJHMk8I5AlgQRkYuCqWrc0KB7zbhfdQSQjqtQbygRYuzJgALxE2EqYGZbDZZk5kkI6AuiKiPVXeENo1yrF15geL0Cc06y6Z1qaq6fBFKU4PCsVa8HSGjDmjNSLvrsVNXFUTNx2ux1+NCaroldMTXxfS9klZfElLhi73YOVRGXZ4U5pu3xPTbstLNLTii2+tCCrsa2xwT/LnmIF5QSRxkZ8Rf/KYasQqF0hyUKfVkPdRr8dlKOplJkiRJkiRbjQMjqjM/U0knM9kSJmrxhJ3J0u7QpmRx9KExiCNr20qxzZTHqVKAvqCBqEwqUYpzKiXhgjTCb8bKxLN/nI1ToQ+04kvNRcLkoOlqbDMlRES3NTTZmYqgS6k09RxdiiPnrX58HqeEkZGTFe2mpehpKmMllTIPJWpaEm5Hyjmad03CaILtoU2jFE8qqzXia0m7G4+n7As6wcm5RUoYJcmIGLiQChWcLKUDda40G9pUB6N76y9YPN9bKe6e7MddsWUhxdew+Ngum9Yc6MfHkz553ERcVrBbcOrGRzTCUblmL7Y15QBFc3JMmF2+bzJ2IGaE2tbZdvy6zQlOLwBCF/pAcLI7Fp+jJWGE5SlVvDVgwmOnD6BlcZ3wgsd1m0u9Y6FNOpDJmrgx6GckM0mSJEmSJBkxGclMkhFwqnlnaLNUjqMGpZLQ1FGJw2/HhTSYSk+Y+HGg/NWhTY24OaQiNBl1hVjebfNa12zJ4qjQ/kacUlWK200qO4j31RMaaBa68bkG6AjTfFrCVCQTahiWhe30hBR3VTiPAGXBTujpoSo0R7WE87hbeB/Vy/HrVm5pkaFl4XN7ZBCn3k8tfUHaX5KsxtGaGc9m0slMtoSG0Dk+XotrMpW0u2JTsvhmpXap9jy+Wd3X+3RoM1/ZH9pMEgvNj3lc/1d1zck60ozTysfa8WXk4onYERkT6i2VC/KiULenlLYCdAWnbrYTyyEpjpji9HUEJ3uhq4mxN4U0nWKzJMkcxTZHl+MvR6e68XvksMflMgBH7e7QptWbC208Z5cnjxQHP8cbf7S7aJIkSZIkSTJS3LWfh4OZvdDMPmNmt5jZzWZ25Yq/vdTMbit+Xips6yoz+7Pi/1eb2bFiu58zs/eY2YZRjYxkJltCpRRHe8pCw4oSpWz34kacgSDqXBGE39U1LbXj5oCTi58JbWrVC0Kb6cbB0GZ3+bLQBmBnL25GumspjpztFTpwFZTGn7aQmlXS7gA1Qd9z31j8XhqVGPtxoWFJiT6qdqc6sc2cMCBgqbd1YoBKQw9AWShPmazFn7eOcL1pdw5La0rOPzYpXf7XwA3u7mb2NODdwFeZ2Q7gDcAVDLP1nzSzG9zF8P+Qd7n7awDM7I+AFwFvWc84I5lJkiRJkiRbjDsM+ib9PLzt+qL7l+OfE3xF2O47gQ+7+8nCsfww8NzVzzez55rZ583sJuB71tqHmVWKbW/ooGYkM9kSlOiiMjmjI0iBLLcfiG2Elr7J8ceFNgCNSjzNaLK+N7RZENZULsWRrJnKhaHNZX5xaANw+bZ4fzsFNSBlUk21FMvzTAkyR8p0oYmKMMoG2D4WyzONNYSCQ4Gl5Tja3xAiuTsEnVCAU0Lz073N2Kbv8ee2LIQzlOlCJxSZI/F+XBbqsn0Q76/X1yKnSfJQbNMaf8zsu4FfAy4Avqt4+ABw7wqz+4rHVj6vAfwe8BzgduBdqzb9oiL9vg/4IvCnG60jncxkSxgIxfG9QXyz7vbiC7p7fCOuCo6h2vjTF7pUFZvxWtzUozi0XY/P0Z3cF9oATCzFzuj2mtZoEqE0rCz3R7MvpaEHYGI5TvPPCA1LiuPbUITW6/FnRNmOSn8sPk81QfFhVki7n5C6seIvIhPti4TtwG2DQ6FNy+LGH2X05KmleWlNyfnHQG/82WVmN6/4/Tp3v249Y3f/38D/NrNnA78MfDtrfwVbXcvyVcBd7n4bgJm9A3jlir+/y91fY2YGvAn4D8C1660j0+VJkiRJkiRbjdj0UyS+j7v7FSt+vuxgmtmri2acW8zsQTIl7v43wOPNbBfDyOXKVNdBYK1vW2ERdZGO/1Pg2RvZZSQz2RJqgnblmCBzpNj0B7EUUHcQ60QqKX6ARjX+rqY0ESnRzmbvZGjTtjhqsliKG5EABsRRsV3Ll4c2e4UBQw1huowyMVHSf6xpCsiKLmVLiK7uHo/fb4qE07KQ4j7c1Jqs2kKjkVKeoJxvF5psykIks6KU1EgjXOFxnX2hzfZBPHry7tqtoc1C657QJqcCnX+MSifT3d/EMKoIgJldBtxRNP58HVADTgAfAv6TmZ1+Y/9z4PWrNvd54FIze7y73wH84Aa7vhK4Y6O1pZOZbAlK57iSnu4LndxK3Wa7G6fBBq7V2im1pAOheU/peK9WYg3MRi1OqddFMfq+xWv60mJ8np4yEzsZ01UhXSw4YgrTwghHgKmx2K4kaGAqKTFlO7WaoIogpOYB5lpxDehST9CTFbLzFUkgPj5HPUHLpSqKoArTMGkTv7fbwqz0dCCT9dikmszvBX7EzLrAMvCiIvJ40sx+GfhEYfdL7v6gyIW7t8zslcCfm9lx4CbgqStMTtdklhhGRq/eaCHpZCZJkiRJkmw1bvSFCWUPe7Puvw78+jp/ux64Pnj+XzCszVz9+FuBtz6ctaSTmWwJZUEnU5nC0xHGvC214qaWWjVOg03XY71JgJoQFaxbbDPGdGhTRZgu43G79+Qg1r8E2FWJU6/bG3G6WNVujKgIepM9odt5vh2fR9B0OSuVeE0LQuf4rBBZnKiObrrMqU78PvnCQlznsNCLX9uF7mj0NrtCKrzZ0yK5rX782rrwfpsuxWn32XpcwtNqx41IybnFMF3+WK9ic0knM9kSSkK6vGGxk1WvxM5abSq2UUZBuiApBNDqx6nw1sZSYgAsWuxkuDCXfLoc39B2PvRL6prsn4hft8cJmffpquAcCinlHUJt4+RU/NqqunMn5mJnfK4VnyOl3nLfZJxSLQup8E5Pu6x3hAjKnkb8xa+7HO9PqducEiadNnvxmg/HbxEAvtSODXs2mk59yx7bZB0GObs8SZIkSZIkGTWbpZN5ppBOZrIlLHfjrui+EF3s9mNx7Fo5jj7Vy0LUVEhxgybq3BG0K+c7cZq/J3SgX1B+QmjTEpuaDgti3DvqSlNPvK+mEFlbFNLcY2Nx1LAspLgBxgVh81NCmruhdGkLUcqu0Mm+2BFONlq6/GQn3p/SzK1oqC8JlQCtfryz+Y4WfbynFHeFL3bjcZDdvqBU0TkirSk5v3AykpkkI6FWiR2/8XIsRt4rxU6WkgpXbFQxdhfqJBWUulWFeY9vjMslTRy6142nHk0uxt3su+rxhXRbNba5fynurldmgKvd5X1hW4rQ+nI3vtQq9Z91obu8KmwHYFsjPgcHJmKH9dhyXLd5bzO2OdaJz7VS29lpaLe1K9vPjNc0iL/U3l+NvxzeJWwnazLPQzwjmUmSJEmSJMnIMfrpZCbJo0cZGdkpxWmngaCTqdhUhCabRmlbaANQ87gDu0XcFe+C8HmtEqf5lXVXXYuaLpZiQfqjrTi6ONuJ97e/EadCx4Qo3byQBj7VFgauAxcIjUbKfPOOkOZWOt6niaOP01PxegCq9Tgq2l4WGn+EaK8yJ92U5qBKvK/xsnbTVmaun+wKc9kFofkkWYvzIV2+aS1vZnahmX3EzG41s8+Z2U8Wj+8wsw+b2W3Fv9tXPe8bzKxvZv9qxWO/UWzjVjP7rWJmZpIkSZIkyVmLu0k/ZyubGcnsAT/t7p8ysyngk2b2YYbq8H/t7tea2euA1wHXAJhZmaGA6IdOb8TM/hnwTcDTioduAr4FuHET156MmG5vNBMvlEk9vX7cZFMuxZGsudK90ppKJUHCRai33FaLdTnVZqSImcEuye4pE/EYz12N+AKopITmhbrFujAVR6mRVKMHx5fjKLWyP4WaMDqnpcgTCdqWAPV2HMlUhKJL8ZhjqkKUsiNIWJ3sxDaqhNGJlhAVFxr2Fu14aKNck5LzE3EK6lnLpjmZ7v4A8EDx/wUzuxU4ALwQuKowextDZ/Ga4vcfB/4E+IaVmwIaDGdvGlAFslXvLKNRjVO4Y5W48adaim/6p5q3hTbd7onQhmq8HoCxWizG3CjH4u+VETUQKZp8e4XueoALJ+Kb+oGx2MmqCs6h4mQozuqOEY2eBFgQ0rwL3fgLy06h0WhC6GSfaMRlJ1PTYrq8IWiXtoXXRHjdys24pOKUkJpeEoTfFb1NgD3j8e1vYSFe9xEhXV4tC9q9vVOhTXJu4dn4MxrM7BLg6cDfA3sKBxR3f8DMLihsDgDfDTyHFU6mu3/MzD7C0GE14LfdfU3tiWLe5is370iSJEmSJElGw4B0Mh8VZjbJMDr5U+4+v0E55RuBa9y9v9LGzC4DngScziV+2Mye7e5/s3oD7n4dcF3xvHM8CH3uoUgGTVR2hzb1qThKp4ynVKd0jAlRSmVST9vjNc0QT/OZ9lhS6LBrEkZ3LcTp8h21+CK5S2gyaSg6kcK3fiX62BBlfhQUfc+y0Izkws1mQdiOMsISYLKuaaVGLApNVMrEnxlhKtTR1ujaCJT+oKly/F6qD+Jop1Kek5x/OCZlAs5mNtXJNLMqQwfzD939vcXDR8xsXxHF3AccLR6/Anhn4WDuAp5vZj3gcuDj7sM7sJl9EHgW8BAnMzlzUQSLO2VhZKBQk7ibi0IbK8U3q7Zpacee0PGrdJf3ELT0lC51Yd7yQKwj/Md2XEvbmIvP945a3F09I4ioTwpp92Yv3pdaRzkjOGI7hFT4nOActgVnVRm9qc5CVpzMSaFTfXw83k6jEjv1nUFcUrPUi89jU/z+MCv42NWSUJ7RuyC0OSqoQsSf7ORc5FyPZG5md7kBvw/c6u7/dcWfbgBeWvz/pcD7Adz9Une/xN0vAd4D/Ft3fx9wD/AtZlYpnNZvAeJRDUmSJEmSJGcww7rM+OdsZTMjmd8EvAT4rJndUjz2s8C1wLvN7OUMHcjvC7bzHoZ1mp9l2AT0F+7+p5uz5OSRYMI3sUY1TuHWTNCbFNK886U4xTXucWRBnfijpNUbxBHYGdsTr0nQ9mtarG057lOhDcDOQVwKcKQZRyAXhK7okpBSnajE+1K6tJd6WnfIRDVO808JEUElXXzXojIVK47A7hAm+YDWsLMwH3eqK1ORWkJ0eVyIdu4fi1+PxZ72ua0J2YzZtjDxqaNMc4pf2+T843zQydzM7vKbYF3v49uC51694v994N+MbmXJqLFSfCOaLMe1lFPEaac+sZOxLDiis8Qj3FQnsyR0l5Ysvsk2PL4R1QQRdcVGSakDLFosvdLtxzf+z8/HqdAL6nEqVKmlLAspdVU25O6F+MvBgYn4HCljLJ8+HqempU5u4fgBasKIyppQS6vMgZ9uC7caQfDhpDiXXaEqfLx3CONQd7XjL8d3D0YjPZaceyi12GczOfEnSZIkSZJkq/HUyUySELM4JDAQuquVDuw6cdRAsekRR2g6Jqo6C5Q9/qgp52ihFIvRbxNS3JfWYhuAfRPxazstBJeqwpf1k0LacU8jXs9YdTTNOqDpcir1Uo26MOpUiAi2hXPkYrdqV0hhKzbSvrrxdpaFkoqucGxqB/oh4eN9bDmOnB/vxRvqmfZ+S84vHJPGm57NSEdnZt9cTONZ+djXbc6SkiRJkiRJzn0Grv2craiRzA8BnzCz73f309N23gyko5ngHkcFBx5HcgYWRw2UCKQiKdQVIgs1jyOioEVgm8yGNkpt5y4/ENpcIEwXmVBCi8BEJba7cCx+3XYI9X+KtO1yP75kzQiv7bYxTZ6qIjTaHBGm2TRPxOtWmoxqQk3q9klthGGtHm+r3YrXPbsYH79yk1xfQvkrjAnHXytr0dcp4TPQG8TbmhN0WZUsRXJ+spk1mWb2DcDHgRe5+3uKx14K/Fxh8ivu/rZgG1cBr3X3F5jZ1cB/Bu5nOH3xVuBH3Nefv6o6mV8oNnyjmb3c3f+O9Zt6kvOMYW/WxrQGgvi3EFeftr2hzUUe6zbOVOImEzWJ0eoLae5+nMJdEnQyx4TRk5PV0aQ4Ae5eiI9N6dIdr8Q2M8I4SMVZUeZ7TwtNNgAXTMTqhYpTpzhiirOqaGkuCU4PaM1Ik8IYy4P74i9QFWH0aF/o5N51LG6OG5uNlSwAbrf4szQmKLa3+vF2lheErqbkvGPYXb452y6yz7/OMEh4+rEdwBsY6pI78Ekzu8Hd4w/xV3iXu7+m2N4fAS8C3rKesepkurv/mZl9AXiXmV1fLDBJkiRJkiR5BGyihNGPMxyG8w0rHvtO4MPufhLAzD4MPBf445VPNLPnMpzCeBz41FobN7MKMAEbp+lUJ9MA3P02M/tmhl7r08TnJuc4Q438jamW4tTzWEloRhG+2jQ9jtA0+nG0r6zk74DmIE5zKlHKZimerlNR0nedeD1KRAy0qOhhoYGiJFxqLhGkBLcJKeXZdhxZ6sxqx79nMn5N6oLMz0RNmK4jRCDnu7Fc2N1C1BRgdzd+TeLiDCgLJQWl5fiDu7gUv25HluI3yaLYrKR8vJVIiiKFNFmNMzCzfE7YW3Ku8TCidbvM7OYVv19XjNJ+CGZ2APhuhhrjK53MA8C9K36/j1UfczNrAL9XPPd24F2rNv8iM7sS2Ad8EdhQt1xyMt396Sv+vwR8v5nFOcnkvKBSjoW9Zyy+XU0JXdHKqMc77NOhzQPE+9rV3xfaANQ9Tr3XhI9aXTj+rlCTer8fD20mu5o49Fglfm2V0XttoSRNEdFWUvNdYV+zQpc2wEnBYVU61acFwfZd43HaXbFRxNEB2kJZwbwwl1wRWnchWtMU1nNcWM+9y1q5gPI+0WpJ42ObYX9oc29okZxruENPj2Qed/crRNs3Ate4e3/V+3Otna1+l38VcJe73wZgZu8AXrni7+9y99cUUx3fBPwHhkN21mTDT7WZ/X9rLGAlP7HR85MkSZIkSZK1Ub6ARZjZq4EfLX59PsOay3cWDuYu4Plm1mMYubxqxVMPAjeutaxon+7uZvanDNPyj8zJBFaGZn+RYcFokjwIRSdTGb1YdWFyjtBvNlWKJwfN9uO4wZzfH9oATJXjVNiEEDmdHMRRwzpxJKcvdKkviRqgh1rxtmpCKURJiPYoaSMlXa50aSvRN4BDy3EkcyA0YymTipTu+jHh2OpCah5AqODgZEs5/vi1VZqMlElFLaHMZW9di+Se6MTbOtqKj+2exfhEnrJ4wlhy/uEwEt0Bd38Tw6jiaS49/R8zeyvwZ+7+vqLx5z+Z2ekb0j8HXr9qc58HLjWzx7v7HcAPbrDrK4E7Nlrbhk7mytZ2M/upqNU9OT/pD+KL7DJxd3m1FN/QlFGPk4N4hOF22xXajAui7gANQWi9L7hQcxZ3Mh+3Y9KaIr62eolk99U74vO9o6ZcJuPjV4S2lbGCXSFd3BFTyktC7eoxRSBdiFYo4ymV7bSa2vt2vhN/YamW4tdWsekITr0iSq3MgK+KYzWb/fhcLsU+PQ9YXJ5ysrXhfTg5j9lKDUx3P2lmvwx8onjo7iJZKQAAIABJREFUl043Aa2waZnZK4E/N7PjwE3AU1eYnK7JLDGMjF690T4fzsSf7CZPkiRJkiQZCbbps8vd/epVv18PXB885y8Y1maufvytwFsfzv5zrGTyqBn04w7c+V6cLvJKnFLcJWhgTnrc1FI3oRGnNLou1bpwIRkn1vdrCyn18XJ8bJdt047t4FgcytkjaCkq6WIlFXqkFUffTnbic72tGq8HYI/QOa6Mw6wJ0b6yxTaK3IkynhFgTuguHxdet0VlO5X4PE4JOqmTgs2CePxK448gk8mlpT2hzWzjiaHN0vLd8c6Sc4rN1Mk8U4gafxb4SgRz3MxO5zyNYd3n9GYuLkmSJEmS5Fylv3k6mWcEUU1mHDZJEiEqqOhkVi3W9xsbxDqB00Jtp8KJQRyhBWgJTTQ7hCjlmHAeXahaKQuSQs2e9vX5rqU4utgdxOdbiXYqtXQNQZPxWDs+j8IpAmBHLY6cXTgeR+mUOtETrfi9rdQkqum3KSG6uKTICgmR3F21+PiVKG1PqNs8IjSrAdy7FJ/L2XYcyV3uKyNTRzeFKzl38LN8LrlCpsuTR02lHKent5cuDG129OOucIWjPhfaDARnbbEUbwe0ueTjg9iBnirHN8eGIHw/IYxwVK9ry0JzxN1NRdg+XvfB8bgD+cB47NDvFrqLTwlNLypKN3tJOOPKmg4L3d4HxLnsOxvx+d4t+KsXCg1bSue44ogfW44dcUVvFWDgyppim8MWj4xcGuRYyWRtNrsm87EmncwkSZIkSZLHgIxkJkmAe5zCVHQy64K+Y11IO/UELcmWx+nbppjiUtL8ZeJtVYQOojEhStnpx1etY5pMJhcIajjK+M17lxUJG6EUQogaailV7bU9IkQOr9gRRwT3NOLoohJZVGxUWv348q80ESk1ZcqNVGlEOtyKbZpaTxd7xuL3SUkoYZlbjEthNMXd5HxjVDqZZzLpZCaPmn5/IbQ50vt8aDNbjgXSTXDWdlicmq8TOzQtQbcS4Hj7i7GNxTaTpVjUfUf/YGizc7AjtBkvaXVrvUFst01IT09XBQ3McrydnqBJWhdSszNV7dI+URFqYIU6SQVFb7Is2HTFufQdwRlXmO8KYyWFlKBSJztWjs/1Qk9LP55sx9v6wmJ8DbivfFdos9w6Gdok5yejmPhzJpNOZpIkSZIkyRbjgNiDedaSTmbyqFE6npXRk2UhXa7QtnhySll464+JCl1PqD5b2Facdu0M4lTwYimOGncRNAkr2lSYaaEreHtN0KWsxe8RJaWqRLt21+OO8Io4FWZW6JxWupm3CfqOdaHbuyRETVuiTuRCN153W2jGUUZ91gVVAEVv88ggtjkhVhQoCgsXVOPPiXcvjvdVi5sDF5q3hTbJucc57mOmk5k8ekqCZFCtNBnaKLWNSpfmA3OfitdTiR3IgxPfENoAzAzimqyGCSP8lFTwIN7OZRPxud4/rqVKLxyPC9ymKqOpKmoJaV5lvndXST+JS1ZS4eOCA6U4dDVBwkhJqati7MqIzgWhU3t/vGzJyVRstgllDqURygVVhG81M+XYEd3mcSlMTjc//xiKsWe6PEmSJEmSJBkxGclMkoByKdbJnCrFGphTg+2hzVgpjkD2Bb3FhdZ9oc09ix8LbQBO1HeHNnsqT4ptfH9os70ch4221+NvxkqEErSxijO1uFNfGRmoRCnnBS3JQ4KWopLiBbh4Mi69qAmjF9u9OLp2XIhkKiMsTwqNOKBpoLaEt0mzH2cy9gkjQ0243SqR1fmOdtue68TvgaoQyewOhHGgQgQ6OQ9JMfYkiakIjk/NhYk/Hqfvqhbf0MpC+n68FjuGY9W4SxtgorQrtOkRO1nHS8dCG6lzXrgxLomC1Xf2YqduTKhJfOJU7KzN1OMvB4rw+UQ39owUuRyAvWPxHWCyHjvZE4L2u5I2WxKctQtK2heIhuD4TEh1ovG+FoTzrUwOagmO8Zh4V2sJNdBzfeELhPDZ7gs2yflHShglSZIkSZIkm4Cd37PLk2RUKN/k3YSifkHUfbocF9mXy3FEsCw04gBSUU1J0PesCiLy8704anbHfHyO7hSva7OdeH8z1XjdXY+bui4dFxqfhOYQJUarpstPtuOoeEVY09RYHKXdIYzMVLrLR9lIoNwA+4LeptKwpNAWNtMQ+372jcUZGCWV2ewJkfN+3IyXnJ8I003PatLJTJIkSZIk2WIyXZ4kAooGZtfiSM4isQZkk7nQpi5EzSZ8W2ij4sJlYsqnQps9NWHdwljJvvDVeLmnXdrKwmt7Xyd+3b60FMs8HRyLo2a7q3FktVwfTQMRQFuQVVoUpIAURhWl7AraliotoQZ0SZBMWhAanxS5qJ21+H3bECZHgTaF6lT8duPQkvCZ7GdNZrI22fiTJAHVUtzUs3OwJ7TZRpxS6nu8nXlbCm3qHjsZ40KTEcBUOXYyttfjm2yjLDgQwgWpL/iPYw3toz8mNAiV2vG6F4R77LF2vKbdwgjLMcER3V6PZ4mDNt+7P4iPvyM4a9NC49PYRHwiF4UUP2iO9rjQ+KMoB0z14s+IInyvzKXvieUCh7vxtr60GB//PZ1Toc0Dvc9Ka0rOP85xH1MqX0qSJEmSJElGyFCMXft5OJjZVWY2Z2a3FD8/v+JvzzWzL5jZ7Wb2OmFbl5jZP62x3c+Y2V+Z2Yb6hJsWyTSz64EXAEfd/anFYzuAdwGXAHcD3+/us2b2YuCa4qmLwI+5+6dXbKsM3Azc7+4v2Kw1J5uHCRGIRjmO9kxV4ijNk+qxbqeiJVkVRw+OqjtQ0QlcFtRp5jvxeoSgKQA7J+LX5KnbhUk9wr6OtOLt7K7Hr/+eyTiSvWNnbANQrsavSWc5PkeLC3GTSU9IzXeE1PSYEFlU7ZT0/LIgT6RMPDolbOfOxfhc98Ubck8oK6kJ+kxzpZOhTbMTTypLzkNcf78+Av52tb9U+FJvAr4DuA/4hJnd4O7/95Fs18x+DXg18Ib1jDczXf5W4LeBP1jx2OuAv3b3awsP+nUMncu7gG8pHM7nAdcBz1zxvJ8EbgW0YdLJltIdxF2xx8sPCNuJb3r7u7F25XQtTgMqH+yyerMS0tPLwg4V4Wtl3ZfF5Z9cNK51V0+PaJ72olCTd0jQ2/xSM35t947Fta3T01q6vD4Tvyerk8I5Ksefkbvuj9/bR5a1mfMKSqd+QxCaHxX7GnGZQ6MU37Lub2m3taPCW0DRAN05iDV3T44/PrQ5PHc03llyTnE6krmFPAO43d3vBDCzdwIvBB7kZJrZ1wPXA03gprU2ZGYGTAG3b7TDTUuXu/vfAKu/4r0QeFvx/7cB/7Kw/Tt3ny0e/zhw8PQTzOwg8F3AmzdrrUmSJEmSJFuNiz+PgG80s0+b2QfN7CnFYweAe1fY3Fc8tpq3AD/h7t+4xt++2cxuAe4Bvp2hM7ouW934s8fdHwBw9wfWyeW/HPjgit/fCPwMQ495Q8zslcArR7HQRKdWjtPTVY/TnGMu6NYJUbOjy3Fk6b6lOIrTFCKroEVXpquxzVQ1/s538WQcWrlsMo4I7RBGQYKmgah0YO+oxedS0a5UOpnvWYojmZ37te/Xl/fiVOjUHmFS0f44IvjkXfHEp8vmhLGKJ+PPEcDJxTgqqrz+ylhNpTmqJ3TFz9Rim/GKdvytfhwVPyU0tR2sxamD2d7jQpvDaGNsk3OLhxHJ3GVmN6/4/Tp3v24d208BF7v7opk9H3gfcDlrVy49aAVmtg2YcfePFg+9HXjeCpOV6fJrgN8AXrXeos+o7nIz+1aGTuaVxe+nazo/aWZXRc8vTvh1xXPP9aatM4Zt1YOhzZNLl4Y2eyYFMW7BN1DSzktCjnubKMauSAaVLb5Z7RAO7sBY7IhNVuIToKQBQRvj1xScTCU1u7MR5y/3Cce2LNT/HRPmmwPcdiROYT+lEac5K1PxuitKbWtFSHEva1+OSkuxk6l06m+biksBXKjtnF2I13NSKBdQxmUC7GvEdm1BFaAr7G6+l6nw5KEMo5RyTf9xd79irT+Y2auBHy1+fb67H/ryPtw/YGa/Y2a7GEYuV04iOQgc4sEYevD0BuBPNjLY6u7yI2a2D6D498ufPDN7GsOU+Avd/XSV9DcB/8LM7gbeCTzHzN6xtUtOkiRJkiQZPaPoLnf3N7n71xY/h8xsb1EziZk9g6GvdwL4BHC5mV1qZjXgBxg6iiu3dQqYM7Mri4devMGurwTu2GhtWx3JvAF4KXBt8e/7AczsIuC9wEvc/Yunjd399cDrC5urgNe6+w9v8ZqTgDFiYfMxQURcyBaPbDrCtLAzRZMSYLETr0oRP1dSky0hanhUaKDpDDQtxYWe0oUfb2dJaPypleJoX0OIZCpd0zOiYPmiEBVVGna2nYhT6pMTsU2lGh9/tyPOVRSo1+LIeUNqfBpNYmle1ABV2F6Lz6Wy6mXhM1kZ4bqTcwdn07rL/xXwY2bWA5aBH3B3B3pm9hrgQ0AZuN7dP7fG818GXG9mzcJ2JadrMg2YA16x0UI2U8Loj4GrGNYR3Mewxf1a4N1m9nKGRaPfV5j/PLAT+J3C+e6tFxZOkiRJkiQ563kEGpjSZt1/m6G6z1p/+wDwgeD5nwS+ZsVDv1A8fiMIUaUVbJqT6e4/uM6fvm0N21cQeMPFwd34qBeWjJwycbRnqSdEqbpx1GxG0LdsCIGceaHv5UuLca0ZwCyLoc3F1TjapVxr7l9WIsLxOVKrgJQ1KRdJRQO1Xo7r7apCvd2Y0EDUKGsSTkrDiiIrpNT2KTTqcZS2JOq77pyOtUKFcmOW5uIGGmk7y3G0T3k9VNklRXpLyRxMCeMpLxzEjT93hhbJuYif4zN/zqjGnyRJkiRJkvOBx0Anc8tJJzNJkiRJkuQx4Bz3MdPJTB49A+L0VL0Up52ma3HaaVucmZfkeZRvjztrWrH+jMfpwkmhO6YuLHyiEi9cKSSf11RumG3HGxurxOueFlKKR1qjGSt6kaDJuX26GdoA7BUkgzqd+DI61xQ0YEc0nlRJTQNUhGPrC+niU4Le5tFmrF1atng9ynjKLyxqn9vDQjWMIod2TNDlXTRtjGly/pGRzCRJkiRJkmSkbGJ3+RlDOpnJlqBID41qdve48K7eKQQ7yqY1a7SFRbWFE3BkOTa6TwiIKBHhZ+7UmiMeNxnvcFKIHPaEiNiJdhztu6cZv3BH29tDm6cJkkoAF+49FdpM7oqjojtKsU1/OX7dWotxJK8mCPYDVMfj91uvFb9ui8JrojRsKZHMKUGe6uJxTZ6q1ReionPxmv6pd29oc8w3HO+cnMdkJDNJkiRJkiQZLa6Xt5ytpJOZPGo6Fhc3dQdKJCOOLi0LAbhFIZDTFGw6fU36XblGtHqxlTB5kidsi6M0lwvi2JdNxbJLABfungttJvfEelAloZa2J0Rpn3A4ru277Xgcybx9YTLeGVAX5JAedzCOdlYvitdNI74cT8zHgu394+JdqywI7QthlgPj8Xtk+kg8MvTkfHyOTgjjQNvCKFSVhnCOLrMD8YaE4GrOLj//cEY3YORMJZ3MJEmSJEmSx4CMZCZJwMDj8OLyII4IdQZxuGtKCPcJzc4MhDF3Ha1sUYpSbq/HoYwnTMfbeeJUHDXe2YijXSpHTk4JVguhxcTOONopaLGzY39c2/h1M3HUrLUkhFbRomtLh+II/LYLhNGLE7FKAePxun2gvf7Ne+P3ZG1SyEAIr9vkznhNA0FofamjvW4KXSGEtF0Y/mAWr2l2YaeypOQ8JCOZSZIkSZIkyUhxnP453vmTTmbyqNnh+0Kb7bU4SiOUP9EVPpCKTqZio9Rjqds6IJTkXTIRR/umhU5uhZbYXX1vO174zSdmQpv/v71zD5L8qu775/RzHjs7s+9d7UtCyAJJSHKQRQjClm3AwsUjDnEBpuJAFaZISZikKhQOlQSCqQqx7MRUIlciYwG2U2BXwLFsiAHb4eWyjQRIoAdIK62kXa2k3ZndmZ1n93T3yR/di0bK7pwzbM/0Ts/3o+rSdO/p+7t9f/fXfX/fex7/cGoitNl3MOHbmHGlTEQy1+e798V++Mm4ZOjVl8Wfv7ArVhZtIFF6c19OGxnZEs8lK8TzxOuJ4xXibYHhejz/97Ri1TyTSxPg0dn45y+V8aLPFwliden32aNFphBCCCHEGqOykkIk2FuIlZyDm+KpNlaJr7ahhC9lpipO2WKb6UYu3165ELf1wk2xL+WWauxL6ImqMCcW4gjcY/O5qigZTaya+PyHpzaHNuUj8dF27omVrMrWuD+bD8SqGcDgWGzXWozniSf8dhmOzxu742vNLsnN2+Lk6dDGDx0PbZqT8dy2RJc8MdkmZ2Ml95mFhG8rOd/tjN/m+ELsbzuXyMAhNiCuRaYQQgghhFgFvM83zLXIFOfNWCWeRgeHY0ng4FAcgbpjIFb7qqXYkSpTgWaukbs8qsX4eIOJfIsZTtdileZEwuaZWk7tSgTFs6Maf/65xHh/ZzyOwP2JYjyPLtodJ9ws7Us4yQLVLQm7UmKQFhK+tPOJqPDJWMmlnPxar3dnTjZOJ/ykE26S5UQk+9aROLvARYlcmgD1VnzeGh7bTNViv9ViwkZsPLRdLoQQQgghVoVmnyfK1CJTnDflTHh1gplExPPAYqzSmSUq0CS2KIoJX0OA6USfjs3FithMwgd0NqEInkiqlBkyroTj9fi8VQtxn2qJPInfOR6rnUOH4vO/bUvOJ9Mu3RUbXRxXfPFNibD4hFOiTZyK23l6PLYBmI/HwBPJYhuz8Xmrz8dzpLYQ/xzNzMUqZWZnAWBbNVaXFz2WYI8PxHP7aGJ3QWxM+nyNqUWmEEIIIcRao7KSQnSJmUasdowkfNumFuMpezJRFeRELW5nsp5TaDPR7C0Sak/i22bvQOxH96pLnwltdl6Sq11euSgep8JoIlI9oXb7XKwsNZ6O/RYnDyd8Uv825yO3y46GNoUdca1037EjPthQwv9zMI6utsVkLtWnY1XUEhWGhq+KD1U6HJ+3qUfiz7aY8KMcSCqZo+V4nE7W4/mfiVKvkVPOxcbDV0nKNLMbgd8GysC4u/9U5/WbgI8BReDj7v7RoJ2LgT9396s6bf4pcBgoAMeBX3L3c6ah6N6+mhBCCCGEyNFJYZR5rAQzGwN+B3iDu18J/GLn9SJwG/Ba4ArgrWZ2xQp7/XV3v9bdrwbuAm5ezlhKphBCCCHEGtPeLl8VJfOXgM+5+xMAS5TG64FD7v4ogJl9Bngj8MDSN5vZS4E7gDngG2c7gJkZMAIcWq4jWmSK8yZTfTGzpZQhk3ak1owPlunOpnLu4s8kIx/KpN4ZjLcUr9ofb4WPXR2aUHzBztgIYOtIbDOasBkZDk0sERxUmY63+Xc+9lRos3hvPI4AC4fjczv4zR+ENoVTceJzto7GNouJtEPHT8Y2AEOJILpEerIM1YPxOO7fHJ/bmcfjOZIp8wlwLJHq6Hgi9dAj0/FW+NOFxzJdEhsMx1cSXb7dzO5e8vx2d7/9HLY/BpTN7Cu0F4Ifc/ffB/YCR5bYHQVedpb3fwJ4j7t/1cxufd6/vdLM7gG2AbPAB5brtBaZQgghhBA9YAUumePufl3StgS8FPhZYBD4WzP7O86urzynB2Y2Coy5+1c7L/0B7e31M3zd3V/XsX0/8BvAu5friBDnxXBCptxZjRWYjJJXSqiGU4nAn1bCoX8kUXoSYDFR6nHXQKx2ZFTK0RfFimhhW6wa+kwi8TfARJzYnFJcetAuj9P8sCdWV30sVvvsQKKsaDMX01k6EatrjSfiMSrOPRHaFK5MjNGWuDwnFyWCjAAaiQCZjAI7FZdMbE0nFNjE5VYeiM/b2GBcsAFgNFF+9ch8/D2xOZH8vrSYK+MqNh7d2C43s5uBX+k8/XnaCuW4u88Cs2b2NeCazuv7l7x1H3Ds+c2RuhoBuBP47HIGCvwRQgghhFhj2hV/PPVYth332zrBONe6+zHaEeCvNLOSmQ3R3hJ/kHagzmVmdomZVYC30F4oLm1rEpgysxs6L71tmUPfADyyXN+kZIrzZlM5VvIy+dozJdyGCrEiuHsoVk1256oKpsikVdm1KVa7BrfG/W7FohHNh+LSg7WJ3P3lyePxQFlC8b3ox2O/xfLL4pKBdvCi0Ma3J3zyMjZJyo2ESndyMraZSqSVaiUU2ERSewCmEyr1yXgu+UL8+T0RHtuci20WFxKJ/yu5cpl7h+P5lmGuESuid48n6mqKDclq1C539wfN7C+A79JOxflxd78PwMxuAb5IO4XRHe5+/1maeAdwh5nNdWyXcsYn04Ap4J3L9UWLTCGEEEKIHrBaydjd/Vbg+UE7uPsXgC8E7/0W7e31M3yo8/pXgESE4rNokSnOm6FifCe2byj2kzqwZSo+1nCsZFrCb7OQ6HPGBqCViGZPVAxk4VR8OS4ci22mZuOk1tP1XJm7RkKlrRQSvn3fiU12Tcd+iwMvj+eRXXVpaNPavz+0AWAkjpz3hLpoo3GpR3sgVnt5OE4Oz2CyhGEpkZA+0VZhR8IHuBbPkdozcXL0UiUe66FNucTntYRfdnEuvpaqiU2BhiUT5IsNRTu6vL9r/miRKYQQQgjRA1YpT+YFgxaZ4rxJVINMMbOQyNuX8P8bGOyOalBPRJYCzC/E/lan52K/rcla/PlPJhTITCm8LM3E99+uROaAyUS/J+6NVaOLEzkgx56IyyUWLj8S2gCwb1dsM5xw8K0n5uR8HPHfPJbwkZzLlVX0xS79uCUE0dZ8fKyF0/F1dOT4WGgzmyg9C3A0cU0+uZDYOViMdzL2Ny8ObR4OLUS/sYrJ2C8YtMgUQgghhOgBvmpemRcGPVlkmtljwDTQBBrufp2Z/SJt59IXA9e7+90d21cDHwUqQB14n7v/dS/6LX50SoWEL1U1VnsKCX/LyclYWXpyelNoM5H0W5xejKWchUTEby1hU0wouVdtjqNmX7AtEe0MbN4a+0CWErkLm7X4s82djsf79FSsPp3661hab/1VrAgCbN8eVw8auTxup7gnUfGoHM8jq8Y2tSdySv74kbhPGX/jSiKau1SK58hCLbEjkLgmD83EcwRgthHPk8l6/PlP1eNrsmjKFijOhkvJXEV+2t2XesPfB/wT4H88z24ceL27HzOzq2iH0yeyFgshhBBCXJhou3wNcfcHAdo115/z+tK41PuBATOrunuyZIlYbRoJtT/jJzWb8MmsFGN/s9lExZ/5ZqwINROVfAAGEnXJy4lEoXvLsSJ0za44SnnX1XEyzfJVyaowey+JbYZjX0qa8XkbmYizC/iR+PP7ZKy+Nk/l1L7Jh+O59PDXY0Vw1/ZYOR3ansjvmIlknsupZuVSwncz8QtRTMz/mdm44s2jk3FmlPGE2pm9bjMuqfVEfs/T9Xgc667ocnE2nKbl8rquV3ql4TvwJTP7lpm9awXvexPwHS0whRBCCLGeOaNkZh7rlV4pma/obH/vBL5sZt93968t9wYzuxL4T8BrlrF5F7CSRavoArWEkjndiKfaUCK6eiChZC4kVMr5Znx/dbyWCJsFBhJ+ohcPx/dF1x58OrQZ+wdxvwsv2BPasC1RAxtgIOGXWonVJR9MHG/rltDEdm+PbZ6Ma8DzUMIGGCvE523wmTiavTEfn7fiSMInd1t8PsqLuUCC6jO5Gt8RlvgVGZqMc1cWEv7GtYm4UtPJhI90lmJCFB0oxue2fOFsGooLjFafB/70RMns1NbE3Y8DfwJcv5y9me3r2P2yu5+zTqa73+7u17n7dd3srxBCCCFEd/Gkjrl+F6JrfntlZsNAwd2nO3+/BvjwMvZjwOeBf+Puf7NG3RQrYCbhUjKa8DfcMxrXbs74kWXyVg6W4v7sG8opIoOJz3bwYKx2DV6aiC4eS0TOTsc+mX78dNwO0DgS17fO5FusvCRRK/zAzthmJPZ/ZGd8rEIxd27t6ETCKjGWT8Vj1KolqlAlVEor57SD4paEX/KpXM7NiEqc3pIttTgrwo7Z+Pxn88RWE37SltBh5hpxO+t5u1OsHg60bP0uIDP0QsncBXzDzO4Fvgl83t3/wsx+wcyOAi8HPm9mZ4qy3wK8EPh3ZnZP55H4NRJCCCGEuHBpJf9br6y5kunuj/LcwutnXv8T2lviz3/9I8BH1qBr4kdkNhE4eSqhLrw4kSdzdH/s21XaFrdjle74owF4I6NSxKpRpp3ad2PV7NTRWO08OZ2oUgNM1eLa3YuJ+ub774v7ve/q74c2lRfHfpvsi/022RZHMgPYjvh45cvjuVQ+HivZrUfjyPnWfKwsWsaRELBKfN6sktg5eCqRlzSRb7OZyFs5XI6v7aFEtDvA6UTGi0yezKfn4j6dtniXxoiP5VJE+wrHadLf0eXyRhZCCCGEWHOcFt1xSblQ0SJTCCGEEKIHrOegngxaZIrzZudgvM2zvRpvc9cTW+qLM3E7mS2+QjXedsptg0NrPrHNfSreCpw+FSesHj8dBz48Mx8nR59LpHCC3NZjJq3UY1Px9vSjX4ttdt4VBzVddsXDoc3A5Tl3AduX2J4fTQQj7Yg/WyGRVqown3DzmIoDaACaj8Vb+IuxCbW5+LqdmIrHaHIhnv8narFNdm5PJwJ2TieC2qqJFEbVxbjf2grfeDje94E/WmQKIYQQQvQAbZcLETBWju/AM2pXI+H4P/7kptDm1KFYyXtyNlayjtdyl0emjN1IIvVStRiPYzGRsLpaiO+Mt1ZyZe4yn202kWg/lWg7EUD0yHQciPT03fG53XRvztl+39hkaLP7iidDm/ILY5XSRhLpqepxv1unYrUXwOvxPCkkcvFnGB2O+zSUmJNj9Tg5/nwioAdgeyX+nhgoxgpk0+N5u62eULvFBsT7fru8V2UlhRBCCCE2LI7T9MXUYyWY2fuWpHy8z8yaZra18283mdkPzOyQmf1aoq2LzewZW3cjAAASzklEQVS+zt83mtlUp93vmtlfRiklpWSK86aSKKuYoZVQzTI0W3E7mYTNP5jO3YNVEkmdd1Rjm83l+I52LJH4/YVjU6HNrv25ZOzVXXG/C5sSXyOtRDLy6UTJ0LjyJieejtXue8e3xQ0B48/E6ZB2TMbq6sUPxYroln3xOcmUnsy69jWmY8P5ifjclhLztjIQz9vFRH3acmL+VxZy8mstUX72hcOZ76T4eKeTCeLFxsNXYbvc3W8FbgUws9cD/8rdT5pZEbgNeDVwFLjLzO509wdW0PzX3f11nbb/I3Az8MFzGWvmCyGEEEKsOb4WidbfCny68/f1wKFOvnLM7DPAG4HnLDLN7KXAHcAc8I2zNWpmBowAh5Y7uBaZYk2YbcSlHpuzsWowvRi388Rc7EdVT6id+3IByCwmVLrdCSXnpTviEob7XhyrXZUrEv5/l1wW2gCwM1b8fDg5UAHFqfizlZ+JE5ZvOnoytDl44miqT42JhAI3mUiinfgdKW6K2yluS6h0pZwCb4NxpobGbKyyZLIilBNq58CmeEtwsBRfa4OJ5OjtPsWfrXw67vfUYqyINvrb7U78iDgrSmG03czuXvL8dne/fbk3mNkQcBPtyokAe4EjS0yOAi87y1s/AbzH3b9qZrc+799eaWb3ANuAWeADy/VBi0whhBBCiDXHcU9vl4+7+3UrPMDrgb9x9zN33me7k33OnZuZjQJj7v7Vzkt/ALx2icnS7fL3A78BvPtcHdAiU5w3GVVw1/BsaLNnd6xkVUfjuz5LzOpmHKRK/XROEZqdjpWc0e1xfsOhyxNR2ru3xh0aTSiLreTd82ycczHlSVuK1R6aiS9bS5RC3BePUXFnrPYCFCficoCV2VgR9PlYXWueilXThYfjiVuIpyMAmd82S/gbV6pxQ6dPx5HztUQ2h2Iib2umHYBnZuKI7xMLcb8nF+M5+VQ9nkdiY9KN7XIzuxn4lc7Tn3f3Y52/38KzW+XQVi73L3m+DzjGczHSnt3cCXx2OQNFlwshhBBCrDGO0/LF1GPZdtxvc/drO49j8ENF8qeAP11iehdwmZldYmYV2ovQO5/X1iQwZWY3dF562zKHvgF4ZLm+SckU582TibR8mbuZoQPxzVP5BWNxQ1sSOekSCs1QLefbNTYTq0ueyd2X6JNPxYpo81AcyTz7WNwdyFVzGRyJx6myNXFud8X+toWLE0puRu3dG1fgAfArErkrExSmYyWr8NSJ0KaU8DfNRPIDtKbieds8lfCTvDQ+3tZSYt5OxkruzOPxN8nxyTi7AOSyWSwmbI7MxTZThTjjg9iIrGrgzy8AX3L3H24junvDzG4BvggUgTvc/f6zvPcdwB1mNtexXcoZn0wDpoB3LtcJLTKFEEIIIdYaZyU+mStr2v2TwCfP8voXgC8E7/0WcM2Slz7Uef0rQO4OvYMWmeK8GY0FKBYT1Vzqx2NFxEqx32YhU/EkoxrWchd/ayYRgXwy/mwzx+PI4fn52GZ6Ia63fSThjwa5Sk0Zm8z5z1QXetGuOAJ/+5XHQ5vyC3Lfk7YnoZxvTihnhYSWPxL70tqBhAfsdK7iT2Z3ITO3vZG4bquxT25hc0I13x4rq3tquRywT03EfrmZyPGRxPffi8t7QpvvV/eFNvO1XFYEsV7o/4o/WmQKIYQQQqwxDngmv9k6RotMcd5cMhwrWYPlWIGYOxWrdJPPxMrC0VOxQnF4JlaNEmInAHPNhEqbiMAfTETOZtSnhcSxMn0GqCaqOY0l8g1mxrLWjI0OP7o3tBl6PB7HXQNxRDjAcDlWBfdticsQbdkX+ySWNnenmk+mkg/kcne2Em7J85PxNVmuxg1VxxKZIxJDVB3K1aUfmo77dGAo9lutJgq8tzweo00Lu0MbKZn9hq9KxZ8LCS0yhRBCCCF6QKuVuylar2iRKc6bkVJ8J7Z5c6zkjFwUKwuWKHiydTZWny5L1GRemM9dHvVEXeKFRmwzV4+du8YTefvqCf/HjB9lllrieJ7wtywmZKpmwkcuo5qeTIw1wOHZeLz/PuHbd93EdGjzogNxdPng9vi8WSIlKcDiTHzeFma68xNRX4jbqT0Vn7hGI+5zqZTbfty2Nc7dOzoSf5dsS5z/6Ubs2ztcjKtrxTNErCd8bcpK9hQtMoUQQggheoB8MoUQQgghRHfxFZWVXJdokSnOm6LFgQb1WryHV08kY7ZSfKxmLd5SayRKwWW2wQHmF+Ot1/lEMvaZRDubyvEYbR2Mt/hGh2P3BYDqQOKcJIKDGvX4/E+eHgxtTszFAVsna7FPxfFk6cHRRFDTroHYzaPeij///Gx8/jPb5aUtuaCuUiKLUzVRMjNR6TNFbTzeLn/iSJyeq1jIKUNDiWCkzPb8QjM+t5XENVKy7iT+F+sLpTASQgghhBBdxrVdLkREJol2JvVIsRrf7RcTOcQrCSVjoBErNMMJFQfg9IlYgdhRiRWo0Utj1bB0ME78bTvjQARGd8Y2AKVEFEk9ER05H6eC2TEbq6uXJc4biUA0ikn5bTFuyyfiAJL6Y3OhzcQj8TwaPxwruSOncip1oRhfb+7xOGXaydCox8faVI3Pf72RjHzqEpmdnJQNuWA00T840HJFlwshhBBCiK4iJVOIkExi70LCJ6m8NZY7S3sTpfdGqqFNRqGrNnIO2UO1xJ1oQsq1TYl+Dyf8tgYT7WSZixVIpmOVzidjmww2GvttMpYo8zjYPf832xr7wFaHT4Y2O0ficojNqfgHqRELq0Cu+MHEVHy91RL+xkOV2P+xklGgE4xtzpXVrAzG121GXa0nfDIzKbzExkSLTCGEEEII0WUcFPgjxPIcSyRa/v7T20Obi2ZmQpstj8SKWHUotikOxspqoYuuXZnyfI2FWDWZn479tqamY7VvJpmMfKGZSDSfsIHYT3SwGCtL24dilWrLWKwaDm1LnBCgPJpQoKsJlSpTwrEWGzUTwnJtOve1nonmPzwVn7cfzMTK+XDCb/Pykfi63TYY+5tmMjkA1MZju+lExoeT9VgRPpFQRBc950sr+giXkimEEEIIIbqMoxRGQoQ8FguQND327RqYipWV2ccTufQSPmmLrUS+zWTQbKatmUSU8kAi4rmUqJnoiX5P1BOSGLClEqs05USfmonv0YFS7Cc5uxjPo8HSjtBmuJTzkVtMjOX2hJK5KZHfdSIROF9MdHtzMkg5MW05mZgmmcwRB4Zjo4dn4uv/3qk4vcR0TqSmmtipyIz3QsKV9MmES3LdE1+kos9w3JMTdp2iRaYQQgghxJqj6HIhQmYSck+zlVC7EpJIwm2NU7VYWnhkcSK0KXtOEmpa7Eu4SHy3OtqM/d+qFssvtS6WKTuRUDybiS/JFgnZLKGabSrEymrma63ezCmZ9Vb82WYT1aOGEsrpXCOhdtZiubNcyOUArSbsLHFNjlXidh6fidtZbMXtZH6Ot1Ry59YTczKj9s4mkktkvpMWWnF2AdGPaJEphBBCCCG6ioOUzAsDM7sJ+BhQBD7u7h/tcZdEh4xP4kJCpbBEVYzFhCJaS6hP99e+GB+rkfORajRjJ9BSolTR5sEDoU0hURVkpvZUaNNo5iJZhyrbQptKKVZgK5bIb5mg3oqjyzc3d4c2I741dbwa8fHGFw+HNtsKB0ObEnGUdtNiRXywlSiLBewjzviwrRrPt8XEb+QTM7Hc18w4Eyd4fCb3o725HP/8DZcSUeGZ3ZV6rEDPL8ZZEUT/kVHUV4qZjQJ/CBygvc77TXf/ROff/jnwbzumH3H3TwVt3Qj8a3d/nZm9HbgVeBIoAw8Cv+zu5/Q6TtZW6y1mVgRuA14LXAG81cyu6G2vhBBCCCHOh1bysSJuBh5w92uAG4HfMrOKmW0FPgi8DLge+KCZbVlh23/k7te6+5VAHXjzcsbrRcm8Hjjk7o8CmNlngDcCD/S0VwKARkLJbCSukcWEK1U9o5o2Y/+nPYPXhDaNZN66hsfOhJbwpfSEL+V8czK0qSRU08FyTslbaMTHm5x6MNVWN9g68pLQZsGmQpsZP5463lwjVpcazVjtnC/E7QyURkObTJ3ji0rxGEFOOczsUmTI+LZOtOIdgWpCyU/5/wLNetynonWnelYj0afFRneqYon1xKoF/jgwYm2n6k3ASaAB/BzwZXc/CWBmXwZuAj699M2dnePfBsaBb5/tAGZWAoaBU8t1ZL0sMvcCR5Y8P0p7Jf4czOxdwLs6T2vQuG8N+rYe2U578nSFT5/4cGx0oltHWxO6Oj59Rk/H5uT0d2KbNejHMvzI4zPdpQ5McHfK7ntdOt4K0HW1PBqfc7MaYxP7sKw+X4RG7LfSZsDMll7ct7v77eew/W/AncAxYAR4s7u3zOxsa6m9S99oZgPA7wI/AxwC/uh5bb/ZzG4A9gAPAX+2XKfXyyLzbBrX/3dr2Bnw2wHM7G53v261O7Ye0dgsj8bn3Ghslkfjc240Nsuj8Tk3/To27n7TKjX9c8A9tBeKlwJfNrOvk1tLvQg47O4PA5jZH/KseAft7fJbOirpbcD7gHPGyKwLn0zaq+39S57vo71CF0IIIYTYsJjZzWZ2T+dxEfAO4HPe5hBwmPbiMbuWCv073N1pq5g/uZzdellk3gVcZmaXmFkFeAttKVgIIYQQYsPi7rd1gnGudfdjwBPAzwKY2S7gcuBR4IvAa8xsSyfg5zWd15byfeASM7u08/ytyxz6BuCR5fq2LrbL3b1hZrfQHowicIe73x+87Vy+CkJjE6HxOTcam+XR+Jwbjc3yaHzOjcZmZfw68Ekz+x7tLfL3u/s4gJn9Om3hDuDDZ4KAzuDuC534ls+b2TjwDeCqJSZnfDILtJXRty/XEfMu5SYTQgghhBDiDOtlu1wIIYQQQqwjtMgUQgghhBBdp+8WmWZ2k5n9wMwOmdmv9bo/vSQaCzN7u5mdWBKV9s5e9PNCwczuMLPjZrah86tG42BmN5rZ1JJ58+/Xuo8XEma238z+r5k9aGb3m9l7e92nXpEZC82fZzGzATP7ppnd2xmv/9DrPvWKzFjoN2v90Vc+mZ3ykw8Br6btkHoX8FZ333CVgTJj0alDep2739KTTl5gmNlPAjPA77v7VZF9vxKNw9JatmvdtwsRM9sD7HH3b5vZCPAt4B9v0O+dcCw0f56lk2tw2N1nzKxMO8jive7+dz3u2pqTGQv9Zq0/+k3J/GH5SXevA2fKT25ENBYrxN2/Rs8LxvQejcPKcPen3P3bnb+ngQd5XhWNjYLGYmV08hjOdJ6WO4/+UX5WgMaiP+m3RWZYMmkDkR2LN5nZd83sf5nZ/rP8uxBn4+Wdba3/Y2ZX9rozFwpmdjHw48Df97YnvScYC82fDmZWNLN7gOO060pv2LmTHAv9Zq0j+m2RmSo/uUHIjMWfARe7+9XAXwKfWvVeiX7g28BBd78G+K/A/+5xfy4IzGwT8FngX7r76V73p5cEY6H5swR3b7r7tbSrr1xvZhvWVScxFvrNWmf02yJT5SefJRwLd59w91rn6e8CL12jvol1jLufPrOt5e5fAMpmtr3H3eopHR+yzwL/090/1+v+9JJoLDR/zo67TwJfAVarnvW64Vxjod+s9Ue/LTJVfvJZwrHoOOmf4Q20/aeEWBYz291x0sfMrqf9PTLR2171js5Y/B7woLv/5173p5dkxkLz51nMbIeZjXX+HgReRbus34YjMxb6zVp/rIuykll+xPKTfcm5xsLMPgzc7e53Ar9qZm8AGrQDPd7esw5fAJjZp4Ebge1mdhT4oLv/Xm97tfacbRxoO+Hj7v8d+KfAvzCzBjAPvMX7KU3FynkF8M+A73X8yQA+0FHpNhpnHQvgAGj+nIU9wKc62UAKwB+7+5/3uE+94qxjod+s9U1fpTASQgghhBAXBv22XS6EEEIIIS4AtMgUQgghhBBdR4tMIYQQQgjRdbTIFEIIIYQQXUeLTCGEEEII0XX6KoWREGJjYGbbgL/qPN0NNIETnedz7v6PetIxIYQQP0QpjIQQ6xoz+xAw4+6/2eu+CCGEeBZtlwsh+gozm+n8/0Yz+6qZ/bGZPWRmHzWzt5nZN83se2Z2acduh5l91szu6jxe0dtPIIQQ/YEWmUKIfuYa4L3AS2hXovkxd78e+Djwno7Nx4D/4u4/Abyp829CCCHOE/lkCiH6mbvc/SkAM3sE+FLn9e8BP935+1XAFZ1y2gCbzWzE3afXtKdCCNFnaJEphOhnakv+bi153uLZ778C8HJ3n1/LjgkhRL+j7XIhxEbnS8AtZ56Y2bU97IsQQvQNWmQKITY6vwpcZ2bfNbMHgHf3ukNCCNEPKIWREEIIIYToOlIyhRBCCCFE19EiUwghhBBCdB0tMoUQQgghRNfRIlMIIYQQQnQdLTKFEEIIIUTX0SJTCCGEEEJ0HS0yhRBCCCFE1/l/T8vxbUYhf2MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "test_spect = data_preparation.compute_spectrogram(test)\n",
    "S_dB = librosa.power_to_db(test_spect, ref=np.max)\n",
    "librosa.display.specshow(S_dB, x_axis='time',\n",
    "                          y_axis='mel', sr=8000)\n",
    "plt.title('Mel-frequency spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "spectrogram = librosa.feature.melspectrogram(y=test,\n",
    "                                                 sr=8000,\n",
    "                                                 n_fft=1024,\n",
    "                                                 hop_length=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 57)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram = librosa.feature.melspectrogram(y=test,\n",
    "                                                 sr=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 18)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApkAAAEYCAYAAAAXq+2yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9eZxkZXX///5UVe/ds/YMywwwI4IIBFERTUTFHVFDXOKu4FclJqhJvjFBTb7BqIm4JDH5SZbRDCgmgiFGUXEhRlASVEDZERhkgGGGGXqWnum9q+r8/ri3sabpFarOM1193rzqRdfdPs+9U3Xr3POcRWZGEARBEARBENSTQuoBBEEQBEEQBM1HGJlBEARBEARB3QkjMwiCIAiCIKg7YWQGQRAEQRAEdSeMzCAIgiAIgqDuhJEZBEEQBEEQ1J0wMoOgyZF0qqQtM6yXpAsl7Zb0U8+xBUEQBM1LGJlBcAAjabOkMUm9k5bfKMkkrauDzCnAi4G1ZnZyHY4XzMBsRn8QBEGzEEZmEBz43Au8ceKNpF8DOup4/COAzWY2ONVKSaU6agVzoN7XXFKxnscLgiCYC2FkBsGBz8XA22renwl8sXYDSW2SPi3pfknbJf2TpFkNUUnvAD4P/LqkAUl/MeFpk3SupIeAC/NtX5F7UPdI+l9JJ9Qc56mSfiZpn6RLJV0i6WP5urMkXTNJ1yQ9cbax14zljyTtkLRN0ttrjtMh6a8l3SepX9I1+bJvSXrvJM2bJf3WFNegXdKXJO3Mz+06SQfl666S9HFJP82P/3VJK2r2fVZ+LfZIuknSqTXrVuRhCFvzUISvSeoCvg0cml/vAUmHSvqwpMvycewFzsqvy2fy/bfmf7fVHP9P8uuxVdI7J13TiyT9o6QrJA0Cz5f0ckk/l7RX0gOSPlxzrHX5/m/P1+2W9G5Jz8iv2x5Jn53t8xQEQVBLGJlBcODzY2CJpCfnHqnXA1+atM0ngKOBE4EnAmuAP5/twGb2L8C7gWvNrNvMzstXHQysIPNyni3pacBG4HeAlcA/A5fnhlAr8DUyY3gF8O/Aa+ZxfrON/WBgab78HcAFkpbn6z4NPB34jVz7T4Aq8AXgLRMHkPSUfP8rptA/Mz/+Yfm5vRsYrln/NuD/AIcCZeDv82OuAb4FfCzXfj/wH5JW5ftdDHQCxwGrgb/NvcUvA7bm17vbzLbm258BXAYsA/4V+FPgWfl1eQpwMvBnufZpwP8FXpRfs+dNcV5vAv4S6AGuAQbzc1kGvBz43SmM7mcCR5F9xj6Tj+FF+Tm8TtJUOkEQBFMSRmYQLAwmvJkvBn4BPDixQpKAdwF/aGa7zGwf8FfAGx6HXhU4z8xGzWw4P/4/m9lPzKxiZl8ARsmMoGcBLcBnzGzczC4DrpuLyBzHPg58JD/2FcAA8CRJBTLj7/fN7MF8XP9rZqPA14GjJB2VH+OtwKVmNjbFMMbJjMsn5se4wcz21qy/2MxuzQ3E/0dmbBXJjNgrzOwKM6ua2ZXA9cDpkg4hMybfbWa787FfPcvluNbMvpYfaxh4c37eO8zsYeAv8vMAeB1woZndZmZD+brJfN3M/ic/3oiZXWVmt+Tvbwa+zKON04/m236PzCj9cq7/IPAj4KmznEMQBMEjhJEZBAuDi8k8U2cxaaocWEXmMbshn9bcA3wnX74fkt5cM0377Rn0HjazkZr3RwB/NHH8XOMwMu/eocCDZmY12983x/Oay9h3mlm55v0Q0A30Au3APZMPmhuaXwHekhujbyS7hlNxMfBd4JJ86vmTklpq1j8w6bxacu0jgN+edE1OAQ4huza7zGz3nK7Co3Ugu6611/G+fNnEutrtJ+/7qGWSninpB5IeltRP5rHtnbTP9pq/h6d43z3jGQRBENQQRmYQLADM7D6yBKDTga9OWt1HZgAcZ2bL8tdSM3uUQWBm/1ozTfuymSQnvX8A+Mua4y8zs04z+zKwDViTeyUnOLzm70EyQxIASQc/lrFPQR8wAhw5zfovkHkDXwgMmdm1U22Uexn/wsyOJZt2fwX7x8AeNum8xnPtB8i8nLXXpMvMzs/XrZC0bCrJacY7eflWMkO2Vntian0bsHaaMU53vH8DLgcOM7OlwD8BetReQRAEdSKMzCBYOLwDeMHkLHAzqwKfA/5W0mrI4gUlvbSO2p8D3p17wySpK08k6QGuJYtVfJ+kkqRXk8UPTnATcJykEyW1Ax+ux9jzfTcCf5MnzxQl/fpEckxuVFaBv2Z6LyaSni/p1/Ip8L1kRmSlZpO3SDpWUifwEeAyM6uQxcW+UtJLc+12ZYlKa81sG1mCzz9IWi6pRdJz8+NtB1ZKWjrLKX4Z+DNJq5SVsPpzfhWL+xXg7XmcbidziL8li83cZWYjkk4m84wHQRA0jDAyg2CBYGb3mNn106w+F9gE/DjPTv4v4El11L6eLHbys8DuXOusfN0Y8Or8/W6ypJGv1ux7F5lx9l/A3WRJKPUa+/uBW8hiQHeRJRHV3te+CPwaj06UquVgsoSbvcAdwNWTtr8YuAh4iGx6/n35eT1AlqzzIeBhMu/lH9fov5XMYP0FsAP4g3y/X5AZkL/Mp9knpsAn8zGyGM+b83P8Wb4MM/s2WQLSD8iu3YSXdnSG8/w94COS9pEZpV+ZYdsgCILHjfYPowqCIHj8SLoI2GJmf5Z4HG8DzjazUx7j/lcBXzKzz9d1YHVG0pOBW4G2SfGrQRAEyQhPZhAETUk+jfx7wIbUY2kEkl4lqTUv5/QJ4BthYAZBcCARRmYQBE1HHtP5MFn8478lHk6j+B2yc7yHLIb0d9MOJwiCAxVlzSGulHR3/v/lc9jnKkkn5X9vlnSLsoYct0g6Y066MV0eBEEQBEGw8FHWdewsMztr0vJPkiX+nS/pA8ByMzt3lmNdBbzfzK6XtBk4ycz6JD0J+J6ZHTHT/hCezCAIgiAIgmbnDLKybuT/n6rFboeylsA3S7oUmK418RKyJM9ZKT2WkS4EJIWLtkloKfa4a3bS5a7ZXvR/5msr+n9NUkyejFb9y0GOV/1PtJig6mUhQanNsQTXdojB2TeqM2OVvbNvFDxW+szsUQ0rPHnpS0+2nTv757TtDTfcdRtZXeAJNpjZfOLND8pLq2Fm2yZKxk3id8lqCp8g6QSyiha1/CCvh/wEsq5js9K0RmZGk5/eIuGgnme6a56ok2ffqM48eVmbu+aR3f4/1uNVd0nuGfA3hLYNVWbfqM70tPg/qHQksGwfHBp317y+eoO75v27r3TXXDyU59qVrGHs3NnPT376z3PatlR8/oiZnTTdekk/AdrIunKtkHRjvupcM/vuHIf0XLLSaJjZzZJunrT++fl0+ZHA9yVdZWYDM457jsJBkIzCfh3+fBg3f0uoJP8f62Ut/snICZxQbC/5f4aWtxXdNVsTBECNJXhoGKv6i5ZtphKkQfAYMKBOn2UzeyZMH5MJbJd0SO7FPISsdu90o5pN6x5J24FjgZ/OtG0YmcG8KBSmC9FoHEuYyqvfWJa1tLprLm1JMb3qr1m1xdHJsNPfxkzCcIKnhpGq/8PRvvFt7ppBs2NQdvssXw6cCZyf///rU2zzQ7JWvD+QdDxwwlQHyqfa1wOzeoPDyAyCIAiCIPDG8AxSPx/4iqR3APcDvz3FNv8IXJhPk9/Io72UP5BUAVqAD5jZ9tlEw8gM5kV3x+HumutY466ZYqrz8E5/78wTelIkM/jP6e4a908eGxj399iOJpi67k4QBwqd7oo/2eMuGTQ9Vrfp8keOaHYVcNUUy3cCL5xl32HgDdOsW/dYxhNGZjAvLEGsYor4yOWt/gbCilZ/I7Ol4H9t9435x0eWEszQJygWgH/qGIwnKBeQonSImX8iV7AISBBf7EkYmUEQBEEQBN7UMfHnQCWMzGBeVM2/dMhognbMu8f8fSVjVX/XVzGBJ7Ot6O8RSpHRPpLA8dWSwGM7WvEX3Tvmf08wmtsYCFJQ/+nyA40wMoMgCIIgCLwxQxX/ByZPwsgM5sXwyIPumiNtI7NvVGcq1W53zRRUEnhPxxNopvAVpOi+k4K94/5u4l3j/jUrR8Z2uWsGi4DwZAbBr0gxXT6gfe6aRq+75kgC46ujxf/fs63k/+TeO9zurjlW9b+97hr1t2z7x/zjAsoJHhsK8v/3jFSjJsdIE8vjSBiZQRAEQRAE7kRMZhAkZ4A+d809o/71QPtG/Wtz9g35d3BqT5D401n0v5H3lPw1h8r+3vAnL/XX7G33r3t6O0e5a+7o/4m7ZuBIZJc/PiT9IfBOskt5C/D2/P0fAEcCq8ysL992ObAxXz4C/B8zu1XSYcAXgYPJQqs2mNnfNXLcwYFFip7B+yr+08i9CYocrlnmH4qQgi1D/sW7U4Rkrmj1n3prKfhrDlX8H8jaC0vcNYNFQII60J407BFU0hrgfcBJZnY8UCSrJP8/wIt4dM/LDwE3mtkJwNuACUOyDPyRmT0ZeBZwjqRjGzXuIAiCIAiChmMG5crcXguURk+Xl4AOSeNkfcC2mtnPAaRHPecfC3wcwMx+IWmdpIPMbBuwLV++T9IdwBrg9gaPPThA6Bu+y13z/s7V7pq39h/jrtleWOWu2Vnyv2GOJGhlWTZ/X+ZggpqVDw/6a966e9hdc+/4FnfNoNmJmMzHjJk9KOnTZI3Yh4Hvmdn3ZtjlJuDVwDWSTgaOANYCjzRgl7QOeCoQgSqLiBStLPvtIXfN3aNPctccT2AIpUimHEpgZG4d9tccLPtf3K2D/g8NO/BvJD5aXhyhJYEzTW5kNnK6fDlwBrAeOBTokvSWGXY5H1gu6UbgvcDPyabKJ47XDfwH8AdmtncazbMlXS/p+jqdRhAEQRAEQf0xULU6p9dCpZHT5S8C7jWzhwEkfRX4DeBLU22cG45vz7cVcG/+QlILmYH5r2b21ekEzWwDsCHfp7mLTy0ixsv97pp7R/2nxu4vjLlr3r631V2zo9jirrnDv55/kiLlu0f9vYqbxrfPvlGdedD8o6XKlSF3zaDZsSwus4lppJF5P/AsSZ1k0+UvBKb1MEpaBgyZ2RhZBvoPzWxvbnD+C3CHmf1NA8cbHKCUil2ph+DCmk5/g29Nh/8TckuC57/Bsn828u5R//NsLSQIf5D/Z2i0POVkVkMpV/yn6INFwAL2Us6Fhk2Xm9lPgMuAn5GVLyoAGyS9T9IWsnjLmyV9Pt/lycBtkn4BvAz4/Xz5s4G3Ai+QdGP+Or1R4w6CIAiCIGg4kV3++DCz84DzJi3++/w1edtr4dHVbs3sGtKUnAsOECpV/0zSLKTYl6EESRsPj/onp7T4S7LbPxKBsQQZTn2j/jVld2uru6bk/yFqbz3UXXM4QdhO4EgUYw+CIAiCIAgaQhiZQZCWYsG/9WEKT8naLn/NY5f4Z8RUEpRN2jvu305puOx/nsUEn9uS2t01x8qD7ppBUH8i8ScIklMo+CfElCv+U/Qppsu3Dvtf27EED+77EmR6D6bILq/6Z0DvsQfcNatWnn2jOmM0t8cpSECDpsslHQNcCDwN+FMz+3TNutPIOioWgc+b2fmzHGsd8E0zO17SqcDXySr/FIAdwJvMbMd0+yeIjgqCIAiCIAio2txe82MXWVvvT9culFQELiBLrj4WeONjaNP9IzM7MW8Bfh1wzkwbhyczmBeS/0emkECzNUHZpFKCR76lLf5Ziymmy3eN+Zcw8q8eCeMad9esVPyTjSpV/0yu8fJud82gyTGDcv298rlncYekl09adTKwycx+CSDpErKmOfsVnpX0dGAjMARcM5VGXl6yB9g001jCyAzmif+UUYq2kj0JMkm7EnwbU7R4HK8ujmIRgwnKjuzQZnfNcgKDr7XU465pCabox6r+BnzgzNxvwr2TuhluyBvQzIc1QG18yxbgmVNsdyHwXjO7WtKnJq17Tt6ZcSUwCHxoJsEwMoMgCIIgCNwxmLsTpc/MTnqcglM94e9n5UpaCiwzs6vzRReTTa9P8CMze0W+7bnAJ4F3TycYRmYwL1J4FStV/wzopRzsrpnCk3l4l/+1TeE93T7a7a65st3/H3T10Dp3zX1F/8AAw99LXNQqd82x8T53zcARoy43REnnAO/K355uZtMVr90CHFbzfi0weVsxyfCcgcvJWn5PSxiZwbxQgrr4KbLLu81/Ou5JPf5TY4cv9+8LPzbuHx+5dsi/DNa2Yf/zLJq/ZlfJ3/gaN/8s+sFqGHxBA6hDdrmZXUCW0DMb1wFHSVoPPAi8AXjTpGPtkdQv6ZS8Gc6bZzjeKcA9MwmGkRkEQRAEQeBNnTyZk5F0MHA9sASoSvoD4Fgz2yvpPcB3yUoYbTSz26Y4xNuBjZKG8m1rmYjJFNAPvHOmsYSRGcwP+XsySwX/Ys+D8i/2vGdshbvmXX3+mttH/D3TN+5JkF0+5D+lOyZ/b/hQZae7Zmdxpb9myf+7stddMfDFGtKX3MweIpsKn2rdFcAVs+x/A/CUmkUfzpdfBSydz1jCyAyCIAiCIPDGmE/iz4IkjMxgnvgXc2wp+sfTHVT1jzNb2+nvhTpqlb8Xau2Qv2d6qOLv+dqXIPa0fcz/u1KSf8vOFDGZo5XwKwb15jEVWl9QhJEZzIusYYAvHSV/A+GQNv8f667SPnfNBNEPSZrzFROcZ4p2aiPyb4dawt/IrCb4FFUS1MkMFgFhZAZBEARBEAR1pUG9yw8kwsgM5om/f6ZV/l7FYgIXXzVBeaihYf8knF3D/v+eg2X/azuWwEPRQou75kod4a45hr/HdrzoP0UfLALCkxkEv6JQ8J8a62S5u2YhwfTqjmH/WMXeTv8fzjVL/MMCdo36G9N37fXX7NUSd83+qr9hW0xwT9itB2bfKAjmgzUmu/xAIozMIAiCIAiCFFh4MoPgEcrlPe6aW8ductestj3RXXOo4h+KsLl/XiXP6kK56u8m3jri723bM+YfazVQHXPX7JG/B97m3PWufvQU/FvNPuSuGLjSoGLsBxJhZAbzIsV0eQo2Dw+4a24Z9m9l2VJo7hvcBLvG/A3bzgR31w75i1YSGHxD5l/uK0XZpKDZiRJGQRAEQRAEQSOI7PIg+BVK4ClpLy1z1+wrPOyuOVb192SubPWfXl2aQLNFXe6aFfNP/Nk37q/Z0+If5jFS8Z9R6Rv1Dy0JmpyYLg+CIAiCIAjqjhmUw5MZBElJ0bYuBUMJajluHfa/tnvG/ZNwtidI/NnpHzaYxKu4qt1fc6js7/1ZMbzaXTNofiw8mUHwKwqLxOAbkX/iT6W57zWPUDF/Y3qw4q/Z7t+BlfEEmfujCX4kRxM4f1K0sgwWAVHCKAiCIAiCIKgrEZMZBPtTTVA6ZM/o/e6apQSlmloKT3HXPLxrxF2zt8O/JeCaTv9/z1v3dLtrpqC75O/h6xvzdxPvHvVPQLzWXTFwJ4zMIEhLS9G/13VHaaW7ZmfR/2azb9z/FtBa8M+A3p2greRIgqlr/+hIGCj7qw6MJwi5aPL2f0ECLOpkBkEQBEEQBA3AIrs8CH6Fmf8XQvL3lHQWlrtrpkgU6SqV3TUHy/6Z3vcP+U+XtyfoppSig1OKZCP5S9JZTPAFDZqbBsVkSnozcG7+dgD4XTO7KV93GvB3QBH4vJmdP8ux1gHfNLPjJZ0KfB24l2ziZAfwJjPbMd3+YWQG8yKFwVdO0I+5y/zjr7oSxLYta/O/tm0JDNsUhlA1QRZ9Z4Jr+/CovwH/0Ij/fSimy4OG0Jjp8nuB55nZbkkvAzYAz5RUBC4AXgxsAa6TdLmZ3T6PY//IzF4BIOnjwDnAedNtHEZmEARBEASBNw2KyTSz/615+2Ngbf73ycAmM/slgKRLgDOA/YxMSU8HNgJDwDVTaUgS0ANsmmksDTcyc8v5euBBM3uFpPXAJcAK4GfAW81sTNIRZCe1CtgFvMXMtuTHOBz4PHAYmYP5dDPb3OixB4+mWPBvz9fV0uuu2WH+yUajCbxtQ2X/58zl3UPumgeX/TPa9yRINirKf7q8teDvgU9Qc55h8/cSB4uAudfJ7JV0fc37DWa2YQ77vQP4dv73GuCBmnVbgGdOsc+FwHvN7GpJn5q07jmSbgRWAoPAh2YS9/iF+X3gDmBJ/v4TwN+a2SWS/onsAvwj8Gngi2b2BUkvAD4OvDXf54vAX5rZlZK6IaripqJq/tOr41V/A6FN/gZCb6v/dFxPgj7iI6P+MZk7hv0fGloL/v+ebUV/zRTF9VPUr64kiEcPmhsD5vGx6jOzk+ZzfEnPJ7OxTplYNM0wavdZCiwzs6vzRRcDL6vZpHa6/Fzgk8C7pxtDQ58HJa0FXk7mhZxwr74AuCzf5AvAb+V/Hwt8P//7B2QuXCQdC5TM7EoAMxswM39XSBAEQRAEQb0wst7lc3nNgKRzJN2Yvw7Nl51AZnudYWY78023kM0IT7AW2Dr5cEwyPGfgcuC5M23QaE/mZ4A/IZu3h8y9usfskXmHLWTuW4CbgNeQZT29CuiRtBI4Gtgj6avAeuC/gA+Y2aMe2SWdDZzdoHMJEjFWGXTX3Nm6c/aN6szSFv8EitUr97lrpqBvyN+TOVLxD0Uom/88cgpPZoLW5exN0Go2aH7q4SA3swvIEnqAR0IMv0oWjnhXzabXAUflYYsPAm8A3jTpWHsk9Us6xcyuAd48g/QpwD0zja1hd0FJrwB2mNkNedo7zOyqfT/wWUlnAT8kuwDlfIzPAZ4K3A9cCpwF/MujDpTFJ2zI9Zu7wmkQBEEQBAuXxrWV/HMyp94/ZBPIlM3sJDMrS3oP8F2yEkYbzey2KfZ/O7BR0lC+bS0TMZkC+oF3zjSQRj5qPxv4TUmnA+1kMZmfAZZJKuXezEdctWa2FXg1QB53+Roz65e0Bfh5TTbU14BnMYWRGTQnrUX/ZCMl6J2yfcQ/DnTTVv/ORu0J4gZTeBVTdFN6OEGy0V37/M9z015/H8IObXbXDBYBDQj1NbN3Mo3xZ2ZXAFfMsv8NQG2f4w/ny68Cls5nLA27O5jZB4EPAuSezPeb2Zsl/TvwWrIM8zPJCnsiqRfYZVm17w+SZZpD5t5dLmmVmT1MFtNZm2EVOJLC+EpRAN4S5JZtHvIv9tySoFrAYZ3+iVwpSGFMp0hN6UxQCK8tReMC/Bs0BE2OGdbkbSVTtLo9F/i/kjaRuXMnPJKnAndKugs4CPhLgDz28v3A9yXdQuai/Zz3oIMgCIIgCOpKdY6vBYrLM2juYr0q//uXZAVBJ29zGb/KOp+87krghMaNMJgrKTx8bcUls29UZ57wSO1aP9Z3+dfhe+5h29w129r9z/OhPv/P0L4x/1JNKVjR4n9PWN6WoNXsYM/sGwXBfDCwSnN7MqPjTzAvSsVOd80UfcRLCZojp8jSTWHwda4cd9dcMepfoaA01O6uuXPPvMKl6kLfmL/BN5agw2N7ggYNwSJgAXsp50IYmUEQBEEQBAlo9hr/YWQG86Ja9e8QM1jtc9cslfy9ijsTeIRueWC1u+aa3f5exRRe4r0JMr1TkGK2byiBJ7Ov+JC/aNDcGOHJDIJaWkrd7prLtGb2jepMOUHful2j/obQ1mH/AvAHd/k37Ops9Z+ir1T9HxoeHnGXTNJH3BJ8P8ei0VxQZ+bZVnJBEkZmEARBEASBN+HJDIL9GS8vjqf5SgJPSQqP0Ppu/5qVrQnqRxaL/nfynvZRd80lI/6e6aGyf1jAtiF/z3RJ/tc2aH6qCUI/PAkjMwiCIAiCwJvwZAbB/lSq/kFfIwy4ayZwZDJY9hdtLfg/Ri9b5u8NHx7y97btHPQvebN33L8254B/FSwSVBhjuLrbXzRoeiImMwhqaGtZ5q650vwTf4oF/1+xgXF/I3PrsL8htHS3fyvLFIwnSPzZNbY4bumdxQQtWM2/RnDQ/KRwaHiyOO5IQRAEQRAEBxIGVBO45R0JIzOYF52tve6aS8y/bFJ70d8LVU3wRHtLv/80cm+bv0fo8OX97por3BVh5ah/csqR5j9FP1T292Qu2bfKXbNQ8J9pqFb9kwEXK1HCKAgmYQm+EcPyz9LtH/f/ahTlb/CduMy/uP5BXf7F2KsJirG3lvzjXQ9q94+Z3jnqb2SWE/wwj+N/HwqDr8kxUa2EJzMIgiAIgiCoM+HJDIIadg/e6a65qdv/Y3pw4cnumm1l/wSnsQTJKSk64VRG/TWHE3jDRyr+08idJf9fyeVtCc5zoMddM2huDLAEsyyehJEZzIv2Vv+4pK7iSnfNEfmXTdpW3eOuCf7VAlpL/jVvxhMYX/1j/uEPKUoYbR32/xm5f8A/FOEh7nbXDJocA2vyxJ8EPUaCIAiCIAgCs7m95oOkMyTdLOlGSddLOqVm3ZmS7s5fZ87hWKdK+mb+91mSHs6Pe5ukyyTNmMkZnsxgXhTk/5Gp4O/5GqvudNccxF9z6/Bz3TWfMNzurllK0Vay1b/14WDZ//u5L0Ex9iRtX2f+LQ2Cx0SDpsu/D1xuZibpBOArwDGSVgDnASeRzdbfIOlyM5tPp4FLzew9AJL+DXg9cOF0G4cnMwiCIAiCwBkzqFY0p9f8jmsDZo88iXWRGZQALwWuNLNduWF5JXDa5P0lnSbpF5KuAV49lYakUn7sGQ3U8GQG82Ks7B+rOFT29/C1JKhPt1bHu2uOJIgH2pcgbnBdj3+dzPYOf09m607/WMXtCUoY3bPX3z9i+F/boNlRwxJ/JL0K+DiwGnh5vngN8EDNZlvyZbX7tQOfA14AbAIunXTo1+fT74cAdwHfmGkcYWQG86Jq/nUVK1X/+nQpjMz+Qp+75kjlYHfNhxMUDB952L80+ppu/3qgrcUEtTnb/I3pgzv9P0OrR9a5a252Vwy8qc79Qb9X0vU17zeY2YbpNjaz/wT+U9JzgY8CLwKmEpsce3IMcK+Z3Q0g6UvA2TXrLzWz90gScAHwx8D5040jpsuDIAiCIAi8mWPSTz7x3WdmJ9W8HjEwJZ2TJ+PcKOnQ/STMfggcKamXzHN5WM3qtcDWqUc2y9Cz6fhvADMG9ocnM5gXbS3+JW+WtK5116yav3dmxPa6a1YS1GhrLyRIwmnx//fsSKA5kiDxpyj/JJxef0cmB8v/3lcq+WuWy3v2MfsAACAASURBVClKqS1O6lUn08wuIPMqAiDpicA9eeLP04BWYCfwXeCvJC3PN30J8MFJh/sFsF7SkWZ2D/DGGaRPAe6ZaWxhZAbzQgmc3ykMvuGK/402xRR9Cla2+4c/HNHr/+/ZliAmc3TYPz5y17D/57bQ3KUFH6FS8Y+BD3xpUEzma4C3SRoHhoHX557HXZI+ClyXb/cRM9u1/3hsRNLZwLck9QHXALUJAxMxmQUyz+hZMw0kjMwgCIIgCAJvTFQq9XfcmNkngE9Ms24jsHGW/b9DFps5eflFwEXzGUsYmcG8KBT8PSUpWFryn6JfU13vrllO0De3kiCjfWTE/3M7Pu7fZWjXgL9X8b5Bf83NCRx84+afVNXWutpdc2R0qhC9oBFk0+WpR9FYwsgM5kWKKd0eJbjR4v8rNlDw11zW6h/zdVCCrOueJSPumqMj/rfXZV3+57liyL9I+cEd/gb8pr2LZI4+cKUavcuDIAiCIAiCetOoOpkHCmFkBvNiYPQhd83O0kp3zaX4149MwUiC+tJjFX8vVAoKBf95sNEx/1t6/7i/5l7/nCp24J88FlPXzY0Rnswg2I+2lqXumi34T9GPyz8DepQhd83B8mGzb1Rntg92uWu2l/wbbLe0+FvwS7r9p8uPGfcvvbV91L+4/hNKve6at7X5x4YPj25x11y0WHgygyAIgiAIgrqjJLWKPQkjM5gXKVo8VvGfG2s3/yn6Kv6p3oNl/yndFDfVsQRFyltb/b2nHT3+35VVVf9ErlV7lrhr9rb7f4Y0EE35mpnFMF3esE+wpMMk/UDSHZJuk/T7+fIVkq6UdHf+/+WT9nuGpIqk19Ys+2R+jDsk/X3eMzMIgiAIgmDBYqY5vRYqjXw0KwN/ZGY/k9QD3CDpSrLq8N83s/MlfQD4AHAugKQiWQHR704cRNJvAM8GTsgXXQM8D7iqgWMPpmG87F9mZ2/ZP/h9UDvdNQ8tHueu2ZYgB2eo7C+6Z9S/D2GCEqSkePweGm511xyr+nv4dgz7e6bHyv7xroEv1aiT+dgws23AtvzvfZLuANYAZwCn5pt9gcxYPDd//17gP4Bn1B4KaCfrvSmgBdjeqHEHM9PWsnz2jepMe9Ff0/BP2lhW9U+qOqLL/w7XXvS/ti0J+qV3tvlPXS89yD/xp63f3/gqbvf/3C5L8ERWkL8BH/hhkfhTHyStA54K/AQ4KDdAMbNtUlZpW9Ia4FXAC6gxMs3sWkk/IDNYBXzWzO6YRuds4OzGnUkQBEEQBEF9qBJG5uNCUjeZd/IPzGzvDOGUnwHONbNK7TaSngg8GZio5XClpOea2Q8nH8DMNgAb8v2a3AmdBsl/mqqz4O/JVOPCladlrOLvEUqRVtCSoH7keILp1b59/p1weNBfMkVtzmbPyJ2gWAhPZjNjKEmbXU8aeneQ1EJmYP6rmX01X7xd0iG5F/MQYEe+/CTgktzA7AVOl1QGjgJ+bGYD+TG/DTwLeJSRGTSeatV/CnBF1b8weof5x/DtLexz19xX9r/BtRb8p8t7WsfcNVNkjbYnmKLv7vavOPGEQX8D/me7u901u9v8731RJ9OXZvdkNjK7XMC/AHeY2d/UrLocODP/+0zg6wBmtt7M1pnZOuAy4PfM7GvA/cDzJJVyo/V5wJTT5UEQBEEQBAuFLC5z9tdCpZGezGcDbwVukXRjvuxDwPnAVyS9g8yA/O1ZjnMZWZzmLWRJQN8xs280ZsjBbJQK/h6+Yfl3wmmxFnfNJdUed80UbSVTJOG0Jkg2SsFwgkxvhv0lK+Yf/rC63V2SovzvQ4Efi6FOZiOzy6+Baf3AL5xl37Nq/q4Av1O/kQWPh57WQ90128z/7j5U8C8wvTRBdvnWIf9H5JEEvctHEhRjX97t/3DUtcQ/LKBQ9P8MDY35G18tBf8p+uUF/7avD3Gtu+Zixpp8ujw6/gRBEARBEHhjUSczCPYjcyz70pYgCYcEmh3y/zqual8cbetSTJe3tPiHBVTG/f89RwYTFNcf8f9+PujvmGZ39QF/0cANQ0lCPzyZ09lJek7ejad22dMaM6QgCIIgCILmp2pzey1U5uo6+S5wnaTXmdlEt53PA2FoLjKqCZrlVeRfP7KK/7e6o+hfIuWJ3f4evs6S/79nW6u/5r4Bf2/bsmX+WTjVBHX+xqr+3tOuUoKSVIUl7pqBL42MyZT0DODHwOvN7LJ82ZnAn+WbfMzMvjDLMU4F3m9mr5B0FvApsoq8LWSVft5mZtP6+edqZN6ZH/gqSe8ws/9l+qSeoIkZLvv39O5t8b/RrmzzTyxI8bS6J8H0aorC6B3t/vUjUxhfw0P+n9vla/wN2+Pb/DsL3zNwhLtm767D3TU3uysuXrLs8sYcO599/gSZk3Bi2QrgPLK65AbcIOlyM9s9j0NfambvyY/3b8DrgQun23iuRqaZ2Tcl3QlcKmljPsAgCIIgCILgMdDAEkbvJWuG84yaZS8FrjSzXQCSrgROA75cu6Ok08i6MPYBP5vq4JJKQBcwo4E6VyNTAGZ2t6TnkFmtJ8xx36CJaEkwpTuaINlopOKfhDNe9Q9F2D6SIGljzL+W49CQv2Zrgin6oRH/82zb6X+eu3Z3uWuOJPBMp6jXG/gyD29dr6Tra95vyFtpPwpJa4BXkdUYrzUy1wC12WRb8mW1+7YDn8v33QRcOunwr5d0CnAIcBcwY93yOf2SmtlTa/4eBF4nyd+PHyRnSdG/zdlQxb9tHf6zq7TJ3+ArJ2glsS9BzcoH9/oXul+7bK+7Zme7f53M3Xv860c+lKCt5MC4v5FZwv+eEPhhBuW5ezL7zOykOW77GeBcM6vkrbonmEps8o/AMcC9ZnY3gKQvAWfXrL/UzN6Td3W8APhjsiY7UzLj3V7S/zfFAGp530z7B0EQBEEQBFNjdZgul3QO8K787elkMZeX5AZmL3C6pDKZ5/LUml3XAldNNazZNM3MJH2DbFr+sRmZQK1r9i/IAkaDRUxLgvqRLQnKue7G3wu10vw7/uwd8/dkLmvxdxN3JMhor1b8PV9trf4hFy0JapD2tPp/hloTOBUfKNzlLxq4YVCXei1mdgGZV3GC9RN/SLoI+KaZfS1P/PkrScvz1S8BPjjpcL8A1ks60szuAd44g/QpwD0zjW3GX+/a1HZJfzBbqnvQ/AzOHOPbEAz/Kfo1hRXumoUEBRuetNRfM8V0eXXY/zwLCXIjxxJc2xRUEsRHVhKkuu4c/aW/aOCKZ1URM9sl6aPAdfmij0wkAdVsMyLpbOBbkvqAa4DjazaZiMkskHlGz5pJcz53pMgmD4IgCIIgqAtqeO9yMztr0vuNwMZZ9vkOWWzm5OUXARfNR39xPPYGdWOo4l8ns7Xgn2HZVfKfG1vZ5q95bM+Iu+ayNv/klJGy/7UtFRM0LmhcOZTpNRPUPW0p+F/bjqK/n+XQ9qe4a945dLe75mKlkXUyDxRmS/zZx688mJ2SJgLVRBb3Ge0IgiAIgiAIHgMpHgw9mS0m07/uR3BA01rwr5PZIX+H+1iCAKzBsr/mQwnqKqbwQhUS3MeHxxfHRNFQgjjQsvl7T7cN+2uO2j53zcAPW+B9yefC4rgLBnWjp7DaXXOo4p9JOpDgm7+8zb/A9L6yv/WVond5iuzyepQmmS+tJf9M796uadsWN4ztAwmKsSd48Nw1ttldM/Cl0TGZqQkjMwiCIAiCIAHhyQyCGlqtw12zp+g/pVtJ0AknBXsSdDF5YMi/W0tHglqO63oG3DVLCUIRdgz6exXvS9Dxp5jA4bSk5RB3zb3c6a65WKlXncwDmTAyg3lx78j/uGtW2k9212zBv+j8zkH/EOj24vLZN6ozazr8Y9t6EkyXF+T/oJJCM8XzWIoY24EErWZ3DN7uLxq4kiKsxpMwMoMgCIIgCJwxIEG+pythZAbzolTw9/AV8a+TubLq3/GnM0E90KWt/k/R3aUUNQ79p8uLCbyKKUhxnq0JwgKGElgDyzrXz75RndnRv8NdczHT7HeJMDKDedFS9I+/StHKciUr3TXXdvkb8E/s9je+Uhh8KTI4B8f9HxpStLJMUeevLYGR2V7yP8+lxUPdNcPE9CMrxh7T5UEQBEEQBEGdCU9mENTQUzzYXXOF+WdYbi9sddc8pe1RrWIbzhN7/GscrugYdtdM0fowRRLOPf3+TdhGq/6emJGK/7/nSILp8oolyDYK/Ihi7EGwPy1q99es+k87FuWvOZrgbrN12P/fs7vFv3d5R0uCAvBt/gbCwWP+BvxY1b8v/KZ9/iWMRisJ4kCrO901Az+ihFEQBEEQBEHQALS4e5cHwYFAa4KPaU91qbvmpn5/z1dHgkL3S0r+XqiDEkzRd7b7e2xXdPqfZ/+Ivzc8RUb70jZ/j+2K8hHumg9xrbvmYqbZ+36EkRkEQRAEQeBMTJcHwSSGrd9dc1S97prL6XbXXN3h/3UcTJDM0J0gPrJU9L+Vj4z6x/WOJ0hwGhz3/9ym8GSu8XfA0zbo38Y38CUSf4KghlV2uLvmCvzbLa5q959G7m5p7ticCcoJspFbEtRVTGHYptBc0uofFrA0QQ3SobK/5ubxn7prBr40uY2J/2NvEARBEATBIicrxj6313yQdKqkfkk35q8/r1l3mqQ7JW2S9IE5HGudpFunOO7Nkv5L0uqZ9m+YJ1PSRuAVwA4zOz5ftgK4FFgHbAZeZ2a7Jb0ZODffdQD4XTO7qeZYReB64EEze0WjxhzMTqf5zxkdt8I/seAgf8kkT7Sj/s136Cz5T5cfeph/mEdlPEH9yEF/b1s5Qc3K/j3+STh7x/2/oWOVQXfNwBGDSuM+Vj+abC/lttQFwIuBLcB1ki43s9sfy3ElfRw4Bzhvuo0bOV1+EfBZ4Is1yz4AfN/Mzs8t6A+QGZf3As/LDc6XARuAZ9bs9/vAHYB/peFgPx4qbnHXHK8uc9csJ4jG7ir5/4g9bVmCwugJSnYU2vyvbanTX3PLVv+2r6Nlf4NvaYv/01F70T+6rKv1IHfNweHN7pqLlQlPpiMnA5vM7JcAki4BzgD2MzIlPR3YCAwB10x1IEkCeoBNMwk27BHUzH4I7Jq0+AzgC/nfXwB+K9/2f81sokH1j4G1EztIWgu8HPh8o8YaBEEQBEHgjc3x9Rj4dUk3Sfq2pOPyZWuAB2q22ZIvm8yFwPvM7NenWPccSTcC9wMvIjNGp8X70ewgM9sGYGbbppnLfwfw7Zr3nwH+BGbP/pB0NnB2PQYaTE0Bf6/Fffv860f2Dfuf5+lr/N2nXQkyvVPUhRvZnaDW6jp/b9sR6yc/1zeeHVv8E/NScFhnm7vm6v4numvu4CfumouZeXgyeyVdX/N+g5ltmGbbnwFHmNmApNOBrwFHAVNNI+03AklLgWVmdnW+6GLgZTWb1E6Xnwt8Enj3dIM+oLLLJT2fzMg8JX8/EdN5g6RTZ9s/v+Ab8n2bPWkrCScWj3bXXN/jb/CNJ5gu704Qq1iS/4n2JChSXin7xw2qw/8W1LrC37Bdum9x9KLvLvl/V9oTxMAHfmReyjmHD/WZ2UlTrZB0DvCu/O3pZrb1EQ2zKyT9g6ReMs/lYTW7rgW2sj9i7s7Ty4H/mGkD72/qdkmHAOT/3zGxQtIJZFPiZ5jZRMPWZwO/KWkzcAnwAklf8h1yEARBEARB/alHdrmZXWBmJ+avrZIOzmMmkXQyma23E7gOOErSekmtwBvIDMXaY+0B+iWdki968wzSpwD3zDQ2b0/m5cCZwPn5/78OIOlw4KvAW83sromNzeyDwAfzbU4F3m9mb3Eec1BDa8E/aUNzf9KrGy0Ffy/UjlH/iYXRqn+iyDElf2/bvgH/qc7qTf4e27YE3tP2Jf4e+O7RUXfNjqL/tV2Ff3vbwA+jYdnlrwV+V1IZGAbeYGYGlCW9B/guUAQ2mtltU+z/dmCjpKF821omYjIF9APvnGkgjSxh9GXgVLI4gi1kKe7nA1+R9A6yoNHfzjf/c2Al8A+58V2ezi0cBEEQBEGw4HkMNTDndFizz5JV95lq3RXAFbPsfwPwlJpFH86XXwXze/JpmJFpZm+cZtULp9j2ncxiDecnd9XjHljwuBhOUdsnQbLRWIL6kQ8OJ2gJmKDG4aGj/t2Uiik6/oz5e6Zb2/29iqP7/M9zaNj/M9STwAPfU/Kvexr4Yk3e8+eASvwJgiAIgiBYDCSok+lOGJlBEARBEAQJaHIbM4zMYH4safWful7W6v81HK74Jxul6PgzkiAsYB4lO+pG73L/9nyLpYrayLD/z8j9e/1rc/7vTv8p+jsr97trBr6EJzMIgiAIgiCoKw3MLj9gCCMzmBcjFf8EipaCv/e0LUEJo9EEOVXPW73XXbOt4O8+LSYopN252v88q/7NsZLQmaBxwep2d0nuG/upv2jgSngygyAIgiAIgvpiadrsehJGZjAvUnwhdo76x/CNJJjDeHavf/HuY4/e7q7ZssRdkop/50Naj0tQSDvBTEPpvgF3zRV9I+6a41X/D+5Bbce5a+4ZvMNdc7FiQIqigJ6EkRkEQRAEQZCA8GQGQQ2VBN+IFv964bT7h4Gyut3fk5mikHbrMv94uqJ/V8k0vx4JmiVUh/3Ps6vDv61kgo66HFw51F3zTnfFxU14MoMgCIIgCIK6YhiVJs/8CSMzmBelBI/zKTpZLkvg+WpNkHW9Y6d/vcGuVbvdNZXgTqdiAhf8Sv8U6JYEX9CePf4xmatam93nFKSguU3MMDKDIAiCIAjcibaSwQGNErhnDun0D1Zc1+Xv4Tu80z/mq6PFP1Zx94i/52vtgL83vP0Qd0k4ZJm/Zu9yd8nC2H3umuUx//jlh0b8PdMPF3a4awaOWBiZQRAEQRAEQQOwJp8wDyNzAVMsdrtrPm25v1fxxJX+MXxtCTqKmPl7+LYNdrprpqDlGH8PXxIXxWCCgqAJYjJb2v01D+/0vyd0mn/MdOBHTJcHQRAEQRAEDSFFWUBPwshcwJSK/l6ogbJ/XNJIeXF8TB/Y5++Z3jLc6q55dJ//57bnqLXumnbkOndN9e1017Rb7nfX7O/zjyVuL/p7T1eSoGtU4EqT25hhZAZBEARBEHgTbSWDA5piwd8LNVL1jxvcOtThrrlv3D+L/lkHP+yu+cJT/OsNqi1BO6UEsYrWk6BJewLU5X8fau/w75feXfKPR09QaTVwxhrkypR0KvAZoAXoM7Pn5ctPA/4OKAKfN7PzZznOOuCbZnZ8fsyvA/eSfTx3AG8ys2nLIMRnOAiCIAiCwJu8hNFcXvNB0jLgH4DfNLPjgN/OlxeBC4CXAccCb5R07DxH/SMzO9HMTgCuA86ZaePwZAZBEARBEDiTTZc3xJP5JuCrZnY/QI2n8WRgk5n9EkDSJcAZwO21O0t6OrARGAKumUpAkoAeYNNMAwkjcwFTLPj3PqwkCFIeq/o73DtL/pEyh/2G/5Ru8cUnuGta70p3TbZsc5cs3Hyru2YSOv2ny3uO8C8ntO8e/5/LTYU73TUDPwybT3Z5r6Tra95vMLMN02x7NNAi6SoyQ/DvzOyLwBrggZrttgDPnGL/C4H3mtnVkj41ad1zJN0IrAQGgQ/NNOgwMoMgCIIgCBIwj5DMPjM7aY7bloCnAy8EOoBrJf0YmCqpYr8RSFoKLDOzq/NFF5NNr0/wIzN7Rb7tucAngXfPNJBggdJa7HLXPKxj3F3z0A5/D1970T/IX10t7pps9U82YkWCwujLEyTh7Nrjr9m7wl9zRYKC4VX/dosrWv3vfd2WoDVp4Eo9psslnQO8K397OpmHss/MBoFBST8EnpIvP6xm17XA1smHgzkP6nLgP2baIBJ/giAIgiAInMk6/ticXjMex+yCPBnnRDPbSpYB/hxJJUmdZFPid5Al6hwlab2kVuANZIZi7bH2AP2STskXvXkG6VOAe2YaW3gyFzCtBf/i3eMJShh1JGjx2Ltk0F2z/JB/OSEe2uIu2br2IHdNW3OouyZd/jMN6t/rrkm//3elmuCr0tMy5q55dOkQd82fuysubhrRu9zM7pD0HeBmslKcnzezWwEkvQf4LlkJo41mdtsUh3g7sFHSUL5tLRMxmQL6gXfONJYwMoMgCIIgCBLQqBRTM/sUMDlpBzO7Arhiln1vIJten+DD+fKrYH5tqMLIXMCU5J9d/uSl+9w1n7B+l7tmqds/jX7M/zTZs92/xePafv/PkD11tbtmCvST6/xFS/7F9Qv+H1u6E8Rkthb8Z44CP7Ls8ubu+RNGZhAEQRAEQQIaVCfzgCGMzAVMCX9P5mDZPwN6bMjfU1Kt+D9dPrTVPwP63r3+mcG9X7/LXbO9K4Hra2mCrOsHtrtLlm/3r1AwcL//T9d1D/tn7u8d949HD/xoYDH2A4YwMoMgCIIgCBJgDYvKPDBIYmRK2gzsAypA2cxOkvTbZMGlTwZONrPr821fDJwPtAJjwB+b2X+nGPeBRooPZ4pM7/Exf0/m1h3zim2uCw8Pt7trPnWtv+dr31b/DjF28Y3umh1P869xWN036q65907/Sng7d/ln7m8d8b8P9VeG3DUDTyw8mQ3k+WbWV/P+VuDVwD9P2q4PeKWZbZV0PFk6/RqnMQZBEARBENSdmC53xMzuAMh6ru+3vLZs121Au6Q2M/N/ZD/AMPy70uwb84/JHBzy93yNlP29Fs95kX9/7dIrnzL7RvWm6H9t7Se/cNcc+bl/x5+q/y2B8rj/93P7oH+M7XiCWc0B+dcgDTwxKmruuNtUHX8M+J6kGySdPY/9XgP8PAzMIAiCIAgWMhOezLm8FiqpPJnPzqe/VwNXSvqFmf1wph0kHQd8AnjJDNucDczHaF3QjJl/T++94/6ezIFRf09Je8nfJVQ6ZqW7Jkv8M6BtqX+8q57m7y1oHbrDXVOt/l7ilhX+96H14/5e4h8+7N9hrc38K4gEvlSbPPEniScz762Jme0A/hM4eabtJa3Nt3ubmU3bJ9PMNpjZSWZ2Uj3HGwRBEARBUF9sjn7MhWuIunsyJXUBBTPbl//9EuAjM2y/DPgW8EEz+x+nYS4IygmiBlZ3+DcNXrXUPy6pa6l/n2Ib8vcq6tpb/DWffIS7ZoquNOr298Az5u+BL7T7+yo6u/2/nyta/acsu+VfcSLww4CqFq4BORdSeDIPAq6RdBPwU+BbZvYdSa+StAX4deBbkiaasr8HeCLw/yTdmL8WR4+4IAiCIAialuoc/1uouHsyzeyX7N94fWL5f5JNiU9e/jHgYw5DC+bAkrYE3tNn+MfTFVb61+Gzfn8v8e7r/T1fK0oPuGtywlHukjphvbum/WzaaKKGUR3y/wEcHvSPVUzxM/+g/CtOBH4YRoXmzi4/YEoYBUEQBEEQLB6MaoJShJ6EkRkEQRAEQZCAhZzUMxfCyFzAtBeWuGuOJShSXulPMJ1Q9W/nNnyf/xPt5m2r3DXtm7vdNVf2bHHX5LCD3SX1pEPdNdmyyV3ygV3+ZbD2jGn2jepMp/mXTQr8MKzpE3/CyAyCIAiCIEhATJcHBywd8n+aH6v4ezIfut0/CefBPf7lhMaq/te2qzTurnnbA/7FIZ52+YPumt3P8/eGp6A65l/a55ClA+6ax4/4lxO6ekd4Mpsba/rp8lRtJYMgCIIgCBYthlGx8Tm95oOkP64p+XirpIqkFfm60yTdKWmTpA/M4VjrJN2a/32qpP78uDdL+q/ZSkqGJ3MB05Kg5VgV/7gkq/prLhav4tHr+9w1C0V/z1ffNn9veOm6Xf6ay/39BhX/rpJ0dvoXY1/W4v/9PKKz010T/46dixprwHS5mX0K+BSApFcCf2hmuyQVgQuAFwNbgOskXW5mt8/j8D8ys1fkx/44cA5w3nQbh5EZBEEQBEHgjnkUWn8j8OX875OBTXm9ciRdApwB7GdkSno6sBEYAq6Z6qCSBPQAM2b+hZEZzIvdo/6t8ioJPJkjFX+P0HPflsAl9ILn+mu2+3vgu2+9012zequ/ty1FK8uW8QRtXwsJvIoDe901e9v9PfCBH8a8Shj1Srq+5v0GM9sw0w6SOoHTyDonAqwBarthbAGeOcWuFwLvNbOrJX1q0rrnSLoRWAkMAh+aaQxhZAZBEARBELhjmM15urzPzE6ap8Argf8xs4nYnak8NvvFL0laCiwzs6vzRRcDL6vZpHa6/Fzgk8C7pxtAGJkLmFH5Z68+aYV/jcODj/TPJE2BehPUOBz1bxPqH5EJdHW4S2qJv8e2fJ//d2W0z/9fdF+ff6b3A/3+FSd2jiT5tgSO1GO6XNI5wLvyt6eb2db87zfwq6lyyDyXh9W8XwtsZX/E3G/TlwP/MdMGkV0eBEEQBEHgjGFUbXxOrxmPY3aBmZ2Yv7bCIx7J5wFfr9n0OuAoSesltZIZoZdPOtYeoF/SKfmiN88gfQpwz0xjC0/mAqZs/l6oVWv9PSXtL1jjrkmXv6eEXfvcJcuX/cRds/SUQ9w17WnHumtymP/ntuXGO9w1S1v8Zzda7/efxfnFdn+fzIND/vf4wJOGJv68CviemT0SNG1mZUnvAb4LFIGNZnbbFPu+HdgoaSjftpaJmEwB/cA7ZxpEGJlBEARBEATeGPOJyZzfoc0uAi6aYvkVwBWz7HsD8JSaRR/Ol18FzKsLTBiZC5gO/HuXD+z0jzPr2PSwu6ba/b8aI3f6e2c237ncXfOwByaHADWe7vYWd00O8e9sxHL/uEH6/D3whR7/OrYr2vy9ista/e/xgSfN3/EnjMwgCIIgCAJnDDALIzM4QFle7XXX7N9Xdtfkx/71I+/Z4d8X/r7Bg901Wwr+2at39/t7Z56w2d/b9oSjNrtrFvwnGhYNna3+tTnX9yT4id7hL7l4sYZ0/DmQCCMzCIIgCIIgAdVqAseNI2FkLmC65Z8B3bvyIXfNniP9n/R6Vm1z1zz4Pv94ur4h/97Iw2X/284DA/6dBHHBnwAACzhJREFUU44Y9e9dXuzy90yP7lwclfCWLfGfUTl2SXMbIIsd82krmZQwMoMgCIIgCBIQMZlBEARBEARBfbF5tZVckISRuYApTtmGtLGMDPt/ZDr2+E8Zje7zL5EyVvHXPKh7cPaN6kyl6v+5fWig211TCWaRWw7yL9VUWuk/RT98r/89YXCw1V1zNMF3JfAlShgFQRAEQRAEdcZiujw4cKnMuYd9/SiV/L8QpR7/p/nOFv8pjGPOSFB/Zv16f82RMXfJJwz4e2ztfn/v6fBNCQqj+zvgKQ8vjmSjxXGWixcDqtbcyV1hZAZBEARBELgTnszgAGbE/D1CnUv9CxK3/Jp/0XmW+pf2oavDX7OcIOh81P9zy+qV7pJq84/ha33Q32O7+w7/n5H2bv/70NLl/iWMunY0d1JIENnlQRAEQRAEQd0xiMSf4EBlT6HfXfPmu/xbHx43vt1ds33lw+6aww/7R2Ddft9B7ppdJX8v1DEn3u2uWVrlf3st7/b/wdq+y7+JQMc+/8/Q7mH/5hd3D/hXCwgcsfBkBkEQBEEQBHXGiBJGwQHMTrvPXfOqHYe7a/58t39LwPuH/DPadwz732wqCe5vFfOvirDql8vdNVe0JahjW/G/tms7/TXbCv6aQxX/mYZNe/3PM/DEMPP3ynsSRmYQBEEQBIE7kV0eHMDsHd/mrlk2f+/MaILv4END/qL9Y/710ory//dMoTlc9vcI7UjwuR2v+p9nJcE9YWWrv2aCjxC7R5u7hmIAkfgTBEEQBEEQ1BmD8GQeGEg6Dfg7oAh83szOTzyk5IyX/WvijSf4PpQTaI4mCFa8pnyFu2ZR/l2Geor+FQqWDq9y12wx/zqZR7f615RtKfh7FXePJuh2luA8+yr+9/jAF2tA5z5JS4EvAYeT2XmfNrML83VnAn+Wb/oxM/vCLMc6FXi/mb1C0lnAp4AHgRbgDuBtZjY03f4LomuVpCJwAfAy4FjgjZKOTTuqIAiCIAiCx0N1jq95cQ5wu5k9BTgV+GtJrZJWAOcBzwROBs6TNN+syEvN7EQzOw4YA14/08YLxZN5MrDJzH4JIOkS4Azg9qSjSkyK0gcpYr7GE8RClRNkQC8rHeGuOVD1rwe6p+xfFaFcGnXXxN/xxeGVFe6apXKCOO0EMw1tRX+fTJno+NPcNCzxx4AeSQK6gV1AGXgpcKWZ7QKQdCVwGvDl2p3zmePPAH3Az6YSkFQCuoDdMw1koRiZa4AHat5vIbPE90PS2cDZ+dtRKN/qMLZkjIzeP9dNe8k+LI+bT957Xj0Ok5q6XY8moemvx675bb5gr8f9fLsRh12w16NBxPXYn4V6Pfyf6h/Nd6E81xiXdknX17zfYGYbptn2s8DlwFagB3i9mVUlTWVLrandUVI78DngBcAm4NJJx369pFOAQ4C7gG/MNOiFYmRO9aj8KFdTfsE3AEi63sxOavTAFgJxLfYnrsf+xPXYn7ge+xPXY3/ieuxPXI/Hjpmd1qBDvxS4kcxQPBK4UtKPmJstdQxwr5ndDSDpS/zKeQfZdPl7ci/pBcAfA9PmyCyImEwya/uwmvdrySz0IAiCIAiCRYukcyTdmL8OBd4OfNUyNgH3khmPc7WlZo0XMzMj82I+d6btFoqReR1wlKT1klqBN5C5goMgCIIgCBYtZnZBnoxzopltBe4HXggg6SDgScAvge8CL5G0PE/4eUm+rJZfAOslHZm/f+MM0qcA98w0tgUxXW5mZUnvIbsYRWCjmd02y27TxSosRuJa7E9cj/2J67E/cT32J67H/sT12J+4HgceHwUuknQL2RT5uWbWByDpo2SOO4CPTCQBTWBmI3l+y7ck9QHXAMfXbDIRk1kg84yeNdNAZAmyaIMgCIIgCILmZqFMlwdBEARBEAQLiDAygyAIgiAIgrrTdEampNMk3Slpk6QPpB5Po5ntfCU9V9LPJJUlvXbSukpNRlrTJVLN4dq8W9It+flf04xdpOb6fZD0Wkkm6aT8/TpJwzWfj3/yG7UPc7k2kl4n6XZJt0n6N+8xNpo5fEf+tuYzcJekPTXrFvv94whJ35d0s6SrJK1NMU4PJG2UtEPSlLWnJR0j6VpJo5Le7z2+4ADGzJrmRZYUdA/wBKAVuAk4NvW4Up4vsA44Afgi8NpJ6wZSn0Pia7Ok5u/fBL6Tetze1yDfrgf4IfBj4KSaz82tqc8h8efjKODnwPL8/erU407x+ajZ/r1kSZcT7xf7/ePfgTPzv18AXJx63A28Hs8FnjbdPQFYDTwD+EuyPtfJxxyvA+PVbJ7MR9pPmtkYMNF+slmZ9XzNbLOZ3cxjaH66wJnLtdlb87aLOdQGW2DM9fvwUeCTwIjn4BIzl2vzLuACM9sNYGY7nMfYaOZ7v3wjk9rPNTFzuTbHAt/P//7BFOubBjP7ITM0zjKzHWZ2HTDuN6pgIdBsRuasLZOajMd7vu2Srpf0Y0m/Vd+hJWdO1yYvYnsPmZH1PqexeTGXFmJPBQ4zs29Osf96ST+XdLWk5zRwnCmYy+fjaOBoSf+Tf0ca1Z0jFXO+f0g6AlgP/HfN4sV+/7gJeE3+96vIekWvdBhbECwYFkSdzHkwp/aTTcTjPd/DzWyrpCcA/y3pFjObsbDqAmKurUgvAC6Q9Cbgz4AzGz0wR2a8BpIKwN8ydZ2zbWSfj52Sng58TdJxk7y/C5m5fD5KZFPmp5J1xviRpOPNbM/kHRco87l/vAG4zMwqNcsW+/3j/cBnJZ1FFm7yIFBu8LiCYEHRbJ7MxdZ+8nGdr2WdATCzXwJXAU+t5+ASM99rcwnQbN6Y2a5BD1mR3askbQaeBVwu6SQzGzWznQBmdgNZfNrRLqP2YS6fjy3A181s3MzuBe4kMzqbhfl8R97ApKnyxX7/MLOtZvZqM3sq8Kf5sn6/IQbBgU+zGZmLrf3kYz7fvK1UW/53L/Bs4PaGjdSfWa+NpFqD4eXA3Y7j82DGa2Bm/WbWa2brzGwdWeLPb5rZ9ZJWSSoC5J6qo8jakjULc/nufA14PjzyHTmaxXcNkPQkYDlwbc2yuH9IvflsAMAHgY3OYwyCA56mmi63x9Z+csEy3flK+ghwvZldLukZwH+S/Ui8UtJfmNlxwP/f3v2zNhXFcRh/voKjnRS6C4KC6KCCCuLQd+Ak4l6w/lmcFRc7COKm4K4IvoFurtbJQgfBTejg4GBRBM3P4d7YIAhRr409fT4QkpvcwO8ews0395yccxh4lGRE92Njuaqa+ZKYpm2ApSQLdIPVP9BWV/m0bfAr54A7Sb4C34DF+mn5sZ1syrYZr/O7TtcGN8dXd1vwG5+Pi8DTqprsLvb80Q2juJuk6LrLr8ys4H8syRO6492f5B1wC9gLUFUPk8wDr4A5YJTkBt2/8VsZXqM/5LKSkiRJGlxr3eWSJEn6DxgyJUmSNDhDpiRJkgZnyJQkSdLgDJmSJEkaXFNTGEnaHfrl+8brRs/TTTH0vt/+VFVnZlKYJOkHpzCStKMluQ1sVtW9WdciSdpid7mkpiTZ7O/PJ3mR5FmSN0mWk1xK8jLJWpKD/X4HkjxPstrfzs72CCSpDYZMSS07BlwHjgKXgUNVdQp4DFzt93kA3K+qk8CF/jVJ0l9yTKaklq1W1QZAkrfASv/8Gv265MACcCTJ+D1zSfZV1cdtrVSSGmPIlNSyLxOPRxPbI7bOf3uA01X1eTsLk6TW2V0uabdbAZbGG0mOz7AWSWqGIVPSbncNOJHkdZJ1YHHWBUlSC5zCSJIkSYPzSqYkSZIGZ8iUJEnS4AyZkiRJGpwhU5IkSYMzZEqSJGlwhkxJkiQNzpApSZKkwX0HcsLBwRti2/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "S_dB = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "librosa.display.specshow(S_dB, x_axis='time',\n",
    "                          y_axis='mel', sr=8000)\n",
    "plt.title('Mel-frequency spectrogram')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
