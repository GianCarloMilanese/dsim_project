{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTzZ1yR6AJcG"
   },
   "source": [
    "# Test model - Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WxSYVrOAJcH"
   },
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:maybe move this function to some .py file\n",
    "def load_audio_model(models_dir, model_name):\n",
    "    full_name = models_dir+\"/\"+model_name\n",
    "\n",
    "    model = keras.models.load_model(full_name)\n",
    "    json_name = full_name.replace(\"h5\", \"json\")\n",
    "\n",
    "    with open(json_name, \"r\") as jf:\n",
    "        d = json.load(jf)\n",
    "    d[\"model\"] = model\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"../best_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spectrogram-based classifiers\n",
    "# digits_model = load_audio_model(models_dir, \"digit_recognition.h5\")\n",
    "# speakers_model = load_audio_model(models_dir, \"speaker_recognition.h5\")\n",
    "# mfcc_speakers_model = load_audio_model(models_dir, \"mfcc_speaker_standard.h5\")\n",
    "# models = [digits_model, speakers_model, mfcc_speakers_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "models = [load_audio_model(models_dir, f) for f in os.listdir(models_dir) if f.endswith(\"h5\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUyrZr67AJcN"
   },
   "outputs": [],
   "source": [
    "def create_recording(duration, rec_rate, name = \"test.wav\", output_dir = \"test/\"):\n",
    "    print(\"Ready in 3...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"2...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"1...\")\n",
    "    time.sleep(1)\n",
    "    print(\"Go.\")\n",
    "    rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "    print(\"Playing the recording.\")\n",
    "    sd.play(rec, rec_rate)\n",
    "\n",
    "    # after hearing the recording, decide whether to record it again or continue to next number\n",
    "    # if you type anything, record again\n",
    "    # if you press enter, save current recording & go to next number\n",
    "    ok = input(\"OK? [Y/n]\")\n",
    "    if (ok == \"\") or (ok.lower() in \"yes\"):\n",
    "        librosa.output.write_wav(output_dir+name, rec, rec_rate)\n",
    "        return rec\n",
    "    ipd.clear_output(wait=True)\n",
    "    create_recording(duration, rec_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QBcrjAzAJcO"
   },
   "outputs": [],
   "source": [
    "def trim_audio(file, input_dir=\"test/\", output_dir=\"test/\", db=-48):\n",
    "\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"There should be an input \\\"{input_dir}\\\" directory.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # create output directory if not there yet\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    temp1 = output_dir+\"temp1.wav\"\n",
    "    temp2 = output_dir+\"temp2.wav\"\n",
    "    temp3 = output_dir+\"temp3.wav\"\n",
    " \n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_dir+file, \"-af\", f\"silenceremove=1:0:{db}dB\", temp1])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp1, \"-af\", \"areverse\", temp2])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp2, \"-af\", f\"silenceremove=1:0.1:{db}dB\", temp3])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp3, \"-af\", \"areverse\", output_dir+file])\n",
    "    \n",
    "    os.remove(temp1)\n",
    "    os.remove(temp2)\n",
    "    os.remove(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Classifiers-SpectrogramBased\n",
    "max_rec_length = 9015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkZPGYwUAJcQ"
   },
   "outputs": [],
   "source": [
    "# Debugging comments are left for the moment\n",
    "def test_NN(models, max_rec_length, answer = None,\n",
    "            duration=2, rec_rate=8000, directory = \"test/\",\n",
    "            filename = \"test.wav\", db=-48):\n",
    "    create_recording(duration, rec_rate, filename, directory)   \n",
    "    ipd.clear_output()\n",
    "    \n",
    "    # this is not great, but at least we make sure that the audio is trimmed\n",
    "    # TODO: find better solution\n",
    "    len_rec = 10000\n",
    "    # print(\"Before padding\")\n",
    "    print(\"Trimming recording...\")\n",
    "    while len_rec > max_rec_length:\n",
    "        # Trim until it the recording is shorter than max_rec_length\n",
    "        \n",
    "        trim_audio(filename, directory, directory, db=db)\n",
    "        rec, _ = librosa.core.load(directory + \"/\" + filename, sr = rec_rate)\n",
    "        \n",
    "        # print(rec.shape)\n",
    "        len_rec = rec.shape[0]\n",
    "        db = int(db*0.95) # trim more violently at each step\n",
    "        \n",
    "    # TODO: is the padding the same for mfcc models?\n",
    "    rec = data_preparation.padding(max_rec_length, rec)\n",
    "    \n",
    "    # print(\"After padding\")\n",
    "    # print(rec.shape)\n",
    "    # sd.play(rec, rec_rate)\n",
    "    \n",
    "    preds = []\n",
    "    print(\"Predicting...\\n\")\n",
    "    for model in models:\n",
    "        if model[\"type\"] == \"spectrogram\":\n",
    "            proc_rec = data_preparation.compute_spectrogram(rec, normalize=True)\n",
    "        else:\n",
    "            # TODO: is the padding the same for mfcc models?\n",
    "            proc_rec = data_preparation.mfcc(rec, flatten = False)\n",
    "        proc_rec = proc_rec[np.newaxis,:,:,np.newaxis]\n",
    "        pred = model[\"class_indices\"][model[\"model\"].predict_classes(proc_rec)[0]]\n",
    "        preds.append(pred)\n",
    "        print(\"{:50s}{}\".format(model[\"name\"]+\" prediction: \", pred))\n",
    "\n",
    "    # print(\"Model prediction: {}\".format(preds[0]))\n",
    "    if answer is not None:\n",
    "        print(\"\\nCorrect answer: {}, {}\".format(*answer))\n",
    "    return preds, rec, rec_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-M4mw6KAJcW",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming recording...\n",
      "Predicting...\n",
      "\n",
      "Spectrogram-based digit classifier prediction:    1\n",
      "MFCC-based speaker classifier prediction:         jackson\n",
      "Spectrogram-based speaker classifier prediction:  jackson\n",
      "\n",
      "Correct answer: gian, 1\n"
     ]
    }
   ],
   "source": [
    "preds, rec, rec_rate = test_NN(models, max_rec_length, answer=[\"gian\", 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- General cleaning\n",
    "- Print prediction confidence? Choose not to display prediction below some threshold?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
