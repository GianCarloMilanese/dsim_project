{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import wavfile as wav\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Strumenti di classificazione\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Feature audio avanzate\n",
    "import librosa\n",
    "import librosa.display as lid\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import data_preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCH=32\n",
    "EPOCHS=50\n",
    "PATIENCE=5\n",
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load recordings and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdd_dir=\"./recordings/\"\n",
    "our_recs_dir=\"./preprocessed_recs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./recordings/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1225dacf792458690ce17a077eb068a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ./preprocessed_recs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f353a8336c546ff838f6655e51e2a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_zeros >>>\n",
      "pad_zeros <<<\n"
     ]
    }
   ],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.6 s, sys: 731 ms, total: 30.3 s\n",
      "Wall time: 49.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = [data_preparation.combo(x) for x in pad_recordings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with label = speaker\n",
    "### No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_speakers,\n",
    "                                                      test_size=0.4, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,\n",
    "                                                      test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal = StandardScaler()\n",
    "scaler_normal.fit(X_train)\n",
    "X_train_scaled = scaler_normal.transform(X_train)\n",
    "X_val_scaled =  scaler_normal.transform(X_val)\n",
    "X_test_scaled =  scaler_normal.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_speaker_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.68 s, sys: 33.4 ms, total: 2.71 s\n",
      "Wall time: 6.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker_normal.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 15 ms, total: 1.02 s\n",
      "Wall time: 2.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf_speaker_normal.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.95      0.98        21\n",
      "      alinda       0.92      1.00      0.96        12\n",
      "        gian       1.00      1.00      1.00        19\n",
      "     jackson       1.00      0.97      0.98        89\n",
      "      khaled       0.95      0.86      0.90        22\n",
      "     nicolas       1.00      1.00      1.00       101\n",
      "        theo       0.95      0.98      0.96       112\n",
      "    yweweler       0.99      1.00      1.00       104\n",
      "\n",
      "    accuracy                           0.98       480\n",
      "   macro avg       0.98      0.97      0.97       480\n",
      "weighted avg       0.98      0.98      0.98       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.6 s, sys: 727 ms, total: 27.3 s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = np.array([data_preparation.mfcc(x, flatten=False) for x in pad_recordings])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_speakers,\n",
    "                                                      test_size=0.4, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,\n",
    "                                                      test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_val_nn = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
    "X_test_nn = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,479,976\n",
      "Trainable params: 1,479,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, y_train_speaker_nn, target_names = data_preparation.transform_categorical_y(y_train)\n",
    "y_val_speaker_nn = enc.transform(y_val.reshape(-1, 1)).toarray()\n",
    "y_test_speaker_nn = enc.transform(y_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "1440/1440 [==============================] - 5s 4ms/sample - loss: 12.7801 - acc: 0.2056 - val_loss: 12.6258 - val_acc: 0.2167\n",
      "Epoch 2/50\n",
      "1440/1440 [==============================] - 4s 3ms/sample - loss: 12.8735 - acc: 0.2007 - val_loss: 12.6258 - val_acc: 0.2167\n",
      "Epoch 3/50\n",
      "1440/1440 [==============================] - 4s 3ms/sample - loss: 12.9057 - acc: 0.1993 - val_loss: 12.6258 - val_acc: 0.2167\n",
      "Epoch 4/50\n",
      "1440/1440 [==============================] - 4s 3ms/sample - loss: 12.7714 - acc: 0.2076 - val_loss: 12.6258 - val_acc: 0.2167\n",
      "Epoch 5/50\n",
      "1440/1440 [==============================] - 4s 3ms/sample - loss: 12.7937 - acc: 0.2062 - val_loss: 12.6258 - val_acc: 0.2167\n",
      "Epoch 6/50\n",
      "1440/1440 [==============================] - 4s 3ms/sample - loss: 12.8161 - acc: 0.2049 - val_loss: 12.6258 - val_acc: 0.2167\n",
      "Epoch 7/50\n",
      "1440/1440 [==============================] - 4s 3ms/sample - loss: 12.7825 - acc: 0.2069 - val_loss: 12.6258 - val_acc: 0.2167\n",
      "Epoch 8/50\n",
      "1440/1440 [==============================] - 4s 3ms/sample - loss: 12.7602 - acc: 0.2083 - val_loss: 12.6258 - val_acc: 0.2167\n",
      "CPU times: user 35.5 s, sys: 4.01 s, total: 39.5 s\n",
      "Wall time: 35.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe865db07d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_nn, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_nn, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.00      0.00      0.00        21\n",
      "      alinda       0.00      0.00      0.00        12\n",
      "        gian       0.00      0.00      0.00        19\n",
      "     jackson       0.00      0.00      0.00        89\n",
      "      khaled       0.00      0.00      0.00        22\n",
      "     nicolas       0.00      0.00      0.00       101\n",
      "        theo       0.00      0.00      0.00       112\n",
      "    yweweler       0.22      1.00      0.36       104\n",
      "\n",
      "    accuracy                           0.22       480\n",
      "   macro avg       0.03      0.12      0.04       480\n",
      "weighted avg       0.05      0.22      0.08       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_speaker_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_nn)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with  batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/50\n",
      "1440/1440 [==============================] - 12s 9ms/sample - loss: 0.8108 - acc: 0.7618 - val_loss: 8.0217 - val_acc: 0.2396\n",
      "Epoch 2/50\n",
      "1440/1440 [==============================] - 9s 6ms/sample - loss: 0.3540 - acc: 0.9187 - val_loss: 5.3142 - val_acc: 0.2458\n",
      "Epoch 3/50\n",
      "1440/1440 [==============================] - 9s 6ms/sample - loss: 0.2010 - acc: 0.9611 - val_loss: 1.6074 - val_acc: 0.4792\n",
      "Epoch 4/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.1537 - acc: 0.9743 - val_loss: 0.3402 - val_acc: 0.8750\n",
      "Epoch 5/50\n",
      "1440/1440 [==============================] - 10s 7ms/sample - loss: 0.1273 - acc: 0.9799 - val_loss: 0.3143 - val_acc: 0.9000\n",
      "Epoch 6/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.1089 - acc: 0.9847 - val_loss: 0.1466 - val_acc: 0.9708\n",
      "Epoch 7/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0841 - acc: 0.9889 - val_loss: 0.5909 - val_acc: 0.7667\n",
      "Epoch 8/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0907 - acc: 0.9840 - val_loss: 0.0782 - val_acc: 0.9833\n",
      "Epoch 9/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0735 - acc: 0.9910 - val_loss: 0.0683 - val_acc: 0.9875\n",
      "Epoch 10/50\n",
      "1440/1440 [==============================] - 9s 6ms/sample - loss: 0.0711 - acc: 0.9903 - val_loss: 0.0878 - val_acc: 0.9771\n",
      "Epoch 11/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0738 - acc: 0.9903 - val_loss: 0.0734 - val_acc: 0.9875\n",
      "Epoch 12/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0544 - acc: 0.9958 - val_loss: 0.0596 - val_acc: 0.9917\n",
      "Epoch 13/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0599 - acc: 0.9937 - val_loss: 0.0595 - val_acc: 0.9896\n",
      "Epoch 14/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0583 - acc: 0.9917 - val_loss: 0.2074 - val_acc: 0.9292\n",
      "Epoch 15/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0537 - acc: 0.9931 - val_loss: 0.0586 - val_acc: 0.9896\n",
      "Epoch 16/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0484 - acc: 0.9944 - val_loss: 0.0850 - val_acc: 0.9896\n",
      "Epoch 17/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0492 - acc: 0.9944 - val_loss: 0.1201 - val_acc: 0.9667\n",
      "Epoch 18/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0490 - acc: 0.9937 - val_loss: 0.0736 - val_acc: 0.9812\n",
      "Epoch 19/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0452 - acc: 0.9937 - val_loss: 0.0900 - val_acc: 0.9729\n",
      "Epoch 20/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0391 - acc: 0.9979 - val_loss: 0.0559 - val_acc: 0.9937\n",
      "Epoch 21/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0328 - acc: 1.0000 - val_loss: 0.0463 - val_acc: 0.9937\n",
      "Epoch 22/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0414 - acc: 0.9944 - val_loss: 0.0581 - val_acc: 0.9854\n",
      "Epoch 23/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0373 - acc: 0.9951 - val_loss: 0.0595 - val_acc: 0.9896\n",
      "Epoch 24/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0296 - acc: 0.9993 - val_loss: 0.0454 - val_acc: 0.9917\n",
      "Epoch 25/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0308 - acc: 0.9986 - val_loss: 0.0759 - val_acc: 0.9833\n",
      "Epoch 26/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0296 - acc: 0.9993 - val_loss: 0.0598 - val_acc: 0.9854\n",
      "Epoch 27/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0321 - acc: 0.9993 - val_loss: 0.0437 - val_acc: 0.9958\n",
      "Epoch 28/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0275 - acc: 0.9986 - val_loss: 0.0396 - val_acc: 0.9937\n",
      "Epoch 29/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0268 - acc: 0.9986 - val_loss: 0.0406 - val_acc: 0.9958\n",
      "Epoch 30/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0281 - acc: 0.9993 - val_loss: 0.0622 - val_acc: 0.9792\n",
      "Epoch 31/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0278 - acc: 0.9986 - val_loss: 0.0457 - val_acc: 0.9875\n",
      "Epoch 32/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0268 - acc: 0.9979 - val_loss: 0.0351 - val_acc: 0.9937\n",
      "Epoch 33/50\n",
      "1440/1440 [==============================] - 7s 5ms/sample - loss: 0.0292 - acc: 0.9986 - val_loss: 0.0627 - val_acc: 0.9792\n",
      "Epoch 34/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0232 - acc: 0.9979 - val_loss: 0.0424 - val_acc: 0.9917\n",
      "Epoch 35/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0241 - acc: 0.9986 - val_loss: 0.0795 - val_acc: 0.9833\n",
      "Epoch 36/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 0.9958\n",
      "Epoch 37/50\n",
      "1440/1440 [==============================] - 7s 5ms/sample - loss: 0.0241 - acc: 0.9993 - val_loss: 0.0318 - val_acc: 0.9917\n",
      "Epoch 38/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0237 - acc: 0.9993 - val_loss: 0.0298 - val_acc: 0.9937\n",
      "Epoch 39/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0201 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 0.9937\n",
      "Epoch 40/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 0.9958\n",
      "Epoch 41/50\n",
      "1440/1440 [==============================] - 8s 5ms/sample - loss: 0.0220 - acc: 0.9979 - val_loss: 0.0313 - val_acc: 0.9958\n",
      "Epoch 42/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0196 - acc: 0.9993 - val_loss: 0.0337 - val_acc: 0.9937\n",
      "Epoch 43/50\n",
      "1440/1440 [==============================] - 8s 6ms/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9917\n",
      "CPU times: user 7min 33s, sys: 39.9 s, total: 8min 13s\n",
      "Wall time: 5min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe865db0fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_nn, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_nn, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.00      0.00      0.00        21\n",
      "      alinda       0.00      0.00      0.00        12\n",
      "        gian       0.00      0.00      0.00        19\n",
      "     jackson       1.00      0.03      0.07        89\n",
      "      khaled       0.04      0.95      0.08        22\n",
      "     nicolas       0.00      0.00      0.00       101\n",
      "        theo       0.00      0.00      0.00       112\n",
      "    yweweler       0.00      0.00      0.00       104\n",
      "\n",
      "    accuracy                           0.05       480\n",
      "   macro avg       0.13      0.12      0.02       480\n",
      "weighted avg       0.19      0.05      0.02       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_nn)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = np.concatenate([X_train_nn, X_val_nn], axis=0)\n",
    "y_train_nn = np.concatenate([y_train_speaker_nn, y_val_speaker_nn], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/38\n",
      "1920/1920 [==============================] - 13s 7ms/sample - loss: 0.7247 - acc: 0.7729\n",
      "Epoch 2/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.2761 - acc: 0.9349\n",
      "Epoch 3/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.1757 - acc: 0.9594\n",
      "Epoch 4/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.1435 - acc: 0.9667\n",
      "Epoch 5/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.0947 - acc: 0.9818\n",
      "Epoch 6/38\n",
      "1920/1920 [==============================] - 11s 6ms/sample - loss: 0.0829 - acc: 0.9880\n",
      "Epoch 7/38\n",
      "1920/1920 [==============================] - 11s 6ms/sample - loss: 0.0750 - acc: 0.9854\n",
      "Epoch 8/38\n",
      "1920/1920 [==============================] - 11s 6ms/sample - loss: 0.0642 - acc: 0.9885\n",
      "Epoch 9/38\n",
      "1920/1920 [==============================] - 11s 6ms/sample - loss: 0.0527 - acc: 0.9917\n",
      "Epoch 10/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.0493 - acc: 0.9927\n",
      "Epoch 11/38\n",
      "1920/1920 [==============================] - 11s 6ms/sample - loss: 0.0497 - acc: 0.9922\n",
      "Epoch 12/38\n",
      "1920/1920 [==============================] - 11s 6ms/sample - loss: 0.0396 - acc: 0.9953\n",
      "Epoch 13/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.0333 - acc: 0.9958\n",
      "Epoch 14/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0291 - acc: 0.9969\n",
      "Epoch 15/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0299 - acc: 0.9969\n",
      "Epoch 16/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0268 - acc: 0.9984\n",
      "Epoch 17/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0298 - acc: 0.9979\n",
      "Epoch 18/38\n",
      "1920/1920 [==============================] - 11s 6ms/sample - loss: 0.0308 - acc: 0.9953\n",
      "Epoch 19/38\n",
      "1920/1920 [==============================] - 11s 5ms/sample - loss: 0.0261 - acc: 0.9979\n",
      "Epoch 20/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.0254 - acc: 0.9984\n",
      "Epoch 21/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.0230 - acc: 0.9974\n",
      "Epoch 22/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0229 - acc: 0.9979\n",
      "Epoch 23/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0282 - acc: 0.9969\n",
      "Epoch 24/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0195 - acc: 0.9990\n",
      "Epoch 25/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0179 - acc: 0.9990\n",
      "Epoch 26/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.0210 - acc: 0.9979\n",
      "Epoch 27/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.0243 - acc: 0.9958\n",
      "Epoch 28/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0206 - acc: 0.9979\n",
      "Epoch 29/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0216 - acc: 0.9984\n",
      "Epoch 30/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0206 - acc: 0.9974\n",
      "Epoch 31/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0189 - acc: 0.9995\n",
      "Epoch 32/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.0184 - acc: 0.9995\n",
      "Epoch 33/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 34/38\n",
      "1920/1920 [==============================] - 10s 5ms/sample - loss: 0.0173 - acc: 0.9990\n",
      "Epoch 35/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 36/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0131 - acc: 0.9995\n",
      "Epoch 37/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0178 - acc: 0.9990\n",
      "Epoch 38/38\n",
      "1920/1920 [==============================] - 9s 5ms/sample - loss: 0.0149 - acc: 0.9990\n",
      "CPU times: user 8min 47s, sys: 48.8 s, total: 9min 36s\n",
      "Wall time: 6min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe86886d590>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)\n",
    "model.fit(X_train_nn, y_train_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=38,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.96      0.96      0.96        23\n",
      "      alinda       0.94      1.00      0.97        17\n",
      "        gian       1.00      0.95      0.98        22\n",
      "     jackson       1.00      1.00      1.00       118\n",
      "      khaled       1.00      1.00      1.00        16\n",
      "     nicolas       1.00      1.00      1.00        94\n",
      "        theo       0.98      0.99      0.98        92\n",
      "    yweweler       1.00      0.99      0.99        98\n",
      "\n",
      "    accuracy                           0.99       480\n",
      "   macro avg       0.98      0.99      0.99       480\n",
      "weighted avg       0.99      0.99      0.99       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_nn = np.argmax(y_test_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_test_nn)\n",
    "print(classification_report(y_test_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/mfcc_speaker_standard.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "transform_recordings >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "transform_recordings <<<\n",
      "CPU times: user 5min 1s, sys: 10.6 s, total: 5min 12s\n",
      "Wall time: 6min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(\n",
    "    audio_dirs= [our_recs_dir, fsdd_dir],\n",
    "    y_type= ['speakers_us', 'speakers_default'],\n",
    "    n_category_test=30,\n",
    "    include_pitch=False,\n",
    "    max_length=17000,\n",
    "    transform_function=\"mfcc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_2d = X_train_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_2d = X_val_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_2d = X_test_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal = StandardScaler()\n",
    "X_train_speaker_2d = scaler_normal.fit_transform(X_train_speaker_2d)\n",
    "X_val_speaker_2d =  scaler_normal.transform(X_val_speaker_2d)\n",
    "X_test_speaker_2d =  scaler_normal.transform(X_test_speaker_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 328 ms, total: 1min 33s\n",
      "Wall time: 1min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker_normal.fit(X_train_speaker_2d, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.97      0.86      0.91        99\n",
      "      alinda       0.88      0.92      0.90        74\n",
      "        gian       0.96      0.89      0.92        82\n",
      "     jackson       0.90      1.00      0.94       540\n",
      "      khaled       0.92      0.83      0.87        81\n",
      "     nicolas       0.99      0.98      0.99       592\n",
      "        theo       0.82      0.82      0.82       565\n",
      "    yweweler       0.87      0.82      0.84       557\n",
      "\n",
      "    accuracy                           0.90      2590\n",
      "   macro avg       0.91      0.89      0.90      2590\n",
      "weighted avg       0.90      0.90      0.90      2590\n",
      "\n",
      "CPU times: user 25 s, sys: 67.5 ms, total: 25.1 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf_speaker_normal.predict(X_val_speaker_2d)\n",
    "print(classification_report(y_val_speaker, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, y_train_speaker_nn, target_names = data_preparation.transform_categorical_y(y_train_speaker)\n",
    "y_val_speaker_nn = enc.transform(y_val_speaker.reshape(-1, 1)).toarray()\n",
    "y_test_speaker_nn = enc.transform(y_test_speaker.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker = X_train_speaker.reshape(X_train_speaker.shape[0],\n",
    "                                          X_train_speaker.shape[1],\n",
    "                                          X_train_speaker.shape[2],\n",
    "                                          1)\n",
    "X_val_speaker = X_val_speaker.reshape(X_val_speaker.shape[0],\n",
    "                                      X_val_speaker.shape[1],\n",
    "                                      X_val_speaker.shape[2],\n",
    "                                      1)\n",
    "X_test_speaker = X_test_speaker.reshape(X_test_speaker.shape[0],\n",
    "                                        X_test_speaker.shape[1],\n",
    "                                        X_test_speaker.shape[2],\n",
    "                                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10358 samples, validate on 2590 samples\n",
      "Epoch 1/50\n",
      "10358/10358 [==============================] - 28s 3ms/sample - loss: 0.6916 - acc: 0.7599 - val_loss: 0.4531 - val_acc: 0.8290\n",
      "Epoch 2/50\n",
      "10358/10358 [==============================] - 27s 3ms/sample - loss: 0.4290 - acc: 0.8490 - val_loss: 0.3432 - val_acc: 0.8865\n",
      "Epoch 3/50\n",
      "10358/10358 [==============================] - 26s 3ms/sample - loss: 0.3602 - acc: 0.8745 - val_loss: 0.3706 - val_acc: 0.8695\n",
      "Epoch 4/50\n",
      "10358/10358 [==============================] - 26s 2ms/sample - loss: 0.3348 - acc: 0.8817 - val_loss: 0.4245 - val_acc: 0.8317\n",
      "Epoch 5/50\n",
      "10358/10358 [==============================] - 26s 2ms/sample - loss: 0.3234 - acc: 0.8858 - val_loss: 0.2674 - val_acc: 0.9093\n",
      "Epoch 6/50\n",
      "10358/10358 [==============================] - 25s 2ms/sample - loss: 0.3070 - acc: 0.8926 - val_loss: 0.3010 - val_acc: 0.8741\n",
      "Epoch 7/50\n",
      "10358/10358 [==============================] - 25s 2ms/sample - loss: 0.2938 - acc: 0.8942 - val_loss: 0.3150 - val_acc: 0.8888\n",
      "Epoch 8/50\n",
      "10358/10358 [==============================] - 25s 2ms/sample - loss: 0.2957 - acc: 0.8939 - val_loss: 0.2872 - val_acc: 0.8853\n",
      "Epoch 9/50\n",
      "10358/10358 [==============================] - 25s 2ms/sample - loss: 0.2751 - acc: 0.8976 - val_loss: 0.3287 - val_acc: 0.8529\n",
      "Epoch 10/50\n",
      "10358/10358 [==============================] - 25s 2ms/sample - loss: 0.2694 - acc: 0.9050 - val_loss: 0.2916 - val_acc: 0.8958\n",
      "CPU times: user 12min 57s, sys: 52.9 s, total: 13min 50s\n",
      "Wall time: 4min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe86e4d2d90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.98      0.90      0.94        99\n",
      "      alinda       0.92      0.89      0.90        74\n",
      "        gian       0.96      0.85      0.90        82\n",
      "     jackson       0.99      0.99      0.99       540\n",
      "      khaled       0.93      0.94      0.93        81\n",
      "     nicolas       0.98      0.98      0.98       592\n",
      "        theo       0.85      0.79      0.82       565\n",
      "    yweweler       0.80      0.89      0.84       557\n",
      "\n",
      "    accuracy                           0.91      2590\n",
      "   macro avg       0.93      0.90      0.91      2590\n",
      "weighted avg       0.91      0.91      0.91      2590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation lead to worse performance that \"clean\" scenario, however its estimate seems \"more accurate\" having seen far more data. Just for being sure I will store it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "12948/12948 [==============================] - 76s 6ms/sample - loss: 0.6522 - acc: 0.7733\n",
      "Epoch 2/5\n",
      "12948/12948 [==============================] - 69s 5ms/sample - loss: 0.3773 - acc: 0.8635\n",
      "Epoch 3/5\n",
      "12948/12948 [==============================] - 67s 5ms/sample - loss: 0.3148 - acc: 0.8839\n",
      "Epoch 4/5\n",
      "12948/12948 [==============================] - 63s 5ms/sample - loss: 0.3104 - acc: 0.8868\n",
      "Epoch 5/5\n",
      "12948/12948 [==============================] - 64s 5ms/sample - loss: 0.2867 - acc: 0.8936\n",
      "CPU times: user 7min 53s, sys: 44.8 s, total: 8min 38s\n",
      "Wall time: 5min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe7dc4de590>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train_nn = np.concatenate([X_train_speaker, X_val_speaker], axis=0)\n",
    "y_train_nn = np.concatenate([y_train_speaker_nn, y_val_speaker_nn], axis=0)\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)\n",
    "model.fit(X_train_nn, y_train_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=5,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.97      0.97      0.97        30\n",
      "      alinda       1.00      0.97      0.98        30\n",
      "        gian       1.00      0.97      0.98        30\n",
      "     jackson       1.00      1.00      1.00        30\n",
      "      khaled       0.97      1.00      0.98        30\n",
      "     nicolas       0.91      1.00      0.95        30\n",
      "        theo       0.97      1.00      0.98        30\n",
      "    yweweler       1.00      0.90      0.95        30\n",
      "\n",
      "    accuracy                           0.97       240\n",
      "   macro avg       0.98      0.98      0.97       240\n",
      "weighted avg       0.98      0.97      0.97       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test_nn = np.argmax(y_test_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(Y_test_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/mfcc_speaker_augm.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with label = number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [data_preparation.combo(x) for x in pad_recordings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_digits,\n",
    "                                                      test_size=0.4, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,\n",
    "                                                      test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal2 = StandardScaler()\n",
    "X_train = scaler_normal2.fit_transform(X_train)\n",
    "X_val_scaled = scaler_normal2.transform(X_val)\n",
    "X_test_scaled =  scaler_normal2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_number_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.96 s, sys: 82.7 ms, total: 4.04 s\n",
      "Wall time: 4.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_number_normal.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 15.6 ms, total: 1.19 s\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf_number_normal.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        44\n",
      "           1       0.95      0.89      0.92        44\n",
      "           2       0.96      0.90      0.92        48\n",
      "           3       0.96      0.95      0.96        58\n",
      "           4       1.00      0.94      0.97        35\n",
      "           5       0.96      0.94      0.95        51\n",
      "           6       0.90      0.87      0.89        54\n",
      "           7       0.96      1.00      0.98        45\n",
      "           8       0.96      0.88      0.92        56\n",
      "           9       0.93      0.91      0.92        45\n",
      "\n",
      "    accuracy                           0.93       480\n",
      "   macro avg       0.93      0.93      0.93       480\n",
      "weighted avg       0.93      0.93      0.93       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation (noise and pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 18000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "transform_recordings >>>\n",
      "17567\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "transform_recordings <<<\n",
      "CPU times: user 7min 6s, sys: 17.5 s, total: 7min 23s\n",
      "Wall time: 4min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digit, y_train_digit, X_val_digit, y_val_digit, X_test_digit, y_test_digit = data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=18000,\n",
    "                             transform_function=\"mfcc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digit.shape\n",
    "X_train_digit_2d = X_train_digit.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_digit.shape\n",
    "X_val_digit_2d = X_val_digit.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_test_digit.shape\n",
    "X_test_digit_2d = X_test_digit.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal = StandardScaler()\n",
    "X_train_digit_2d = scaler_normal.fit_transform(X_train_digit_2d)\n",
    "X_val_digit_2d =  scaler_normal.transform(X_val_digit_2d)\n",
    "X_test_digit_2d =  scaler_normal.transform(X_test_digit_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 48s, sys: 1.97 s, total: 7min 50s\n",
      "Wall time: 10min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker_normal.fit(X_train_digit_2d, y_train_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89       468\n",
      "           1       0.74      0.87      0.80       461\n",
      "           2       0.85      0.74      0.79       428\n",
      "           3       0.79      0.82      0.80       461\n",
      "           4       0.96      0.82      0.88       481\n",
      "           5       0.81      0.88      0.84       487\n",
      "           6       0.73      0.74      0.73       449\n",
      "           7       0.89      0.78      0.83       472\n",
      "           8       0.82      0.85      0.84       442\n",
      "           9       0.76      0.85      0.80       469\n",
      "\n",
      "    accuracy                           0.82      4618\n",
      "   macro avg       0.83      0.82      0.82      4618\n",
      "weighted avg       0.83      0.82      0.82      4618\n",
      "\n",
      "CPU times: user 2min 7s, sys: 949 ms, total: 2min 8s\n",
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf_speaker_normal.predict(X_val_digit_2d)\n",
    "print(classification_report(y_val_digit, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_digit_nn = tf.keras.utils.to_categorical(y_train_digit, 10)\n",
    "y_val_digit_nn = tf.keras.utils.to_categorical(y_val_digit, 10)\n",
    "y_test_digit_nn = tf.keras.utils.to_categorical(y_test_digit, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digit = X_train_digit.reshape(X_train_digit.shape[0],\n",
    "                                          X_train_digit.shape[1],\n",
    "                                          X_train_digit.shape[2],\n",
    "                                          1)\n",
    "X_val_digit = X_val_digit.reshape(X_val_digit.shape[0],\n",
    "                                      X_val_digit.shape[1],\n",
    "                                      X_val_digit.shape[2],\n",
    "                                      1)\n",
    "X_test_digit = X_test_digit.reshape(X_test_digit.shape[0],\n",
    "                                        X_test_digit.shape[1],\n",
    "                                        X_test_digit.shape[2],\n",
    "                                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (X_train_digit.shape[1], X_train_digit.shape[2], 1)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,480,874\n",
      "Trainable params: 1,480,554\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=10, input_shape=input_shape, batch_normalisation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18471 samples, validate on 4618 samples\n",
      "Epoch 1/50\n",
      "18471/18471 [==============================] - 86s 5ms/sample - loss: 1.2177 - acc: 0.5901 - val_loss: 0.8624 - val_acc: 0.7170\n",
      "Epoch 2/50\n",
      "18471/18471 [==============================] - 85s 5ms/sample - loss: 0.8838 - acc: 0.7098 - val_loss: 0.8292 - val_acc: 0.7291\n",
      "Epoch 3/50\n",
      "18471/18471 [==============================] - 85s 5ms/sample - loss: 0.8161 - acc: 0.7318 - val_loss: 0.8555 - val_acc: 0.7181\n",
      "Epoch 4/50\n",
      "18471/18471 [==============================] - 88s 5ms/sample - loss: 0.7647 - acc: 0.7448 - val_loss: 0.8059 - val_acc: 0.7291\n",
      "Epoch 5/50\n",
      "18471/18471 [==============================] - 87s 5ms/sample - loss: 0.7226 - acc: 0.7612 - val_loss: 0.6414 - val_acc: 0.7919\n",
      "Epoch 6/50\n",
      "18471/18471 [==============================] - 97s 5ms/sample - loss: 0.6977 - acc: 0.7730 - val_loss: 0.6613 - val_acc: 0.7655\n",
      "Epoch 7/50\n",
      "18471/18471 [==============================] - 115s 6ms/sample - loss: 0.6808 - acc: 0.7769 - val_loss: 0.6470 - val_acc: 0.7863\n",
      "Epoch 8/50\n",
      "18471/18471 [==============================] - 107s 6ms/sample - loss: 0.6698 - acc: 0.7776 - val_loss: 0.9161 - val_acc: 0.6851\n",
      "Epoch 9/50\n",
      "18471/18471 [==============================] - 105s 6ms/sample - loss: 0.6629 - acc: 0.7827 - val_loss: 0.6590 - val_acc: 0.7709\n",
      "Epoch 10/50\n",
      "18471/18471 [==============================] - 118s 6ms/sample - loss: 0.6448 - acc: 0.7875 - val_loss: 0.6240 - val_acc: 0.7902\n",
      "Epoch 11/50\n",
      "18471/18471 [==============================] - 92s 5ms/sample - loss: 0.6466 - acc: 0.7873 - val_loss: 0.5401 - val_acc: 0.8190\n",
      "Epoch 12/50\n",
      "18471/18471 [==============================] - 92s 5ms/sample - loss: 0.6284 - acc: 0.7906 - val_loss: 0.5523 - val_acc: 0.8149\n",
      "Epoch 13/50\n",
      "18471/18471 [==============================] - 118s 6ms/sample - loss: 0.6364 - acc: 0.7908 - val_loss: 0.6540 - val_acc: 0.7733\n",
      "Epoch 14/50\n",
      "18471/18471 [==============================] - 96s 5ms/sample - loss: 0.6189 - acc: 0.7952 - val_loss: 0.5796 - val_acc: 0.8068\n",
      "Epoch 15/50\n",
      "18471/18471 [==============================] - 85s 5ms/sample - loss: 0.6041 - acc: 0.7952 - val_loss: 0.5660 - val_acc: 0.8181\n",
      "Epoch 16/50\n",
      "18471/18471 [==============================] - 105s 6ms/sample - loss: 0.6010 - acc: 0.8010 - val_loss: 0.5942 - val_acc: 0.7973\n",
      "CPU times: user 36min 3s, sys: 3min 5s, total: 39min 9s\n",
      "Wall time: 26min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe6e7aa6190>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit, y_train_digit_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digit, y_val_digit_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       468\n",
      "           1       0.95      0.77      0.85       461\n",
      "           2       0.67      0.89      0.77       428\n",
      "           3       0.86      0.60      0.71       461\n",
      "           4       0.88      0.87      0.88       481\n",
      "           5       0.87      0.87      0.87       487\n",
      "           6       0.73      0.83      0.78       449\n",
      "           7       0.88      0.79      0.83       472\n",
      "           8       0.87      0.76      0.81       442\n",
      "           9       0.76      0.88      0.82       469\n",
      "\n",
      "    accuracy                           0.82      4618\n",
      "   macro avg       0.83      0.82      0.82      4618\n",
      "weighted avg       0.83      0.82      0.82      4618\n",
      "\n",
      "CPU times: user 4.6 s, sys: 191 ms, total: 4.79 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Y_val_nn = np.argmax(y_val_digit_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_digit)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies are similar, however the prediction \"speed\" of the CNN is better than the classic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,480,874\n",
      "Trainable params: 1,480,554\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/11\n",
      "23089/23089 [==============================] - 105s 5ms/sample - loss: 1.1736 - acc: 0.6095\n",
      "Epoch 2/11\n",
      "23089/23089 [==============================] - 124s 5ms/sample - loss: 0.8821 - acc: 0.7123\n",
      "Epoch 3/11\n",
      "23089/23089 [==============================] - 133s 6ms/sample - loss: 0.8190 - acc: 0.7346\n",
      "Epoch 4/11\n",
      "23089/23089 [==============================] - 110s 5ms/sample - loss: 0.7673 - acc: 0.7489\n",
      "Epoch 5/11\n",
      "23089/23089 [==============================] - 128s 6ms/sample - loss: 0.7344 - acc: 0.7598\n",
      "Epoch 6/11\n",
      "23089/23089 [==============================] - 103s 4ms/sample - loss: 0.7070 - acc: 0.7686\n",
      "Epoch 7/11\n",
      "23089/23089 [==============================] - 113s 5ms/sample - loss: 0.6660 - acc: 0.7773\n",
      "Epoch 8/11\n",
      "23089/23089 [==============================] - 100s 4ms/sample - loss: 0.6560 - acc: 0.7828\n",
      "Epoch 9/11\n",
      "23089/23089 [==============================] - 106s 5ms/sample - loss: 0.6363 - acc: 0.7883\n",
      "Epoch 10/11\n",
      "23089/23089 [==============================] - 117s 5ms/sample - loss: 0.6294 - acc: 0.7900\n",
      "Epoch 11/11\n",
      "23089/23089 [==============================] - 132s 6ms/sample - loss: 0.6105 - acc: 0.7987\n",
      "CPU times: user 29min 51s, sys: 2min 43s, total: 32min 35s\n",
      "Wall time: 21min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe6d5b080d0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train_nn = np.concatenate([X_train_digit, X_val_digit], axis=0)\n",
    "y_train_nn = np.concatenate([y_train_digit_nn, y_val_digit_nn], axis=0)\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=10, batch_normalisation=True)\n",
    "model.fit(X_train_nn, y_train_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=11,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        30\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       0.91      0.97      0.94        30\n",
      "           3       0.88      1.00      0.94        30\n",
      "           4       0.83      1.00      0.91        30\n",
      "           5       1.00      0.83      0.91        30\n",
      "           6       1.00      0.77      0.87        30\n",
      "           7       1.00      0.77      0.87        30\n",
      "           8       0.89      0.83      0.86        30\n",
      "           9       0.86      1.00      0.92        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.93      0.92      0.91       300\n",
      "weighted avg       0.93      0.92      0.91       300\n",
      "\n",
      "CPU times: user 737 ms, sys: 149 ms, total: 887 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Y_test_nn = np.argmax(y_test_digit_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_test_digit)\n",
    "print(classification_report(Y_test_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/mfcc_digit_augm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
