{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import wavfile as wav\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Strumenti di classificazione\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Feature audio avanzate\n",
    "import librosa\n",
    "import librosa.display as lid\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import data_preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BATCH=32\n",
    "EPOCHS=50\n",
    "PATIENCE=5\n",
    "import tensorflow as tf\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load recordings and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdd_dir=\"./recordings/\"\n",
    "our_recs_dir=\"./preprocessed_recs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./recordings/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1559cf30af1465b8baa55c80d418081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ./preprocessed_recs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69960c8d79e64ed89a39f8cfec257799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_zeros >>>\n",
      "pad_zeros <<<\n"
     ]
    }
   ],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.7 s, sys: 504 ms, total: 28.2 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = [data_preparation.combo(x) for x in pad_recordings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier with label = speaker\n",
    "### No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_speakers,\n",
    "                                                      test_size=0.4, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,\n",
    "                                                      test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal = StandardScaler()\n",
    "scaler_normal.fit(X_train)\n",
    "X_train_scaled = scaler_normal.transform(X_train)\n",
    "X_val_scaled =  scaler_normal.transform(X_val)\n",
    "X_test_scaled =  scaler_normal.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_speaker_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 s, sys: 27.3 ms, total: 2.21 s\n",
      "Wall time: 2.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker_normal.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 800 ms, sys: 9.85 ms, total: 809 ms\n",
      "Wall time: 894 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf_speaker_normal.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.95      0.98        21\n",
      "      alinda       0.92      1.00      0.96        12\n",
      "        gian       1.00      1.00      1.00        19\n",
      "     jackson       1.00      0.97      0.98        89\n",
      "      khaled       0.95      0.86      0.90        22\n",
      "     nicolas       1.00      1.00      1.00       101\n",
      "        theo       0.95      0.98      0.96       112\n",
      "    yweweler       0.99      1.00      1.00       104\n",
      "\n",
      "    accuracy                           0.98       480\n",
      "   macro avg       0.98      0.97      0.97       480\n",
      "weighted avg       0.98      0.98      0.98       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 s, sys: 463 ms, total: 26.4 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = np.array([data_preparation.mfcc(x, flatten=False) for x in pad_recordings])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels_speakers,\n",
    "                                                      test_size=0.4, random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,\n",
    "                                                      test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_val_nn = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
    "X_test_nn = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,479,976\n",
      "Trainable params: 1,479,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, y_train_speaker_nn, target_names = data_preparation.transform_categorical_y(y_train)\n",
    "y_val_speaker_nn = enc.transform(y_val.reshape(-1, 1)).toarray()\n",
    "y_test_speaker_nn = enc.transform(y_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "1440/1440 [==============================] - 3s 2ms/sample - loss: 12.7747 - acc: 0.2069 - val_loss: 12.7266 - val_acc: 0.2104\n",
      "Epoch 2/50\n",
      "1440/1440 [==============================] - 3s 2ms/sample - loss: 12.7042 - acc: 0.2118 - val_loss: 12.7266 - val_acc: 0.2104\n",
      "Epoch 3/50\n",
      "1440/1440 [==============================] - 3s 2ms/sample - loss: 12.7053 - acc: 0.2111 - val_loss: 12.7266 - val_acc: 0.2104\n",
      "Epoch 4/50\n",
      "1440/1440 [==============================] - 2s 2ms/sample - loss: 12.7042 - acc: 0.2118 - val_loss: 12.7266 - val_acc: 0.2104\n",
      "Epoch 5/50\n",
      "1440/1440 [==============================] - 2s 2ms/sample - loss: 12.7042 - acc: 0.2118 - val_loss: 12.7266 - val_acc: 0.2104\n",
      "Epoch 6/50\n",
      "1440/1440 [==============================] - 2s 2ms/sample - loss: 12.7042 - acc: 0.2118 - val_loss: 12.7266 - val_acc: 0.2104\n",
      "Epoch 7/50\n",
      "1440/1440 [==============================] - 2s 2ms/sample - loss: 12.7042 - acc: 0.2118 - val_loss: 12.7266 - val_acc: 0.2104\n",
      "CPU times: user 29.7 s, sys: 3.14 s, total: 32.8 s\n",
      "Wall time: 19.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd057bde090>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_nn, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_nn, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.00      0.00      0.00        21\n",
      "      alinda       0.00      0.00      0.00        12\n",
      "        gian       0.00      0.00      0.00        19\n",
      "     jackson       0.00      0.00      0.00        89\n",
      "      khaled       0.00      0.00      0.00        22\n",
      "     nicolas       0.21      1.00      0.35       101\n",
      "        theo       0.00      0.00      0.00       112\n",
      "        theo       0.00      0.00      0.00       104\n",
      "\n",
      "    accuracy                           0.21       480\n",
      "   macro avg       0.03      0.12      0.04       480\n",
      "weighted avg       0.04      0.21      0.07       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_speaker_nn,  axis=1)\n",
    "y_pred = model.predict_classes(X_val_nn)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with  batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/50\n",
      "1440/1440 [==============================] - 5s 4ms/sample - loss: 0.8189 - acc: 0.7500 - val_loss: 11.6792 - val_acc: 0.2333\n",
      "Epoch 2/50\n",
      "1440/1440 [==============================] - 5s 4ms/sample - loss: 0.3262 - acc: 0.9083 - val_loss: 5.2288 - val_acc: 0.2500\n",
      "Epoch 3/50\n",
      "1440/1440 [==============================] - 6s 4ms/sample - loss: 0.2151 - acc: 0.9465 - val_loss: 0.9741 - val_acc: 0.5896\n",
      "Epoch 4/50\n",
      "1440/1440 [==============================] - 5s 3ms/sample - loss: 0.1583 - acc: 0.9701 - val_loss: 0.5399 - val_acc: 0.7583\n",
      "Epoch 5/50\n",
      "1440/1440 [==============================] - 6s 4ms/sample - loss: 0.1408 - acc: 0.9715 - val_loss: 0.1354 - val_acc: 0.9688\n",
      "Epoch 6/50\n",
      "1440/1440 [==============================] - 6s 4ms/sample - loss: 0.1103 - acc: 0.9771 - val_loss: 0.0673 - val_acc: 0.9833\n",
      "Epoch 7/50\n",
      "1440/1440 [==============================] - 7s 5ms/sample - loss: 0.0920 - acc: 0.9868 - val_loss: 0.0802 - val_acc: 0.9896\n",
      "Epoch 8/50\n",
      "1440/1440 [==============================] - 5s 3ms/sample - loss: 0.0886 - acc: 0.9840 - val_loss: 0.0771 - val_acc: 0.9833\n",
      "Epoch 9/50\n",
      "1440/1440 [==============================] - 6s 4ms/sample - loss: 0.0570 - acc: 0.9958 - val_loss: 0.1052 - val_acc: 0.9771\n",
      "Epoch 10/50\n",
      "1440/1440 [==============================] - 6s 4ms/sample - loss: 0.0599 - acc: 0.9917 - val_loss: 0.0733 - val_acc: 0.9833\n",
      "Epoch 11/50\n",
      "1440/1440 [==============================] - 4s 3ms/sample - loss: 0.0519 - acc: 0.9931 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "CPU times: user 2min, sys: 9.61 s, total: 2min 9s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd05a57e050>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_nn, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_nn, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.95      0.95      0.95        21\n",
      "      alinda       0.92      1.00      0.96        12\n",
      "        gian       1.00      0.95      0.97        19\n",
      "     jackson       1.00      1.00      1.00        89\n",
      "      khaled       1.00      0.95      0.98        22\n",
      "     nicolas       1.00      1.00      1.00       101\n",
      "        theo       0.96      0.98      0.97       112\n",
      "        theo       0.98      0.97      0.98       104\n",
      "\n",
      "    accuracy                           0.98       480\n",
      "   macro avg       0.98      0.98      0.98       480\n",
      "weighted avg       0.98      0.98      0.98       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_nn)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nn = np.concatenate([X_train_nn, X_val_nn], axis=0)\n",
    "y_train_nn = np.concatenate([y_train_speaker_nn, y_val_speaker_nn], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "1920/1920 [==============================] - 8s 4ms/sample - loss: 0.7741 - acc: 0.7625\n",
      "Epoch 2/6\n",
      "1920/1920 [==============================] - 6s 3ms/sample - loss: 0.3058 - acc: 0.9286\n",
      "Epoch 3/6\n",
      "1920/1920 [==============================] - 7s 4ms/sample - loss: 0.2024 - acc: 0.9578\n",
      "Epoch 4/6\n",
      "1920/1920 [==============================] - 7s 4ms/sample - loss: 0.1517 - acc: 0.9693\n",
      "Epoch 5/6\n",
      "1920/1920 [==============================] - 7s 4ms/sample - loss: 0.1345 - acc: 0.9760\n",
      "Epoch 6/6\n",
      "1920/1920 [==============================] - 7s 4ms/sample - loss: 0.1345 - acc: 0.9729\n",
      "CPU times: user 1min 23s, sys: 6.81 s, total: 1min 30s\n",
      "Wall time: 44 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd05a46e8d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = cnn_models.simple_model(input_shape=input_shape, num_classes=8, batch_normalisation=True)\n",
    "model.fit(X_train_nn, y_train_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=6,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.96      1.00      0.98        23\n",
      "      alinda       0.89      1.00      0.94        17\n",
      "        gian       1.00      1.00      1.00        22\n",
      "     jackson       0.97      1.00      0.98       118\n",
      "      khaled       1.00      0.75      0.86        16\n",
      "     nicolas       1.00      1.00      1.00        94\n",
      "        theo       0.99      0.99      0.99        92\n",
      "        theo       1.00      0.97      0.98        98\n",
      "\n",
      "    accuracy                           0.98       480\n",
      "   macro avg       0.98      0.96      0.97       480\n",
      "weighted avg       0.98      0.98      0.98       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_nn = np.argmax(y_test_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_test_nn)\n",
    "print(classification_report(y_test_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../best_models/mfcc_speaker_standard.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "transform_recordings >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "transform_recordings <<<\n",
      "CPU times: user 3min 42s, sys: 7.72 s, total: 3min 50s\n",
      "Wall time: 2min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(\n",
    "    audio_dirs= [our_recs_dir, fsdd_dir],\n",
    "    y_type= ['speakers_us', 'speakers_default'],\n",
    "    n_category_test=30,\n",
    "    include_pitch=False,\n",
    "    max_length=17000,\n",
    "    transform_function=\"mfcc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_2d = X_train_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_2d = X_val_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_test_speaker.shape\n",
    "X_test_speaker_2d = X_test_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal = StandardScaler()\n",
    "X_train_speaker_2d = scaler_normal.fit_transform(X_train_speaker_2d)\n",
    "X_val_speaker_2d =  scaler_normal.transform(X_val_speaker_2d)\n",
    "X_test_speaker_2d =  scaler_normal.transform(X_test_speaker_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 1.52 s, total: 1min 47s\n",
      "Wall time: 2min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_speaker_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")\n",
    "clf_speaker_normal.fit(X_train_speaker_2d, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.98      0.95      0.96        92\n",
      "      alinda       0.95      0.97      0.96        90\n",
      "        gian       0.92      0.92      0.92        79\n",
      "     jackson       0.94      0.99      0.97       576\n",
      "      khaled       0.95      0.80      0.87        75\n",
      "     nicolas       0.98      0.98      0.98       558\n",
      "        theo       0.84      0.81      0.82       560\n",
      "    yweweler       0.85      0.85      0.85       560\n",
      "\n",
      "    accuracy                           0.91      2590\n",
      "   macro avg       0.93      0.91      0.92      2590\n",
      "weighted avg       0.91      0.91      0.91      2590\n",
      "\n",
      "CPU times: user 29.6 s, sys: 494 ms, total: 30.1 s\n",
      "Wall time: 35.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf_speaker_normal.predict(X_val_speaker_2d)\n",
    "print(classification_report(y_val_speaker, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc, y_train_speaker_nn, target_names = data_preparation.transform_categorical_y(y_train_speaker)\n",
    "y_val_speaker_nn = enc.transform(y_val_speaker.reshape(-1, 1)).toarray()\n",
    "y_test_speaker_nn = enc.transform(y_test_speaker.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker = X_train_speaker.reshape(X_train_speaker.shape[0],\n",
    "                                          X_train_speaker.shape[1],\n",
    "                                          X_train_speaker.shape[2],\n",
    "                                          1)\n",
    "X_val_speaker = X_val_speaker.reshape(X_val_speaker.shape[0],\n",
    "                                      X_val_speaker.shape[1],\n",
    "                                      X_val_speaker.shape[2],\n",
    "                                      1)\n",
    "X_test_speaker = X_test_speaker.reshape(X_test_speaker.shape[0],\n",
    "                                        X_test_speaker.shape[1],\n",
    "                                        X_test_speaker.shape[2],\n",
    "                                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 39, 39, 32)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 39, 39, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 11552)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               1478784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,480,616\n",
      "Trainable params: 1,480,296\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.simple_model(num_classes=8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10358 samples, validate on 2590 samples\n",
      "Epoch 1/50\n",
      "10358/10358 [==============================] - 36s 3ms/sample - loss: 0.6850 - acc: 0.7649 - val_loss: 0.4243 - val_acc: 0.8185\n",
      "Epoch 2/50\n",
      "10358/10358 [==============================] - 35s 3ms/sample - loss: 0.4066 - acc: 0.8550 - val_loss: 0.5173 - val_acc: 0.8320\n",
      "Epoch 3/50\n",
      "10358/10358 [==============================] - 37s 4ms/sample - loss: 0.3617 - acc: 0.8706 - val_loss: 0.3202 - val_acc: 0.8834\n",
      "Epoch 4/50\n",
      "10358/10358 [==============================] - 34s 3ms/sample - loss: 0.3190 - acc: 0.8844 - val_loss: 0.2933 - val_acc: 0.9042\n",
      "Epoch 5/50\n",
      "10358/10358 [==============================] - 34s 3ms/sample - loss: 0.3092 - acc: 0.8868 - val_loss: 0.2389 - val_acc: 0.9066\n",
      "Epoch 6/50\n",
      "10358/10358 [==============================] - 34s 3ms/sample - loss: 0.2934 - acc: 0.8951 - val_loss: 0.2557 - val_acc: 0.9135\n",
      "Epoch 7/50\n",
      "10358/10358 [==============================] - 36s 3ms/sample - loss: 0.2704 - acc: 0.9046 - val_loss: 0.2626 - val_acc: 0.8996\n",
      "Epoch 8/50\n",
      "10358/10358 [==============================] - 36s 3ms/sample - loss: 0.2562 - acc: 0.9097 - val_loss: 0.2457 - val_acc: 0.9039\n",
      "Epoch 9/50\n",
      "10358/10358 [==============================] - 36s 3ms/sample - loss: 0.2577 - acc: 0.9052 - val_loss: 0.2953 - val_acc: 0.8799\n",
      "Epoch 10/50\n",
      "10358/10358 [==============================] - 35s 3ms/sample - loss: 0.2543 - acc: 0.9064 - val_loss: 0.2834 - val_acc: 0.8792\n",
      "CPU times: user 12min 26s, sys: 59.1 s, total: 13min 25s\n",
      "Wall time: 5min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd05fbed5d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker_nn,\n",
    "          batch_size=N_BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.98      0.87      0.92        92\n",
      "      alinda       0.97      0.86      0.91        90\n",
      "        gian       0.94      0.86      0.90        79\n",
      "     jackson       0.99      0.99      0.99       576\n",
      "      khaled       0.93      0.95      0.94        75\n",
      "     nicolas       0.98      0.97      0.98       558\n",
      "        theo       0.78      0.89      0.83       560\n",
      "        theo       0.86      0.79      0.82       560\n",
      "\n",
      "    accuracy                           0.91      2590\n",
      "   macro avg       0.93      0.90      0.91      2590\n",
      "weighted avg       0.91      0.91      0.91      2590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_speaker_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation lead to worse performance that \"clean\" scenario, therefore I won't store that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO REFACTOR from here\n",
    "## Classifier with label = number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_normal = features[\"normal\"]\n",
    "labels_number_normal = labels_number[\"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_normal, labels_number_normal,\n",
    "                                                      test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_normal2 = StandardScaler()\n",
    "scaler_normal2.fit(X_train)\n",
    "X_train_scaled = scaler_normal2.transform(X_train)\n",
    "X_test_scaled =  scaler_normal2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_number_normal = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_number_normal.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 339 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf_number_normal.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        35\n",
      "           1       0.97      0.95      0.96        38\n",
      "           2       1.00      0.94      0.97        36\n",
      "           3       0.91      0.91      0.91        33\n",
      "           4       1.00      0.97      0.99        34\n",
      "           5       1.00      0.97      0.99        38\n",
      "           6       0.83      1.00      0.91        34\n",
      "           7       0.97      1.00      0.99        37\n",
      "           8       1.00      0.94      0.97        34\n",
      "           9       1.00      0.95      0.97        41\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation (noise and pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_digit, y_train_digit, X_val_digit, y_val_digit, X_test_digit, y_test_digit = load_augm_dataset(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=18000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = np.concatenate(list(features.values( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_number_all = np.concatenate(list(labels_number.values( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_all, labels_number_all, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_all = StandardScaler()\n",
    "scaler_all.fit(X_train)\n",
    "X_train_scaled = scaler_all.transform(X_train)\n",
    "X_test_scaled = scaler_all.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_number_all = SVC(kernel='rbf', class_weight='balanced', gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf_number_all.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf_number_all.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       414\n",
      "           1       0.77      0.88      0.82       403\n",
      "           2       0.89      0.74      0.80       412\n",
      "           3       0.72      0.86      0.78       409\n",
      "           4       0.94      0.78      0.85       399\n",
      "           5       0.91      0.88      0.90       356\n",
      "           6       0.75      0.78      0.77       371\n",
      "           7       0.89      0.86      0.88       422\n",
      "           8       0.89      0.87      0.88       385\n",
      "           9       0.78      0.89      0.83       389\n",
      "\n",
      "    accuracy                           0.84      3960\n",
      "   macro avg       0.85      0.84      0.84      3960\n",
      "weighted avg       0.85      0.84      0.84      3960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on the spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recording(duration, rec_rate, name = \"test.wav\", output_dir = \"test/\"):\n",
    "    print(\"Ready in 3...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"2...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"1...\")\n",
    "    time.sleep(1)\n",
    "    print(\"Go.\")\n",
    "    rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "    print(\"Playing the recording.\")\n",
    "    sd.play(rec, rec_rate)\n",
    "\n",
    "    # after hearing the recording, decide whether to record it again or continue to next number\n",
    "    # if you type anything, record again\n",
    "    # if you press enter, save current recording & go to next number\n",
    "    ok = input(\"OK?\")\n",
    "    if ok == \"\":\n",
    "        librosa.output.write_wav(output_dir+name, rec, rec_rate)\n",
    "        return rec\n",
    "    ipd.clear_output(wait=True)\n",
    "    create_recording(duration, rec_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio(file, input_dir=\"test/\", output_dir=\"test/\", db=-48):\n",
    "\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"There should be an input \\\"{input_dir}\\\" directory.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # create output directory if not there yet\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    temp1 = output_dir+\"temp1.wav\"\n",
    "    temp2 = output_dir+\"temp2.wav\"\n",
    "    temp3 = output_dir+\"temp3.wav\"\n",
    " \n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_dir+file, \"-af\", f\"silenceremove=1:0:{db}dB\", temp1])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp1, \"-af\", \"areverse\", temp2])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp2, \"-af\", f\"silenceremove=1:0.1:{db}dB\", temp3])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp3, \"-af\", \"areverse\", output_dir+file])\n",
    "    \n",
    "    os.remove(temp1)\n",
    "    os.remove(temp2)\n",
    "    os.remove(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifiers(clfs, scalers, answer = None, duration=2, rec_rate=8000, directory = \"test/\", filename = \"test.wav\"):\n",
    "    create_recording(duration, rec_rate, filename, directory)   \n",
    "    ipd.clear_output()\n",
    "    trim_audio(filename, directory, directory)\n",
    "    _, rec = wav.read(directory + \"/\" + filename)\n",
    "    # sd.play(rec, rec_rate)\n",
    "    rec_features = combo(rec.flatten())\n",
    "    scaled_features = [0]*len(clfs)\n",
    "    preds = scaled_features\n",
    "    for i in range(len(clfs)):\n",
    "        scaled_features[i] = scalers[i].transform([rec_features])\n",
    "        preds[i] = clfs[i].predict(scaled_features[i])[0]\n",
    "        print(\"Classifier {} prediction: {}\".format(i+1, preds[i]))\n",
    "    if answer is not None:\n",
    "        print((\"Correct answer: \"+ \", \".join([\"{}\"]*len(answer))).format(*answer))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [clf_speaker_normal, clf_number_normal, clf_speaker_no_pitch, clf_number_all]\n",
    "scalers = [scaler_normal, scaler_normal2, scaler_no_pitch, scaler_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = test_classifiers(clfs, scalers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
