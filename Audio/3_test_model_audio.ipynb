{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTzZ1yR6AJcG"
   },
   "source": [
    "# Test model - Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WxSYVrOAJcH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_model(models_dir, model_name):\n",
    "    full_name = models_dir+\"/\"+model_name\n",
    "    print(full_name)\n",
    "    model = keras.models.load_model(full_name)\n",
    "    json_name = full_name.replace(\"h5\", \"json\")\n",
    "\n",
    "    with open(json_name, \"r\") as jf:\n",
    "        d = json.load(jf)\n",
    "    d[\"model\"] = model\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"./best_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./best_models/speakers.h5\n",
      "./best_models/digits.h5\n"
     ]
    }
   ],
   "source": [
    "models = [load_audio_model(models_dir, f) for f in os.listdir(models_dir) if f.endswith(\"h5\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = sorted(models, key = lambda x : x[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MFCC-based Digit classifier', 'Spectrogram-based speaker classifier']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by name\n",
    "[model[\"name\"] for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUyrZr67AJcN"
   },
   "outputs": [],
   "source": [
    "def create_recording(duration, rec_rate, name = \"test.wav\", output_dir = \"test/\", wait_time = 0.5):\n",
    "    print(\"Ready in 3...\", end = \"\")\n",
    "    time.sleep(wait_time)\n",
    "    print(\"2...\", end = \"\")\n",
    "    time.sleep(wait_time)\n",
    "    print(\"1...\")\n",
    "    time.sleep(wait_time)\n",
    "    print(\"Go.\")\n",
    "    rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "    print(\"Playing the recording.\")\n",
    "    sd.play(rec, rec_rate)\n",
    "\n",
    "    # after hearing the recording, decide whether to record it again or continue to next number\n",
    "    # if you type anything, record again\n",
    "    # if you press enter, save current recording & go to next number\n",
    "    ok = input(\"OK? [Y/n]\")\n",
    "    if (ok == \"\") or (ok.lower() in \"yes\"):\n",
    "        librosa.output.write_wav(output_dir+name, rec, rec_rate)\n",
    "        return rec\n",
    "    ipd.clear_output(wait=True)\n",
    "    create_recording(duration, rec_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QBcrjAzAJcO"
   },
   "outputs": [],
   "source": [
    "def trim_audio(file, input_dir=\"test/\", output_dir=\"test/\", db=-48):\n",
    "\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"There should be an input \\\"{input_dir}\\\" directory.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # create output directory if not there yet\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    temp1 = output_dir+\"temp1.wav\"\n",
    "    temp2 = output_dir+\"temp2.wav\"\n",
    "    temp3 = output_dir+\"temp3.wav\"\n",
    " \n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_dir+file, \"-af\", f\"silenceremove=1:0:{db}dB\", temp1])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp1, \"-af\", \"areverse\", temp2])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp2, \"-af\", f\"silenceremove=1:0.1:{db}dB\", temp3])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp3, \"-af\", \"areverse\", output_dir+file])\n",
    "    \n",
    "    os.remove(temp1)\n",
    "    os.remove(temp2)\n",
    "    os.remove(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from Classifiers-SpectrogramBased\n",
    "max_rec_length = 9015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkZPGYwUAJcQ"
   },
   "outputs": [],
   "source": [
    "# Debugging comments are left for the moment\n",
    "def test_nets(models, max_rec_length, answer = None,\n",
    "            duration=1.5, rec_rate=8000, directory = \"test/\",\n",
    "            filename = \"test.wav\", wait_time=0.5, db=-48):\n",
    "    create_recording(duration, rec_rate, filename, directory, wait_time=wait_time)   \n",
    "    ipd.clear_output()\n",
    "    \n",
    "    # this is not great, but at least we make sure that the audio is trimmed\n",
    "    # TODO: find better solution\n",
    "    len_rec = max_rec_length + 1\n",
    "    # print(\"Before padding\")\n",
    "    print(\"Trimming recording...\")\n",
    "    while len_rec > max_rec_length:\n",
    "        # Trim until it the recording is shorter than max_rec_length\n",
    "        \n",
    "        trim_audio(filename, directory, directory, db=db)\n",
    "        rec, _ = librosa.core.load(directory + \"/\" + filename, sr = rec_rate)\n",
    "        \n",
    "        # print(rec.shape)\n",
    "        len_rec = rec.shape[0]\n",
    "        db = int(db*0.95) # trim more violently at each step\n",
    "\n",
    "    rec = data_preparation.padding(max_rec_length, rec)\n",
    "\n",
    "    preds = []\n",
    "    print(\"Predicting...\\n\")\n",
    "    for model in models:\n",
    "        if model[\"type\"] == \"spectrogram\":\n",
    "            proc_rec = data_preparation.compute_spectrogram(rec, normalize=True, paper_data=model['paper_data'])\n",
    "        else:\n",
    "            proc_rec = data_preparation.mfcc(rec, flatten = False)\n",
    "        proc_rec = proc_rec[np.newaxis,:,:,np.newaxis]\n",
    "        model_prediction = model[\"model\"].predict_classes(proc_rec)[0]\n",
    "        prediction_label = model[\"class_indices\"][model_prediction]\n",
    "        preds.append(prediction_label)\n",
    "        print(\"{:50s}{}\".format(model[\"name\"]+\" prediction: \", prediction_label))\n",
    "\n",
    "    # print(\"Model prediction: {}\".format(preds[0]))\n",
    "    if answer is not None:\n",
    "        print(\"\\nCorrect answer: {}, {}\".format(*answer))\n",
    "    return preds, rec, rec_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-M4mw6KAJcW",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming recording...\n",
      "Predicting...\n",
      "\n",
      "MFCC-based Digit classifier prediction:           8\n",
      "Spectrogram-based speaker classifier prediction:  yweweler\n",
      "\n",
      "Correct answer: khaled, 8\n"
     ]
    }
   ],
   "source": [
    "preds, rec, rec_rate = test_nets(models, max_rec_length, answer=[\"khaled\", 8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
