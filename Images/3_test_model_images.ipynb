{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications import resnet_v2\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for face alignment\n",
    "# How to install:\n",
    "#    pip install imutils\n",
    "#    conda install -c conda-forge dlib  \n",
    "import imutils\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dlib Detector and Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good models:\n",
    "\n",
    "- 8, more or less\n",
    "- 13\n",
    "- 14\n",
    "- 17\n",
    "- 18/19?\n",
    "- 20 (model trained on heavily resized pictures)\n",
    "- 21? (model trained also on pictures where Khaled is not wearing glasses, needs further testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"maxpool\"\n",
    "model, labels, preprocess_fun = utils_2d.load_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "preprocess_fun(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['alessandro', 'alinda', 'cami', 'gian', 'khaled', 'mamma', 'papi'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = utils_2d.create_mask()\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, labels, mask, preprocess_fun = preprocess_fun, model_number = model_name,\n",
    "               basedir = \"test_pictures\", new_width=200, mirror=True, more_space=10, threshold = 50):\n",
    "    \n",
    "    if not os.path.isdir(basedir):\n",
    "        print(f\"Created new directory {basedir}\")\n",
    "        os.makedirs(basedir)\n",
    "\n",
    "    current_images = [img for img in os.listdir(basedir) if (img.endswith(\".png\") and img.startswith(str(model_number)))]\n",
    "    \n",
    "    filename_format = f\"{basedir}/{model_number}_\"+\"{}.png\"\n",
    "    \n",
    "    i = utils_2d.find_last_filename_id(current_images)\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    cap = cv.VideoCapture(0)\n",
    "    while(True):\n",
    "        \n",
    "        r, frame = cap.read()\n",
    "        if mirror:\n",
    "            frame = cv.flip(frame, 1)\n",
    "        \n",
    "        try:\n",
    "            frame = add_box(frame, model, labels, mask, preprocess_fun, new_width, more_space, threshold)\n",
    "            cv.imshow('Video', frame)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "        \n",
    "        key = cv.waitKey(1)\n",
    "        \n",
    "        if (key & 0xFF) == ord('q'):\n",
    "            break\n",
    "            \n",
    "        elif (key & 0xFF) == ord('s'):            \n",
    "            i += 1\n",
    "            filename = filename_format.format(i)\n",
    "            cv.imwrite(filename, frame)\n",
    "            ipd.clear_output(wait=True)\n",
    "            print(f\"Saved {filename}\".replace(\"//\", \"/\"))\n",
    "                \n",
    "        \n",
    "\n",
    "                        \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_box(img, model, labels, mask, preprocess_fun = preprocess_fun, new_width=200, more_space=10, threshold=50):\n",
    "    m = more_space\n",
    "    \n",
    "    fontColors = [(0,0,255), (255,160,0), (0,255,0),\n",
    "                  (0,255, 255), (193,182,255)]\n",
    "    fontScale              = 2\n",
    "    lineType               = 2\n",
    "    font                   = cv.FONT_HERSHEY_PLAIN\n",
    "    \n",
    "    if img is not None:\n",
    "        \n",
    "        face = 0\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        og_width = gray.shape[1]\n",
    "        scaler = og_width/new_width\n",
    "        gray = imutils.resize(gray, width = new_width)\n",
    "\n",
    "        faces = detector(gray, 2) # check: what is the 2\n",
    "        \n",
    "        for rect in faces:\n",
    "            \n",
    "            \n",
    "            (x, y, w, h) = rect_to_bb(rect)\n",
    "            \n",
    "            gray2 = utils_2d.preprocess_face(gray, mask, fa, rect)\n",
    "            \n",
    "            gray2 = preprocess_fun(gray2)\n",
    "            \n",
    "            # # uncomment to test if the preprocessing is working\n",
    "            # plt.imshow(gray2, cmap=\"gray\")\n",
    "            # plt.show()\n",
    "            \n",
    "            # rescale box\n",
    "            (x, y, w, h) = (np.array((x,y,w,h))*scaler).astype(int)\n",
    "                \n",
    "            # make prediction\n",
    "            pred = model.predict(gray2[np.newaxis,:,:, np.newaxis])[0]            \n",
    "            text = labels[np.argmax(pred)]\n",
    "            \n",
    "            # no prediction if model's confidence below threshold\n",
    "            conf = pred[np.argmax(pred)]*100\n",
    "            if conf < threshold:\n",
    "                text = \"?\"\n",
    "                \n",
    "            # add box and text\n",
    "            topLeftCornerOfText = (x-m,y-m-5)\n",
    "            bottomLeftCornerOfText = (x-m,y+h+35)    \n",
    "            fontColor              = fontColors[face]\n",
    "            face += 1\n",
    "                  \n",
    "            cv.rectangle(img,(x-m,y-m),(x+w+m,y+h+m),fontColor,2)\n",
    "            cv.putText(img, f\"{text}\", topLeftCornerOfText,\n",
    "                       font, fontScale, fontColor, lineType)\n",
    "            cv.putText(img, f\"{conf:.2f}%\", bottomLeftCornerOfText,\n",
    "                       font, fontScale, fontColor, lineType)\n",
    "                    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`new_width` is the width of the resized image passed to the dlib detector.\n",
    "\n",
    "Smaller values mean smoother webcam preview, but prediction is slightly affected.\n",
    "\n",
    "OK values are between 150/250 depending on how far the face is from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test_pictures/2/maxpool_54.png\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "basedir=f\"test_pictures/{n}/\"\n",
    "test_model(model,labels, mask, new_width=200, threshold=50, basedir=basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test single shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_single_shot(model,labels, mask, preprocess_fun = preprocess_fun,\n",
    "                           new_width=200, threshold=50, mirror = True):\n",
    "    \n",
    "    cap = cv.VideoCapture(0)\n",
    "    result, img = cap.read()\n",
    "    \n",
    "    if mirror:\n",
    "            img = cv.flip(img, 1)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    img2 = add_box(img, model, labels, mask, preprocess_fun, new_width, threshold=threshold)[:,:,::-1]\n",
    "    \n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "    \n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = test_model_single_shot(model, labels, mask, threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'C:/Users/gianc/Anaconda3/envs/dsim/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml'\n",
    "face_detector = cv.CascadeClassifier(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_picture(filename, model, labels, mask, preprocess_fun = preprocess_fun, new_width=500,\n",
    "                 threshold = 50, resize = None, cut = False):\n",
    "    # might make sense to test on some pictures not used during training\n",
    "\n",
    "    img = cv.imread(filename)\n",
    "    \n",
    "    if resize is not None:\n",
    "        img = imutils.resize(img, resize)\n",
    "    img2 = add_box(img, model, labels, mask, preprocess_fun, new_width, threshold=threshold)[:,:,::-1]\n",
    "    \n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "    \n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = test_picture(\"misc_pictures/13.jpg\", model, labels, mask, resize = 400, new_width=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_directory(name, basedir, labels, model, mask, preprocess_fun=preprocess_fun, new_width=200):\n",
    "    # might make sense to test on some pictures not used during training\n",
    "    \n",
    "    srcdir = basedir+\"/\"+name\n",
    "    counts={}\n",
    "    for label in labels:\n",
    "        counts[label] = 0\n",
    "    total = 1\n",
    "    \n",
    "    for file in os.listdir(srcdir):\n",
    "        img = cv.imread(srcdir+\"/\"+file)\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        gray = imutils.resize(gray, new_width)\n",
    "        faces = detector(gray, 2)\n",
    "        if len(faces)>0:\n",
    "            rect = faces[0]\n",
    "            gray2 = fa.align(gray, gray, rect)\n",
    "        else:\n",
    "            gray2 = cv.resize(gray, (224, 224))\n",
    "        gray2 = cv.equalizeHist(gray2)\n",
    "        gray2[~mask] = 0\n",
    "        gray2 = preprocess_fun(gray2)\n",
    "        \n",
    "        pred = model.predict(gray2[np.newaxis,:,:, np.newaxis])[0]            \n",
    "        text = labels[np.argmax(pred)]\n",
    "        \n",
    "        counts[text] += 1\n",
    "        ipd.clear_output(wait=True)\n",
    "        for i in counts.keys():\n",
    "            print(\"{}: {}\".format(i, counts[i]))\n",
    "        print(\"\\ntotal: \", total)\n",
    "        print(\"accuracy: \", counts[name]/total)\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also gives an idea of the difference in speed and accuracy when resizing the picture before detecting the face with dlib.\n",
    "\n",
    "(Note that the following is resizing a picture that is already cropped and with a face, while in the above tests it is resizing the picture from the webcam).\n",
    "\n",
    "(pictures in \"test_pictures\" were not used during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_directory(\"alinda\", \"test_pictures\", labels, model, mask, new_width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_directory(\"alinda\", \"test_pictures\", labels, model, mask, new_width=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_directory(\"alinda\", \"test_pictures\", labels, model, mask, new_width=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_directory(\"alinda\", \"test_pictures\", labels, model, mask, new_width=80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
