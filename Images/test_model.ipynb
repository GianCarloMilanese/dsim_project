{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications import resnet_v2\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for face alignment\n",
    "# pip install imutils\n",
    "# conda install -c conda-forge dlib  \n",
    "import imutils\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keras model\n",
    "model_number = 8\n",
    "model = keras.models.load_model(f\"./models/{model_number}_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"models/{model_number}_model.json\") as jf:\n",
    "    mjson = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Caricamento modello per il rilevamento di volti frontali\n",
    "# CV Face detector\n",
    "model_filename = 'C:/Users/gianc/Anaconda3/envs/dsim/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml'\n",
    "face_detector = cv.CascadeClassifier(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLIB Face detector fol alignment\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't save the \"class_indicices\" field for some models...\n",
    "if \"class_indices\" not in mjson:\n",
    "    if model.output_shape[1] == 8:\n",
    "        labels = np.array([\"alessandro\", \"alinda\", \"cami\", \"gian\",\n",
    "                           \"luca\", \"mamma\", \"papi\", \"umbe\"])\n",
    "        \n",
    "    if model.output_shape[1] == 7:\n",
    "        labels = np.array([\"alessandro\", \"alinda\", \"cami\", \"gian\",\n",
    "                           \"luca\", \"mamma\", \"papi\"])\n",
    "    if model.output_shape[1] == 6:\n",
    "        labels = np.array([\"alessandro\", \"alinda\", \"cami\", \"gian\",\n",
    "                           \"mamma\", \"papi\"])\n",
    "    if model.output_shape[1] == 5:\n",
    "        labels = np.array([\"alinda\", \"cami\",  \"gian\",\n",
    "                           \"mamma\",  \"papi\",])\n",
    "else:\n",
    "    labels = np.array(mjson[\"class_indices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...should have decided what to save in the json from the start...\n",
    "if model_number > 3:\n",
    "    mu = np.array([float(e) for e in mjson[\"mean\"]]).reshape(1,1,3)\n",
    "    std = np.array([float(e) for e in mjson[\"std\"]]).reshape(1,1,3)\n",
    "\n",
    "\n",
    "if \"fine_tuning\" in mjson:\n",
    "    if mjson[\"fine_tuning\"] == \"resnet\":\n",
    "        preprocess_function = resnet_v2.preprocess_input\n",
    "    elif mjson[\"fine_tuning\"] == \"no\":\n",
    "        mu = np.array([float(e) for e in mjson[\"mean\"]]).reshape(1,1,3)\n",
    "        std = np.array([float(e) for e in mjson[\"std\"]]).reshape(1,1,3)\n",
    "        preprocess_function = lambda x : (x - mu)/std\n",
    "else:\n",
    "    if model_number <= 3:\n",
    "        preprocess_function = resnet_v2.preprocess_input\n",
    "    else:\n",
    "        preprocess_function = lambda x : (x - mu)/std\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranks(ar):\n",
    "    return ar.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_box(img, model, mu, std, labels, preprocessing, align, more_space=10, threshold=50):\n",
    "    m = more_space\n",
    "    \n",
    "    fontColors = [(0,0,255), (255,160,0)]\n",
    "    fontScale              = 2\n",
    "    \n",
    "    lineType               = 2\n",
    "    font                   = cv.FONT_HERSHEY_PLAIN\n",
    "    if img is not None:\n",
    "        \n",
    "        face = 0\n",
    "        \n",
    "        if align:\n",
    "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "            faces = detector(gray, 2)\n",
    "        else:\n",
    "            faces = face_detector.detectMultiScale(img[:,:,1])\n",
    "        \n",
    "        # -1::-1 because cv img is BGR, but we need RGB (check)\n",
    "        img2 = img[:,:,::-1]\n",
    "        \n",
    "        for rect in faces:    \n",
    "            \n",
    "            \n",
    "            if align:\n",
    "                (x, y, w, h) = rect_to_bb(rect)\n",
    "                img2 = fa.align(img2, gray, rect)\n",
    "                # img2 = cv.resize(img2, (224, 224))\n",
    "\n",
    "            else:\n",
    "                (x, y, w, h) = rect\n",
    "                img2 = img[(y-m):(y+h+m), (x-m):(x+w+m), ::-1]\n",
    "                img2 = cv.resize(img2, (224, 224))\n",
    "                \n",
    "            img2 = preprocessing(img2)\n",
    "                \n",
    "            pred = model.predict(img2[np.newaxis,:,:,:])[0]            \n",
    "            text = labels[np.argmax(pred)]\n",
    "            top3 = labels[ranks(pred)][:2]\n",
    "            conf3 = pred[ranks(pred)][:2]\n",
    "            \n",
    "            \n",
    "            bottomLeftCornerOfText = (x-m,y-m-5)      \n",
    "            fontColor              = fontColors[face]\n",
    "                  \n",
    "            cv.rectangle(img,(x-m,y-m),(x+w+m,y+h+m),fontColor,2)\n",
    "            cv.putText(img, text, bottomLeftCornerOfText,\n",
    "                       font, fontScale, fontColor, lineType)\n",
    "            \n",
    "            for i in range(len(top3)):\n",
    "                line = \"{}: {}\".format(top3[i], str(np.around(conf3[i]*100, decimals = 2))+\"%\")\n",
    "                cv.putText(img, line, (10, 25+30*i+face*420), # this won't work for more than two faces\n",
    "                           font, fontScale, fontColor, lineType)\n",
    "            face += 1\n",
    "            # this function would not work for more than two faces anyway\n",
    "            if face > 1:\n",
    "                break\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, mu, std, labels, preprocessing,\n",
    "               basedir = \"test_pictures\", align=False, mirror=True, more_space=10, threshold=50):\n",
    "    file_format = \"png\"\n",
    "    if not os.path.isdir(basedir):\n",
    "        print(f\"Created new directory {basedir}\")\n",
    "        os.makedirs(basedir)\n",
    "\n",
    "    current_images = [img for img in os.listdir(basedir) if img.endswith(file_format)]\n",
    "    \n",
    "    if len(current_images) == 0:\n",
    "        latest_picture = -1\n",
    "    else:\n",
    "        latest_picture = max([int(re.findall(\"\\d+\", current_images[i])[0]) for i in range(len(current_images))])\n",
    "    \n",
    "    filename_format = f\"{basedir}/\"+\"{}\"+f\".{file_format}\"\n",
    "    \n",
    "    i = latest_picture\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    cap = cv.VideoCapture(0)\n",
    "    while(True):\n",
    "        \n",
    "        r, frame = cap.read()\n",
    "        if mirror:\n",
    "            frame = cv.flip(frame, 1)\n",
    "        \n",
    "        try:\n",
    "            frame = add_box(frame, model, mu, std, labels, preprocessing, align, more_space, threshold)\n",
    "            cv.imshow('Video', frame)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    \n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('s'):\n",
    "            \n",
    "            i += 1\n",
    "            filename = filename_format.format(i)\n",
    "            cv.imwrite(filename, frame)\n",
    "            ipd.clear_output(wait=True)\n",
    "            print(f\"Saved {filename}\".replace(\"//\", \"/\"))\n",
    "                \n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "                        \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Faster but if you tilt your head the prediction might be wrong or your head might not be detected\n",
    "test_model(model, mu, std, labels, preprocess_function, align=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_model(model, mu, std, labels, preprocess_function, align=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test single shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_single_shot(model, mu, std, labels, preprocessing, align=False, mirror = True):\n",
    "    cap = cv.VideoCapture(0)\n",
    "    result, img = cap.read()\n",
    "    if mirror:\n",
    "            img = cv.flip(img, 1)\n",
    "    \n",
    "    cap.release()\n",
    "    plt.figure(figsize=(14,7))\n",
    "    img2 = add_box(img, model, mu, std, labels, preprocessing, align)[:,:,::-1]\n",
    "    plt.imshow(img2)\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = test_model_single_shot(model, mu, std, labels, preprocess_function, align=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = test_model_single_shot(model, mu, std, labels, preprocess_function, align=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = test_model_single_shot(model, mu, std, labels, preprocess_function, align=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# might make sense to test on some pictures not used during training\n",
    "name = \"gian\"\n",
    "basedir = \"pictures_table/\"+name\n",
    "counts={}\n",
    "for label in labels:\n",
    "    counts[label] = 0\n",
    "total = 1\n",
    "for file in os.listdir(basedir):\n",
    "    img = cv.imread(basedir+\"/\"+file)\n",
    "    img2 = img[:,:,::-1]\n",
    "    img2 = cv.resize(img2, (224, 224))\n",
    "    img2 = (img2 - mu)/std\n",
    "\n",
    "    pred = model.predict(img2[np.newaxis,:,:,:])\n",
    "    \n",
    "    text = labels[np.argmax(pred)]\n",
    "    counts[text] += 1\n",
    "    ipd.clear_output(wait=True)\n",
    "    for i in counts.keys():\n",
    "        print(\"{}: {}\".format(i, counts[i]))\n",
    "    print(\"\\ntotal: \", total)\n",
    "    print(\"accuracy: \", counts[name]/total)\n",
    "    total += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
