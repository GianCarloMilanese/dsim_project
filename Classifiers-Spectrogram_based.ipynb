{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcpAdLEIAOMh"
   },
   "source": [
    "# Just for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p-dutOrvAPZg",
    "outputId": "b3c51368-3f49-4296-f170-cd4d5a9f7ade"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b135b7e453ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'User name: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Password: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# your password is converted into url format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         )\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import urllib\n",
    "\n",
    "user = input('User name: ')\n",
    "password = getpass('Password: ')\n",
    "password = urllib.parse.quote(password) # your password is converted into url format\n",
    "\n",
    "cmd_string = 'git clone https://{0}:{1}@github.com/GianCarloMilanese/dsim_project.git'.format(user, password)\n",
    "\n",
    "os.system(cmd_string)\n",
    "cmd_string, password = \"\", \"\" # removing the password from the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "mVoN9qvnGPqR",
    "outputId": "252dcd03-1a49-4a08-8f84-c2c441fc5408"
   },
   "outputs": [],
   "source": [
    "!ls -lh dsim_project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "7_p69CQOG8Sn",
    "outputId": "a6271bc7-a6c0-45ce-d49b-62404ffb80e0"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git && mv free-spoken-digit-dataset/recordings dsim_project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "PAQ5VI3zHei1",
    "outputId": "a99953d0-6eac-4870-8ea3-b804f52270c8"
   },
   "outputs": [],
   "source": [
    "!ls -lh dsim_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"dsim_project/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SD8Nx-3tAJY_"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SP35h9g6AJZB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import data_augmentation\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wQvjtLSAJZG"
   },
   "source": [
    "# Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSZ1nRq_AJZH"
   },
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "tf.random.set_random_seed(SEED)# if working on tf < 2.0\n",
    "#tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YLZTM3YDAJZK"
   },
   "source": [
    "# Load recordings\n",
    "## STANDARD RECORDINGS - No spectrogram normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1G8haE_GIkzR"
   },
   "outputs": [],
   "source": [
    "fsdd_dir=\"dsim_project/recordings\"\n",
    "our_recs_dir=\"dsim_project/preprocessed_recs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdd_dir=\"./recordings/\"\n",
    "our_recs_dir=\"./preprocessed_recs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "74521556c16e4badb587537f36771810",
      "5f5badcb0b1e4938901d1ccebf26bc1f",
      "041ee309cd2a4523b8cbb817a7133aeb",
      "ab519d0c6d6241c5afbc76dbde2306fd",
      "8f16c91328fb4555af28b4fa2522f1b6",
      "8db829965d284a9b848aa89f1d6e1a7e",
      "eef3bdb92f1e43eb9241be66f3360fbc",
      "c29d5436c6514002b1380c6dfb229f76",
      "b20e330bbd0541b9ad6e8897ba359fc3",
      "6532c85805db453f8a76edaf34996c0c",
      "bce824cee09446879776ce8440927c32",
      "d877478de1de4e2a9e67d33302b19075",
      "a9b4078544ee4fc4b203252a8539169c",
      "b365514386b341d6896420c06f2a9a86",
      "0471feee5a704241bc959bf9f25cf86b",
      "f110b274d39141b892be18de60d7fd3b"
     ]
    },
    "colab_type": "code",
    "id": "EhEjE2JZAJZL",
    "outputId": "bc2b6b8d-494b-4745-ecf0-82ee4b51fadc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./recordings/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cef060a0f0f4c2d9957e0e6d9eccd8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ./preprocessed_recs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e76b3e7f424f00aab3a8e0e3eb914b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrZ1SrCyAJZO"
   },
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "USN0CDHyAJZO",
    "outputId": "2126cd10-edbe-4ef7-b2a3-2c41e50a6be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 18262\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is quite huge! Let's see which are the longest recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18262, 17567, 9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two recordings have length 18262 and 17567, while the others are around 20K. Let's identify them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "first_length=18262\n",
    "second_length=17567\n",
    "index_first = a.index(first_length)\n",
    "index_second = a.index(second_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18262"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recordings[index_first])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17567"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recordings[index_second])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have found them. For knowing to which digit and speaker they are associated I first need to load the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest track is associated with speaker theo, digit 9\n",
      "Second longest track is associated with speaker theo, digit 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_first],labels_digits[index_first]))\n",
    "print(\"Second longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_second],labels_digits[index_second]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problem is with theo, which has 500 recordings, digit 9 and 7, which respectively have 200 recordings. We can safely delete them and saving to pad many thousands of 0s (there will be (18262 - 9015) less zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "max_track_length=17000 # it will be useful later on\n",
    "print(\"Before: {}\".format(len(recordings)))\n",
    "recordings=np.delete(recordings,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(recordings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_speakers)))\n",
    "labels_speakers=np.delete(labels_speakers,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_speakers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_digits)))\n",
    "labels_digits=np.delete(labels_digits,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_digits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now double check to see if everything went well. Now the longest recording will be around 9 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356, 7147, 7038]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIOfNR7UAJZR"
   },
   "source": [
    "Yes! However the recordings have all different lengths: for this reason we can add 0s at the beginning and at the end in order to uniform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DAqhOQfXAJZS",
    "outputId": "f4fb11ac-3e4e-4ef7-92cc-4106a989315c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_zeros >>>\n",
      "pad_zeros <<<\n"
     ]
    }
   ],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knxJsuQHAJZV"
   },
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UH4CNtcaAJZV",
    "outputId": "70f33b43-ad02-4214-dc91-4c934af961cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9015 9015\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzTvIWFqAJZY"
   },
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBOpha3yAJZZ"
   },
   "outputs": [],
   "source": [
    "spects = [data_preparation.compute_spectrogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UcS3jm3hAJZf"
   },
   "source": [
    "Let's also compute \"normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBHB2jB0AJZf"
   },
   "outputs": [],
   "source": [
    "norm_spects = [data_preparation.compute_spectrogram(x, normalize=True) for x in pad_recordings]\n",
    "norm_spects = np.array(norm_spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NifXsIaiAJZi"
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "S7lJzOxaAJZi",
    "outputId": "d7dd58d8-9103-4b00-9784-7e872b59eab9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 5min 17s, sys: 15.4 s, total: 5min 33s\n",
      "Wall time: 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digit, y_train_digit, X_val_digit, y_val_digit, X_test_digit, y_test_digit = data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=max_track_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q7kf01G8AJZl",
    "outputId": "70bde817-b594-4519-f3cd-ed14aafec37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 18462, 18462, 4616, 4616, 300, 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}, {}, {}\".format(len(X_train_digit),\n",
    "                                                len(y_train_digit),\n",
    "                                                len(X_val_digit),\n",
    "                                                len(y_val_digit),\n",
    "                                                len(X_test_digit),\n",
    "                                                len(y_test_digit),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "mAS0dEAeAJZn",
    "outputId": "5f5b8ee6-7d0b-4575-d9d6-ac9708bbda97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 5min 27s, sys: 17.9 s, total: 5min 45s\n",
      "Wall time: 6min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(\n",
    "    audio_dirs= [our_recs_dir, fsdd_dir],\n",
    "    y_type= ['speakers_us', 'speakers_default'],\n",
    "    n_category_test=30,\n",
    "    include_pitch=True,\n",
    "    max_length=max_track_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U7pt5gp8AJZq",
    "outputId": "264e985b-797d-4478-fb22-19febb261b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 18990, 18990, 4748, 4748, 240, 240\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}, {}, {}\".format(len(X_train_speaker),\n",
    "                                        len(y_train_speaker),\n",
    "                                        len(X_val_speaker),\n",
    "                                        len(y_val_speaker),\n",
    "                                        len(X_test_speaker),\n",
    "                                        len(y_test_speaker)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcNM7Ju3AJZt"
   },
   "source": [
    "# Standard recordings\n",
    "## Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z08J1Ly2AJZu"
   },
   "source": [
    "Split data in train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zxTeijsAJZu"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pq-h50cLAJZx"
   },
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pGL-51TeAJZ0",
    "outputId": "c8c1f7ec-0a59-4df0-e6a4-80a897a32e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 s, sys: 501 ms, total: 29.5 s\n",
      "Wall time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "eOuf4fYdAJZ3",
    "outputId": "8de901a9-de7a-466a-b29a-8f8ada4fe913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.12      0.20        43\n",
      "           1       0.41      0.35      0.38        43\n",
      "           2       0.53      0.17      0.25        48\n",
      "           3       0.62      0.23      0.34        56\n",
      "           4       0.23      0.44      0.30        43\n",
      "           5       0.81      0.35      0.49        48\n",
      "           6       0.15      0.64      0.24        55\n",
      "           7       0.88      0.27      0.41        56\n",
      "           8       0.85      0.23      0.37        47\n",
      "           9       0.67      0.49      0.56        41\n",
      "\n",
      "    accuracy                           0.33       480\n",
      "   macro avg       0.60      0.33      0.35       480\n",
      "weighted avg       0.60      0.33      0.35       480\n",
      "\n",
      "CPU times: user 6.11 s, sys: 104 ms, total: 6.21 s\n",
      "Wall time: 9.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZIG3MZXAJZ5"
   },
   "source": [
    "### Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adr8LZdqAJZ5"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PVFxb6UAAJZ-",
    "outputId": "f1631091-a65e-410d-869f-982e7a25e54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.6 s, sys: 251 ms, total: 16.8 s\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "9YNlZ5ZGAJaB",
    "outputId": "408a182d-3e8d-4b53-a8bc-403523798c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.82      0.72      0.77        43\n",
      "           2       0.57      0.92      0.70        48\n",
      "           3       0.91      0.52      0.66        56\n",
      "           4       0.94      0.72      0.82        43\n",
      "           5       0.95      0.77      0.85        48\n",
      "           6       0.63      0.84      0.72        55\n",
      "           7       0.80      0.88      0.84        56\n",
      "           8       0.84      0.66      0.74        47\n",
      "           9       0.81      0.93      0.86        41\n",
      "\n",
      "    accuracy                           0.78       480\n",
      "   macro avg       0.82      0.79      0.79       480\n",
      "weighted avg       0.82      0.78      0.78       480\n",
      "\n",
      "CPU times: user 5.88 s, sys: 115 ms, total: 6 s\n",
      "Wall time: 8.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjYwbLVWAJaD"
   },
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaUkrMXHAJaD"
   },
   "source": [
    "#### Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWl0glyyAJaE"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "jp-yDTbVAJaG",
    "outputId": "8f73212b-eec8-474f-d751-4583a963eee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               38500     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 77,436\n",
      "Trainable params: 77,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjsYe2MZAJaJ"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "dorwbEtUAJaM",
    "outputId": "41eeef7c-3bf0-4747-e426-5864708d9951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1438 samples, validate on 480 samples\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 2.2992 - acc: 0.1231 - val_loss: 2.2502 - val_acc: 0.1646\n",
      "Epoch 2/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 2.2384 - acc: 0.1669 - val_loss: 2.1869 - val_acc: 0.2292\n",
      "Epoch 3/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.1910 - acc: 0.1912 - val_loss: 2.0988 - val_acc: 0.3792\n",
      "Epoch 4/10\n",
      "1438/1438 [==============================] - 5s 3ms/sample - loss: 2.0901 - acc: 0.2601 - val_loss: 1.9388 - val_acc: 0.4125\n",
      "Epoch 5/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 1.9513 - acc: 0.2928 - val_loss: 1.7452 - val_acc: 0.4896\n",
      "Epoch 6/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 1.7811 - acc: 0.3310 - val_loss: 1.5541 - val_acc: 0.4688\n",
      "Epoch 7/10\n",
      "1438/1438 [==============================] - 5s 4ms/sample - loss: 1.6421 - acc: 0.3769 - val_loss: 1.3987 - val_acc: 0.5208\n",
      "Epoch 8/10\n",
      "1438/1438 [==============================] - 7s 5ms/sample - loss: 1.5265 - acc: 0.4075 - val_loss: 1.3869 - val_acc: 0.4833\n",
      "Epoch 9/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 1.4422 - acc: 0.4416 - val_loss: 1.2250 - val_acc: 0.5417\n",
      "Epoch 10/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 1.3348 - acc: 0.5035 - val_loss: 1.1747 - val_acc: 0.5833\n",
      "CPU times: user 59.1 s, sys: 4.44 s, total: 1min 3s\n",
      "Wall time: 44.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2903c2710>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "z1EFnJFhAJaP",
    "outputId": "abe441d8-2f01-4ef9-b3df-688dcd232937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.95      0.67        43\n",
      "           1       0.61      0.47      0.53        43\n",
      "           2       0.49      0.52      0.51        48\n",
      "           3       0.70      0.12      0.21        56\n",
      "           4       0.74      0.79      0.76        43\n",
      "           5       1.00      0.60      0.75        48\n",
      "           6       0.49      0.67      0.56        55\n",
      "           7       0.67      0.57      0.62        56\n",
      "           8       0.50      0.49      0.49        47\n",
      "           9       0.52      0.78      0.63        41\n",
      "\n",
      "    accuracy                           0.58       480\n",
      "   macro avg       0.62      0.60      0.57       480\n",
      "weighted avg       0.62      0.58      0.56       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ab3NBIvkAJaR"
   },
   "source": [
    "#### Standard spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sWPsfH8AJaS"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "9RPhwIyPAJaU",
    "outputId": "bf9606af-72d8-4fdf-f2ee-77049129bd1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               38500     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 77,436\n",
      "Trainable params: 77,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "tEl6k7s6AJaX",
    "outputId": "e26b03f7-b375-467e-adf7-99259cf371b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1438 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1438/1438 [==============================] - 7s 5ms/sample - loss: 2.5114 - acc: 0.1474 - val_loss: 2.2489 - val_acc: 0.1813\n",
      "Epoch 2/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 2.2616 - acc: 0.1857 - val_loss: 2.2041 - val_acc: 0.1688\n",
      "Epoch 3/10\n",
      "1438/1438 [==============================] - 5s 3ms/sample - loss: 2.2047 - acc: 0.1926 - val_loss: 2.1549 - val_acc: 0.1896\n",
      "Epoch 4/10\n",
      "1438/1438 [==============================] - 5s 3ms/sample - loss: 2.1409 - acc: 0.2197 - val_loss: 2.0624 - val_acc: 0.2396\n",
      "Epoch 5/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 2.0966 - acc: 0.2594 - val_loss: 2.1405 - val_acc: 0.1750\n",
      "Epoch 6/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 2.0918 - acc: 0.2344 - val_loss: 2.0275 - val_acc: 0.2542\n",
      "Epoch 7/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.0567 - acc: 0.2538 - val_loss: 2.1863 - val_acc: 0.1750\n",
      "Epoch 8/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 2.0395 - acc: 0.2524 - val_loss: 2.0300 - val_acc: 0.2333\n",
      "Epoch 9/10\n",
      "1438/1438 [==============================] - 5s 3ms/sample - loss: 2.0094 - acc: 0.2663 - val_loss: 1.9948 - val_acc: 0.2479\n",
      "Epoch 10/10\n",
      "1438/1438 [==============================] - 6s 4ms/sample - loss: 1.9967 - acc: 0.2914 - val_loss: 1.9416 - val_acc: 0.2896\n",
      "CPU times: user 59.7 s, sys: 4.17 s, total: 1min 3s\n",
      "Wall time: 48.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe2b687c310>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "3e7-NrFzAJaZ",
    "outputId": "1be23cb6-6ef8-4ffa-c296-6b3ec5764a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.09      0.17        43\n",
      "           1       0.24      0.37      0.29        43\n",
      "           2       0.33      0.54      0.41        48\n",
      "           3       0.45      0.30      0.36        56\n",
      "           4       0.54      0.16      0.25        43\n",
      "           5       0.50      0.40      0.44        48\n",
      "           6       0.57      0.24      0.33        55\n",
      "           7       0.64      0.12      0.21        56\n",
      "           8       0.30      0.15      0.20        47\n",
      "           9       0.12      0.56      0.20        41\n",
      "\n",
      "    accuracy                           0.29       480\n",
      "   macro avg       0.45      0.29      0.29       480\n",
      "weighted avg       0.46      0.29      0.29       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hm-UCrvqAJac"
   },
   "source": [
    "From what we can see normalising spectrograms is the way to go. Let's use it by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AzfoB2vwAJad"
   },
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "9UD8AN11h68p",
    "outputId": "dd4a9cd9-5bb7-45dd-f7ec-9256a6b4a8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88        44\n",
      "           1       0.88      0.86      0.87        49\n",
      "           2       0.76      0.91      0.83        56\n",
      "           3       0.97      0.70      0.81        43\n",
      "           4       0.98      0.90      0.94        49\n",
      "           5       0.90      0.87      0.88        52\n",
      "           6       0.69      0.83      0.75        42\n",
      "           7       0.79      0.98      0.88        47\n",
      "           8       0.97      0.72      0.83        50\n",
      "           9       0.90      0.79      0.84        48\n",
      "\n",
      "    accuracy                           0.85       480\n",
      "   macro avg       0.87      0.85      0.85       480\n",
      "weighted avg       0.87      0.85      0.85       480\n",
      "\n",
      "CPU times: user 33.9 s, sys: 599 ms, total: 34.5 s\n",
      "Wall time: 48.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_digits)\n",
    "X_train = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train = np.concatenate([y_train, y_val], axis=0)\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RofgNOXIAJaf"
   },
   "source": [
    "## Speakers\n",
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsOEsXNrAJag"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nq86YnS3AJai",
    "outputId": "056c8fa2-0ed7-463f-f38a-e9e06c370911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 173 ms, total: 11 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3qK9OpoAJam",
    "outputId": "b8e82428-9b91-4849-e078-6139ac8ed99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.91      0.95      0.93        21\n",
      "      alinda       0.90      0.90      0.90        20\n",
      "        gian       1.00      1.00      1.00        20\n",
      "     jackson       1.00      1.00      1.00        86\n",
      "      khaled       0.91      1.00      0.95        21\n",
      "     nicolas       0.98      1.00      0.99       103\n",
      "        theo       0.86      0.87      0.86       105\n",
      "    yweweler       0.92      0.87      0.89       104\n",
      "\n",
      "    accuracy                           0.94       480\n",
      "   macro avg       0.93      0.95      0.94       480\n",
      "weighted avg       0.94      0.94      0.94       480\n",
      "\n",
      "CPU times: user 4.45 s, sys: 63.3 ms, total: 4.51 s\n",
      "Wall time: 6.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Px6AnQPyAJap"
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qw6UWfD6AJap"
   },
   "source": [
    "For neural networks it is not possible to pass the labels as-is: we need to transform them in numbers. The safest way is through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MEyOqyZAJaq"
   },
   "outputs": [],
   "source": [
    "y, target_names = data_preparation.transform_categorical_y(labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4ZWZPxSAJas"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, y, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5nbGXEqAJav",
    "outputId": "c22a47d5-52ab-4bfa-bc21-b919ef3d4b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 67,744\n",
      "Trainable params: 67,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzq1wprbAJay",
    "outputId": "f3a4929c-1629-4a45-b07a-cad28a8cf1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1438 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1438/1438 [==============================] - 5s 3ms/sample - loss: 1.9063 - acc: 0.2483 - val_loss: 1.8241 - val_acc: 0.2417\n",
      "Epoch 2/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 1.8254 - acc: 0.3032 - val_loss: 1.7613 - val_acc: 0.3500\n",
      "Epoch 3/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 1.7464 - acc: 0.3616 - val_loss: 1.6746 - val_acc: 0.4083\n",
      "Epoch 4/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 1.6728 - acc: 0.4117 - val_loss: 1.5704 - val_acc: 0.5042\n",
      "Epoch 5/10\n",
      "1438/1438 [==============================] - 3s 2ms/sample - loss: 1.5641 - acc: 0.4631 - val_loss: 1.4579 - val_acc: 0.6021\n",
      "Epoch 6/10\n",
      "1438/1438 [==============================] - 5s 3ms/sample - loss: 1.4848 - acc: 0.5139 - val_loss: 1.3183 - val_acc: 0.6021\n",
      "Epoch 7/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 1.3698 - acc: 0.5466 - val_loss: 1.2378 - val_acc: 0.6271\n",
      "Epoch 8/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 1.2831 - acc: 0.5494 - val_loss: 1.1135 - val_acc: 0.6167\n",
      "Epoch 9/10\n",
      "1438/1438 [==============================] - 4s 3ms/sample - loss: 1.2262 - acc: 0.5834 - val_loss: 1.0620 - val_acc: 0.6187\n",
      "Epoch 10/10\n",
      "1438/1438 [==============================] - 5s 3ms/sample - loss: 1.1251 - acc: 0.6022 - val_loss: 1.0126 - val_acc: 0.6292\n",
      "CPU times: user 1min, sys: 4.89 s, total: 1min 5s\n",
      "Wall time: 42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe1807d93d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F15PVwnlAJa0",
    "outputId": "cc510785-80ce-4518-bdfe-7ab7707d93ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.38        21\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.45      0.99      0.61        86\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.81      0.61      0.70       103\n",
      "           6       0.72      0.70      0.71       105\n",
      "           7       0.73      0.73      0.73       104\n",
      "\n",
      "    accuracy                           0.63       480\n",
      "   macro avg       0.46      0.41      0.39       480\n",
      "weighted avg       0.61      0.63      0.59       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qk3vDDTAJa4"
   },
   "source": [
    "#### Paper - batch_normalisation=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NibB6mqLAJa4",
    "outputId": "08b73978-af62-44fb-c3a1-40508d4f7683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJFqES0hAJa8",
    "outputId": "e87aa981-bfcb-4d60-ee8e-47448a8d0482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1438 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1438/1438 [==============================] - 10s 7ms/sample - loss: 1.7787 - acc: 0.4089 - val_loss: 1.7603 - val_acc: 0.3979\n",
      "Epoch 2/10\n",
      "1438/1438 [==============================] - 11s 8ms/sample - loss: 1.0523 - acc: 0.6773 - val_loss: 1.6681 - val_acc: 0.3792\n",
      "Epoch 3/10\n",
      "1438/1438 [==============================] - 10s 7ms/sample - loss: 0.8228 - acc: 0.7427 - val_loss: 1.6394 - val_acc: 0.3771\n",
      "Epoch 4/10\n",
      "1438/1438 [==============================] - 10s 7ms/sample - loss: 0.6534 - acc: 0.8018 - val_loss: 1.4862 - val_acc: 0.3812\n",
      "Epoch 5/10\n",
      "1438/1438 [==============================] - 11s 8ms/sample - loss: 0.5719 - acc: 0.8268 - val_loss: 1.3969 - val_acc: 0.4062\n",
      "Epoch 6/10\n",
      "1438/1438 [==============================] - 9s 6ms/sample - loss: 0.5170 - acc: 0.8442 - val_loss: 1.2343 - val_acc: 0.4771\n",
      "Epoch 7/10\n",
      "1438/1438 [==============================] - 7s 5ms/sample - loss: 0.4235 - acc: 0.8734 - val_loss: 1.2529 - val_acc: 0.4604\n",
      "Epoch 8/10\n",
      "1438/1438 [==============================] - 8s 5ms/sample - loss: 0.4294 - acc: 0.8720 - val_loss: 1.0593 - val_acc: 0.5583\n",
      "Epoch 9/10\n",
      "1438/1438 [==============================] - 7s 5ms/sample - loss: 0.4020 - acc: 0.8839 - val_loss: 0.8914 - val_acc: 0.6583\n",
      "Epoch 10/10\n",
      "1438/1438 [==============================] - 8s 6ms/sample - loss: 0.3451 - acc: 0.9019 - val_loss: 0.5828 - val_acc: 0.8146\n",
      "CPU times: user 2min 22s, sys: 27.1 s, total: 2min 49s\n",
      "Wall time: 1min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe1807aa550>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eePEJDMdAJa_",
    "outputId": "dc423068-db5d-46fc-a0ed-c24f08820613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.38        21\n",
      "           1       1.00      0.80      0.89        20\n",
      "           2       1.00      0.65      0.79        20\n",
      "           3       0.79      1.00      0.88        86\n",
      "           4       0.83      0.71      0.77        21\n",
      "           5       0.99      0.85      0.92       103\n",
      "           6       0.64      0.96      0.77       105\n",
      "           7       0.93      0.64      0.76       104\n",
      "\n",
      "    accuracy                           0.81       480\n",
      "   macro avg       0.90      0.73      0.77       480\n",
      "weighted avg       0.86      0.81      0.81       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLz38np3juZf"
   },
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5PZSGZljsLN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.96      0.98        24\n",
      "      alinda       0.90      1.00      0.95        19\n",
      "        gian       0.96      1.00      0.98        24\n",
      "     jackson       1.00      1.00      1.00       121\n",
      "      khaled       0.93      1.00      0.97        14\n",
      "     nicolas       1.00      1.00      1.00        89\n",
      "        theo       0.95      0.86      0.90        98\n",
      "    yweweler       0.89      0.96      0.92        91\n",
      "\n",
      "    accuracy                           0.96       480\n",
      "   macro avg       0.96      0.97      0.96       480\n",
      "weighted avg       0.96      0.96      0.96       480\n",
      "\n",
      "CPU times: user 21.4 s, sys: 336 ms, total: 21.7 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_speakers)\n",
    "X_train = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train = np.concatenate([y_train, y_val], axis=0)\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJh1FkRdAJbD"
   },
   "source": [
    "# Data augmentation\n",
    "## Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_speaker.shape\n",
    "X_train_speaker_2d = X_train_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_val_speaker.shape\n",
    "X_val_speaker_2d = X_val_speaker.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Switch to LinearSVC because SVC with RBF kernel takes a lot of time\n",
    "from sklearn.svm import LinearSVC\n",
    "clf1 = LinearSVC(class_weight='balanced')\n",
    "clf1 = clf1.fit(X_train_speaker_2d, y_train_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.71      0.76      0.73       157\n",
      "      alinda       0.57      0.68      0.62       149\n",
      "        gian       0.65      0.72      0.68       166\n",
      "     jackson       0.92      0.97      0.94      1004\n",
      "      khaled       0.67      0.77      0.72       144\n",
      "     nicolas       0.93      0.99      0.96      1052\n",
      "        theo       0.76      0.79      0.77      1048\n",
      "    yweweler       0.86      0.65      0.74      1028\n",
      "\n",
      "    accuracy                           0.84      4748\n",
      "   macro avg       0.76      0.79      0.77      4748\n",
      "weighted avg       0.84      0.84      0.83      4748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf1.predict(X_val_speaker_2d)\n",
    "print(classification_report(y_val_speaker, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HurXrYSAAJbE"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y_train_speaker = enc.fit_transform(y_train_speaker.reshape(-1, 1)).toarray()\n",
    "y_val_speaker = enc.transform(y_val_speaker.reshape(-1, 1)).toarray()\n",
    "y_test_speaker = enc.transform(y_test_speaker.reshape(-1, 1)).toarray()\n",
    "label_0 = enc.inverse_transform(np.array([1, 0, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_1 = enc.inverse_transform(np.array([0, 1, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_2 = enc.inverse_transform(np.array([0, 0, 1, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_3 = enc.inverse_transform(np.array([0, 0, 0, 1, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_4 = enc.inverse_transform(np.array([0, 0, 0, 0, 1, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_5 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 1, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_6 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 1, 0]).reshape(1, -1))[0][0]\n",
    "label_7 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 0, 1]).reshape(1, -1))[0][0]\n",
    "target_names = [label_0, label_1, label_2, label_3, label_4, label_5, label_6, label_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSJDK6FnAJbJ"
   },
   "outputs": [],
   "source": [
    "X_train_speaker = X_train_speaker.reshape(X_train_speaker.shape[0],\n",
    "                                          X_train_speaker.shape[1],\n",
    "                                          X_train_speaker.shape[2],\n",
    "                                          1)\n",
    "X_val_speaker = X_val_speaker.reshape(X_val_speaker.shape[0],\n",
    "                                      X_val_speaker.shape[1],\n",
    "                                      X_val_speaker.shape[2],\n",
    "                                      1)\n",
    "X_test_speaker = X_test_speaker.reshape(X_test_speaker.shape[0],\n",
    "                                        X_test_speaker.shape[1],\n",
    "                                        X_test_speaker.shape[2],\n",
    "                                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHT6j2GWAJbL"
   },
   "outputs": [],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K47DbwgyAJbO",
    "outputId": "fa96fcc6-7da6-432f-885e-9648fda4bd42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 67,744\n",
      "Trainable params: 67,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzGH3FQYAJbQ",
    "outputId": "fdfd9b3e-a399-4628-d74f-4b2ad118821e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18990 samples, validate on 4748 samples\n",
      "Epoch 1/10\n",
      "18990/18990 [==============================] - 41s 2ms/sample - loss: 1.6748 - acc: 0.3592 - val_loss: 1.3268 - val_acc: 0.5657\n",
      "Epoch 2/10\n",
      "18990/18990 [==============================] - 47s 2ms/sample - loss: 1.1451 - acc: 0.5912 - val_loss: 0.7871 - val_acc: 0.7053\n",
      "Epoch 3/10\n",
      "18990/18990 [==============================] - 37s 2ms/sample - loss: 0.8546 - acc: 0.6835 - val_loss: 0.6719 - val_acc: 0.7580\n",
      "Epoch 4/10\n",
      "18990/18990 [==============================] - 43s 2ms/sample - loss: 0.7188 - acc: 0.7269 - val_loss: 0.5716 - val_acc: 0.7904\n",
      "Epoch 5/10\n",
      "18990/18990 [==============================] - 68s 4ms/sample - loss: 0.6208 - acc: 0.7609 - val_loss: 0.4826 - val_acc: 0.8166\n",
      "Epoch 6/10\n",
      "18990/18990 [==============================] - 61s 3ms/sample - loss: 0.5665 - acc: 0.7822 - val_loss: 0.6302 - val_acc: 0.7424\n",
      "Epoch 7/10\n",
      "18990/18990 [==============================] - 47s 2ms/sample - loss: 0.5195 - acc: 0.8021 - val_loss: 0.3882 - val_acc: 0.8357\n",
      "Epoch 8/10\n",
      "18990/18990 [==============================] - 46s 2ms/sample - loss: 0.4785 - acc: 0.8176 - val_loss: 0.3401 - val_acc: 0.8793\n",
      "Epoch 9/10\n",
      "18990/18990 [==============================] - 48s 3ms/sample - loss: 0.4340 - acc: 0.8340 - val_loss: 0.3950 - val_acc: 0.8566\n",
      "Epoch 10/10\n",
      "18990/18990 [==============================] - 48s 3ms/sample - loss: 0.4060 - acc: 0.8475 - val_loss: 0.3963 - val_acc: 0.8612\n",
      "CPU times: user 16min 8s, sys: 1min 6s, total: 17min 15s\n",
      "Wall time: 8min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0ec143090>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLNYwlEQAJbW",
    "outputId": "60fc3bfa-a1ef-4523-8e2d-b052f3733d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.73      0.92      0.81       157\n",
      "      alinda       0.76      0.54      0.64       149\n",
      "        gian       0.71      0.51      0.60       166\n",
      "     jackson       0.83      1.00      0.91      1004\n",
      "      khaled       0.74      0.57      0.64       144\n",
      "     nicolas       0.93      0.92      0.93      1052\n",
      "        theo       0.88      0.83      0.85      1048\n",
      "    yweweler       0.87      0.83      0.85      1028\n",
      "\n",
      "    accuracy                           0.86      4748\n",
      "   macro avg       0.81      0.77      0.78      4748\n",
      "weighted avg       0.86      0.86      0.86      4748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5KqZBYNZAJbZ"
   },
   "source": [
    "### Batch_normalization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH6cPoI9AJba",
    "outputId": "96517b9b-1c96-4d34-cdf8-e57eca5ce5da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 80)                30800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 68,608\n",
      "Trainable params: 68,176\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Y6DRC5kAJbg",
    "outputId": "a4dd3912-a1ef-48ef-ac89-7bca897cc3a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18990 samples, validate on 4748 samples\n",
      "Epoch 1/10\n",
      "18990/18990 [==============================] - 107s 6ms/sample - loss: 1.0654 - acc: 0.6311 - val_loss: 0.7258 - val_acc: 0.7532\n",
      "Epoch 2/10\n",
      "18990/18990 [==============================] - 113s 6ms/sample - loss: 0.6376 - acc: 0.7609 - val_loss: 0.4690 - val_acc: 0.8359\n",
      "Epoch 3/10\n",
      "18990/18990 [==============================] - 103s 5ms/sample - loss: 0.5250 - acc: 0.7993 - val_loss: 0.3700 - val_acc: 0.8561\n",
      "Epoch 4/10\n",
      "18990/18990 [==============================] - 83s 4ms/sample - loss: 0.4441 - acc: 0.8329 - val_loss: 0.3919 - val_acc: 0.8349\n",
      "Epoch 5/10\n",
      "18990/18990 [==============================] - 78s 4ms/sample - loss: 0.3956 - acc: 0.8469 - val_loss: 0.3214 - val_acc: 0.8842\n",
      "Epoch 6/10\n",
      "18990/18990 [==============================] - 81s 4ms/sample - loss: 0.3734 - acc: 0.8579 - val_loss: 0.3518 - val_acc: 0.8589\n",
      "Epoch 7/10\n",
      "18990/18990 [==============================] - 79s 4ms/sample - loss: 0.3386 - acc: 0.8686 - val_loss: 0.2356 - val_acc: 0.9122\n",
      "Epoch 8/10\n",
      "18990/18990 [==============================] - 82s 4ms/sample - loss: 0.3105 - acc: 0.8818 - val_loss: 0.2685 - val_acc: 0.8865\n",
      "Epoch 9/10\n",
      "18990/18990 [==============================] - 80s 4ms/sample - loss: 0.3006 - acc: 0.8844 - val_loss: 0.2221 - val_acc: 0.9162\n",
      "Epoch 10/10\n",
      "18990/18990 [==============================] - 81s 4ms/sample - loss: 0.2766 - acc: 0.8935 - val_loss: 0.2181 - val_acc: 0.9105\n",
      "CPU times: user 30min 22s, sys: 6min 8s, total: 36min 30s\n",
      "Wall time: 14min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0ec621f90>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhMXBIZLAJbj",
    "outputId": "404da482-df82-4797-c591-e8f13f7b0074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.94      0.90      0.92       157\n",
      "      alinda       0.88      0.85      0.86       149\n",
      "        gian       0.97      0.79      0.87       166\n",
      "     jackson       0.95      1.00      0.97      1004\n",
      "      khaled       0.93      0.78      0.85       144\n",
      "     nicolas       0.99      0.99      0.99      1052\n",
      "        theo       0.86      0.82      0.84      1048\n",
      "    yweweler       0.83      0.88      0.85      1028\n",
      "\n",
      "    accuracy                           0.91      4748\n",
      "   macro avg       0.92      0.88      0.89      4748\n",
      "weighted avg       0.91      0.91      0.91      4748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fw0IuGRwAJbm"
   },
   "source": [
    "### Different architecture\n",
    "Let's change a bit the architecture and see if we can improve scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4DjuMehAJbn",
    "outputId": "584137dc-46a7-4bc1-d237-ff87e41fa1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 607,976\n",
      "Trainable params: 607,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRqPhHRsAJbs",
    "outputId": "439effc6-cd35-40a0-ece9-7b5339bfb048"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18990 samples, validate on 4748 samples\n",
      "Epoch 1/10\n",
      "18990/18990 [==============================] - 65s 3ms/sample - loss: 1.1693 - acc: 0.5718 - val_loss: 0.7878 - val_acc: 0.6969\n",
      "Epoch 2/10\n",
      "18990/18990 [==============================] - 64s 3ms/sample - loss: 0.6192 - acc: 0.7691 - val_loss: 0.4914 - val_acc: 0.8058\n",
      "Epoch 3/10\n",
      "18990/18990 [==============================] - 65s 3ms/sample - loss: 0.4263 - acc: 0.8384 - val_loss: 0.3282 - val_acc: 0.8827\n",
      "Epoch 4/10\n",
      "18990/18990 [==============================] - 66s 3ms/sample - loss: 0.3284 - acc: 0.8744 - val_loss: 0.3224 - val_acc: 0.8743\n",
      "Epoch 5/10\n",
      "18990/18990 [==============================] - 72s 4ms/sample - loss: 0.2740 - acc: 0.8937 - val_loss: 0.2205 - val_acc: 0.9164\n",
      "Epoch 6/10\n",
      "18990/18990 [==============================] - 82s 4ms/sample - loss: 0.2280 - acc: 0.9109 - val_loss: 0.1961 - val_acc: 0.9231\n",
      "Epoch 7/10\n",
      "18990/18990 [==============================] - 79s 4ms/sample - loss: 0.2144 - acc: 0.9154 - val_loss: 0.1915 - val_acc: 0.9195\n",
      "Epoch 8/10\n",
      "18990/18990 [==============================] - 78s 4ms/sample - loss: 0.1898 - acc: 0.9245 - val_loss: 0.2267 - val_acc: 0.9002\n",
      "Epoch 9/10\n",
      "18990/18990 [==============================] - 80s 4ms/sample - loss: 0.1671 - acc: 0.9334 - val_loss: 0.2324 - val_acc: 0.8953\n",
      "Epoch 10/10\n",
      "18990/18990 [==============================] - 85s 4ms/sample - loss: 0.1592 - acc: 0.9371 - val_loss: 0.1445 - val_acc: 0.9431\n",
      "CPU times: user 27min 11s, sys: 3min 28s, total: 30min 40s\n",
      "Wall time: 12min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0ee0de8d0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0c85SLvAJbu",
    "outputId": "b1dfcfd5-ff0e-4b40-bb8e-260f0563788f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.94      0.97      0.95       157\n",
      "      alinda       0.90      0.93      0.91       149\n",
      "        gian       0.99      0.84      0.91       166\n",
      "     jackson       0.98      1.00      0.99      1004\n",
      "      khaled       0.99      0.83      0.90       144\n",
      "     nicolas       0.99      0.99      0.99      1052\n",
      "        theo       0.95      0.86      0.90      1048\n",
      "    yweweler       0.86      0.95      0.90      1028\n",
      "\n",
      "    accuracy                           0.94      4748\n",
      "   macro avg       0.95      0.92      0.93      4748\n",
      "weighted avg       0.95      0.94      0.94      4748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model\n",
    "Based on the f1-score, the best model is the \"custom cnn\" one. Let's see its result on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 607,976\n",
      "Trainable params: 607,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "23738/23738 [==============================] - 88s 4ms/sample - loss: 1.0489 - acc: 0.6216\n",
      "Epoch 2/10\n",
      "23738/23738 [==============================] - 103s 4ms/sample - loss: 0.5285 - acc: 0.8019\n",
      "Epoch 3/10\n",
      "23738/23738 [==============================] - 93s 4ms/sample - loss: 0.3672 - acc: 0.8587\n",
      "Epoch 4/10\n",
      "23738/23738 [==============================] - 105s 4ms/sample - loss: 0.2868 - acc: 0.8895\n",
      "Epoch 5/10\n",
      "23738/23738 [==============================] - 93s 4ms/sample - loss: 0.2379 - acc: 0.9078\n",
      "Epoch 6/10\n",
      "23738/23738 [==============================] - 87s 4ms/sample - loss: 0.2053 - acc: 0.9209\n",
      "Epoch 7/10\n",
      "23738/23738 [==============================] - 92s 4ms/sample - loss: 0.1805 - acc: 0.9290\n",
      "Epoch 8/10\n",
      "23738/23738 [==============================] - 87s 4ms/sample - loss: 0.1682 - acc: 0.9336\n",
      "Epoch 9/10\n",
      "23738/23738 [==============================] - 103s 4ms/sample - loss: 0.1615 - acc: 0.9385\n",
      "Epoch 10/10\n",
      "23738/23738 [==============================] - 94s 4ms/sample - loss: 0.1391 - acc: 0.9462\n",
      "CPU times: user 31min 44s, sys: 4min 21s, total: 36min 6s\n",
      "Wall time: 15min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0f1afa690>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train = np.concatenate([X_train_speaker, X_val_speaker], axis=0)\n",
    "y_train = np.concatenate([y_train_speaker, y_val_speaker], axis=0)\n",
    "model = cnn_models.custom_cnn(8, input_shape=input_shape)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.97      0.98        30\n",
      "      alinda       1.00      1.00      1.00        30\n",
      "        gian       1.00      1.00      1.00        30\n",
      "     jackson       0.91      0.97      0.94        30\n",
      "      khaled       0.96      0.90      0.93        30\n",
      "     nicolas       1.00      1.00      1.00        30\n",
      "        theo       0.94      1.00      0.97        30\n",
      "    yweweler       1.00      0.97      0.98        30\n",
      "\n",
      "    accuracy                           0.97       240\n",
      "   macro avg       0.98      0.98      0.98       240\n",
      "weighted avg       0.98      0.97      0.98       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_nn = np.argmax(y_test_speaker, axis=1)\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(y_test_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_models/speaker_recognition.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6hWHr2CAJbx"
   },
   "source": [
    "## Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_digit.shape\n",
    "X_train_digit_2d = X_train_digit.reshape((nsamples, nx * ny))\n",
    "nsamples, nx, ny = X_val_digit.shape\n",
    "X_val_digit_2d = X_val_digit.reshape((nsamples, nx * ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ew0HbFTlAJby"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.75       438\n",
      "           1       0.64      0.68      0.66       456\n",
      "           2       0.62      0.62      0.62       455\n",
      "           3       0.54      0.59      0.57       428\n",
      "           4       0.68      0.78      0.73       485\n",
      "           5       0.76      0.71      0.74       464\n",
      "           6       0.58      0.65      0.61       442\n",
      "           7       0.69      0.51      0.59       490\n",
      "           8       0.72      0.72      0.72       499\n",
      "           9       0.72      0.70      0.71       459\n",
      "\n",
      "    accuracy                           0.67      4616\n",
      "   macro avg       0.67      0.67      0.67      4616\n",
      "weighted avg       0.67      0.67      0.67      4616\n",
      "\n",
      "CPU times: user 9min 22s, sys: 8.96 s, total: 9min 31s\n",
      "Wall time: 10min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Switch to LinearSVC because SVC with RBF kernel takes a lot of time\n",
    "clf1 = LinearSVC(class_weight='balanced')\n",
    "clf1 = clf1.fit(X_train_digit_2d, y_train_digit)\n",
    "y_pred = clf1.predict(X_val_digit_2d)\n",
    "print(classification_report(y_val_digit, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gP6JS1xLAJb1"
   },
   "outputs": [],
   "source": [
    "X_train_digit = X_train_digit.reshape(X_train_digit.shape[0], X_train_digit.shape[1], X_train_digit.shape[2], 1)\n",
    "X_val_digit = X_val_digit.reshape(X_val_digit.shape[0], X_val_digit.shape[1], X_val_digit.shape[2], 1)\n",
    "X_test_digit = X_test_digit.reshape(X_test_digit.shape[0], X_test_digit.shape[1], X_test_digit.shape[2], 1)\n",
    "y_train_digit = tf.keras.utils.to_categorical(y_train_digit, 10)\n",
    "y_test_digit = tf.keras.utils.to_categorical(y_test_digit, 10)\n",
    "y_val_digit = tf.keras.utils.to_categorical(y_val_digit, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBDON2ZdAJb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 57, 1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (X_train_digit.shape[1], X_train_digit.shape[2], 1)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-NVkJ-QAJb7"
   },
   "source": [
    "#### Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XC3UZAcOAJb8",
    "outputId": "bc153d1f-f02e-430a-d369-6260bf7fe004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 63, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 30, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 5, 64)         32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 14, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               38500     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 78,420\n",
      "Trainable params: 77,928\n",
      "Non-trainable params: 492\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPg3NJywAJb9",
    "outputId": "0f871699-0dad-45e3-c8f8-1af666ddf316"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18462 samples, validate on 4616 samples\n",
      "Epoch 1/10\n",
      "18462/18462 [==============================] - 88s 5ms/sample - loss: 1.6704 - acc: 0.4172 - val_loss: 1.2297 - val_acc: 0.5737\n",
      "Epoch 2/10\n",
      "18462/18462 [==============================] - 91s 5ms/sample - loss: 1.1497 - acc: 0.5997 - val_loss: 1.0029 - val_acc: 0.6716\n",
      "Epoch 3/10\n",
      "18462/18462 [==============================] - 88s 5ms/sample - loss: 0.9729 - acc: 0.6659 - val_loss: 0.8507 - val_acc: 0.7223\n",
      "Epoch 4/10\n",
      "18462/18462 [==============================] - 76s 4ms/sample - loss: 0.8708 - acc: 0.7015 - val_loss: 0.7005 - val_acc: 0.7593\n",
      "Epoch 5/10\n",
      "18462/18462 [==============================] - 74s 4ms/sample - loss: 0.7821 - acc: 0.7325 - val_loss: 0.5967 - val_acc: 0.7972\n",
      "Epoch 6/10\n",
      "18462/18462 [==============================] - 78s 4ms/sample - loss: 0.7307 - acc: 0.7495 - val_loss: 0.6257 - val_acc: 0.7844\n",
      "Epoch 7/10\n",
      "18462/18462 [==============================] - 118s 6ms/sample - loss: 0.6822 - acc: 0.7657 - val_loss: 0.6391 - val_acc: 0.7805\n",
      "Epoch 8/10\n",
      "18462/18462 [==============================] - 86s 5ms/sample - loss: 0.6654 - acc: 0.7716 - val_loss: 0.6055 - val_acc: 0.7929\n",
      "CPU times: user 23min 42s, sys: 4min 46s, total: 28min 29s\n",
      "Wall time: 11min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0ac37e790>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit, y_train_digit,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digit, y_val_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8W5ebLFOAJb_",
    "outputId": "4cc55fb9-de41-4c1c-819a-bf0ddee91d73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       438\n",
      "           1       0.89      0.70      0.78       456\n",
      "           2       0.63      0.89      0.74       455\n",
      "           3       0.85      0.59      0.70       428\n",
      "           4       0.82      0.84      0.83       485\n",
      "           5       0.86      0.78      0.82       464\n",
      "           6       0.83      0.77      0.80       442\n",
      "           7       0.79      0.80      0.80       490\n",
      "           8       0.80      0.80      0.80       499\n",
      "           9       0.71      0.90      0.80       459\n",
      "\n",
      "    accuracy                           0.80      4616\n",
      "   macro avg       0.81      0.80      0.80      4616\n",
      "weighted avg       0.81      0.80      0.80      4616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val = np.argmax(y_val_digit, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val_digit)\n",
    "print(classification_report(Y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNe34g3rAJcB"
   },
   "source": [
    "#### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVvhmAq_AJcB",
    "outputId": "ce6e89d0-9672-4dd1-f7fe-0b579280555f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 608,234\n",
      "Trainable params: 608,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejqqynFOAJcD",
    "outputId": "bcf3bdb5-8986-486f-a849-084d955340ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18462 samples, validate on 4616 samples\n",
      "Epoch 1/10\n",
      "18462/18462 [==============================] - 76s 4ms/sample - loss: 1.5156 - acc: 0.4577 - val_loss: 1.0718 - val_acc: 0.6228\n",
      "Epoch 2/10\n",
      "18462/18462 [==============================] - 70s 4ms/sample - loss: 1.0182 - acc: 0.6371 - val_loss: 0.8690 - val_acc: 0.6969\n",
      "Epoch 3/10\n",
      "18462/18462 [==============================] - 69s 4ms/sample - loss: 0.8379 - acc: 0.7040 - val_loss: 0.7638 - val_acc: 0.7370\n",
      "Epoch 4/10\n",
      "18462/18462 [==============================] - 71s 4ms/sample - loss: 0.7341 - acc: 0.7439 - val_loss: 0.6451 - val_acc: 0.7821\n",
      "Epoch 5/10\n",
      "18462/18462 [==============================] - 70s 4ms/sample - loss: 0.6549 - acc: 0.7690 - val_loss: 0.5909 - val_acc: 0.7964\n",
      "Epoch 6/10\n",
      "18462/18462 [==============================] - 70s 4ms/sample - loss: 0.6037 - acc: 0.7895 - val_loss: 0.5802 - val_acc: 0.8070\n",
      "Epoch 7/10\n",
      "18462/18462 [==============================] - 71s 4ms/sample - loss: 0.5630 - acc: 0.8022 - val_loss: 0.6321 - val_acc: 0.7814\n",
      "Epoch 8/10\n",
      "18462/18462 [==============================] - 69s 4ms/sample - loss: 0.5270 - acc: 0.8154 - val_loss: 0.5458 - val_acc: 0.8122\n",
      "Epoch 9/10\n",
      "18462/18462 [==============================] - 69s 4ms/sample - loss: 0.4862 - acc: 0.8298 - val_loss: 0.4944 - val_acc: 0.8265\n",
      "Epoch 10/10\n",
      "18462/18462 [==============================] - 72s 4ms/sample - loss: 0.4619 - acc: 0.8366 - val_loss: 0.5225 - val_acc: 0.8228\n",
      "CPU times: user 26min 24s, sys: 3min 25s, total: 29min 50s\n",
      "Wall time: 11min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0ac368cd0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit, y_train_digit,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digit, y_val_digit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3px-T1QRAJcF",
    "outputId": "9b7ed3c6-e597-4a11-a9c3-ec4517e58ed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.90       438\n",
      "           1       0.96      0.73      0.83       456\n",
      "           2       0.87      0.76      0.81       455\n",
      "           3       0.96      0.65      0.77       428\n",
      "           4       0.82      0.90      0.86       485\n",
      "           5       0.87      0.88      0.88       464\n",
      "           6       0.51      0.93      0.66       442\n",
      "           7       0.96      0.81      0.88       490\n",
      "           8       0.78      0.87      0.82       499\n",
      "           9       0.94      0.84      0.89       459\n",
      "\n",
      "    accuracy                           0.82      4616\n",
      "   macro avg       0.86      0.82      0.83      4616\n",
      "weighted avg       0.86      0.82      0.83      4616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_digit)\n",
    "print(classification_report(Y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model\n",
    "Based on F1-Score the best model is once again the custom paper architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 63, 27, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 14, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4480)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               573568    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 608,234\n",
      "Trainable params: 608,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "23078/23078 [==============================] - 87s 4ms/sample - loss: 1.4360 - acc: 0.4872\n",
      "Epoch 2/10\n",
      "23078/23078 [==============================] - 86s 4ms/sample - loss: 0.9657 - acc: 0.6596\n",
      "Epoch 3/10\n",
      "23078/23078 [==============================] - 85s 4ms/sample - loss: 0.7915 - acc: 0.7200\n",
      "Epoch 4/10\n",
      "23078/23078 [==============================] - 86s 4ms/sample - loss: 0.6827 - acc: 0.7596\n",
      "Epoch 5/10\n",
      "23078/23078 [==============================] - 86s 4ms/sample - loss: 0.6117 - acc: 0.7851\n",
      "Epoch 6/10\n",
      "23078/23078 [==============================] - 85s 4ms/sample - loss: 0.5521 - acc: 0.8055\n",
      "Epoch 7/10\n",
      "23078/23078 [==============================] - 86s 4ms/sample - loss: 0.5123 - acc: 0.8185\n",
      "Epoch 8/10\n",
      "23078/23078 [==============================] - 88s 4ms/sample - loss: 0.4827 - acc: 0.8320\n",
      "Epoch 9/10\n",
      "23078/23078 [==============================] - 95s 4ms/sample - loss: 0.4531 - acc: 0.8428\n",
      "Epoch 10/10\n",
      "23078/23078 [==============================] - 99s 4ms/sample - loss: 0.4295 - acc: 0.8473\n",
      "CPU times: user 31min 9s, sys: 4min 16s, total: 35min 26s\n",
      "Wall time: 14min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0ae850750>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train = np.concatenate([X_train_digit, X_val_digit], axis=0)\n",
    "y_train = np.concatenate([y_train_digit, y_val_digit], axis=0)\n",
    "model = cnn_models.custom_cnn(10, input_shape=input_shape)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        30\n",
      "           1       0.97      0.97      0.97        30\n",
      "           2       0.97      1.00      0.98        30\n",
      "           3       0.96      0.90      0.93        30\n",
      "           4       0.96      0.90      0.93        30\n",
      "           5       0.76      0.93      0.84        30\n",
      "           6       0.88      1.00      0.94        30\n",
      "           7       0.93      0.90      0.92        30\n",
      "           8       1.00      0.93      0.97        30\n",
      "           9       0.96      0.87      0.91        30\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.94      0.93      0.93       300\n",
      "weighted avg       0.94      0.93      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_nn = np.argmax(y_test_digit, axis=1)\n",
    "y_pred = model.predict_classes(X_test_digit)\n",
    "print(classification_report(y_test_nn, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best_models/digit_recognition.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTzZ1yR6AJcG"
   },
   "source": [
    "# Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WxSYVrOAJcH"
   },
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "from scipy.io import wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SyhhZ8dAJcL"
   },
   "outputs": [],
   "source": [
    "def pad_zeros_single_rec(rec, max_y):\n",
    "    rec = np.array(rec)\n",
    "    diff_in_y = max_y - rec.shape[0]\n",
    "    if diff_in_y > 0:\n",
    "        half_diff = int(diff_in_y/2)\n",
    "        remaining_diff = diff_in_y-half_diff\n",
    "        v = np.pad(rec, (half_diff, remaining_diff), 'constant', constant_values=0)\n",
    "        return v\n",
    "    else:\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUyrZr67AJcN"
   },
   "outputs": [],
   "source": [
    "def create_recording(duration, rec_rate, name = \"test.wav\", output_dir = \"test/\"):\n",
    "    print(\"Ready in 3...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"2...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"1...\")\n",
    "    time.sleep(1)\n",
    "    print(\"Go.\")\n",
    "    rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "    print(\"Playing the recording.\")\n",
    "    sd.play(rec, rec_rate)\n",
    "\n",
    "    # after hearing the recording, decide whether to record it again or continue to next number\n",
    "    # if you type anything, record again\n",
    "    # if you press enter, save current recording & go to next number\n",
    "    ok = input(\"OK?\")\n",
    "    if ok == \"\":\n",
    "        librosa.output.write_wav(output_dir+name, rec, rec_rate)\n",
    "        return rec\n",
    "    ipd.clear_output(wait=True)\n",
    "    create_recording(duration, rec_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QBcrjAzAJcO"
   },
   "outputs": [],
   "source": [
    "def trim_audio(file, input_dir=\"test/\", output_dir=\"test/\", db=-48):\n",
    "\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"There should be an input \\\"{input_dir}\\\" directory.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # create output directory if not there yet\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    temp1 = output_dir+\"temp1.wav\"\n",
    "    temp2 = output_dir+\"temp2.wav\"\n",
    "    temp3 = output_dir+\"temp3.wav\"\n",
    " \n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_dir+file, \"-af\", f\"silenceremove=1:0:{db}dB\", temp1])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp1, \"-af\", \"areverse\", temp2])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp2, \"-af\", f\"silenceremove=1:0.1:{db}dB\", temp3])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp3, \"-af\", \"areverse\", output_dir+file])\n",
    "    \n",
    "    os.remove(temp1)\n",
    "    os.remove(temp2)\n",
    "    os.remove(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkZPGYwUAJcQ"
   },
   "outputs": [],
   "source": [
    "def test_NN(nn, max_y, target_names, answer = None, duration=2, rec_rate=8000, directory = \"test/\", filename = \"test.wav\"):\n",
    "    create_recording(duration, rec_rate, filename, directory)   \n",
    "    ipd.clear_output()\n",
    "    trim_audio(filename, directory, directory)\n",
    "    # _, rec = wav.read(directory + \"/\" + filename)\n",
    "    rec, _ = librosa.core.load(directory + \"/\" + filename, sr = rec_rate)\n",
    "    rec = pad_zeros_single_rec(rec, max_y)\n",
    "    # sd.play(rec, rec_rate)\n",
    "    rec = data_preparation.compute_spectrogram(rec, normalize=True)\n",
    "    rec = rec[np.newaxis,:,:,np.newaxis]\n",
    "    preds = nn.predict_classes(rec)\n",
    "    print(\"Model prediction: {}\".format(target_names[preds[0]]))\n",
    "    if answer is not None:\n",
    "        print(f\"Correct answer {answer}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VP6Hng1sAJcT"
   },
   "outputs": [],
   "source": [
    "max_y = len(data_augm_pad_recordings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-M4mw6KAJcW"
   },
   "outputs": [],
   "source": [
    "pred = test_NN(model, max_y, target_names, answer = \"gian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9GkS5ZFAJcY"
   },
   "source": [
    "# TO DO:\n",
    "- [x] Set random seed\n",
    "- [x] Use only original recordings in test set of augmented scenario\n",
    "- [x] Use proper validation set for picking best models and params\n",
    "- [x] Data augmentation also for digit recognition\n",
    "- [ ] Evaluate each best model on test set, after training it on x_train + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ubpdv577AJcY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classifiers-Spectrogram_based.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041ee309cd2a4523b8cbb817a7133aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8db829965d284a9b848aa89f1d6e1a7e",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8f16c91328fb4555af28b4fa2522f1b6",
      "value": 2000
     }
    },
    "0471feee5a704241bc959bf9f25cf86b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f5badcb0b1e4938901d1ccebf26bc1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6532c85805db453f8a76edaf34996c0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74521556c16e4badb587537f36771810": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_041ee309cd2a4523b8cbb817a7133aeb",
       "IPY_MODEL_ab519d0c6d6241c5afbc76dbde2306fd"
      ],
      "layout": "IPY_MODEL_5f5badcb0b1e4938901d1ccebf26bc1f"
     }
    },
    "8db829965d284a9b848aa89f1d6e1a7e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f16c91328fb4555af28b4fa2522f1b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a9b4078544ee4fc4b203252a8539169c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ab519d0c6d6241c5afbc76dbde2306fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c29d5436c6514002b1380c6dfb229f76",
      "placeholder": "​",
      "style": "IPY_MODEL_eef3bdb92f1e43eb9241be66f3360fbc",
      "value": " 2000/2000 [57:14&lt;00:00,  1.72s/it]"
     }
    },
    "b20e330bbd0541b9ad6e8897ba359fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bce824cee09446879776ce8440927c32",
       "IPY_MODEL_d877478de1de4e2a9e67d33302b19075"
      ],
      "layout": "IPY_MODEL_6532c85805db453f8a76edaf34996c0c"
     }
    },
    "b365514386b341d6896420c06f2a9a86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bce824cee09446879776ce8440927c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b365514386b341d6896420c06f2a9a86",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a9b4078544ee4fc4b203252a8539169c",
      "value": 400
     }
    },
    "c29d5436c6514002b1380c6dfb229f76": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d877478de1de4e2a9e67d33302b19075": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f110b274d39141b892be18de60d7fd3b",
      "placeholder": "​",
      "style": "IPY_MODEL_0471feee5a704241bc959bf9f25cf86b",
      "value": " 400/400 [01:40&lt;00:00,  3.97it/s]"
     }
    },
    "eef3bdb92f1e43eb9241be66f3360fbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f110b274d39141b892be18de60d7fd3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
