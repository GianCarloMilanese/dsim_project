{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcpAdLEIAOMh"
   },
   "source": [
    "# Just for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "p-dutOrvAPZg",
    "outputId": "b3c51368-3f49-4296-f170-cd4d5a9f7ade"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "import urllib\n",
    "\n",
    "user = input('User name: ')\n",
    "password = getpass('Password: ')\n",
    "password = urllib.parse.quote(password) # your password is converted into url format\n",
    "\n",
    "cmd_string = 'git clone https://{0}:{1}@github.com/GianCarloMilanese/dsim_project.git'.format(user, password)\n",
    "\n",
    "os.system(cmd_string)\n",
    "cmd_string, password = \"\", \"\" # removing the password from the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "mVoN9qvnGPqR",
    "outputId": "252dcd03-1a49-4a08-8f84-c2c441fc5408"
   },
   "outputs": [],
   "source": [
    "!ls -lh dsim_project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "7_p69CQOG8Sn",
    "outputId": "a6271bc7-a6c0-45ce-d49b-62404ffb80e0"
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/Jakobovski/free-spoken-digit-dataset.git && mv free-spoken-digit-dataset/recordings dsim_project/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "PAQ5VI3zHei1",
    "outputId": "a99953d0-6eac-4870-8ea3-b804f52270c8"
   },
   "outputs": [],
   "source": [
    "!ls -lh dsim_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"dsim_project/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SD8Nx-3tAJY_"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SP35h9g6AJZB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import data_augmentation\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wQvjtLSAJZG"
   },
   "source": [
    "# Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSZ1nRq_AJZH"
   },
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "tf.random.set_random_seed(SEED)# if working on tf < 2.0\n",
    "#tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YLZTM3YDAJZK"
   },
   "source": [
    "# Load recordings\n",
    "## STANDARD RECORDINGS - No spectrogram normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1G8haE_GIkzR"
   },
   "outputs": [],
   "source": [
    "fsdd_dir=\"dsim_project/recordings\"\n",
    "our_recs_dir=\"dsim_project/preprocessed_recs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsdd_dir=\"./recordings/\"\n",
    "our_recs_dir=\"./preprocessed_recs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 149,
     "referenced_widgets": [
      "74521556c16e4badb587537f36771810",
      "5f5badcb0b1e4938901d1ccebf26bc1f",
      "041ee309cd2a4523b8cbb817a7133aeb",
      "ab519d0c6d6241c5afbc76dbde2306fd",
      "8f16c91328fb4555af28b4fa2522f1b6",
      "8db829965d284a9b848aa89f1d6e1a7e",
      "eef3bdb92f1e43eb9241be66f3360fbc",
      "c29d5436c6514002b1380c6dfb229f76",
      "b20e330bbd0541b9ad6e8897ba359fc3",
      "6532c85805db453f8a76edaf34996c0c",
      "bce824cee09446879776ce8440927c32",
      "d877478de1de4e2a9e67d33302b19075",
      "a9b4078544ee4fc4b203252a8539169c",
      "b365514386b341d6896420c06f2a9a86",
      "0471feee5a704241bc959bf9f25cf86b",
      "f110b274d39141b892be18de60d7fd3b"
     ]
    },
    "colab_type": "code",
    "id": "EhEjE2JZAJZL",
    "outputId": "bc2b6b8d-494b-4745-ecf0-82ee4b51fadc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ./recordings/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57b8a3190e1410585dd2e3e2aa43ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from ./preprocessed_recs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b750177c01bd436fb715fd147719fc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrZ1SrCyAJZO"
   },
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "USN0CDHyAJZO",
    "outputId": "2126cd10-edbe-4ef7-b2a3-2c41e50a6be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010 18262\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is quite huge! Let's see which are the longest recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18262, 17567, 9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two recordings have length 18262 and 17567, while the others are around 20K. Let's identify them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "first_length=18262\n",
    "second_length=17567\n",
    "index_first = a.index(first_length)\n",
    "index_second = a.index(second_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18262"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recordings[index_first])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17567"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recordings[index_second])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have found them. For knowing to which digit and speaker they are associated I first need to load the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=[fsdd_dir, our_recs_dir])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest track is associated with speaker theo, digit 9\n",
      "Second longest track is associated with speaker theo, digit 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_first],labels_digits[index_first]))\n",
    "print(\"Second longest track is associated with speaker {}, digit {}\".format(labels_speakers[index_second],labels_digits[index_second]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problem is with theo, which has 500 recordings, digit 9 and 7, which respectively have 200 recordings. We can safely delete them and saving to pad many thousands of 0s (there will be (18262 - 9015) less zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "max_track_length=17000 # it will be useful later on\n",
    "print(\"Before: {}\".format(len(recordings)))\n",
    "recordings=np.delete(recordings,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(recordings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_speakers)))\n",
    "labels_speakers=np.delete(labels_speakers,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_speakers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 2400\n",
      "After: 2398\n"
     ]
    }
   ],
   "source": [
    "print(\"Before: {}\".format(len(labels_digits)))\n",
    "labels_digits=np.delete(labels_digits,[index_first, index_second])\n",
    "print(\"After: {}\".format(len(labels_digits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now double check to see if everything went well. Now the longest recording will be around 9 K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9015, 8995, 8435, 8281, 8201, 8068, 7755, 7356, 7147, 7038]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [len(x) for x in recordings]\n",
    "a.sort(reverse=True)\n",
    "a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIOfNR7UAJZR"
   },
   "source": [
    "Yes! However the recordings have all different lengths: for this reason we can add 0s at the beginning and at the end in order to uniform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DAqhOQfXAJZS",
    "outputId": "f4fb11ac-3e4e-4ef7-92cc-4106a989315c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_zeros >>>\n",
      "pad_zeros <<<\n"
     ]
    }
   ],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knxJsuQHAJZV"
   },
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UH4CNtcaAJZV",
    "outputId": "70f33b43-ad02-4214-dc91-4c934af961cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9015 9015\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzTvIWFqAJZY"
   },
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBOpha3yAJZZ"
   },
   "outputs": [],
   "source": [
    "spects = [data_preparation.compute_spectrogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UcS3jm3hAJZf"
   },
   "source": [
    "Let's also compute \"normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UBHB2jB0AJZf"
   },
   "outputs": [],
   "source": [
    "norm_spects = [data_preparation.compute_spectrogram(x, normalize=True) for x in pad_recordings]\n",
    "norm_spects = np.array(norm_spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NifXsIaiAJZi"
   },
   "source": [
    "##Â Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "S7lJzOxaAJZi",
    "outputId": "d7dd58d8-9103-4b00-9784-7e872b59eab9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 4min 49s, sys: 10.8 s, total: 5min\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digit, y_train_digit, X_val_digit, y_val_digit, X_test_digit, y_test_digit = data_preparation.prepare_augmented_recordings(audio_dirs= [fsdd_dir, our_recs_dir],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True,\n",
    "                             max_length=max_track_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q7kf01G8AJZl",
    "outputId": "70bde817-b594-4519-f3cd-ed14aafec37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 18462, 18462, 4616, 4616, 300, 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}, {}, {}\".format(len(X_train_digit),\n",
    "                                                len(y_train_digit),\n",
    "                                                len(X_val_digit),\n",
    "                                                len(y_val_digit),\n",
    "                                                len(X_test_digit),\n",
    "                                                len(y_test_digit),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "mAS0dEAeAJZn",
    "outputId": "5f5b8ee6-7d0b-4575-d9d6-ac9708bbda97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "split_and_augment_dataset >>>\n",
      "enrich_dataset>>>\n",
      "Max length: 17000, shape:(17567,)\n",
      "Max length: 17000, shape:(18262,)\n",
      "enrich_dataset <<<\n",
      "split_and_augment_dataset <<<\n",
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "9015\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 4min 57s, sys: 13.4 s, total: 5min 10s\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(\n",
    "    audio_dirs= [our_recs_dir, fsdd_dir],\n",
    "    y_type= ['speakers_us', 'speakers_default'],\n",
    "    n_category_test=30,\n",
    "    include_pitch=True,\n",
    "    max_length=max_track_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U7pt5gp8AJZq",
    "outputId": "264e985b-797d-4478-fb22-19febb261b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 18990, 18990, 4748, 4748, 240, 240\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}, {}, {}\".format(len(X_train_speaker),\n",
    "                                        len(y_train_speaker),\n",
    "                                        len(X_val_speaker),\n",
    "                                        len(y_val_speaker),\n",
    "                                        len(X_test_speaker),\n",
    "                                        len(y_test_speaker)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcNM7Ju3AJZt"
   },
   "source": [
    "# Standard recordings\n",
    "## Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z08J1Ly2AJZu"
   },
   "source": [
    "Split data in train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zxTeijsAJZu"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pq-h50cLAJZx"
   },
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pGL-51TeAJZ0",
    "outputId": "c8c1f7ec-0a59-4df0-e6a4-80a897a32e52"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "eOuf4fYdAJZ3",
    "outputId": "8de901a9-de7a-466a-b29a-8f8ada4fe913"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZIG3MZXAJZ5"
   },
   "source": [
    "### Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adr8LZdqAJZ5"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PVFxb6UAAJZ-",
    "outputId": "f1631091-a65e-410d-869f-982e7a25e54e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "9YNlZ5ZGAJaB",
    "outputId": "408a182d-3e8d-4b53-a8bc-403523798c87"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjYwbLVWAJaD"
   },
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaUkrMXHAJaD"
   },
   "source": [
    "#### Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWl0glyyAJaE"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "jp-yDTbVAJaG",
    "outputId": "8f73212b-eec8-474f-d751-4583a963eee0"
   },
   "outputs": [],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OjsYe2MZAJaJ"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "dorwbEtUAJaM",
    "outputId": "41eeef7c-3bf0-4747-e426-5864708d9951"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "z1EFnJFhAJaP",
    "outputId": "abe441d8-2f01-4ef9-b3df-688dcd232937"
   },
   "outputs": [],
   "source": [
    "y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ab3NBIvkAJaR"
   },
   "source": [
    "#### Standard spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sWPsfH8AJaS"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "9RPhwIyPAJaU",
    "outputId": "bf9606af-72d8-4fdf-f2ee-77049129bd1a"
   },
   "outputs": [],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "tEl6k7s6AJaX",
    "outputId": "e26b03f7-b375-467e-adf7-99259cf371b8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "3e7-NrFzAJaZ",
    "outputId": "1be23cb6-6ef8-4ffa-c296-6b3ec5764a60"
   },
   "outputs": [],
   "source": [
    "y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hm-UCrvqAJac"
   },
   "source": [
    "From what we can see normalising spectrograms is the way to go. Let's use it by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AzfoB2vwAJad"
   },
   "source": [
    "### Best model\n",
    "The best model for this task is the paper CNN, using the \"normalized\" spectrograms. Let's train it on X_train + X_val for 10 epochs and evaluate it on the not-yet-seen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "9UD8AN11h68p",
    "outputId": "dd4a9cd9-5bb7-45dd-f7ec-9256a6b4a8d5"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, labels_digits)\n",
    "model = cnn_models.paper_architecture(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYPCD2VPiMUc"
   },
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train = np.concatenate([y_train, y_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "04BVWh1kAJad",
    "outputId": "c2e8e656-ff69-412c-eea6-935779578b3c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XykiG7Ljbq8"
   },
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RofgNOXIAJaf"
   },
   "source": [
    "## Speakers\n",
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IsOEsXNrAJag"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nq86YnS3AJai",
    "outputId": "056c8fa2-0ed7-463f-f38a-e9e06c370911"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3qK9OpoAJam",
    "outputId": "b8e82428-9b91-4849-e078-6139ac8ed99f"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Px6AnQPyAJap"
   },
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qw6UWfD6AJap"
   },
   "source": [
    "For neural networks it is not possible to pass the labels as-is: we need to transform them in numbers. The safest way is through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MEyOqyZAJaq"
   },
   "outputs": [],
   "source": [
    "y, target_names = data_preparation.transform_categorical_y(labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4ZWZPxSAJas"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, y, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5nbGXEqAJav",
    "outputId": "c22a47d5-52ab-4bfa-bc21-b919ef3d4b25"
   },
   "outputs": [],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nzq1wprbAJay",
    "outputId": "f3a4929c-1629-4a45-b07a-cad28a8cf1d3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F15PVwnlAJa0",
    "outputId": "cc510785-80ce-4518-bdfe-7ab7707d93ce"
   },
   "outputs": [],
   "source": [
    "Y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qk3vDDTAJa4"
   },
   "source": [
    "#### Paper - batch_normalisation=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NibB6mqLAJa4",
    "outputId": "08b73978-af62-44fb-c3a1-40508d4f7683"
   },
   "outputs": [],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJFqES0hAJa8",
    "outputId": "e87aa981-bfcb-4d60-ee8e-47448a8d0482"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eePEJDMdAJa_",
    "outputId": "dc423068-db5d-46fc-a0ed-c24f08820613"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLz38np3juZf"
   },
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5PZSGZljsLN"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_speakers)\n",
    "X_train = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train = np.concatenate([y_train, y_val], axis=0)\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJh1FkRdAJbD"
   },
   "source": [
    "# Data augmentation\n",
    "## Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HurXrYSAAJbE"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y_train_speaker = enc.fit_transform(np.array(y_train_speaker).reshape(-1, 1)).toarray()\n",
    "y_val_speaker = enc.transform(np.array(y_val_speaker).reshape(-1, 1)).toarray()\n",
    "y_test_speaker = enc.transform(np.array(y_test_speaker).reshape(-1, 1)).toarray()\n",
    "label_0 = enc.inverse_transform(np.array([1, 0, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_1 = enc.inverse_transform(np.array([0, 1, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_2 = enc.inverse_transform(np.array([0, 0, 1, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_3 = enc.inverse_transform(np.array([0, 0, 0, 1, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_4 = enc.inverse_transform(np.array([0, 0, 0, 0, 1, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_5 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 1, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_6 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 1, 0]).reshape(1, -1))[0][0]\n",
    "label_7 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 0, 1]).reshape(1, -1))[0][0]\n",
    "target_names = [label_0, label_1, label_2, label_3, label_4, label_5, label_6, label_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "be1r34oCAJbH"
   },
   "outputs": [],
   "source": [
    "X_train_speaker = np.array(X_train_speaker)\n",
    "X_val_speaker = np.array(X_val_speaker)\n",
    "X_test_speaker = np.array(X_test_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSJDK6FnAJbJ"
   },
   "outputs": [],
   "source": [
    "X_train_speaker = X_train_speaker.reshape(X_train_speaker.shape[0],\n",
    "                                          X_train_speaker.shape[1],\n",
    "                                          X_train_speaker.shape[2],\n",
    "                                          1)\n",
    "X_val_speaker = X_val_speaker.reshape(X_val_speaker.shape[0],\n",
    "                                      X_val_speaker.shape[1],\n",
    "                                      X_val_speaker.shape[2],\n",
    "                                      1)\n",
    "X_test_speaker = X_test_speaker.reshape(X_test_speaker.shape[0],\n",
    "                                        X_test_speaker.shape[1],\n",
    "                                        X_test_speaker.shape[2],\n",
    "                                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHT6j2GWAJbL"
   },
   "outputs": [],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K47DbwgyAJbO",
    "outputId": "fa96fcc6-7da6-432f-885e-9648fda4bd42"
   },
   "outputs": [],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzGH3FQYAJbQ",
    "outputId": "fdfd9b3e-a399-4628-d74f-4b2ad118821e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLNYwlEQAJbW",
    "outputId": "60fc3bfa-a1ef-4523-8e2d-b052f3733d70"
   },
   "outputs": [],
   "source": [
    "Y_val_nn = np.argmax(y_val_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5KqZBYNZAJbZ"
   },
   "source": [
    "### Batch_normalization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH6cPoI9AJba",
    "outputId": "96517b9b-1c96-4d34-cdf8-e57eca5ce5da"
   },
   "outputs": [],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Y6DRC5kAJbg",
    "outputId": "a4dd3912-a1ef-48ef-ac89-7bca897cc3a4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhMXBIZLAJbj",
    "outputId": "404da482-df82-4797-c591-e8f13f7b0074"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fw0IuGRwAJbm"
   },
   "source": [
    "### Different architecture\n",
    "Let's change a bit the architecture and see if we can improve scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X4DjuMehAJbn",
    "outputId": "584137dc-46a7-4bc1-d237-ff87e41fa1fe"
   },
   "outputs": [],
   "source": [
    "model = cnn_models.custom_cnn(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRqPhHRsAJbs",
    "outputId": "439effc6-cd35-40a0-ece9-7b5339bfb048"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0c85SLvAJbu",
    "outputId": "b1dfcfd5-ff0e-4b40-bb8e-260f0563788f"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model\n",
    "Based on the f1-score, the best model is the \"custom cnn\" one. Let's see its result on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = np.concatenate([X_train_speaker, X_val_speaker], axis=0)\n",
    "y_train = np.concatenate([y_train_speaker, y_val_speaker], axis=0)\n",
    "model = cnn_models.custom_cnn(8, input_shape=input_shape)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_nn = np.argmax(y_test_speaker, axis=1)\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(y_test_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P6hWHr2CAJbx"
   },
   "source": [
    "### Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ew0HbFTlAJby"
   },
   "outputs": [],
   "source": [
    "X_train_digit_nn = np.array(X_train_digit)\n",
    "X_val_digit_nn = np.array(X_val_digit)\n",
    "X_test_digit_nn = np.array(X_test_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gP6JS1xLAJb1"
   },
   "outputs": [],
   "source": [
    "X_train_digit_nn = X_train_digit_nn.reshape(X_train_digit_nn.shape[0], X_train_digit_nn.shape[1], X_train_digit_nn.shape[2], 1)\n",
    "X_val_digit_nn = X_val_digit_nn.reshape(X_val_digit_nn.shape[0], X_val_digit_nn.shape[1], X_val_digit_nn.shape[2], 1)\n",
    "X_test_digit_nn = X_test_digit_nn.reshape(X_test_digit_nn.shape[0], X_test_digit_nn.shape[1], X_test_digit_nn.shape[2], 1)\n",
    "y_train_digit_nn = tf.keras.utils.to_categorical(y_train_digit, 10)\n",
    "y_test_digit_nn = tf.keras.utils.to_categorical(y_test_digit, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V88VBbwqAJb3"
   },
   "outputs": [],
   "source": [
    "y_val_digit_nn = tf.keras.utils.to_categorical(y_val_digit, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBDON2ZdAJb5"
   },
   "outputs": [],
   "source": [
    "input_shape = (X_train_digit_nn.shape[1], X_train_digit_nn.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-NVkJ-QAJb7"
   },
   "source": [
    "#### Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XC3UZAcOAJb8",
    "outputId": "bc153d1f-f02e-430a-d369-6260bf7fe004"
   },
   "outputs": [],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPg3NJywAJb9",
    "outputId": "0f871699-0dad-45e3-c8f8-1af666ddf316"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit_nn, y_train_digit_nn,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digit_nn, y_val_digit_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8W5ebLFOAJb_",
    "outputId": "4cc55fb9-de41-4c1c-819a-bf0ddee91d73"
   },
   "outputs": [],
   "source": [
    "Y_val_nn = np.argmax(y_val_digit_nn, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val_digit_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iNe34g3rAJcB"
   },
   "source": [
    "#### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVvhmAq_AJcB",
    "outputId": "ce6e89d0-9672-4dd1-f7fe-0b579280555f"
   },
   "outputs": [],
   "source": [
    "model = cnn_models.custom_cnn(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejqqynFOAJcD",
    "outputId": "bcf3bdb5-8986-486f-a849-084d955340ca"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit_nn, y_train_digit_nn,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digit_nn, y_val_digit_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3px-T1QRAJcF",
    "outputId": "9b7ed3c6-e597-4a11-a9c3-ec4517e58ed5"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_val_digit_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model\n",
    "Based on F1-Score the best model is once again the custom paper architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = np.concatenate([X_train_digit_nn, X_val_digit_nn], axis=0)\n",
    "y_train = np.concatenate([y_train_digit_nn, y_val_digit_nn], axis=0)\n",
    "model = cnn_models.custom_cnn(10, input_shape=input_shape)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_nn = np.argmax(y_test_digit_nn, axis=1)\n",
    "y_pred = model.predict_classes(X_test_digit_nn)\n",
    "print(classification_report(y_test_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rTzZ1yR6AJcG"
   },
   "source": [
    "# Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WxSYVrOAJcH"
   },
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "from scipy.io import wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SyhhZ8dAJcL"
   },
   "outputs": [],
   "source": [
    "def pad_zeros_single_rec(rec, max_y):\n",
    "    rec = np.array(rec)\n",
    "    diff_in_y = max_y - rec.shape[0]\n",
    "    if diff_in_y > 0:\n",
    "        half_diff = int(diff_in_y/2)\n",
    "        remaining_diff = diff_in_y-half_diff\n",
    "        v = np.pad(rec, (half_diff, remaining_diff), 'constant', constant_values=0)\n",
    "        return v\n",
    "    else:\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUyrZr67AJcN"
   },
   "outputs": [],
   "source": [
    "def create_recording(duration, rec_rate, name = \"test.wav\", output_dir = \"test/\"):\n",
    "    print(\"Ready in 3...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"2...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"1...\")\n",
    "    time.sleep(1)\n",
    "    print(\"Go.\")\n",
    "    rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "    print(\"Playing the recording.\")\n",
    "    sd.play(rec, rec_rate)\n",
    "\n",
    "    # after hearing the recording, decide whether to record it again or continue to next number\n",
    "    # if you type anything, record again\n",
    "    # if you press enter, save current recording & go to next number\n",
    "    ok = input(\"OK?\")\n",
    "    if ok == \"\":\n",
    "        librosa.output.write_wav(output_dir+name, rec, rec_rate)\n",
    "        return rec\n",
    "    ipd.clear_output(wait=True)\n",
    "    create_recording(duration, rec_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QBcrjAzAJcO"
   },
   "outputs": [],
   "source": [
    "def trim_audio(file, input_dir=\"test/\", output_dir=\"test/\", db=-48):\n",
    "\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"There should be an input \\\"{input_dir}\\\" directory.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # create output directory if not there yet\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    temp1 = output_dir+\"temp1.wav\"\n",
    "    temp2 = output_dir+\"temp2.wav\"\n",
    "    temp3 = output_dir+\"temp3.wav\"\n",
    " \n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_dir+file, \"-af\", f\"silenceremove=1:0:{db}dB\", temp1])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp1, \"-af\", \"areverse\", temp2])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp2, \"-af\", f\"silenceremove=1:0.1:{db}dB\", temp3])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp3, \"-af\", \"areverse\", output_dir+file])\n",
    "    \n",
    "    os.remove(temp1)\n",
    "    os.remove(temp2)\n",
    "    os.remove(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bkZPGYwUAJcQ"
   },
   "outputs": [],
   "source": [
    "def test_NN(nn, max_y, target_names, answer = None, duration=2, rec_rate=8000, directory = \"test/\", filename = \"test.wav\"):\n",
    "    create_recording(duration, rec_rate, filename, directory)   \n",
    "    ipd.clear_output()\n",
    "    trim_audio(filename, directory, directory)\n",
    "    # _, rec = wav.read(directory + \"/\" + filename)\n",
    "    rec, _ = librosa.core.load(directory + \"/\" + filename, sr = rec_rate)\n",
    "    rec = pad_zeros_single_rec(rec, max_y)\n",
    "    # sd.play(rec, rec_rate)\n",
    "    rec = data_preparation.compute_spectrogram(rec, normalize=True)\n",
    "    rec = rec[np.newaxis,:,:,np.newaxis]\n",
    "    preds = nn.predict_classes(rec)\n",
    "    print(\"Model prediction: {}\".format(target_names[preds[0]]))\n",
    "    if answer is not None:\n",
    "        print(f\"Correct answer {answer}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VP6Hng1sAJcT"
   },
   "outputs": [],
   "source": [
    "max_y = len(data_augm_pad_recordings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-M4mw6KAJcW"
   },
   "outputs": [],
   "source": [
    "pred = test_NN(model, max_y, target_names, answer = \"gian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9GkS5ZFAJcY"
   },
   "source": [
    "# TO DO:\n",
    "- [x] Set random seed\n",
    "- [x] Use only original recordings in test set of augmented scenario\n",
    "- [x] Use proper validation set for picking best models and params\n",
    "- [x] Data augmentation also for digit recognition\n",
    "- [ ] Evaluate each best model on test set, after training it on x_train + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ubpdv577AJcY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classifiers-Spectrogram_based.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041ee309cd2a4523b8cbb817a7133aeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8db829965d284a9b848aa89f1d6e1a7e",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8f16c91328fb4555af28b4fa2522f1b6",
      "value": 2000
     }
    },
    "0471feee5a704241bc959bf9f25cf86b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f5badcb0b1e4938901d1ccebf26bc1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6532c85805db453f8a76edaf34996c0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74521556c16e4badb587537f36771810": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_041ee309cd2a4523b8cbb817a7133aeb",
       "IPY_MODEL_ab519d0c6d6241c5afbc76dbde2306fd"
      ],
      "layout": "IPY_MODEL_5f5badcb0b1e4938901d1ccebf26bc1f"
     }
    },
    "8db829965d284a9b848aa89f1d6e1a7e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f16c91328fb4555af28b4fa2522f1b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a9b4078544ee4fc4b203252a8539169c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ab519d0c6d6241c5afbc76dbde2306fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c29d5436c6514002b1380c6dfb229f76",
      "placeholder": "â",
      "style": "IPY_MODEL_eef3bdb92f1e43eb9241be66f3360fbc",
      "value": " 2000/2000 [57:14&lt;00:00,  1.72s/it]"
     }
    },
    "b20e330bbd0541b9ad6e8897ba359fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bce824cee09446879776ce8440927c32",
       "IPY_MODEL_d877478de1de4e2a9e67d33302b19075"
      ],
      "layout": "IPY_MODEL_6532c85805db453f8a76edaf34996c0c"
     }
    },
    "b365514386b341d6896420c06f2a9a86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bce824cee09446879776ce8440927c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b365514386b341d6896420c06f2a9a86",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a9b4078544ee4fc4b203252a8539169c",
      "value": 400
     }
    },
    "c29d5436c6514002b1380c6dfb229f76": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d877478de1de4e2a9e67d33302b19075": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f110b274d39141b892be18de60d7fd3b",
      "placeholder": "â",
      "style": "IPY_MODEL_0471feee5a704241bc959bf9f25cf86b",
      "value": " 400/400 [01:40&lt;00:00,  3.97it/s]"
     }
    },
    "eef3bdb92f1e43eb9241be66f3360fbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f110b274d39141b892be18de60d7fd3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
