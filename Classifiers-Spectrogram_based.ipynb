{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import wavfile as wav\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Strumenti di classificazione\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Feature audio avanzate\n",
    "import librosa\n",
    "import librosa.display as lid\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: fix seed\n",
    "# Load recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recordings(paths = [\"recordings\"]):\n",
    "    res = []\n",
    "    for path in paths:\n",
    "        print(f\"Loading from {path}\")    \n",
    "        for f in tqdm(sorted(os.listdir(path))):\n",
    "            if f.endswith('.wav'):\n",
    "                # Carica file ed estraine le features\n",
    "                audio, sample_rate = librosa.load(path + \"/\" + f)\n",
    "                res.append(audio)\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(paths = [\"recordings\"], label_type = \"number\"):\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for path in paths:\n",
    "        for f in sorted(os.listdir(path)):\n",
    "            if f.endswith('.wav'):\n",
    "                if label_type.startswith(\"n\"):\n",
    "                    label = f.split('_')[0]\n",
    "                else:\n",
    "                    label = f.split('_')[1]\n",
    "                labels.append(label)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectogram(audio, rate=8000, n_fft=1024, hop_length=160, n_mels=128, normalize=False):\n",
    "    spectogram = librosa.feature.melspectrogram(y=np.array(audio),\n",
    "                                                sr=rate,\n",
    "                                                n_fft=n_fft,\n",
    "                                                hop_length=hop_length,\n",
    "                                                n_mels=n_mels)\n",
    "    if normalize:\n",
    "        spectogram = np.log10(10000*spectogram+1)\n",
    "    return spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from recordings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c257eff1b8894a9e871c8b433814efc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from output\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2bb1c870d44f36ab66f2a47f0f5b4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = load_recordings(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2784 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! They vary a lot. For this reason we can add 0s at the beginning and at the end in order to uniform them\n",
    "\n",
    "**TO DO: Another strategy may be to vary spectrogram params so that spectograms will have the same length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_zeros(recordings):\n",
    "    min_y = min(map(np.shape, recordings))[0]\n",
    "    max_y = max(map(np.shape, recordings))[0]\n",
    "    res = []\n",
    "    for rec in recordings:\n",
    "        diff_in_y = max_y - rec.shape[0]\n",
    "        if diff_in_y > 0:\n",
    "            half_diff = int(diff_in_y/2)\n",
    "            remaining_diff = diff_in_y-half_diff\n",
    "            v = np.pad(rec,  ((half_diff,remaining_diff)), 'constant', constant_values=0)\n",
    "            res.append(v)\n",
    "        else:\n",
    "            res.append(rec)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_recordings = pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50335 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [compute_spectogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure worked as expected! we can now move on to the prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard recordings\n",
    "### Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = spects.shape\n",
    "spects_2d = spects.reshape((nsamples,nx*ny))\n",
    "X_train, X_test, y_train, y_test = train_test_split(spects_2d, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 47s, sys: 1.7 s, total: 3min 49s\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.20      0.32        44\n",
      "           1       0.18      0.78      0.29        45\n",
      "           2       0.87      0.26      0.40        50\n",
      "           3       0.39      0.58      0.47        45\n",
      "           4       0.33      0.53      0.40        55\n",
      "           5       0.77      0.40      0.52        43\n",
      "           6       0.47      0.14      0.21        51\n",
      "           7       0.83      0.32      0.46        47\n",
      "           8       0.88      0.17      0.28        42\n",
      "           9       0.79      0.39      0.53        38\n",
      "\n",
      "    accuracy                           0.38       460\n",
      "   macro avg       0.63      0.38      0.39       460\n",
      "weighted avg       0.62      0.38      0.39       460\n",
      "\n",
      "CPU times: user 36.1 s, sys: 262 ms, total: 36.4 s\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [compute_spectogram(x, normalize=True) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = spects.shape\n",
    "spects_2d = spects.reshape((nsamples,nx*ny))\n",
    "X_train, X_test, y_train, y_test = train_test_split(spects_2d, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 18s, sys: 1.57 s, total: 2min 20s\n",
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        44\n",
      "           1       0.98      0.91      0.94        45\n",
      "           2       0.81      0.96      0.88        50\n",
      "           3       0.82      0.82      0.82        45\n",
      "           4       1.00      1.00      1.00        55\n",
      "           5       0.93      0.98      0.95        43\n",
      "           6       0.83      0.84      0.83        51\n",
      "           7       0.96      0.94      0.95        47\n",
      "           8       0.94      0.76      0.84        42\n",
      "           9       0.89      0.89      0.89        38\n",
      "\n",
      "    accuracy                           0.91       460\n",
      "   macro avg       0.91      0.91      0.91       460\n",
      "weighted avg       0.91      0.91      0.91       460\n",
      "\n",
      "CPU times: user 42.9 s, sys: 755 ms, total: 43.6 s\n",
      "Wall time: 59.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects, labels, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_architecture(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(4, 4), strides=(2,2), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=(4, 4), strides=(2,2), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10*num_classes, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5*num_classes, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = paper_architecture(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 21s 11ms/step - loss: 2.3020 - accuracy: 0.1082 - val_loss: 2.2883 - val_accuracy: 0.1413\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 24s 13ms/step - loss: 2.2733 - accuracy: 0.1337 - val_loss: 2.2659 - val_accuracy: 0.2043\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 20s 11ms/step - loss: 2.2502 - accuracy: 0.1560 - val_loss: 2.2418 - val_accuracy: 0.1935\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 22s 12ms/step - loss: 2.2226 - accuracy: 0.1973 - val_loss: 2.2123 - val_accuracy: 0.1957\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 2.1929 - accuracy: 0.2207 - val_loss: 2.1551 - val_accuracy: 0.2761\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 2.1502 - accuracy: 0.2168 - val_loss: 2.1140 - val_accuracy: 0.2587\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 2.0796 - accuracy: 0.2723 - val_loss: 1.9900 - val_accuracy: 0.3978\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 19s 10ms/step - loss: 2.0021 - accuracy: 0.3038 - val_loss: 1.9125 - val_accuracy: 0.4391\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 20s 11ms/step - loss: 1.9265 - accuracy: 0.3424 - val_loss: 1.7500 - val_accuracy: 0.4783\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 21s 11ms/step - loss: 1.8692 - accuracy: 0.3745 - val_loss: 1.6849 - val_accuracy: 0.5152\n",
      "CPU times: user 8min 32s, sys: 1min 19s, total: 9min 52s\n",
      "Wall time: 3min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3fb32450>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.30      0.43        44\n",
      "           1       0.45      0.49      0.47        45\n",
      "           2       0.66      0.76      0.70        50\n",
      "           3       0.36      0.33      0.34        45\n",
      "           4       0.95      0.65      0.77        55\n",
      "           5       0.27      0.16      0.20        43\n",
      "           6       0.74      0.63      0.68        51\n",
      "           7       0.67      0.34      0.45        47\n",
      "           8       0.71      0.52      0.60        42\n",
      "           9       0.27      0.95      0.42        38\n",
      "\n",
      "    accuracy                           0.52       460\n",
      "   macro avg       0.58      0.51      0.51       460\n",
      "weighted avg       0.60      0.52      0.52       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [compute_spectogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects, labels, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = paper_architecture(10)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels(paths=['recordings', 'output'], label_type=\"speakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "Y = enc.fit_transform(np.array(labels).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects, Y, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = paper_architecture(7)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train1,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association between numbers and speakers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['alinda']], dtype='<U8')"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,0,0,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['gian']], dtype='<U8')"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,1,0,0,0,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['jackson']], dtype='<U8')"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,1,0,0,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['khaled']], dtype='<U8')"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,1,0,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['nicolas']], dtype='<U8')"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,0,1,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['theo']], dtype='<U8')"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,0,0,1,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['yweweler']], dtype='<U8')"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,0,0,0,1]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
