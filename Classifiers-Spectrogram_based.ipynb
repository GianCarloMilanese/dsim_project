{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import data_augmentation\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "tf.random.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load recordings\n",
    "## STANDARD RECORDINGS - No spectrogram normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from recordings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a303f495c9a4e848c58645967d79f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from output\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fad07c531c4d8e88455cce745e1666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2784 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! They vary a lot. For this reason we can add 0s at the beginning and at the end in order to uniform them\n",
    "\n",
    "**TO DO: Another strategy may be to vary spectrogram params so that spectograms will have the same length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_zeros >>>\n",
      "pad_zeros <<<\n"
     ]
    }
   ],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50335 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [data_preparation.compute_spectrogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure worked as expected! we can now move on to the prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=['recordings', 'output'], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_spects = [data_preparation.compute_spectrogram(x, normalize=True) for x in pad_recordings]\n",
    "norm_spects = np.array(norm_spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE!\n",
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 5min 23s, sys: 19.6 s, total: 5min 42s\n",
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digit, y_train_digit, X_test_digit, y_test_digit = data_preparation.prepare_augmented_recordings(audio_dirs= ['output', 'recordings'],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 22000, 22000, 300, 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}\".format(len(X_train_digit),\n",
    "                                                 len(y_train_digit),\n",
    "                                                 len(X_test_digit),\n",
    "                                                 len(y_test_digit),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE!\n",
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 5min 45s, sys: 22.4 s, total: 6min 7s\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(audio_dirs= ['output', 'recordings'],\n",
    "                             y_type= ['speakers_us', 'speakers_default'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 22000, 22000, 300, 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}\".format(len(X_train_speaker),\n",
    "                                                 len(y_train_speaker),\n",
    "                                                 len(X_test_speaker),\n",
    "                                                 len(y_test_speaker)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard recordings\n",
    "## Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_preparation.split_train_test_baseline_spectrograms(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 2s, sys: 4.49 s, total: 4min 6s\n",
      "Wall time: 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.20      0.32        44\n",
      "           1       0.18      0.78      0.29        45\n",
      "           2       0.87      0.26      0.40        50\n",
      "           3       0.39      0.58      0.47        45\n",
      "           4       0.33      0.53      0.40        55\n",
      "           5       0.77      0.40      0.52        43\n",
      "           6       0.47      0.14      0.21        51\n",
      "           7       0.83      0.32      0.46        47\n",
      "           8       0.88      0.17      0.28        42\n",
      "           9       0.79      0.39      0.53        38\n",
      "\n",
      "    accuracy                           0.38       460\n",
      "   macro avg       0.63      0.38      0.39       460\n",
      "weighted avg       0.62      0.38      0.39       460\n",
      "\n",
      "CPU times: user 38.8 s, sys: 767 ms, total: 39.5 s\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 49s, sys: 3.02 s, total: 2min 52s\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88        44\n",
      "           1       0.93      0.87      0.90        45\n",
      "           2       0.57      0.94      0.71        50\n",
      "           3       0.87      0.44      0.59        45\n",
      "           4       1.00      0.89      0.94        55\n",
      "           5       0.85      0.95      0.90        43\n",
      "           6       0.56      0.69      0.62        51\n",
      "           7       0.80      0.85      0.82        47\n",
      "           8       0.76      0.60      0.67        42\n",
      "           9       0.96      0.63      0.76        38\n",
      "\n",
      "    accuracy                           0.78       460\n",
      "   macro avg       0.82      0.77      0.78       460\n",
      "weighted avg       0.81      0.78      0.78       460\n",
      "\n",
      "CPU times: user 35.4 s, sys: 579 ms, total: 36 s\n",
      "Wall time: 39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 23s 12ms/sample - loss: 2.2652 - acc: 0.1663 - val_loss: 2.1910 - val_acc: 0.4239\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 2.0984 - acc: 0.2636 - val_loss: 1.8936 - val_acc: 0.4000\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 22s 12ms/sample - loss: 1.8501 - acc: 0.3451 - val_loss: 1.6263 - val_acc: 0.4652\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 22s 12ms/sample - loss: 1.6482 - acc: 0.4212 - val_loss: 1.3823 - val_acc: 0.5413\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 1.4481 - acc: 0.4859 - val_loss: 1.1894 - val_acc: 0.6239\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 1.3256 - acc: 0.5332 - val_loss: 1.0873 - val_acc: 0.6348\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 1.2025 - acc: 0.5750 - val_loss: 1.4076 - val_acc: 0.5087\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 1.1118 - acc: 0.6087 - val_loss: 0.9806 - val_acc: 0.6717\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 0.9764 - acc: 0.6522 - val_loss: 0.7932 - val_acc: 0.7109\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 22s 12ms/sample - loss: 0.9399 - acc: 0.6636 - val_loss: 0.6831 - val_acc: 0.7804\n",
      "CPU times: user 8min 11s, sys: 51.3 s, total: 9min 2s\n",
      "Wall time: 3min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a385acc90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        44\n",
      "           1       0.75      0.89      0.82        45\n",
      "           2       0.88      0.72      0.79        50\n",
      "           3       0.74      0.62      0.67        45\n",
      "           4       0.98      0.73      0.83        55\n",
      "           5       0.72      0.95      0.82        43\n",
      "           6       0.67      0.69      0.68        51\n",
      "           7       0.77      0.85      0.81        47\n",
      "           8       0.61      0.79      0.69        42\n",
      "           9       0.90      0.68      0.78        38\n",
      "\n",
      "    accuracy                           0.78       460\n",
      "   macro avg       0.79      0.78      0.78       460\n",
      "weighted avg       0.80      0.78      0.78       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 2.3005 - acc: 0.1560 - val_loss: 2.1092 - val_acc: 0.2870\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 2.1971 - acc: 0.2245 - val_loss: 2.0836 - val_acc: 0.3109\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 2.1195 - acc: 0.2750 - val_loss: 2.0177 - val_acc: 0.3261\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 2.0684 - acc: 0.2995 - val_loss: 1.9839 - val_acc: 0.2978\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 2.0373 - acc: 0.3038 - val_loss: 1.8618 - val_acc: 0.3587\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 24s 13ms/sample - loss: 1.9330 - acc: 0.3451 - val_loss: 1.7749 - val_acc: 0.4109\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 24s 13ms/sample - loss: 1.8738 - acc: 0.3652 - val_loss: 1.7688 - val_acc: 0.4043\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 1.8546 - acc: 0.3712 - val_loss: 1.7073 - val_acc: 0.4478\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 1.8201 - acc: 0.3897 - val_loss: 1.6713 - val_acc: 0.4804\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 23s 13ms/sample - loss: 1.7789 - acc: 0.3951 - val_loss: 1.7882 - val_acc: 0.4022\n",
      "CPU times: user 8min 2s, sys: 51.9 s, total: 8min 54s\n",
      "Wall time: 3min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3fac0b10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.30      0.42        44\n",
      "           1       0.45      0.31      0.37        45\n",
      "           2       1.00      0.02      0.04        50\n",
      "           3       0.22      0.93      0.35        45\n",
      "           4       0.83      0.35      0.49        55\n",
      "           5       0.63      0.60      0.62        43\n",
      "           6       0.94      0.29      0.45        51\n",
      "           7       0.62      0.32      0.42        47\n",
      "           8       0.47      0.21      0.30        42\n",
      "           9       0.33      0.82      0.47        38\n",
      "\n",
      "    accuracy                           0.40       460\n",
      "   macro avg       0.62      0.42      0.39       460\n",
      "weighted avg       0.64      0.40      0.39       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we can see normalising spectrograms is the way to go. Let's use it by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speakers\n",
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 1.7 s, total: 1min 47s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       0.86      1.00      0.93        19\n",
      "        gian       0.92      1.00      0.96        23\n",
      "     jackson       0.98      0.98      0.98        98\n",
      "      khaled       0.91      0.97      0.94        30\n",
      "     nicolas       1.00      0.96      0.98        94\n",
      "        theo       0.80      0.84      0.82        98\n",
      "    yweweler       0.84      0.78      0.81        98\n",
      "\n",
      "    accuracy                           0.90       460\n",
      "   macro avg       0.90      0.93      0.91       460\n",
      "weighted avg       0.90      0.90      0.90       460\n",
      "\n",
      "CPU times: user 31.4 s, sys: 495 ms, total: 31.9 s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neural networks it is not possible to pass the labels as-is: we need to transform them in numbers. The safest way is through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, target_names = data_preparation.transform_categorical_y(labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, y, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,143\n",
      "Trainable params: 493,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(7, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 1.8496 - acc: 0.2299 - val_loss: 1.7506 - val_acc: 0.2630\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 1.6731 - acc: 0.3723 - val_loss: 1.5252 - val_acc: 0.5652\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 1.4443 - acc: 0.4973 - val_loss: 1.3066 - val_acc: 0.6239\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 1.2248 - acc: 0.5788 - val_loss: 1.2711 - val_acc: 0.5609\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 1.0909 - acc: 0.6228 - val_loss: 1.0178 - val_acc: 0.6761\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 0.9615 - acc: 0.6685 - val_loss: 0.8704 - val_acc: 0.7065\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 0.8555 - acc: 0.6967 - val_loss: 0.7604 - val_acc: 0.7587\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 0.8169 - acc: 0.7190 - val_loss: 0.8352 - val_acc: 0.6804\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 24s 13ms/sample - loss: 0.7072 - acc: 0.7473 - val_loss: 0.6446 - val_acc: 0.7848\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 0.6590 - acc: 0.7880 - val_loss: 0.4829 - val_acc: 0.8435\n",
      "CPU times: user 8min 1s, sys: 47 s, total: 8min 48s\n",
      "Wall time: 3min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3ff5e190>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59        19\n",
      "           1       0.67      0.52      0.59        23\n",
      "           2       0.77      0.94      0.84        98\n",
      "           3       0.92      0.37      0.52        30\n",
      "           4       0.94      0.96      0.95        94\n",
      "           5       0.80      0.94      0.86        98\n",
      "           6       0.91      0.85      0.88        98\n",
      "\n",
      "    accuracy                           0.84       460\n",
      "   macro avg       0.86      0.71      0.75       460\n",
      "weighted avg       0.85      0.84      0.83       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper - batch_normalisation=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 63, 156, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 14, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 35)                140       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,947\n",
      "Trainable params: 493,545\n",
      "Non-trainable params: 402\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(7, input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 52s 29ms/sample - loss: 1.1255 - acc: 0.6353 - val_loss: 1.9349 - val_acc: 0.2130\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 50s 27ms/sample - loss: 0.5760 - acc: 0.8342 - val_loss: 2.0859 - val_acc: 0.2130\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 47s 26ms/sample - loss: 0.3942 - acc: 0.9038 - val_loss: 2.1561 - val_acc: 0.2478\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 50s 27ms/sample - loss: 0.3590 - acc: 0.9114 - val_loss: 1.9939 - val_acc: 0.2196\n",
      "CPU times: user 7min 6s, sys: 1min 19s, total: 8min 26s\n",
      "Wall time: 3min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a419088d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       0.00      0.00      0.00        19\n",
      "        gian       0.00      0.00      0.00        23\n",
      "     jackson       0.00      0.00      0.00        98\n",
      "      khaled       0.00      0.00      0.00        30\n",
      "     nicolas       0.00      0.00      0.00        94\n",
      "        theo       0.00      0.00      0.00        98\n",
      "    yweweler       0.21      1.00      0.35        98\n",
      "\n",
      "    accuracy                           0.21       460\n",
      "   macro avg       0.03      0.14      0.05       460\n",
      "weighted avg       0.05      0.21      0.07       460\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "## Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y_train_speaker = enc.fit_transform(np.array(y_train_speaker).reshape(-1, 1)).toarray()\n",
    "y_test_speaker = enc.transform(np.array(y_test_speaker).reshape(-1, 1)).toarray()\n",
    "label_0 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_1 = enc.inverse_transform(np.array([0, 1, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_2 = enc.inverse_transform(np.array([0, 0, 1, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_3 = enc.inverse_transform(np.array([0, 0, 0, 1, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_4 = enc.inverse_transform(np.array([0, 0, 0, 0, 1, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_5 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 1, 0]).reshape(1, -1))[0][0]\n",
    "label_6 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 1]).reshape(1, -1))[0][0]\n",
    "target_names = [label_0, label_1, label_2, label_3, label_4, label_5, label_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker = np.array(X_train_speaker)\n",
    "X_test_speaker = np.array(X_test_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker = X_train_speaker.reshape(X_train_speaker.shape[0],\n",
    "                                          X_train_speaker.shape[1],\n",
    "                                          X_train_speaker.shape[2],\n",
    "                                          1)\n",
    "X_test_speaker = X_test_speaker.reshape(X_test_speaker.shape[0], X_test_speaker.shape[1], X_test_speaker.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 70)                134470    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 170,583\n",
      "Trainable params: 170,583\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(7, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24145 samples, validate on 105 samples\n",
      "Epoch 1/10\n",
      "24145/24145 [==============================] - 99s 4ms/sample - loss: 1.3695 - acc: 0.4873 - val_loss: 1.2513 - val_acc: 0.5143\n",
      "Epoch 2/10\n",
      "24145/24145 [==============================] - 94s 4ms/sample - loss: 0.8986 - acc: 0.6644 - val_loss: 0.9401 - val_acc: 0.6190\n",
      "Epoch 3/10\n",
      "24145/24145 [==============================] - 96s 4ms/sample - loss: 0.6972 - acc: 0.7282 - val_loss: 0.6563 - val_acc: 0.6952\n",
      "Epoch 4/10\n",
      "24145/24145 [==============================] - 96s 4ms/sample - loss: 0.5868 - acc: 0.7718 - val_loss: 0.5878 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "24145/24145 [==============================] - 97s 4ms/sample - loss: 0.5021 - acc: 0.7998 - val_loss: 0.7646 - val_acc: 0.7238\n",
      "Epoch 6/10\n",
      "24145/24145 [==============================] - 98s 4ms/sample - loss: 0.4313 - acc: 0.8291 - val_loss: 0.3210 - val_acc: 0.9238\n",
      "Epoch 7/10\n",
      "24145/24145 [==============================] - 99s 4ms/sample - loss: 0.3968 - acc: 0.8457 - val_loss: 0.3478 - val_acc: 0.8952\n",
      "Epoch 8/10\n",
      "24145/24145 [==============================] - 97s 4ms/sample - loss: 0.3681 - acc: 0.8582 - val_loss: 0.2824 - val_acc: 0.9238\n",
      "Epoch 9/10\n",
      "24145/24145 [==============================] - 95s 4ms/sample - loss: 0.3260 - acc: 0.8710 - val_loss: 0.2393 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "24145/24145 [==============================] - 98s 4ms/sample - loss: 0.3066 - acc: 0.8804 - val_loss: 0.1802 - val_acc: 0.9429\n",
      "CPU times: user 32min 58s, sys: 3min 13s, total: 36min 12s\n",
      "Wall time: 16min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4415d910>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test_speaker, y_test_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       0.93      0.93      0.93        15\n",
      "        gian       1.00      0.93      0.97        15\n",
      "     jackson       0.88      1.00      0.94        15\n",
      "      khaled       1.00      0.80      0.89        15\n",
      "     nicolas       1.00      1.00      1.00        15\n",
      "        theo       0.93      0.93      0.93        15\n",
      "    yweweler       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.94       105\n",
      "   macro avg       0.95      0.94      0.94       105\n",
      "weighted avg       0.95      0.94      0.94       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch_normalization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 63, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 30, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 14, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 6, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 70)                134470    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 35)                140       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 171,387\n",
      "Trainable params: 170,985\n",
      "Non-trainable params: 402\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(7, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24145 samples, validate on 105 samples\n",
      "Epoch 1/10\n",
      "24145/24145 [==============================] - 234s 10ms/sample - loss: 0.8579 - acc: 0.6865 - val_loss: 0.4487 - val_acc: 0.8857\n",
      "Epoch 2/10\n",
      "24145/24145 [==============================] - 215s 9ms/sample - loss: 0.4962 - acc: 0.8055 - val_loss: 0.1943 - val_acc: 0.9619\n",
      "Epoch 3/10\n",
      "24145/24145 [==============================] - 239s 10ms/sample - loss: 0.4143 - acc: 0.8406 - val_loss: 0.2986 - val_acc: 0.9143\n",
      "Epoch 4/10\n",
      "24145/24145 [==============================] - 271s 11ms/sample - loss: 0.3509 - acc: 0.8651 - val_loss: 0.1840 - val_acc: 0.9619\n",
      "Epoch 5/10\n",
      "24145/24145 [==============================] - 224s 9ms/sample - loss: 0.3128 - acc: 0.8809 - val_loss: 0.1060 - val_acc: 0.9619\n",
      "Epoch 6/10\n",
      "24145/24145 [==============================] - 212s 9ms/sample - loss: 0.2916 - acc: 0.8884 - val_loss: 0.0940 - val_acc: 0.9714\n",
      "Epoch 7/10\n",
      "24145/24145 [==============================] - 208s 9ms/sample - loss: 0.2587 - acc: 0.9025 - val_loss: 0.0998 - val_acc: 0.9619\n",
      "Epoch 8/10\n",
      "24145/24145 [==============================] - 207s 9ms/sample - loss: 0.2477 - acc: 0.9045 - val_loss: 0.0724 - val_acc: 0.9810\n",
      "Epoch 9/10\n",
      "24145/24145 [==============================] - 208s 9ms/sample - loss: 0.2411 - acc: 0.9071 - val_loss: 0.0509 - val_acc: 0.9810\n",
      "Epoch 10/10\n",
      "24145/24145 [==============================] - 206s 9ms/sample - loss: 0.2226 - acc: 0.9143 - val_loss: 0.2092 - val_acc: 0.9143\n",
      "CPU times: user 1h 17min 14s, sys: 13min 45s, total: 1h 31min\n",
      "Wall time: 37min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a45c253d0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test_speaker, y_test_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       0.75      1.00      0.86        15\n",
      "        gian       1.00      0.60      0.75        15\n",
      "     jackson       1.00      0.80      0.89        15\n",
      "      khaled       0.94      1.00      0.97        15\n",
      "     nicolas       0.88      1.00      0.94        15\n",
      "        theo       1.00      1.00      1.00        15\n",
      "    yweweler       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.91       105\n",
      "   macro avg       0.93      0.91      0.91       105\n",
      "weighted avg       0.93      0.91      0.91       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different architecture\n",
    "Let's change a bit the architecture and see if we can improve scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 27, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 14, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 10752)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               1376384   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 1,410,663\n",
      "Trainable params: 1,410,663\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(7, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24145 samples, validate on 105 samples\n",
      "Epoch 1/10\n",
      "24145/24145 [==============================] - 175s 7ms/sample - loss: 0.9655 - acc: 0.6378 - val_loss: 0.6175 - val_acc: 0.8095\n",
      "Epoch 2/10\n",
      "24145/24145 [==============================] - 176s 7ms/sample - loss: 0.5075 - acc: 0.8052 - val_loss: 0.3901 - val_acc: 0.9048\n",
      "Epoch 3/10\n",
      "24145/24145 [==============================] - 175s 7ms/sample - loss: 0.3322 - acc: 0.8709 - val_loss: 0.4505 - val_acc: 0.8571\n",
      "Epoch 4/10\n",
      "24145/24145 [==============================] - 176s 7ms/sample - loss: 0.2645 - acc: 0.8980 - val_loss: 0.7727 - val_acc: 0.7810\n",
      "Epoch 5/10\n",
      "24145/24145 [==============================] - 180s 7ms/sample - loss: 0.2222 - acc: 0.9129 - val_loss: 0.1569 - val_acc: 0.9619\n",
      "Epoch 6/10\n",
      "24145/24145 [==============================] - 179s 7ms/sample - loss: 0.1794 - acc: 0.9304 - val_loss: 0.0522 - val_acc: 0.9810\n",
      "Epoch 7/10\n",
      "24145/24145 [==============================] - 177s 7ms/sample - loss: 0.1607 - acc: 0.9371 - val_loss: 0.0685 - val_acc: 0.9714\n",
      "Epoch 8/10\n",
      "24145/24145 [==============================] - 175s 7ms/sample - loss: 0.1442 - acc: 0.9432 - val_loss: 0.0544 - val_acc: 0.9714\n",
      "Epoch 9/10\n",
      "24145/24145 [==============================] - 200s 8ms/sample - loss: 0.1347 - acc: 0.9472 - val_loss: 0.1515 - val_acc: 0.9619\n",
      "CPU times: user 1h 2min 58s, sys: 11min 42s, total: 1h 14min 41s\n",
      "Wall time: 26min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a43bb4cd0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test_speaker, y_test_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       1.00      1.00      1.00        15\n",
      "        gian       1.00      1.00      1.00        15\n",
      "     jackson       0.93      0.93      0.93        15\n",
      "      khaled       0.93      0.93      0.93        15\n",
      "     nicolas       1.00      1.00      1.00        15\n",
      "        theo       1.00      1.00      1.00        15\n",
      "    yweweler       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "from scipy.io import wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_zeros_single_rec(rec, max_y):\n",
    "    rec = np.array(rec)\n",
    "    diff_in_y = max_y - rec.shape[0]\n",
    "    if diff_in_y > 0:\n",
    "        half_diff = int(diff_in_y/2)\n",
    "        remaining_diff = diff_in_y-half_diff\n",
    "        v = np.pad(rec, (half_diff, remaining_diff), 'constant', constant_values=0)\n",
    "        return v\n",
    "    else:\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recording(duration, rec_rate, name = \"test.wav\", output_dir = \"test/\"):\n",
    "    print(\"Ready in 3...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"2...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"1...\")\n",
    "    time.sleep(1)\n",
    "    print(\"Go.\")\n",
    "    rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "    print(\"Playing the recording.\")\n",
    "    sd.play(rec, rec_rate)\n",
    "\n",
    "    # after hearing the recording, decide whether to record it again or continue to next number\n",
    "    # if you type anything, record again\n",
    "    # if you press enter, save current recording & go to next number\n",
    "    ok = input(\"OK?\")\n",
    "    if ok == \"\":\n",
    "        librosa.output.write_wav(output_dir+name, rec, rec_rate)\n",
    "        return rec\n",
    "    ipd.clear_output(wait=True)\n",
    "    create_recording(duration, rec_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio(file, input_dir=\"test/\", output_dir=\"test/\", db=-48):\n",
    "\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"There should be an input \\\"{input_dir}\\\" directory.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # create output directory if not there yet\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    temp1 = output_dir+\"temp1.wav\"\n",
    "    temp2 = output_dir+\"temp2.wav\"\n",
    "    temp3 = output_dir+\"temp3.wav\"\n",
    " \n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_dir+file, \"-af\", f\"silenceremove=1:0:{db}dB\", temp1])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp1, \"-af\", \"areverse\", temp2])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp2, \"-af\", f\"silenceremove=1:0.1:{db}dB\", temp3])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp3, \"-af\", \"areverse\", output_dir+file])\n",
    "    \n",
    "    os.remove(temp1)\n",
    "    os.remove(temp2)\n",
    "    os.remove(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NN(nn, max_y, target_names, answer = None, duration=2, rec_rate=8000, directory = \"test/\", filename = \"test.wav\"):\n",
    "    create_recording(duration, rec_rate, filename, directory)   \n",
    "    ipd.clear_output()\n",
    "    trim_audio(filename, directory, directory)\n",
    "    # _, rec = wav.read(directory + \"/\" + filename)\n",
    "    rec, _ = librosa.core.load(directory + \"/\" + filename, sr = rec_rate)\n",
    "    rec = pad_zeros_single_rec(rec, max_y)\n",
    "    # sd.play(rec, rec_rate)\n",
    "    rec = data_preparation.compute_spectrogram(rec, normalize=True)\n",
    "    rec = rec[np.newaxis,:,:,np.newaxis]\n",
    "    preds = nn.predict_classes(rec)\n",
    "    print(\"Model prediction: {}\".format(target_names[preds[0]]))\n",
    "    if answer is not None:\n",
    "        print(f\"Correct answer {answer}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y = len(data_augm_pad_recordings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test_NN(model, max_y, target_names, answer = \"gian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- [x] Set random seed\n",
    "- [x] Use only original recordings in test set of augmented scenario\n",
    "- Use proper validation set (optional: also crossvalidation) for picking best models and params\n",
    "- Data augmentation also for digit recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
