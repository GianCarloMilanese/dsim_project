{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import wavfile as wav\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Strumenti di classificazione\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Feature audio avanzate\n",
    "import librosa\n",
    "import librosa.display as lid\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: fix seed\n",
    "# Load recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recordings(paths = [\"recordings\"]):\n",
    "    res = []\n",
    "    for path in paths:\n",
    "        print(f\"Loading from {path}\")    \n",
    "        for f in tqdm(sorted(os.listdir(path))):\n",
    "            if f.endswith('.wav'):\n",
    "                # Carica file ed estraine le features\n",
    "                audio, sample_rate = librosa.load(path + \"/\" + f)\n",
    "                res.append(audio)\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(paths = [\"recordings\"], label_type = \"number\"):\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for path in paths:\n",
    "        for f in sorted(os.listdir(path)):\n",
    "            if f.endswith('.wav'):\n",
    "                if label_type.startswith(\"n\"):\n",
    "                    label = f.split('_')[0]\n",
    "                else:\n",
    "                    label = f.split('_')[1]\n",
    "                labels.append(label)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectogram(audio, rate=8000, n_fft=1024, hop_length=160, n_mels=128, normalize=False):\n",
    "    spectogram = librosa.feature.melspectrogram(y=np.array(audio),\n",
    "                                                sr=rate,\n",
    "                                                n_fft=n_fft,\n",
    "                                                hop_length=hop_length,\n",
    "                                                n_mels=n_mels)\n",
    "    if normalize:\n",
    "        spectogram = np.log10(10000*spectogram+1)\n",
    "    return spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from recordings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e07eb65b76484da1cb574093f1fc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from output\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae50217fd994e23b6db159b7330d79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = load_recordings(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2784 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! They vary a lot. For this reason we can add 0s at the beginning and at the end in order to uniform them\n",
    "\n",
    "**TO DO: Another strategy may be to vary spectrogram params so that spectograms will have the same length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_zeros(recordings):\n",
    "    min_y = min(map(np.shape, recordings))[0]\n",
    "    max_y = max(map(np.shape, recordings))[0]\n",
    "    res = []\n",
    "    for rec in recordings:\n",
    "        diff_in_y = max_y - rec.shape[0]\n",
    "        if diff_in_y > 0:\n",
    "            half_diff = int(diff_in_y/2)\n",
    "            remaining_diff = diff_in_y-half_diff\n",
    "            v = np.pad(rec,  ((half_diff,remaining_diff)), 'constant', constant_values=0)\n",
    "            res.append(v)\n",
    "        else:\n",
    "            res.append(rec)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_recordings = pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50335 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [compute_spectogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure worked as expected! we can now move on to the prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard recordings\n",
    "### Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = spects.shape\n",
    "spects_2d = spects.reshape((nsamples,nx*ny))\n",
    "X_train, X_test, y_train, y_test = train_test_split(spects_2d, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 29s, sys: 498 ms, total: 3min 29s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.20      0.32        44\n",
      "           1       0.18      0.78      0.29        45\n",
      "           2       0.87      0.26      0.40        50\n",
      "           3       0.39      0.58      0.47        45\n",
      "           4       0.33      0.53      0.40        55\n",
      "           5       0.77      0.40      0.52        43\n",
      "           6       0.47      0.14      0.21        51\n",
      "           7       0.83      0.32      0.46        47\n",
      "           8       0.88      0.17      0.28        42\n",
      "           9       0.79      0.39      0.53        38\n",
      "\n",
      "    accuracy                           0.38       460\n",
      "   macro avg       0.63      0.38      0.39       460\n",
      "weighted avg       0.62      0.38      0.39       460\n",
      "\n",
      "CPU times: user 34.1 s, sys: 116 ms, total: 34.2 s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [compute_spectogram(x, normalize=True) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = spects.shape\n",
    "spects_2d = spects.reshape((nsamples,nx*ny))\n",
    "X_train, X_test, y_train, y_test = train_test_split(spects_2d, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 458 ms, total: 1min 59s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        44\n",
      "           1       0.98      0.91      0.94        45\n",
      "           2       0.81      0.96      0.88        50\n",
      "           3       0.82      0.82      0.82        45\n",
      "           4       1.00      1.00      1.00        55\n",
      "           5       0.93      0.98      0.95        43\n",
      "           6       0.83      0.84      0.83        51\n",
      "           7       0.96      0.94      0.95        47\n",
      "           8       0.94      0.76      0.84        42\n",
      "           9       0.89      0.89      0.89        38\n",
      "\n",
      "    accuracy                           0.91       460\n",
      "   macro avg       0.91      0.91      0.91       460\n",
      "weighted avg       0.91      0.91      0.91       460\n",
      "\n",
      "CPU times: user 30.4 s, sys: 88.9 ms, total: 30.5 s\n",
      "Wall time: 30.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects, labels, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_architecture(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(4, 4), strides=(2,2), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=(4, 4), strides=(2,2), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10*num_classes, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5*num_classes, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = paper_architecture(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 2.2971 - accuracy: 0.1125 - val_loss: 2.2870 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 2.2817 - accuracy: 0.1201 - val_loss: 2.2734 - val_accuracy: 0.1478\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.2638 - accuracy: 0.1446 - val_loss: 2.2553 - val_accuracy: 0.1609\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.2475 - accuracy: 0.1755 - val_loss: 2.2345 - val_accuracy: 0.1761\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.2146 - accuracy: 0.1886 - val_loss: 2.1896 - val_accuracy: 0.2978\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.1784 - accuracy: 0.2266 - val_loss: 2.1374 - val_accuracy: 0.2891\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 19s 10ms/step - loss: 2.1221 - accuracy: 0.2500 - val_loss: 2.0490 - val_accuracy: 0.4152\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 2.0437 - accuracy: 0.2973 - val_loss: 1.9274 - val_accuracy: 0.4500\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 19s 10ms/step - loss: 1.9649 - accuracy: 0.3277 - val_loss: 1.8414 - val_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 1.8812 - accuracy: 0.3440 - val_loss: 1.7094 - val_accuracy: 0.4826\n",
      "CPU times: user 8min 41s, sys: 1min 21s, total: 10min 2s\n",
      "Wall time: 2min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4b6bf3d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.68      0.35        44\n",
      "           1       0.42      0.67      0.52        45\n",
      "           2       0.58      0.62      0.60        50\n",
      "           3       0.52      0.29      0.37        45\n",
      "           4       0.85      0.75      0.80        55\n",
      "           5       0.82      0.33      0.47        43\n",
      "           6       0.64      0.67      0.65        51\n",
      "           7       0.50      0.02      0.04        47\n",
      "           8       0.45      0.67      0.54        42\n",
      "           9       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.48       460\n",
      "   macro avg       0.50      0.47      0.43       460\n",
      "weighted avg       0.52      0.48      0.45       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [compute_spectogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects, labels, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = paper_architecture(10)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 2.4383 - accuracy: 0.1326 - val_loss: 2.1915 - val_accuracy: 0.2326\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 21s 12ms/step - loss: 2.2358 - accuracy: 0.1978 - val_loss: 2.1716 - val_accuracy: 0.3283\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.1592 - accuracy: 0.2739 - val_loss: 2.0852 - val_accuracy: 0.3239\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.1366 - accuracy: 0.2571 - val_loss: 2.0381 - val_accuracy: 0.3870\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.1161 - accuracy: 0.2766 - val_loss: 2.0525 - val_accuracy: 0.3435\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 2.0725 - accuracy: 0.2946 - val_loss: 1.9752 - val_accuracy: 0.3717\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.0247 - accuracy: 0.3082 - val_loss: 1.9183 - val_accuracy: 0.4152\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.0485 - accuracy: 0.3239 - val_loss: 1.9519 - val_accuracy: 0.4174\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 2.0016 - accuracy: 0.3348 - val_loss: 1.8893 - val_accuracy: 0.3913\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 1.9598 - accuracy: 0.3446 - val_loss: 1.8633 - val_accuracy: 0.4109\n",
      "CPU times: user 8min 32s, sys: 1min 19s, total: 9min 52s\n",
      "Wall time: 2min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4b71bc50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.23      0.36        44\n",
      "           1       0.35      0.42      0.38        45\n",
      "           2       0.47      0.46      0.46        50\n",
      "           3       0.27      0.76      0.40        45\n",
      "           4       0.57      0.44      0.49        55\n",
      "           5       0.47      0.60      0.53        43\n",
      "           6       0.52      0.31      0.39        51\n",
      "           7       0.44      0.43      0.43        47\n",
      "           8       0.80      0.10      0.17        42\n",
      "           9       0.31      0.34      0.33        38\n",
      "\n",
      "    accuracy                           0.41       460\n",
      "   macro avg       0.50      0.41      0.39       460\n",
      "weighted avg       0.51      0.41      0.40       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we can see normalising spectrograms is the way to go. Let's use it by default:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [compute_spectogram(x, normalize=True) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels(paths=['recordings', 'output'], label_type=\"speakers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neural networks it is not possible to pass the labels as-is: we need to transform them in numbers. The safest way is through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "Y = enc.fit_transform(np.array(labels).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0=enc.inverse_transform(np.array([0,0,0,0,0,0,0]).reshape(1, -1))[0][0]\n",
    "label_1=enc.inverse_transform(np.array([0,1,0,0,0,0,0]).reshape(1, -1))[0][0]\n",
    "label_2=enc.inverse_transform(np.array([0,0,1,0,0,0,0]).reshape(1, -1))[0][0]\n",
    "label_3=enc.inverse_transform(np.array([0,0,0,1,0,0,0]).reshape(1, -1))[0][0]\n",
    "label_4=enc.inverse_transform(np.array([0,0,0,0,1,0,0]).reshape(1, -1))[0][0]\n",
    "label_5=enc.inverse_transform(np.array([0,0,0,0,0,1,0]).reshape(1, -1))[0][0]\n",
    "label_6=enc.inverse_transform(np.array([0,0,0,0,0,0,1]).reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names=[label_0,label_1,label_2,label_3,label_4,label_5,label_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects, Y, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,143\n",
      "Trainable params: 493,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = paper_architecture(7)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 16s 9ms/step - loss: 1.7858 - accuracy: 0.3293 - val_loss: 1.5838 - val_accuracy: 0.3652\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 15s 8ms/step - loss: 1.4346 - accuracy: 0.5005 - val_loss: 1.2625 - val_accuracy: 0.5413\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 16s 8ms/step - loss: 1.2159 - accuracy: 0.5723 - val_loss: 1.0858 - val_accuracy: 0.6478\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 16s 9ms/step - loss: 1.0973 - accuracy: 0.6484 - val_loss: 0.9903 - val_accuracy: 0.6609\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 15s 8ms/step - loss: 0.9796 - accuracy: 0.6761 - val_loss: 0.9158 - val_accuracy: 0.6826\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 15s 8ms/step - loss: 0.8767 - accuracy: 0.7114 - val_loss: 0.7307 - val_accuracy: 0.7413\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 15s 8ms/step - loss: 0.7965 - accuracy: 0.7304 - val_loss: 0.6582 - val_accuracy: 0.7457\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 15s 8ms/step - loss: 0.7119 - accuracy: 0.7592 - val_loss: 0.5445 - val_accuracy: 0.8326\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 15s 8ms/step - loss: 0.6633 - accuracy: 0.7783 - val_loss: 0.5644 - val_accuracy: 0.8348\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 15s 8ms/step - loss: 0.6241 - accuracy: 0.7978 - val_loss: 0.4915 - val_accuracy: 0.8196\n",
      "CPU times: user 7min 55s, sys: 33.1 s, total: 8min 28s\n",
      "Wall time: 2min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4c679810>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.26      0.31        19\n",
      "           1       0.75      0.13      0.22        23\n",
      "           2       0.69      0.98      0.81        98\n",
      "           3       0.75      0.30      0.43        30\n",
      "           4       0.99      0.97      0.98        94\n",
      "           5       0.85      0.84      0.84        98\n",
      "           6       0.88      0.93      0.91        98\n",
      "\n",
      "    accuracy                           0.82       460\n",
      "   macro avg       0.76      0.63      0.64       460\n",
      "weighted avg       0.82      0.82      0.80       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = spects.shape\n",
    "spects_2d = spects.reshape((nsamples,nx*ny))\n",
    "X_train, X_test, y_train, y_test = train_test_split(spects_2d, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 412 ms, total: 1min 15s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       0.90      1.00      0.95        19\n",
      "        gian       0.96      1.00      0.98        23\n",
      "     jackson       0.99      0.98      0.98        98\n",
      "      khaled       0.85      0.97      0.91        30\n",
      "     nicolas       0.99      0.99      0.99        94\n",
      "        theo       0.91      0.92      0.91        98\n",
      "    yweweler       0.98      0.91      0.94        98\n",
      "\n",
      "    accuracy                           0.95       460\n",
      "   macro avg       0.94      0.97      0.95       460\n",
      "weighted avg       0.96      0.95      0.95       460\n",
      "\n",
      "CPU times: user 25.1 s, sys: 85.4 ms, total: 25.2 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "def modified_paper_architecture(num_classes, normalize = True):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(4, 4), strides=(2,2), activation='relu', input_shape=input_shape))\n",
    "    if normalize:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=(4, 4), strides=(2,2), activation='relu', input_shape=input_shape))\n",
    "    if normalize:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10*num_classes, activation='relu'))\n",
    "    if normalize:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5*num_classes, activation='relu'))\n",
    "    if normalize:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 63, 156, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 35)                140       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,947\n",
      "Trainable params: 493,545\n",
      "Non-trainable params: 402\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = modified_paper_architecture(7)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 39s 21ms/step - loss: 1.1831 - accuracy: 0.6125 - val_loss: 1.6434 - val_accuracy: 0.4022\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 38s 21ms/step - loss: 0.6100 - accuracy: 0.8359 - val_loss: 2.0955 - val_accuracy: 0.2130\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 38s 20ms/step - loss: 0.4394 - accuracy: 0.8870 - val_loss: 2.2066 - val_accuracy: 0.2130\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 37s 20ms/step - loss: 0.3621 - accuracy: 0.9043 - val_loss: 1.6660 - val_accuracy: 0.2348\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 37s 20ms/step - loss: 0.2769 - accuracy: 0.9370 - val_loss: 1.1617 - val_accuracy: 0.5391\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 37s 20ms/step - loss: 0.2804 - accuracy: 0.9288 - val_loss: 0.8992 - val_accuracy: 0.6696\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 37s 20ms/step - loss: 0.2280 - accuracy: 0.9511 - val_loss: 0.5551 - val_accuracy: 0.8130\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 37s 20ms/step - loss: 0.1875 - accuracy: 0.9592 - val_loss: 0.3773 - val_accuracy: 0.8935\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 37s 20ms/step - loss: 0.1576 - accuracy: 0.9663 - val_loss: 0.2950 - val_accuracy: 0.9109\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 36s 20ms/step - loss: 0.1516 - accuracy: 0.9745 - val_loss: 0.2407 - val_accuracy: 0.9043\n",
      "CPU times: user 18min, sys: 2min 48s, total: 20min 49s\n",
      "Wall time: 6min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a4c6bfe10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(spects, Y, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       1.00      0.21      0.35        19\n",
      "        gian       0.67      0.87      0.75        23\n",
      "     jackson       0.88      1.00      0.93        98\n",
      "      khaled       1.00      0.40      0.57        30\n",
      "     nicolas       1.00      0.99      0.99        94\n",
      "        theo       0.96      0.94      0.95        98\n",
      "    yweweler       0.86      0.99      0.92        98\n",
      "\n",
      "    accuracy                           0.90       460\n",
      "   macro avg       0.91      0.77      0.78       460\n",
      "weighted avg       0.92      0.90      0.89       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
