{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import data_augmentation\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "tf.random.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load recordings\n",
    "## STANDARD RECORDINGS - No spectrogram normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from recordings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1945db10762470ba8a1bff0cd622fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from output\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a379f9c6fb4740509a38928b768a6767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2784 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! They vary a lot. For this reason we can add 0s at the beginning and at the end in order to uniform them\n",
    "\n",
    "**TO DO: Another strategy may be to vary spectrogram params so that spectograms will have the same length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_zeros >>>\n",
      "pad_zeros <<<\n"
     ]
    }
   ],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50335 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [data_preparation.compute_spectrogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure worked as expected! we can now move on to the prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=['recordings', 'output'], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_spects = [data_preparation.compute_spectrogram(x, normalize=True) for x in pad_recordings]\n",
    "norm_spects = np.array(norm_spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 6min 4s, sys: 22.3 s, total: 6min 26s\n",
      "Wall time: 5min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digit, y_train_digit, X_val_digit, y_val_digit, X_test_digit, y_test_digit = data_preparation.prepare_augmented_recordings(audio_dirs= ['output', 'recordings'],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 18480, 18480, 300, 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}\".format(len(X_train_digit),\n",
    "                                                 len(y_train_digit),\n",
    "                                                 len(X_test_digit),\n",
    "                                                 len(y_test_digit),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 5min 28s, sys: 16.9 s, total: 5min 45s\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_val_speaker, y_val_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(audio_dirs= ['output', 'recordings'],\n",
    "                             y_type= ['speakers_us', 'speakers_default'],\n",
    "                             n_category_test=30,\n",
    "                             include_pitch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 19008, 19008, 240, 240\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}\".format(len(X_train_speaker),\n",
    "                                                 len(y_train_speaker),\n",
    "                                                 len(X_test_speaker),\n",
    "                                                 len(y_test_speaker)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard recordings\n",
    "## Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 1.05 s, total: 2min 20s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.20      0.32        44\n",
      "           1       0.46      0.39      0.42        44\n",
      "           2       0.69      0.19      0.30        48\n",
      "           3       0.60      0.31      0.41        58\n",
      "           4       0.22      0.46      0.29        35\n",
      "           5       0.83      0.37      0.51        51\n",
      "           6       0.15      0.63      0.24        54\n",
      "           7       0.78      0.31      0.44        45\n",
      "           8       0.88      0.27      0.41        56\n",
      "           9       0.85      0.49      0.62        45\n",
      "\n",
      "    accuracy                           0.36       480\n",
      "   macro avg       0.62      0.36      0.40       480\n",
      "weighted avg       0.63      0.36      0.40       480\n",
      "\n",
      "CPU times: user 32 s, sys: 375 ms, total: 32.4 s\n",
      "Wall time: 35.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 54s, sys: 2.16 s, total: 1min 56s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.68      0.75        44\n",
      "           1       0.68      0.73      0.70        44\n",
      "           2       0.45      0.83      0.59        48\n",
      "           3       0.70      0.28      0.40        58\n",
      "           4       0.90      0.80      0.85        35\n",
      "           5       0.84      0.73      0.78        51\n",
      "           6       0.39      0.61      0.48        54\n",
      "           7       0.69      0.69      0.69        45\n",
      "           8       0.75      0.71      0.73        56\n",
      "           9       0.93      0.60      0.73        45\n",
      "\n",
      "    accuracy                           0.65       480\n",
      "   macro avg       0.72      0.67      0.67       480\n",
      "weighted avg       0.71      0.65      0.66       480\n",
      "\n",
      "CPU times: user 31.3 s, sys: 539 ms, total: 31.9 s\n",
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 18s 12ms/sample - loss: 2.2765 - acc: 0.1444 - val_loss: 2.2258 - val_acc: 0.2583\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 26s 18ms/sample - loss: 2.1792 - acc: 0.2361 - val_loss: 2.0557 - val_acc: 0.4083\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 24s 17ms/sample - loss: 2.0274 - acc: 0.2917 - val_loss: 1.8084 - val_acc: 0.4417\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 17s 12ms/sample - loss: 1.8210 - acc: 0.3597 - val_loss: 1.5928 - val_acc: 0.4313\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 18s 12ms/sample - loss: 1.6220 - acc: 0.4111 - val_loss: 1.4830 - val_acc: 0.4500\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 21s 14ms/sample - loss: 1.4927 - acc: 0.4715 - val_loss: 1.3169 - val_acc: 0.5188\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 16s 11ms/sample - loss: 1.3977 - acc: 0.5181 - val_loss: 1.1498 - val_acc: 0.5854\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 20s 14ms/sample - loss: 1.3014 - acc: 0.5382 - val_loss: 1.0915 - val_acc: 0.6646\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 29s 20ms/sample - loss: 1.2354 - acc: 0.5806 - val_loss: 0.9780 - val_acc: 0.7167\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 21s 14ms/sample - loss: 1.1368 - acc: 0.5993 - val_loss: 0.8638 - val_acc: 0.7042\n",
      "CPU times: user 6min 46s, sys: 43.7 s, total: 7min 30s\n",
      "Wall time: 3min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a2fea0b90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76        44\n",
      "           1       0.81      0.77      0.79        44\n",
      "           2       0.62      0.85      0.72        48\n",
      "           3       0.67      0.50      0.57        58\n",
      "           4       0.91      0.86      0.88        35\n",
      "           5       0.71      0.78      0.75        51\n",
      "           6       0.56      0.72      0.63        54\n",
      "           7       0.82      0.51      0.63        45\n",
      "           8       0.64      0.70      0.67        56\n",
      "           9       0.93      0.58      0.71        45\n",
      "\n",
      "    accuracy                           0.70       480\n",
      "   macro avg       0.74      0.71      0.71       480\n",
      "weighted avg       0.73      0.70      0.70       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 17s 11ms/sample - loss: 2.3281 - acc: 0.1465 - val_loss: 2.1928 - val_acc: 0.2229\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 19s 13ms/sample - loss: 2.2335 - acc: 0.2097 - val_loss: 2.1541 - val_acc: 0.2562\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 19s 13ms/sample - loss: 2.1551 - acc: 0.2354 - val_loss: 2.1004 - val_acc: 0.2979\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 21s 14ms/sample - loss: 2.1135 - acc: 0.2708 - val_loss: 2.0296 - val_acc: 0.3083\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 23s 16ms/sample - loss: 2.0584 - acc: 0.3049 - val_loss: 1.9638 - val_acc: 0.3729\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 19s 13ms/sample - loss: 2.0141 - acc: 0.3160 - val_loss: 1.9351 - val_acc: 0.3729\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 22s 16ms/sample - loss: 1.9814 - acc: 0.3250 - val_loss: 1.9246 - val_acc: 0.3646\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 19s 13ms/sample - loss: 1.9177 - acc: 0.3625 - val_loss: 1.8201 - val_acc: 0.4313\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 18s 13ms/sample - loss: 1.9086 - acc: 0.3639 - val_loss: 1.8060 - val_acc: 0.4437\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 22s 15ms/sample - loss: 1.8708 - acc: 0.3660 - val_loss: 1.8032 - val_acc: 0.4292\n",
      "CPU times: user 6min 42s, sys: 41.6 s, total: 7min 24s\n",
      "Wall time: 3min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a370670d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.39      0.45        44\n",
      "           1       0.62      0.45      0.53        44\n",
      "           2       0.34      0.40      0.37        48\n",
      "           3       0.26      0.48      0.34        58\n",
      "           4       0.55      0.17      0.26        35\n",
      "           5       0.74      0.39      0.51        51\n",
      "           6       0.90      0.17      0.28        54\n",
      "           7       0.50      0.67      0.57        45\n",
      "           8       0.53      0.30      0.39        56\n",
      "           9       0.35      0.89      0.50        45\n",
      "\n",
      "    accuracy                           0.43       480\n",
      "   macro avg       0.53      0.43      0.42       480\n",
      "weighted avg       0.53      0.43      0.42       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we can see normalising spectrograms is the way to go. Let's use it by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO : Pick best model, train it on X_train + X_val, evaluate on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speakers\n",
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 1.72 s, total: 1min 25s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.87      0.95      0.91        21\n",
      "      alinda       0.92      1.00      0.96        12\n",
      "        gian       0.90      1.00      0.95        19\n",
      "     jackson       0.94      0.94      0.94        89\n",
      "      khaled       0.77      0.91      0.83        22\n",
      "     nicolas       0.96      0.92      0.94       101\n",
      "        theo       0.77      0.82      0.79       112\n",
      "    yweweler       0.86      0.75      0.80       104\n",
      "\n",
      "    accuracy                           0.87       480\n",
      "   macro avg       0.87      0.91      0.89       480\n",
      "weighted avg       0.87      0.87      0.87       480\n",
      "\n",
      "CPU times: user 29.4 s, sys: 584 ms, total: 30 s\n",
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neural networks it is not possible to pass the labels as-is: we need to transform them in numbers. The safest way is through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, target_names = data_preparation.transform_categorical_y(labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, y, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 80)                522320    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 559,264\n",
      "Trainable params: 559,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 21s 15ms/sample - loss: 1.9242 - acc: 0.2444 - val_loss: 1.8312 - val_acc: 0.1896\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 19s 13ms/sample - loss: 1.7932 - acc: 0.3368 - val_loss: 1.6464 - val_acc: 0.3812\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 20s 14ms/sample - loss: 1.6188 - acc: 0.4611 - val_loss: 1.4285 - val_acc: 0.5938\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 19s 13ms/sample - loss: 1.4634 - acc: 0.5250 - val_loss: 1.2005 - val_acc: 0.6146\n",
      "Epoch 5/10\n",
      "1440/1440 [==============================] - 19s 13ms/sample - loss: 1.3037 - acc: 0.5667 - val_loss: 1.0257 - val_acc: 0.6729\n",
      "Epoch 6/10\n",
      "1440/1440 [==============================] - 18s 13ms/sample - loss: 1.1794 - acc: 0.6056 - val_loss: 0.9399 - val_acc: 0.6854\n",
      "Epoch 7/10\n",
      "1440/1440 [==============================] - 20s 14ms/sample - loss: 1.0833 - acc: 0.6361 - val_loss: 0.8572 - val_acc: 0.6917\n",
      "Epoch 8/10\n",
      "1440/1440 [==============================] - 20s 14ms/sample - loss: 0.9964 - acc: 0.6535 - val_loss: 0.7776 - val_acc: 0.7333\n",
      "Epoch 9/10\n",
      "1440/1440 [==============================] - 17s 12ms/sample - loss: 0.8898 - acc: 0.6938 - val_loss: 0.7264 - val_acc: 0.7417\n",
      "Epoch 10/10\n",
      "1440/1440 [==============================] - 17s 12ms/sample - loss: 0.8536 - acc: 0.7118 - val_loss: 0.6536 - val_acc: 0.7875\n",
      "CPU times: user 6min 38s, sys: 39.7 s, total: 7min 18s\n",
      "Wall time: 3min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a2fdff050>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.76        21\n",
      "           1       0.55      0.50      0.52        12\n",
      "           2       0.75      0.32      0.44        19\n",
      "           3       0.76      0.88      0.82        89\n",
      "           4       0.56      0.23      0.32        22\n",
      "           5       0.78      0.96      0.86       101\n",
      "           6       0.91      0.69      0.78       112\n",
      "           7       0.76      0.92      0.83       104\n",
      "\n",
      "    accuracy                           0.79       480\n",
      "   macro avg       0.76      0.64      0.67       480\n",
      "weighted avg       0.79      0.79      0.77       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper - batch_normalisation=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 63, 156, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 14, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 80)                522320    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 560,128\n",
      "Trainable params: 559,696\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1440/1440 [==============================] - 43s 30ms/sample - loss: 1.3107 - acc: 0.5917 - val_loss: 1.7392 - val_acc: 0.3438\n",
      "Epoch 2/10\n",
      "1440/1440 [==============================] - 43s 30ms/sample - loss: 0.7045 - acc: 0.7882 - val_loss: 1.8618 - val_acc: 0.2333\n",
      "Epoch 3/10\n",
      "1440/1440 [==============================] - 41s 29ms/sample - loss: 0.4702 - acc: 0.8708 - val_loss: 2.0463 - val_acc: 0.2333\n",
      "Epoch 4/10\n",
      "1440/1440 [==============================] - 39s 27ms/sample - loss: 0.3931 - acc: 0.8972 - val_loss: 1.8883 - val_acc: 0.2333\n",
      "CPU times: user 5min 47s, sys: 1min 5s, total: 6min 52s\n",
      "Wall time: 2min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a399e6890>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.19      0.09        21\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.00      0.00      0.00        19\n",
      "           3       0.95      0.24      0.38        89\n",
      "           4       0.00      0.00      0.00        22\n",
      "           5       0.00      0.00      0.00       101\n",
      "           6       0.38      0.94      0.54       112\n",
      "           7       0.32      0.34      0.33       104\n",
      "\n",
      "    accuracy                           0.34       480\n",
      "   macro avg       0.21      0.21      0.17       480\n",
      "weighted avg       0.34      0.34      0.27       480\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "## Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y_train_speaker = enc.fit_transform(np.array(y_train_speaker).reshape(-1, 1)).toarray()\n",
    "y_val_speaker = enc.transform(np.array(y_val_speaker).reshape(-1, 1)).toarray()\n",
    "y_test_speaker = enc.transform(np.array(y_test_speaker).reshape(-1, 1)).toarray()\n",
    "label_0 = enc.inverse_transform(np.array([1, 0, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_1 = enc.inverse_transform(np.array([0, 1, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_2 = enc.inverse_transform(np.array([0, 0, 1, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_3 = enc.inverse_transform(np.array([0, 0, 0, 1, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_4 = enc.inverse_transform(np.array([0, 0, 0, 0, 1, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_5 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 1, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_6 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 1, 0]).reshape(1, -1))[0][0]\n",
    "label_7 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 0, 1]).reshape(1, -1))[0][0]\n",
    "target_names = [label_0, label_1, label_2, label_3, label_4, label_5, label_6, label_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker = np.array(X_train_speaker)\n",
    "X_val_speaker = np.array(X_val_speaker)\n",
    "X_test_speaker = np.array(X_test_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker = X_train_speaker.reshape(X_train_speaker.shape[0],\n",
    "                                          X_train_speaker.shape[1],\n",
    "                                          X_train_speaker.shape[2],\n",
    "                                          1)\n",
    "X_val_speaker = X_val_speaker.reshape(X_val_speaker.shape[0],\n",
    "                                      X_val_speaker.shape[1],\n",
    "                                      X_val_speaker.shape[2],\n",
    "                                      1)\n",
    "X_test_speaker = X_test_speaker.reshape(X_test_speaker.shape[0],\n",
    "                                        X_test_speaker.shape[1],\n",
    "                                        X_test_speaker.shape[2],\n",
    "                                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 80)                153680    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 190,624\n",
      "Trainable params: 190,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19008 samples, validate on 4752 samples\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "19008/19008 [==============================] - 142s 7ms/sample - loss: 1.1053 - acc: 0.6003 - val_loss: 0.7498 - val_acc: 0.7193\n",
      "Epoch 2/10\n",
      "19008/19008 [==============================] - 146s 8ms/sample - loss: 0.6162 - acc: 0.7686 - val_loss: 0.4434 - val_acc: 0.8251\n",
      "Epoch 3/10\n",
      "19008/19008 [==============================] - 134s 7ms/sample - loss: 0.4357 - acc: 0.8363 - val_loss: 0.3235 - val_acc: 0.8832\n",
      "Epoch 4/10\n",
      "19008/19008 [==============================] - 130s 7ms/sample - loss: 0.3481 - acc: 0.8666 - val_loss: 0.2478 - val_acc: 0.9139\n",
      "Epoch 5/10\n",
      "19008/19008 [==============================] - 130s 7ms/sample - loss: 0.2947 - acc: 0.8868 - val_loss: 0.2349 - val_acc: 0.9127\n",
      "Epoch 6/10\n",
      "19008/19008 [==============================] - 130s 7ms/sample - loss: 0.2407 - acc: 0.9058 - val_loss: 0.1947 - val_acc: 0.9144\n",
      "Epoch 7/10\n",
      "19008/19008 [==============================] - 130s 7ms/sample - loss: 0.2144 - acc: 0.9177 - val_loss: 0.1811 - val_acc: 0.9356\n",
      "Epoch 8/10\n",
      "19008/19008 [==============================] - 131s 7ms/sample - loss: 0.1901 - acc: 0.9265 - val_loss: 0.1949 - val_acc: 0.9217\n",
      "Epoch 9/10\n",
      "19008/19008 [==============================] - 132s 7ms/sample - loss: 0.1820 - acc: 0.9288 - val_loss: 0.1609 - val_acc: 0.9352\n",
      "Epoch 10/10\n",
      "19008/19008 [==============================] - 131s 7ms/sample - loss: 0.1622 - acc: 0.9364 - val_loss: 0.1682 - val_acc: 0.9278\n",
      "CPU times: user 59min 46s, sys: 9min 31s, total: 1h 9min 17s\n",
      "Wall time: 22min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a39d27350>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.96      0.94      0.95       138\n",
      "      alinda       0.93      0.95      0.94       144\n",
      "        gian       0.89      0.91      0.90       162\n",
      "     jackson       0.99      0.99      0.99      1040\n",
      "      khaled       0.99      0.91      0.95       172\n",
      "     nicolas       1.00      0.97      0.99      1049\n",
      "        theo       0.93      0.81      0.86      1037\n",
      "    yweweler       0.80      0.94      0.87      1010\n",
      "\n",
      "    accuracy                           0.93      4752\n",
      "   macro avg       0.94      0.93      0.93      4752\n",
      "weighted avg       0.93      0.93      0.93      4752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch_normalization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 63, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 14, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 80)                153680    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 191,488\n",
      "Trainable params: 191,056\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19008 samples, validate on 4752 samples\n",
      "Epoch 1/10\n",
      "19008/19008 [==============================] - 145s 8ms/sample - loss: 0.8969 - acc: 0.6839 - val_loss: 0.5192 - val_acc: 0.8085\n",
      "Epoch 2/10\n",
      "19008/19008 [==============================] - 145s 8ms/sample - loss: 0.5761 - acc: 0.7778 - val_loss: 0.4993 - val_acc: 0.8068\n",
      "Epoch 3/10\n",
      "19008/19008 [==============================] - 147s 8ms/sample - loss: 0.4659 - acc: 0.8204 - val_loss: 0.4451 - val_acc: 0.8493\n",
      "Epoch 4/10\n",
      "19008/19008 [==============================] - 148s 8ms/sample - loss: 0.4121 - acc: 0.8445 - val_loss: 0.3313 - val_acc: 0.8813\n",
      "Epoch 5/10\n",
      "19008/19008 [==============================] - 146s 8ms/sample - loss: 0.3659 - acc: 0.8588 - val_loss: 0.2428 - val_acc: 0.9139\n",
      "Epoch 6/10\n",
      "19008/19008 [==============================] - 146s 8ms/sample - loss: 0.3373 - acc: 0.8721 - val_loss: 0.2460 - val_acc: 0.8963\n",
      "Epoch 7/10\n",
      "19008/19008 [==============================] - 146s 8ms/sample - loss: 0.3119 - acc: 0.8785 - val_loss: 0.2573 - val_acc: 0.8923\n",
      "Epoch 8/10\n",
      "19008/19008 [==============================] - 148s 8ms/sample - loss: 0.2984 - acc: 0.8864 - val_loss: 0.2434 - val_acc: 0.9043\n",
      "CPU times: user 50min 5s, sys: 8min 19s, total: 58min 25s\n",
      "Wall time: 19min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3b4f7690>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.94      0.85      0.89       138\n",
      "      alinda       0.89      0.67      0.77       144\n",
      "        gian       0.78      0.86      0.82       162\n",
      "     jackson       0.99      0.98      0.98      1040\n",
      "      khaled       0.81      0.93      0.86       172\n",
      "     nicolas       0.99      0.99      0.99      1049\n",
      "        theo       0.82      0.92      0.87      1037\n",
      "    yweweler       0.91      0.81      0.86      1010\n",
      "\n",
      "    accuracy                           0.91      4752\n",
      "   macro avg       0.89      0.88      0.88      4752\n",
      "weighted avg       0.92      0.91      0.91      4752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different architecture\n",
    "Let's change a bit the architecture and see if we can improve scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 27, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 10752)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               1376384   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,410,792\n",
      "Trainable params: 1,410,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19008 samples, validate on 4752 samples\n",
      "Epoch 1/10\n",
      "19008/19008 [==============================] - 131s 7ms/sample - loss: 1.1035 - acc: 0.6002 - val_loss: 0.6821 - val_acc: 0.7771\n",
      "Epoch 2/10\n",
      "19008/19008 [==============================] - 130s 7ms/sample - loss: 0.6034 - acc: 0.7754 - val_loss: 0.3892 - val_acc: 0.8434\n",
      "Epoch 3/10\n",
      "19008/19008 [==============================] - 134s 7ms/sample - loss: 0.4343 - acc: 0.8345 - val_loss: 0.3631 - val_acc: 0.8678\n",
      "Epoch 4/10\n",
      "19008/19008 [==============================] - 134s 7ms/sample - loss: 0.3276 - acc: 0.8761 - val_loss: 0.3356 - val_acc: 0.8678\n",
      "Epoch 5/10\n",
      "19008/19008 [==============================] - 133s 7ms/sample - loss: 0.2683 - acc: 0.8964 - val_loss: 0.2132 - val_acc: 0.9198\n",
      "Epoch 6/10\n",
      "19008/19008 [==============================] - 133s 7ms/sample - loss: 0.2265 - acc: 0.9109 - val_loss: 0.1985 - val_acc: 0.9211\n",
      "Epoch 7/10\n",
      "19008/19008 [==============================] - 135s 7ms/sample - loss: 0.2065 - acc: 0.9178 - val_loss: 0.2168 - val_acc: 0.9087\n",
      "Epoch 8/10\n",
      "19008/19008 [==============================] - 134s 7ms/sample - loss: 0.1777 - acc: 0.9314 - val_loss: 0.1844 - val_acc: 0.9341\n",
      "Epoch 9/10\n",
      "19008/19008 [==============================] - 132s 7ms/sample - loss: 0.1718 - acc: 0.9338 - val_loss: 0.1909 - val_acc: 0.9190\n",
      "Epoch 10/10\n",
      "19008/19008 [==============================] - 134s 7ms/sample - loss: 0.1486 - acc: 0.9400 - val_loss: 0.1820 - val_acc: 0.9257\n",
      "CPU times: user 59min 48s, sys: 10min 8s, total: 1h 9min 56s\n",
      "Wall time: 22min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3dcc9550>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_speaker, y_val_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.99      0.91      0.95       138\n",
      "      alinda       0.93      0.96      0.95       144\n",
      "        gian       0.98      0.87      0.92       162\n",
      "     jackson       0.98      1.00      0.99      1040\n",
      "      khaled       0.96      0.88      0.92       172\n",
      "     nicolas       0.99      0.99      0.99      1049\n",
      "        theo       0.98      0.74      0.84      1037\n",
      "    yweweler       0.78      0.99      0.87      1010\n",
      "\n",
      "    accuracy                           0.93      4752\n",
      "   macro avg       0.95      0.92      0.93      4752\n",
      "weighted avg       0.94      0.93      0.92      4752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_speaker)\n",
    "print(classification_report(Y_val_nn, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digit_nn = np.array(X_train_digit)\n",
    "X_val_digit_nn = np.array(X_val_digit)\n",
    "X_test_digit_nn = np.array(X_test_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digit_nn = X_train_digit_nn.reshape(X_train_digit_nn.shape[0], X_train_digit_nn.shape[1], X_train_digit_nn.shape[2], 1)\n",
    "X_val_digit_nn = X_val_digit_nn.reshape(X_val_digit_nn.shape[0], X_val_digit_nn.shape[1], X_val_digit_nn.shape[2], 1)\n",
    "X_test_digit_nn = X_test_digit_nn.reshape(X_test_digit_nn.shape[0], X_test_digit_nn.shape[1], X_test_digit_nn.shape[2], 1)\n",
    "y_train_digit_nn = tf.keras.utils.to_categorical(y_train_digit, 10)\n",
    "y_test_digit_nn = tf.keras.utils.to_categorical(y_test_digit, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_digit_nn = tf.keras.utils.to_categorical(y_val_digit, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train_digit_nn.shape[1], X_train_digit_nn.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 63, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 14, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               192100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 232,020\n",
      "Trainable params: 231,528\n",
      "Non-trainable params: 492\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18480 samples, validate on 4620 samples\n",
      "Epoch 1/10\n",
      "18480/18480 [==============================] - 148s 8ms/sample - loss: 1.5950 - acc: 0.4432 - val_loss: 1.2522 - val_acc: 0.5530\n",
      "Epoch 2/10\n",
      "18480/18480 [==============================] - 143s 8ms/sample - loss: 1.1149 - acc: 0.6149 - val_loss: 0.7899 - val_acc: 0.7519\n",
      "Epoch 3/10\n",
      "18480/18480 [==============================] - 144s 8ms/sample - loss: 0.9122 - acc: 0.6918 - val_loss: 0.8882 - val_acc: 0.7058\n",
      "Epoch 4/10\n",
      "18480/18480 [==============================] - 144s 8ms/sample - loss: 0.8336 - acc: 0.7214 - val_loss: 0.7434 - val_acc: 0.7500\n",
      "Epoch 5/10\n",
      "18480/18480 [==============================] - 142s 8ms/sample - loss: 0.7698 - acc: 0.7439 - val_loss: 0.5994 - val_acc: 0.8035\n",
      "Epoch 6/10\n",
      "18480/18480 [==============================] - 146s 8ms/sample - loss: 0.7486 - acc: 0.7525 - val_loss: 0.8507 - val_acc: 0.7182\n",
      "Epoch 7/10\n",
      "18480/18480 [==============================] - 142s 8ms/sample - loss: 0.7086 - acc: 0.7602 - val_loss: 0.7502 - val_acc: 0.7639\n",
      "Epoch 8/10\n",
      "18480/18480 [==============================] - 143s 8ms/sample - loss: 0.6987 - acc: 0.7640 - val_loss: 0.5544 - val_acc: 0.8139\n",
      "Epoch 9/10\n",
      "18480/18480 [==============================] - 143s 8ms/sample - loss: 0.6707 - acc: 0.7722 - val_loss: 0.5535 - val_acc: 0.8268\n",
      "Epoch 10/10\n",
      "18480/18480 [==============================] - 167s 9ms/sample - loss: 0.6333 - acc: 0.7857 - val_loss: 0.5936 - val_acc: 0.8009\n",
      "CPU times: user 1h 1min 9s, sys: 10min 25s, total: 1h 11min 35s\n",
      "Wall time: 24min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3e75db90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit_nn, y_train_digit_nn,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digit_nn, y_val_digit_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       486\n",
      "           1       0.93      0.77      0.84       441\n",
      "           2       0.96      0.67      0.79       468\n",
      "           3       0.88      0.78      0.83       481\n",
      "           4       0.88      0.84      0.86       467\n",
      "           5       0.50      0.96      0.66       483\n",
      "           6       0.63      0.89      0.74       418\n",
      "           7       0.93      0.75      0.83       462\n",
      "           8       0.98      0.63      0.77       470\n",
      "           9       0.91      0.81      0.86       444\n",
      "\n",
      "    accuracy                           0.80      4620\n",
      "   macro avg       0.85      0.80      0.81      4620\n",
      "weighted avg       0.86      0.80      0.81      4620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_val_nn = np.argmax(y_val_digit_nn, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_val_digit_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 27, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 10752)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               1376384   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,411,050\n",
      "Trainable params: 1,411,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18480 samples, validate on 4620 samples\n",
      "Epoch 1/10\n",
      "18480/18480 [==============================] - 173s 9ms/sample - loss: 1.5401 - acc: 0.4494 - val_loss: 1.1111 - val_acc: 0.6065\n",
      "Epoch 2/10\n",
      "18480/18480 [==============================] - 172s 9ms/sample - loss: 1.0322 - acc: 0.6351 - val_loss: 0.8405 - val_acc: 0.7245\n",
      "Epoch 3/10\n",
      "18480/18480 [==============================] - 161s 9ms/sample - loss: 0.8454 - acc: 0.7031 - val_loss: 0.7403 - val_acc: 0.7437\n",
      "Epoch 4/10\n",
      "18480/18480 [==============================] - 153s 8ms/sample - loss: 0.7291 - acc: 0.7432 - val_loss: 0.6913 - val_acc: 0.7641\n",
      "Epoch 5/10\n",
      "18480/18480 [==============================] - 156s 8ms/sample - loss: 0.6545 - acc: 0.7713 - val_loss: 0.5594 - val_acc: 0.8026\n",
      "Epoch 6/10\n",
      "18480/18480 [==============================] - 153s 8ms/sample - loss: 0.6030 - acc: 0.7891 - val_loss: 0.5868 - val_acc: 0.7950\n",
      "Epoch 7/10\n",
      "18480/18480 [==============================] - 161s 9ms/sample - loss: 0.5485 - acc: 0.8086 - val_loss: 0.5550 - val_acc: 0.8015\n",
      "Epoch 8/10\n",
      "18480/18480 [==============================] - 192s 10ms/sample - loss: 0.5152 - acc: 0.8182 - val_loss: 0.5329 - val_acc: 0.8121\n",
      "Epoch 9/10\n",
      "18480/18480 [==============================] - 192s 10ms/sample - loss: 0.4893 - acc: 0.8287 - val_loss: 0.4981 - val_acc: 0.8253\n",
      "Epoch 10/10\n",
      "18480/18480 [==============================] - 129s 7ms/sample - loss: 0.4637 - acc: 0.8366 - val_loss: 0.4239 - val_acc: 0.8550\n",
      "CPU times: user 58min 12s, sys: 9min 36s, total: 1h 7min 48s\n",
      "Wall time: 27min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3afbf890>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit_nn, y_train_digit_nn,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_val_digit_nn, y_val_digit_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93       486\n",
      "           1       0.83      0.86      0.85       441\n",
      "           2       0.93      0.78      0.85       468\n",
      "           3       0.70      0.91      0.79       481\n",
      "           4       0.80      0.91      0.85       467\n",
      "           5       0.96      0.83      0.89       483\n",
      "           6       0.70      0.91      0.79       418\n",
      "           7       0.98      0.77      0.86       462\n",
      "           8       0.93      0.84      0.88       470\n",
      "           9       0.93      0.86      0.89       444\n",
      "\n",
      "    accuracy                           0.85      4620\n",
      "   macro avg       0.87      0.86      0.86      4620\n",
      "weighted avg       0.87      0.85      0.86      4620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_val_digit_nn)\n",
    "print(classification_report(Y_val_nn, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "from scipy.io import wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_zeros_single_rec(rec, max_y):\n",
    "    rec = np.array(rec)\n",
    "    diff_in_y = max_y - rec.shape[0]\n",
    "    if diff_in_y > 0:\n",
    "        half_diff = int(diff_in_y/2)\n",
    "        remaining_diff = diff_in_y-half_diff\n",
    "        v = np.pad(rec, (half_diff, remaining_diff), 'constant', constant_values=0)\n",
    "        return v\n",
    "    else:\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recording(duration, rec_rate, name = \"test.wav\", output_dir = \"test/\"):\n",
    "    print(\"Ready in 3...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"2...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"1...\")\n",
    "    time.sleep(1)\n",
    "    print(\"Go.\")\n",
    "    rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "    print(\"Playing the recording.\")\n",
    "    sd.play(rec, rec_rate)\n",
    "\n",
    "    # after hearing the recording, decide whether to record it again or continue to next number\n",
    "    # if you type anything, record again\n",
    "    # if you press enter, save current recording & go to next number\n",
    "    ok = input(\"OK?\")\n",
    "    if ok == \"\":\n",
    "        librosa.output.write_wav(output_dir+name, rec, rec_rate)\n",
    "        return rec\n",
    "    ipd.clear_output(wait=True)\n",
    "    create_recording(duration, rec_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio(file, input_dir=\"test/\", output_dir=\"test/\", db=-48):\n",
    "\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"There should be an input \\\"{input_dir}\\\" directory.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # create output directory if not there yet\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    temp1 = output_dir+\"temp1.wav\"\n",
    "    temp2 = output_dir+\"temp2.wav\"\n",
    "    temp3 = output_dir+\"temp3.wav\"\n",
    " \n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_dir+file, \"-af\", f\"silenceremove=1:0:{db}dB\", temp1])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp1, \"-af\", \"areverse\", temp2])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp2, \"-af\", f\"silenceremove=1:0.1:{db}dB\", temp3])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp3, \"-af\", \"areverse\", output_dir+file])\n",
    "    \n",
    "    os.remove(temp1)\n",
    "    os.remove(temp2)\n",
    "    os.remove(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NN(nn, max_y, target_names, answer = None, duration=2, rec_rate=8000, directory = \"test/\", filename = \"test.wav\"):\n",
    "    create_recording(duration, rec_rate, filename, directory)   \n",
    "    ipd.clear_output()\n",
    "    trim_audio(filename, directory, directory)\n",
    "    # _, rec = wav.read(directory + \"/\" + filename)\n",
    "    rec, _ = librosa.core.load(directory + \"/\" + filename, sr = rec_rate)\n",
    "    rec = pad_zeros_single_rec(rec, max_y)\n",
    "    # sd.play(rec, rec_rate)\n",
    "    rec = data_preparation.compute_spectrogram(rec, normalize=True)\n",
    "    rec = rec[np.newaxis,:,:,np.newaxis]\n",
    "    preds = nn.predict_classes(rec)\n",
    "    print(\"Model prediction: {}\".format(target_names[preds[0]]))\n",
    "    if answer is not None:\n",
    "        print(f\"Correct answer {answer}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y = len(data_augm_pad_recordings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test_NN(model, max_y, target_names, answer = \"gian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- [x] Set random seed\n",
    "- [x] Use only original recordings in test set of augmented scenario\n",
    "- [x] Use proper validation set for picking best models and params\n",
    "- [x] Data augmentation also for digit recognition\n",
    "- [ ] Evaluate each best model on test set, after training it on x_train + x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
