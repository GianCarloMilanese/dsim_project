{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import wavfile as wav\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Strumenti di classificazione\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Feature audio avanzate\n",
    "import librosa\n",
    "import librosa.display as lid\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recordings(paths = [\"recordings\"], normalize=False):\n",
    "    res = []\n",
    "    for path in paths:\n",
    "        print(f\"Loading from {path}\")    \n",
    "        for f in tqdm(sorted(os.listdir(path))):\n",
    "            if f.endswith('.wav'):\n",
    "                # Carica file ed estraine le features\n",
    "                audio, sample_rate = librosa.load(path + \"/\" + f)\n",
    "                res.append(audio)\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(paths = [\"recordings\"], label_type = \"number\"):\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for path in paths:\n",
    "        for f in sorted(os.listdir(path)):\n",
    "            if f.endswith('.wav'):\n",
    "                if label_type.startswith(\"n\"):\n",
    "                    label = f.split('_')[0]\n",
    "                else:\n",
    "                    label = f.split('_')[1]\n",
    "                labels.append(label)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectogram(audio, rate=8000):\n",
    "    spectogram = librosa.feature.melspectrogram(y=np.array(audio), sr=rate, n_fft=1024, hop_length=160)\n",
    "    return (spectogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from recordings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93d98ed5ebc4827ab4223cc0e309f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from output\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1624302992aa47b8b1c2930720253f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = load_recordings(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2784 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! They vary a lot. For this reason we can add 0s at the beginning and at the end in order to uniform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_zeros(recordings):\n",
    "    min_y = min(map(np.shape, recordings))[0]\n",
    "    max_y = max(map(np.shape, recordings))[0]\n",
    "    res = []\n",
    "    for rec in recordings:\n",
    "        diff_in_y = max_y - rec.shape[0]\n",
    "        if diff_in_y > 0:\n",
    "            half_diff = int(diff_in_y/2)\n",
    "            remaining_diff = diff_in_y-half_diff\n",
    "            v = np.pad(rec,  ((half_diff,remaining_diff)), 'constant', constant_values=0)\n",
    "            res.append(v)\n",
    "        else:\n",
    "            res.append(rec)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_recordings = pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50335 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [compute_spectogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure worked as expected! we can now move on to the prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard recordings\n",
    "### Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = spects.shape\n",
    "spects_2d = spects.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects_2d, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 44s, sys: 2.12 s, total: 3min 46s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.20      0.32        44\n",
      "           1       0.18      0.78      0.29        45\n",
      "           2       0.87      0.26      0.40        50\n",
      "           3       0.39      0.58      0.47        45\n",
      "           4       0.33      0.53      0.40        55\n",
      "           5       0.77      0.40      0.52        43\n",
      "           6       0.47      0.14      0.21        51\n",
      "           7       0.83      0.32      0.46        47\n",
      "           8       0.88      0.17      0.28        42\n",
      "           9       0.79      0.39      0.53        38\n",
      "\n",
      "    accuracy                           0.38       460\n",
      "   macro avg       0.63      0.38      0.39       460\n",
      "weighted avg       0.62      0.38      0.39       460\n",
      "\n",
      "CPU times: user 36.9 s, sys: 398 ms, total: 37.3 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1840, 128, 315)"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source https://keras.io/examples/mnist_cnn/\n",
    "def mnist_cnn(num_classes=10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mnist_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_56 (Conv2D)           (None, 126, 313, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 124, 311, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 62, 155, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 62, 155, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 615040)            0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 128)               78725248  \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 78,745,354\n",
      "Trainable params: 78,745,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/5\n",
      "  64/1840 [>.............................] - ETA: 8:24 - loss: 4.2948 - accuracy: 0.0781"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9275315074816994, 0.7782608866691589]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71        44\n",
      "           1       0.91      0.71      0.80        45\n",
      "           2       0.81      0.84      0.82        50\n",
      "           3       0.85      0.73      0.79        45\n",
      "           4       0.88      0.82      0.85        55\n",
      "           5       0.94      0.77      0.85        43\n",
      "           6       0.54      0.92      0.68        51\n",
      "           7       0.97      0.74      0.84        47\n",
      "           8       0.96      0.64      0.77        42\n",
      "           9       0.72      0.74      0.73        38\n",
      "\n",
      "    accuracy                           0.78       460\n",
      "   macro avg       0.82      0.77      0.78       460\n",
      "weighted avg       0.82      0.78      0.78       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paper_architecture(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(4, 4), strides=(2,2), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=(4, 4), strides=(2,2), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4), strides=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10*num_classes, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5*num_classes, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = paper_architecture(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 19s 11ms/step - loss: 2.4062 - accuracy: 0.1342 - val_loss: 2.2251 - val_accuracy: 0.2217\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 20s 11ms/step - loss: 2.2591 - accuracy: 0.2043 - val_loss: 2.1466 - val_accuracy: 0.2870\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 21s 12ms/step - loss: 2.1992 - accuracy: 0.2353 - val_loss: 2.1076 - val_accuracy: 0.3130\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 25s 14ms/step - loss: 2.1344 - accuracy: 0.2674 - val_loss: 2.0577 - val_accuracy: 0.3239\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 20s 11ms/step - loss: 2.1075 - accuracy: 0.2957 - val_loss: 2.0443 - val_accuracy: 0.2978\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 19s 10ms/step - loss: 2.0887 - accuracy: 0.2908 - val_loss: 2.0139 - val_accuracy: 0.3261\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 2.0825 - accuracy: 0.2973 - val_loss: 1.9753 - val_accuracy: 0.3870\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 19s 10ms/step - loss: 2.0563 - accuracy: 0.3087 - val_loss: 1.9447 - val_accuracy: 0.3848\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 20s 11ms/step - loss: 1.9987 - accuracy: 0.3408 - val_loss: 1.9480 - val_accuracy: 0.3783\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 19s 10ms/step - loss: 1.9838 - accuracy: 0.3386 - val_loss: 1.9064 - val_accuracy: 0.4000\n",
      "CPU times: user 8min 39s, sys: 1min 22s, total: 10min 1s\n",
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b238f6bd0>"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.48      0.43        44\n",
      "           1       0.39      0.27      0.32        45\n",
      "           2       0.49      0.56      0.52        50\n",
      "           3       0.22      0.27      0.24        45\n",
      "           4       0.57      0.44      0.49        55\n",
      "           5       0.48      0.67      0.56        43\n",
      "           6       0.90      0.18      0.30        51\n",
      "           7       0.53      0.51      0.52        47\n",
      "           8       0.88      0.17      0.28        42\n",
      "           9       0.18      0.47      0.26        38\n",
      "\n",
      "    accuracy                           0.40       460\n",
      "   macro avg       0.50      0.40      0.39       460\n",
      "weighted avg       0.51      0.40      0.40       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels(paths=['recordings', 'output'], label_type=\"speakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "Y = enc.fit_transform(np.array(labels).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects, Y, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_60 (Conv2D)           (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,143\n",
      "Trainable params: 493,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = paper_architecture(7)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 1.7651 - accuracy: 0.3886 - val_loss: 1.6023 - val_accuracy: 0.5457\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 16s 9ms/step - loss: 1.5946 - accuracy: 0.5000 - val_loss: 1.4807 - val_accuracy: 0.5587\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 16s 9ms/step - loss: 1.4803 - accuracy: 0.5228 - val_loss: 1.4398 - val_accuracy: 0.5413\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 19s 10ms/step - loss: 1.3637 - accuracy: 0.5370 - val_loss: 1.2902 - val_accuracy: 0.5761\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 1.2357 - accuracy: 0.5500 - val_loss: 1.1307 - val_accuracy: 0.5543\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 20s 11ms/step - loss: 1.1199 - accuracy: 0.5538 - val_loss: 1.0259 - val_accuracy: 0.6022\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 19s 10ms/step - loss: 1.0487 - accuracy: 0.5897 - val_loss: 1.0107 - val_accuracy: 0.5848\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 1.0341 - accuracy: 0.6054 - val_loss: 0.8901 - val_accuracy: 0.6217\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 0.9644 - accuracy: 0.5913 - val_loss: 0.8186 - val_accuracy: 0.6261\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 16s 9ms/step - loss: 0.8846 - accuracy: 0.6234 - val_loss: 0.8474 - val_accuracy: 0.6370\n",
      "CPU times: user 8min 10s, sys: 39 s, total: 8min 49s\n",
      "Wall time: 2min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b244f3c50>"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train1,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       1.00      0.09      0.16        23\n",
      "           2       0.88      0.95      0.91        98\n",
      "           3       1.00      0.27      0.42        30\n",
      "           4       0.64      0.98      0.78        94\n",
      "           5       0.48      0.93      0.64        98\n",
      "           6       0.54      0.07      0.13        98\n",
      "\n",
      "    accuracy                           0.64       460\n",
      "   macro avg       0.65      0.47      0.43       460\n",
      "weighted avg       0.65      0.64      0.55       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc(input, rate=8000, min_len=40, sampling=1):\n",
    "    # Campiona i valori\n",
    "    signal = input[::sampling]\n",
    "    # Calcola coefficienti MFCC\n",
    "    mfcc = librosa.feature.mfcc(signal*1.0, sr=int(rate/sampling))\n",
    "    # Applica eventuali zeri aggiuntivi per raggiungere una lunghezza fissa\n",
    "    pad_width = min_len - mfcc.shape[1]\n",
    "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [compute_spectogram(x) for x in pad_recordings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spects, Y, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_62 (Conv2D)           (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,143\n",
      "Trainable params: 493,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = paper_architecture(7)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 1.7368 - accuracy: 0.3511 - val_loss: 1.6103 - val_accuracy: 0.4391\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 1.6034 - accuracy: 0.4826 - val_loss: 1.5162 - val_accuracy: 0.5826\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 1.5023 - accuracy: 0.5484 - val_loss: 1.4286 - val_accuracy: 0.6174\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 1.4096 - accuracy: 0.5777 - val_loss: 1.3246 - val_accuracy: 0.6217\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 1.2903 - accuracy: 0.5859 - val_loss: 1.2647 - val_accuracy: 0.5543\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 1.1974 - accuracy: 0.5973 - val_loss: 1.0082 - val_accuracy: 0.6239\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 1.0898 - accuracy: 0.5832 - val_loss: 0.8872 - val_accuracy: 0.7217\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 17s 9ms/step - loss: 0.9633 - accuracy: 0.6223 - val_loss: 0.7778 - val_accuracy: 0.7543\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 18s 10ms/step - loss: 0.8980 - accuracy: 0.6293 - val_loss: 0.7319 - val_accuracy: 0.6543\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 20s 11ms/step - loss: 0.8272 - accuracy: 0.6543 - val_loss: 0.7016 - val_accuracy: 0.7935\n",
      "CPU times: user 8min 17s, sys: 41.7 s, total: 8min 59s\n",
      "Wall time: 3min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b3d7e6ed0>"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train1,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.21      0.33        19\n",
      "           1       0.71      0.22      0.33        23\n",
      "           2       0.86      0.99      0.92        98\n",
      "           3       1.00      0.40      0.57        30\n",
      "           4       0.79      0.94      0.85        94\n",
      "           5       0.75      0.82      0.78        98\n",
      "           6       0.75      0.81      0.78        98\n",
      "\n",
      "    accuracy                           0.79       460\n",
      "   macro avg       0.81      0.63      0.65       460\n",
      "weighted avg       0.80      0.79      0.77       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCC is more promising :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association between numbers and speakers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['alinda']], dtype='<U8')"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,0,0,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['gian']], dtype='<U8')"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,1,0,0,0,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['jackson']], dtype='<U8')"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,1,0,0,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['khaled']], dtype='<U8')"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,1,0,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['nicolas']], dtype='<U8')"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,0,1,0,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['theo']], dtype='<U8')"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,0,0,1,0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['yweweler']], dtype='<U8')"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.inverse_transform(np.array([0,0,0,0,0,0,1]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
