{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO: fix seed\n",
    "# Load recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from recordings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7edd7226d84b0d9a02f1b2ab5cd837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from output\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4a261b32f742d4a21526183bd739ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2784 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! They vary a lot. For this reason we can add 0s at the beginning and at the end in order to uniform them\n",
    "\n",
    "**TO DO: Another strategy may be to vary spectrogram params so that spectograms will have the same length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50335 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [data_preparation.compute_spectrogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure worked as expected! we can now move on to the prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard recordings\n",
    "## Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_preparation.load_labels(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_preparation.split_train_test_baseline_spectrograms(spects, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 49s, sys: 3.39 s, total: 3min 53s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.20      0.32        44\n",
      "           1       0.18      0.78      0.29        45\n",
      "           2       0.87      0.26      0.40        50\n",
      "           3       0.39      0.58      0.47        45\n",
      "           4       0.33      0.53      0.40        55\n",
      "           5       0.77      0.40      0.52        43\n",
      "           6       0.47      0.14      0.21        51\n",
      "           7       0.83      0.32      0.46        47\n",
      "           8       0.88      0.17      0.28        42\n",
      "           9       0.79      0.39      0.53        38\n",
      "\n",
      "    accuracy                           0.38       460\n",
      "   macro avg       0.63      0.38      0.39       460\n",
      "weighted avg       0.62      0.38      0.39       460\n",
      "\n",
      "CPU times: user 35.3 s, sys: 314 ms, total: 35.6 s\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_spects = [data_preparation.compute_spectrogram(x, normalize=True) for x in pad_recordings]\n",
    "norm_spects = np.array(norm_spects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 31s, sys: 978 ms, total: 2min 32s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88        44\n",
      "           1       0.93      0.87      0.90        45\n",
      "           2       0.57      0.94      0.71        50\n",
      "           3       0.87      0.44      0.59        45\n",
      "           4       1.00      0.89      0.94        55\n",
      "           5       0.85      0.95      0.90        43\n",
      "           6       0.56      0.69      0.62        51\n",
      "           7       0.80      0.85      0.82        47\n",
      "           8       0.76      0.60      0.67        42\n",
      "           9       0.96      0.63      0.76        38\n",
      "\n",
      "    accuracy                           0.78       460\n",
      "   macro avg       0.82      0.77      0.78       460\n",
      "weighted avg       0.81      0.78      0.78       460\n",
      "\n",
      "CPU times: user 32.2 s, sys: 209 ms, total: 32.4 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 18s 10ms/sample - loss: 2.2791 - acc: 0.1478 - val_loss: 2.2519 - val_acc: 0.2304\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 22s 12ms/sample - loss: 2.1902 - acc: 0.2136 - val_loss: 2.0659 - val_acc: 0.2457\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 22s 12ms/sample - loss: 1.9832 - acc: 0.2989 - val_loss: 1.7836 - val_acc: 0.4022\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 22s 12ms/sample - loss: 1.7328 - acc: 0.3848 - val_loss: 1.5000 - val_acc: 0.4543\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 1.5315 - acc: 0.4467 - val_loss: 1.3199 - val_acc: 0.5587\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 1.3809 - acc: 0.5109 - val_loss: 1.1453 - val_acc: 0.6457\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 24s 13ms/sample - loss: 1.2352 - acc: 0.5712 - val_loss: 0.9582 - val_acc: 0.7000\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 22s 12ms/sample - loss: 1.1397 - acc: 0.5962 - val_loss: 0.9791 - val_acc: 0.6522\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 23s 12ms/sample - loss: 1.0384 - acc: 0.6386 - val_loss: 0.8389 - val_acc: 0.6783\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 26s 14ms/sample - loss: 0.9178 - acc: 0.6793 - val_loss: 0.7215 - val_acc: 0.7500\n",
      "CPU times: user 8min 17s, sys: 53.8 s, total: 9min 11s\n",
      "Wall time: 3min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a328c9190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "callback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        44\n",
      "           1       1.00      0.69      0.82        45\n",
      "           2       0.70      0.96      0.81        50\n",
      "           3       0.70      0.67      0.68        45\n",
      "           4       0.98      0.89      0.93        55\n",
      "           5       0.78      0.42      0.55        43\n",
      "           6       0.81      0.57      0.67        51\n",
      "           7       0.87      0.70      0.78        47\n",
      "           8       0.65      0.76      0.70        42\n",
      "           9       0.48      0.92      0.63        38\n",
      "\n",
      "    accuracy                           0.75       460\n",
      "   macro avg       0.78      0.75      0.74       460\n",
      "weighted avg       0.79      0.75      0.75       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(spects, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 30s 16ms/sample - loss: 2.3696 - acc: 0.1429 - val_loss: 2.1917 - val_acc: 0.2587\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 21s 12ms/sample - loss: 2.2384 - acc: 0.1799 - val_loss: 2.1015 - val_acc: 0.2543\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 23s 12ms/sample - loss: 2.1368 - acc: 0.2636 - val_loss: 2.0144 - val_acc: 0.3348\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 22s 12ms/sample - loss: 2.0963 - acc: 0.2636 - val_loss: 1.9244 - val_acc: 0.3196\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 19s 10ms/sample - loss: 2.0345 - acc: 0.2859 - val_loss: 1.8909 - val_acc: 0.3478\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 22s 12ms/sample - loss: 1.9977 - acc: 0.3217 - val_loss: 1.8974 - val_acc: 0.3522\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 21s 11ms/sample - loss: 1.9275 - acc: 0.3511 - val_loss: 1.8298 - val_acc: 0.4174\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 20s 11ms/sample - loss: 1.9107 - acc: 0.3598 - val_loss: 1.7414 - val_acc: 0.4391\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 18s 10ms/sample - loss: 1.8711 - acc: 0.3614 - val_loss: 1.7568 - val_acc: 0.4043\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 28s 15ms/sample - loss: 1.8205 - acc: 0.3989 - val_loss: 1.6371 - val_acc: 0.4935\n",
      "CPU times: user 8min 13s, sys: 47.4 s, total: 9min 1s\n",
      "Wall time: 3min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a32e791d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.43      0.54        44\n",
      "           1       0.60      0.47      0.52        45\n",
      "           2       0.53      0.62      0.57        50\n",
      "           3       0.25      0.71      0.37        45\n",
      "           4       0.81      0.31      0.45        55\n",
      "           5       0.81      0.49      0.61        43\n",
      "           6       0.84      0.41      0.55        51\n",
      "           7       0.48      0.64      0.55        47\n",
      "           8       0.75      0.14      0.24        42\n",
      "           9       0.42      0.76      0.54        38\n",
      "\n",
      "    accuracy                           0.49       460\n",
      "   macro avg       0.62      0.50      0.49       460\n",
      "weighted avg       0.63      0.49      0.50       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we can see normalising spectrograms is the way to go. Let's use it by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 41s, sys: 3.37 s, total: 2min 44s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88        44\n",
      "           1       0.93      0.87      0.90        45\n",
      "           2       0.57      0.94      0.71        50\n",
      "           3       0.87      0.44      0.59        45\n",
      "           4       1.00      0.89      0.94        55\n",
      "           5       0.85      0.95      0.90        43\n",
      "           6       0.56      0.69      0.62        51\n",
      "           7       0.80      0.85      0.82        47\n",
      "           8       0.76      0.60      0.67        42\n",
      "           9       0.96      0.63      0.76        38\n",
      "\n",
      "    accuracy                           0.78       460\n",
      "   macro avg       0.82      0.77      0.78       460\n",
      "weighted avg       0.81      0.78      0.78       460\n",
      "\n",
      "CPU times: user 35.4 s, sys: 725 ms, total: 36.1 s\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_preparation.load_labels(paths=['recordings', 'output'], label_type=\"speakers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neural networks it is not possible to pass the labels as-is: we need to transform them in numbers. The safest way is through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, target_names = data_preparation.transform_categorical_y(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, y, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,143\n",
      "Trainable params: 493,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(7, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 19s 10ms/sample - loss: 1.8304 - acc: 0.2543 - val_loss: 1.7058 - val_acc: 0.2761\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 19s 10ms/sample - loss: 1.6253 - acc: 0.4011 - val_loss: 1.4992 - val_acc: 0.5891\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 17s 9ms/sample - loss: 1.4276 - acc: 0.5326 - val_loss: 1.2803 - val_acc: 0.5891\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 17s 9ms/sample - loss: 1.2359 - acc: 0.5962 - val_loss: 1.1408 - val_acc: 0.6457\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 17s 9ms/sample - loss: 1.0736 - acc: 0.6299 - val_loss: 1.0031 - val_acc: 0.6283\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 17s 9ms/sample - loss: 0.9673 - acc: 0.6739 - val_loss: 0.8623 - val_acc: 0.7457\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 17s 9ms/sample - loss: 0.8596 - acc: 0.7179 - val_loss: 0.6445 - val_acc: 0.8130\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 17s 9ms/sample - loss: 0.7431 - acc: 0.7587 - val_loss: 0.6610 - val_acc: 0.8043\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 17s 9ms/sample - loss: 0.6635 - acc: 0.7712 - val_loss: 0.6191 - val_acc: 0.7935\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 17s 9ms/sample - loss: 0.5853 - acc: 0.8043 - val_loss: 0.7802 - val_acc: 0.6913\n",
      "CPU times: user 8min 8s, sys: 43.6 s, total: 8min 52s\n",
      "Wall time: 2min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a54a1ffd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.74      0.80        19\n",
      "           1       0.67      0.61      0.64        23\n",
      "           2       0.54      0.97      0.69        98\n",
      "           3       0.83      0.50      0.62        30\n",
      "           4       1.00      0.18      0.31        94\n",
      "           5       0.70      1.00      0.82        98\n",
      "           6       0.92      0.66      0.77        98\n",
      "\n",
      "    accuracy                           0.69       460\n",
      "   macro avg       0.79      0.67      0.66       460\n",
      "weighted avg       0.79      0.69      0.65       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper - batch_normalisation=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 63, 156, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 14, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 35)                140       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,947\n",
      "Trainable params: 493,545\n",
      "Non-trainable params: 402\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(7, input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1840 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "1840/1840 [==============================] - 43s 24ms/sample - loss: 1.0276 - acc: 0.6614 - val_loss: 1.8044 - val_acc: 0.2109\n",
      "Epoch 2/10\n",
      "1840/1840 [==============================] - 51s 28ms/sample - loss: 0.5638 - acc: 0.8397 - val_loss: 1.8515 - val_acc: 0.2500\n",
      "Epoch 3/10\n",
      "1840/1840 [==============================] - 58s 32ms/sample - loss: 0.3764 - acc: 0.9011 - val_loss: 1.8848 - val_acc: 0.3565\n",
      "Epoch 4/10\n",
      "1840/1840 [==============================] - 57s 31ms/sample - loss: 0.3048 - acc: 0.9234 - val_loss: 1.7145 - val_acc: 0.3543\n",
      "Epoch 5/10\n",
      "1840/1840 [==============================] - 65s 35ms/sample - loss: 0.2468 - acc: 0.9478 - val_loss: 1.5936 - val_acc: 0.3370\n",
      "Epoch 6/10\n",
      "1840/1840 [==============================] - 63s 34ms/sample - loss: 0.1989 - acc: 0.9565 - val_loss: 1.1980 - val_acc: 0.5022\n",
      "Epoch 7/10\n",
      "1840/1840 [==============================] - 77s 42ms/sample - loss: 0.1780 - acc: 0.9652 - val_loss: 0.8366 - val_acc: 0.7478\n",
      "Epoch 8/10\n",
      "1840/1840 [==============================] - 63s 34ms/sample - loss: 0.1447 - acc: 0.9750 - val_loss: 0.5713 - val_acc: 0.8674\n",
      "Epoch 9/10\n",
      "1840/1840 [==============================] - 46s 25ms/sample - loss: 0.1397 - acc: 0.9799 - val_loss: 0.3830 - val_acc: 0.9087\n",
      "Epoch 10/10\n",
      "1840/1840 [==============================] - 42s 23ms/sample - loss: 0.1411 - acc: 0.9685 - val_loss: 0.3660 - val_acc: 0.9196\n",
      "CPU times: user 18min 28s, sys: 3min 37s, total: 22min 6s\n",
      "Wall time: 9min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a55990790>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       1.00      0.79      0.88        19\n",
      "        gian       1.00      0.48      0.65        23\n",
      "     jackson       0.97      0.92      0.94        98\n",
      "      khaled       0.84      0.90      0.87        30\n",
      "     nicolas       0.99      0.99      0.99        94\n",
      "        theo       0.97      0.92      0.94        98\n",
      "    yweweler       0.80      0.99      0.88        98\n",
      "\n",
      "    accuracy                           0.92       460\n",
      "   macro avg       0.94      0.85      0.88       460\n",
      "weighted avg       0.93      0.92      0.92       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "## Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from recordings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8662d204e1c4c19afcf00d5f9bbc37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from augmentation_recs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b685d1b487a342eca5a75b6f145687be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3302.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_augm_recordings = data_preparation.load_recordings(paths=['recordings', 'augmentation_recs'], label_type=\"speaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augm_pad_recordings = data_preparation.pad_zeros(data_augm_recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augm_spects = [data_preparation.compute_spectrogram(x, normalize=True) for x in data_augm_pad_recordings]\n",
    "data_augm_spects = np.array(data_augm_spects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augm_labels = data_preparation.load_labels(paths=['recordings', 'augmentation_recs'], label_type=\"speaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, target_names = data_preparation.transform_categorical_y(data_augm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(data_augm_spects, y, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,143\n",
      "Trainable params: 493,143\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(7, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3040 samples, validate on 760 samples\n",
      "Epoch 1/10\n",
      "3040/3040 [==============================] - 38s 13ms/sample - loss: 1.7475 - acc: 0.2451 - val_loss: 1.4804 - val_acc: 0.4895\n",
      "Epoch 2/10\n",
      "3040/3040 [==============================] - 30s 10ms/sample - loss: 1.5013 - acc: 0.4010 - val_loss: 1.2268 - val_acc: 0.6066\n",
      "Epoch 3/10\n",
      "3040/3040 [==============================] - 41s 13ms/sample - loss: 1.3496 - acc: 0.4625 - val_loss: 1.1342 - val_acc: 0.5974\n",
      "Epoch 4/10\n",
      "3040/3040 [==============================] - 39s 13ms/sample - loss: 1.2153 - acc: 0.5217 - val_loss: 0.9843 - val_acc: 0.5868\n",
      "Epoch 5/10\n",
      "3040/3040 [==============================] - 30s 10ms/sample - loss: 1.1176 - acc: 0.5530 - val_loss: 0.8382 - val_acc: 0.7013\n",
      "Epoch 6/10\n",
      "3040/3040 [==============================] - 28s 9ms/sample - loss: 1.0032 - acc: 0.5987 - val_loss: 0.7601 - val_acc: 0.6974\n",
      "Epoch 7/10\n",
      "3040/3040 [==============================] - 29s 9ms/sample - loss: 0.9146 - acc: 0.6359 - val_loss: 0.6581 - val_acc: 0.7605\n",
      "Epoch 8/10\n",
      "3040/3040 [==============================] - 28s 9ms/sample - loss: 0.8305 - acc: 0.6687 - val_loss: 0.5315 - val_acc: 0.8342\n",
      "Epoch 9/10\n",
      "3040/3040 [==============================] - 28s 9ms/sample - loss: 0.7282 - acc: 0.7141 - val_loss: 0.4887 - val_acc: 0.8684\n",
      "Epoch 10/10\n",
      "3040/3040 [==============================] - 33s 11ms/sample - loss: 0.6803 - acc: 0.7385 - val_loss: 0.4444 - val_acc: 0.8355\n",
      "CPU times: user 13min 34s, sys: 1min 16s, total: 14min 51s\n",
      "Wall time: 5min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a55498b90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       0.88      0.60      0.71       125\n",
      "        gian       0.66      0.85      0.74       119\n",
      "     jackson       0.97      0.84      0.90        93\n",
      "      khaled       0.78      0.87      0.82       108\n",
      "     nicolas       0.92      0.97      0.95        98\n",
      "        theo       0.87      0.91      0.89       110\n",
      "    yweweler       0.88      0.86      0.87       107\n",
      "\n",
      "    accuracy                           0.84       760\n",
      "   macro avg       0.85      0.84      0.84       760\n",
      "weighted avg       0.85      0.84      0.83       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch_normalization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 63, 156, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 14, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 70)                457030    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 35)                140       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 7)                 252       \n",
      "=================================================================\n",
      "Total params: 493,947\n",
      "Trainable params: 493,545\n",
      "Non-trainable params: 402\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(7, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3040 samples, validate on 760 samples\n",
      "Epoch 1/10\n",
      "3040/3040 [==============================] - 74s 24ms/sample - loss: 1.1932 - acc: 0.5793 - val_loss: 2.1440 - val_acc: 0.2684\n",
      "Epoch 2/10\n",
      "3040/3040 [==============================] - 70s 23ms/sample - loss: 0.6990 - acc: 0.7859 - val_loss: 2.4205 - val_acc: 0.3250\n",
      "Epoch 3/10\n",
      "3040/3040 [==============================] - 70s 23ms/sample - loss: 0.5043 - acc: 0.8625 - val_loss: 2.1499 - val_acc: 0.3868\n",
      "Epoch 4/10\n",
      "3040/3040 [==============================] - 68s 22ms/sample - loss: 0.3844 - acc: 0.9020 - val_loss: 1.7557 - val_acc: 0.5197\n",
      "Epoch 5/10\n",
      "3040/3040 [==============================] - 72s 24ms/sample - loss: 0.3063 - acc: 0.9247 - val_loss: 0.9293 - val_acc: 0.7829\n",
      "Epoch 6/10\n",
      "3040/3040 [==============================] - 72s 24ms/sample - loss: 0.2464 - acc: 0.9510 - val_loss: 0.4243 - val_acc: 0.8895\n",
      "Epoch 7/10\n",
      "3040/3040 [==============================] - 71s 23ms/sample - loss: 0.2207 - acc: 0.9487 - val_loss: 0.1433 - val_acc: 0.9684\n",
      "Epoch 8/10\n",
      "3040/3040 [==============================] - 79s 26ms/sample - loss: 0.2001 - acc: 0.9516 - val_loss: 0.1290 - val_acc: 0.9776\n",
      "Epoch 9/10\n",
      "3040/3040 [==============================] - 70s 23ms/sample - loss: 0.1682 - acc: 0.9576 - val_loss: 0.1144 - val_acc: 0.9763\n",
      "Epoch 10/10\n",
      "3040/3040 [==============================] - 69s 23ms/sample - loss: 0.1606 - acc: 0.9635 - val_loss: 0.1917 - val_acc: 0.9237\n",
      "CPU times: user 29min 26s, sys: 5min 26s, total: 34min 52s\n",
      "Wall time: 11min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5ba51f90>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       1.00      0.85      0.92       125\n",
      "        gian       0.98      0.82      0.89       119\n",
      "     jackson       1.00      0.85      0.92        93\n",
      "      khaled       0.69      1.00      0.82       108\n",
      "     nicolas       1.00      1.00      1.00        98\n",
      "        theo       0.95      0.99      0.97       110\n",
      "    yweweler       0.98      0.98      0.98       107\n",
      "\n",
      "    accuracy                           0.92       760\n",
      "   macro avg       0.94      0.93      0.93       760\n",
      "weighted avg       0.94      0.92      0.93       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different architecture\n",
    "Let's change a bit the architecture and see if we can improve scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 77, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 33152)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               4243584   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 4,277,863\n",
      "Trainable params: 4,277,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(7, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3040 samples, validate on 760 samples\n",
      "Epoch 1/10\n",
      "3040/3040 [==============================] - 59s 19ms/sample - loss: 1.4421 - acc: 0.4313 - val_loss: 1.0588 - val_acc: 0.5842\n",
      "Epoch 2/10\n",
      "3040/3040 [==============================] - 68s 23ms/sample - loss: 1.0405 - acc: 0.6046 - val_loss: 0.8022 - val_acc: 0.6697\n",
      "Epoch 3/10\n",
      "3040/3040 [==============================] - 91s 30ms/sample - loss: 0.8146 - acc: 0.6947 - val_loss: 0.7040 - val_acc: 0.7487\n",
      "Epoch 4/10\n",
      "3040/3040 [==============================] - 82s 27ms/sample - loss: 0.6460 - acc: 0.7612 - val_loss: 0.5684 - val_acc: 0.7921\n",
      "Epoch 5/10\n",
      "3040/3040 [==============================] - 73s 24ms/sample - loss: 0.5435 - acc: 0.7898 - val_loss: 0.6444 - val_acc: 0.7579\n",
      "Epoch 6/10\n",
      "3040/3040 [==============================] - 59s 19ms/sample - loss: 0.4293 - acc: 0.8408 - val_loss: 0.2771 - val_acc: 0.9329\n",
      "Epoch 7/10\n",
      "3040/3040 [==============================] - 57s 19ms/sample - loss: 0.3211 - acc: 0.8908 - val_loss: 0.3145 - val_acc: 0.8816\n",
      "Epoch 8/10\n",
      "3040/3040 [==============================] - 57s 19ms/sample - loss: 0.2528 - acc: 0.9164 - val_loss: 0.2173 - val_acc: 0.9263\n",
      "Epoch 9/10\n",
      "3040/3040 [==============================] - 57s 19ms/sample - loss: 0.2157 - acc: 0.9326 - val_loss: 0.1281 - val_acc: 0.9658\n",
      "Epoch 10/10\n",
      "3040/3040 [==============================] - 57s 19ms/sample - loss: 0.1674 - acc: 0.9497 - val_loss: 0.1148 - val_acc: 0.9711\n",
      "CPU times: user 27min 20s, sys: 3min 47s, total: 31min 7s\n",
      "Wall time: 11min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5a8beb10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      alinda       0.96      0.98      0.97       125\n",
      "        gian       0.91      0.97      0.94       119\n",
      "     jackson       0.99      1.00      0.99        93\n",
      "      khaled       1.00      0.90      0.95       108\n",
      "     nicolas       1.00      0.98      0.99        98\n",
      "        theo       0.98      0.99      0.99       110\n",
      "    yweweler       0.98      0.97      0.98       107\n",
      "\n",
      "    accuracy                           0.97       760\n",
      "   macro avg       0.97      0.97      0.97       760\n",
      "weighted avg       0.97      0.97      0.97       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- Set random seed\n",
    "- Data augmentation also for digit recognition\n",
    "- Use only original recordings in test set of augmented scenario\n",
    "- Use proper validation set (optional: also crossvalidation) for picking best models and params\n",
    "- Augment also recording dataset digit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
