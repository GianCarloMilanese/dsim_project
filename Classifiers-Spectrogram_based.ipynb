{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cnn_models\n",
    "import data_preparation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "import data_augmentation\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "tf.random.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load recordings\n",
    "## STANDARD RECORDINGS - No spectrogram normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from recordings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ed2c22b1e444be8de1e8009ea87119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from output\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e2d77eecf941a1a2b1082a3e4fdf48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recordings = data_preparation.load_recordings(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw recordings have different lengths? Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2784 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, recordings))[0]\n",
    "max_y = max(map(np.shape, recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! They vary a lot. For this reason we can add 0s at the beginning and at the end in order to uniform them\n",
    "\n",
    "**TO DO: Another strategy may be to vary spectrogram params so that spectograms will have the same length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_zeros >>>\n",
      "pad_zeros <<<\n"
     ]
    }
   ],
   "source": [
    "pad_recordings = data_preparation.pad_zeros(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the range now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50335 50335\n"
     ]
    }
   ],
   "source": [
    "min_y = min(map(np.shape, pad_recordings))[0]\n",
    "max_y = max(map(np.shape, pad_recordings))[0]\n",
    "print(min_y, max_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute spectograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spects = [data_preparation.compute_spectrogram(x) for x in pad_recordings]\n",
    "spects = np.array(spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure worked as expected! we can now move on to the prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_speakers = data_preparation.load_labels(paths=['recordings', 'output'], label_type=\"speakers\")\n",
    "labels_digits = data_preparation.load_labels(paths=['recordings', 'output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_spects = [data_preparation.compute_spectrogram(x, normalize=True) for x in pad_recordings]\n",
    "norm_spects = np.array(norm_spects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 7min 3s, sys: 23 s, total: 7min 26s\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_digit, y_train_digit, X_test_digit, y_test_digit = data_preparation.prepare_augmented_recordings(audio_dirs= ['output', 'recordings'],\n",
    "                             y_type= ['digit', 'digit'],\n",
    "                             n_category_test=15,\n",
    "                             include_pitch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 23100, 23100, 300, 300\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}\".format(len(X_train_digit),\n",
    "                                                 len(y_train_digit),\n",
    "                                                 len(X_test_digit),\n",
    "                                                 len(y_test_digit),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion_done!\n",
      "compute_spectrograms >>>\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "pad_zeros >>>\n",
      "pad_zeros <<<\n",
      "Padding done\n",
      "compute_spectrograms <<<\n",
      "CPU times: user 6min 52s, sys: 21 s, total: 7min 13s\n",
      "Wall time: 5min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_speaker, y_train_speaker, X_test_speaker, y_test_speaker = data_preparation.prepare_augmented_recordings(audio_dirs= ['output', 'recordings'],\n",
    "                             y_type= ['speakers_us', 'speakers_default'],\n",
    "                             n_category_test=30,\n",
    "                             include_pitch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths : 23760, 23760, 240, 240\n"
     ]
    }
   ],
   "source": [
    "print(\"Lengths : {}, {}, {}, {}\".format(len(X_train_speaker),\n",
    "                                                 len(y_train_speaker),\n",
    "                                                 len(X_test_speaker),\n",
    "                                                 len(y_test_speaker)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard recordings\n",
    "## Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_preparation.split_train_test_baseline_spectrograms(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 56s, sys: 1.77 s, total: 3min 58s\n",
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.27      0.42        41\n",
      "           1       0.51      0.50      0.51        40\n",
      "           2       0.81      0.26      0.39        50\n",
      "           3       0.52      0.27      0.35        52\n",
      "           4       0.27      0.48      0.35        48\n",
      "           5       0.94      0.36      0.52        45\n",
      "           6       0.16      0.55      0.25        62\n",
      "           7       0.72      0.39      0.51        46\n",
      "           8       0.85      0.35      0.49        49\n",
      "           9       0.86      0.51      0.64        47\n",
      "\n",
      "    accuracy                           0.40       480\n",
      "   macro avg       0.66      0.39      0.44       480\n",
      "weighted avg       0.64      0.40      0.43       480\n",
      "\n",
      "CPU times: user 37.9 s, sys: 260 ms, total: 38.1 s\n",
      "Wall time: 38.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 2.48 s, total: 3min 2s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85        41\n",
      "           1       0.79      0.82      0.80        40\n",
      "           2       0.56      0.90      0.69        50\n",
      "           3       0.77      0.44      0.56        52\n",
      "           4       0.93      0.85      0.89        48\n",
      "           5       0.87      0.73      0.80        45\n",
      "           6       0.61      0.74      0.67        62\n",
      "           7       0.70      0.85      0.76        46\n",
      "           8       0.82      0.73      0.77        49\n",
      "           9       0.97      0.64      0.77        47\n",
      "\n",
      "    accuracy                           0.75       480\n",
      "   macro avg       0.79      0.75      0.76       480\n",
      "weighted avg       0.78      0.75      0.75       480\n",
      "\n",
      "CPU times: user 36.7 s, sys: 337 ms, total: 37 s\n",
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 480 samples\n",
      "WARNING:tensorflow:From /Users/kappa/opt/miniconda3/envs/dsim/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1920/1920 [==============================] - 24s 12ms/sample - loss: 2.2689 - acc: 0.1703 - val_loss: 2.2025 - val_acc: 0.2646\n",
      "Epoch 2/10\n",
      "1920/1920 [==============================] - 26s 13ms/sample - loss: 2.1098 - acc: 0.2615 - val_loss: 1.9102 - val_acc: 0.4333\n",
      "Epoch 3/10\n",
      "1920/1920 [==============================] - 23s 12ms/sample - loss: 1.8666 - acc: 0.3516 - val_loss: 1.6058 - val_acc: 0.5292\n",
      "Epoch 4/10\n",
      "1920/1920 [==============================] - 20s 11ms/sample - loss: 1.6297 - acc: 0.4187 - val_loss: 1.3857 - val_acc: 0.5188\n",
      "Epoch 5/10\n",
      "1920/1920 [==============================] - 22s 12ms/sample - loss: 1.4626 - acc: 0.4927 - val_loss: 1.1161 - val_acc: 0.6542\n",
      "Epoch 6/10\n",
      "1920/1920 [==============================] - 28s 14ms/sample - loss: 1.3157 - acc: 0.5365 - val_loss: 1.0770 - val_acc: 0.6146\n",
      "Epoch 7/10\n",
      "1920/1920 [==============================] - 26s 13ms/sample - loss: 1.1919 - acc: 0.5781 - val_loss: 1.0792 - val_acc: 0.6375\n",
      "Epoch 8/10\n",
      "1920/1920 [==============================] - 27s 14ms/sample - loss: 1.0762 - acc: 0.6307 - val_loss: 0.8164 - val_acc: 0.7604\n",
      "Epoch 9/10\n",
      "1920/1920 [==============================] - 21s 11ms/sample - loss: 1.0394 - acc: 0.6500 - val_loss: 0.7421 - val_acc: 0.7708\n",
      "Epoch 10/10\n",
      "1920/1920 [==============================] - 20s 10ms/sample - loss: 0.9213 - acc: 0.6750 - val_loss: 0.6850 - val_acc: 0.8000\n",
      "CPU times: user 8min 40s, sys: 55.7 s, total: 9min 35s\n",
      "Wall time: 3min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3f7642d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        41\n",
      "           1       0.94      0.75      0.83        40\n",
      "           2       0.89      0.82      0.85        50\n",
      "           3       0.77      0.63      0.69        52\n",
      "           4       0.94      0.92      0.93        48\n",
      "           5       0.86      0.71      0.78        45\n",
      "           6       0.87      0.65      0.74        62\n",
      "           7       0.63      0.96      0.76        46\n",
      "           8       0.71      0.76      0.73        49\n",
      "           9       0.68      0.94      0.79        47\n",
      "\n",
      "    accuracy                           0.80       480\n",
      "   macro avg       0.82      0.81      0.80       480\n",
      "weighted avg       0.82      0.80      0.80       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(spects, labels_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               652900    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 691,836\n",
      "Trainable params: 691,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1920/1920 [==============================] - 23s 12ms/sample - loss: 2.3112 - acc: 0.1542 - val_loss: 2.1489 - val_acc: 0.2792\n",
      "Epoch 2/10\n",
      "1920/1920 [==============================] - 20s 10ms/sample - loss: 2.1599 - acc: 0.2438 - val_loss: 2.0400 - val_acc: 0.3562\n",
      "Epoch 3/10\n",
      "1920/1920 [==============================] - 20s 10ms/sample - loss: 2.1303 - acc: 0.2620 - val_loss: 2.0265 - val_acc: 0.3042\n",
      "Epoch 4/10\n",
      "1920/1920 [==============================] - 20s 11ms/sample - loss: 2.0835 - acc: 0.2646 - val_loss: 2.0087 - val_acc: 0.3042\n",
      "Epoch 5/10\n",
      "1920/1920 [==============================] - 21s 11ms/sample - loss: 2.0202 - acc: 0.3010 - val_loss: 1.9423 - val_acc: 0.3250\n",
      "Epoch 6/10\n",
      "1920/1920 [==============================] - 21s 11ms/sample - loss: 1.9777 - acc: 0.3255 - val_loss: 1.8864 - val_acc: 0.3521\n",
      "Epoch 7/10\n",
      "1920/1920 [==============================] - 20s 10ms/sample - loss: 1.9308 - acc: 0.3328 - val_loss: 1.8352 - val_acc: 0.4042\n",
      "Epoch 8/10\n",
      "1920/1920 [==============================] - 20s 10ms/sample - loss: 1.8826 - acc: 0.3495 - val_loss: 1.7509 - val_acc: 0.4333\n",
      "Epoch 9/10\n",
      "1920/1920 [==============================] - 20s 10ms/sample - loss: 1.8291 - acc: 0.3708 - val_loss: 1.7428 - val_acc: 0.4354\n",
      "Epoch 10/10\n",
      "1920/1920 [==============================] - 26s 13ms/sample - loss: 1.8311 - acc: 0.3609 - val_loss: 1.6808 - val_acc: 0.4417\n",
      "CPU times: user 8min 29s, sys: 51.7 s, total: 9min 21s\n",
      "Wall time: 3min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a355c7750>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.34      0.47        41\n",
      "           1       0.40      0.53      0.46        40\n",
      "           2       0.41      0.78      0.54        50\n",
      "           3       0.38      0.29      0.33        52\n",
      "           4       0.92      0.25      0.39        48\n",
      "           5       0.70      0.31      0.43        45\n",
      "           6       0.64      0.37      0.47        62\n",
      "           7       0.71      0.37      0.49        46\n",
      "           8       0.55      0.24      0.34        49\n",
      "           9       0.28      0.96      0.43        47\n",
      "\n",
      "    accuracy                           0.44       480\n",
      "   macro avg       0.58      0.44      0.43       480\n",
      "weighted avg       0.58      0.44      0.43       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what we can see normalising spectrograms is the way to go. Let's use it by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speakers\n",
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_preparation.split_train_test_baseline_spectrograms(norm_spects, labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 1s, sys: 1.59 s, total: 2min 3s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = SVC(kernel='rbf', class_weight='balanced', gamma=\"auto\")\n",
    "clf1 = clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.87      0.93        15\n",
      "      alinda       0.93      1.00      0.97        14\n",
      "        gian       0.87      1.00      0.93        20\n",
      "     jackson       0.98      0.95      0.97       109\n",
      "      khaled       0.78      1.00      0.88        14\n",
      "     nicolas       0.99      0.95      0.97        91\n",
      "        theo       0.75      0.87      0.81       106\n",
      "    yweweler       0.89      0.77      0.82       111\n",
      "\n",
      "    accuracy                           0.89       480\n",
      "   macro avg       0.90      0.92      0.91       480\n",
      "weighted avg       0.90      0.89      0.89       480\n",
      "\n",
      "CPU times: user 33.5 s, sys: 256 ms, total: 33.8 s\n",
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = clf1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neural networks it is not possible to pass the labels as-is: we need to transform them in numbers. The safest way is through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, target_names = data_preparation.transform_categorical_y(labels_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, input_shape = data_preparation.split_train_test_nn(norm_spects, y, number_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 80)                522320    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 559,264\n",
      "Trainable params: 559,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1920/1920 [==============================] - 22s 12ms/sample - loss: 1.9018 - acc: 0.2453 - val_loss: 1.6902 - val_acc: 0.3854\n",
      "Epoch 2/10\n",
      "1920/1920 [==============================] - 19s 10ms/sample - loss: 1.7141 - acc: 0.3979 - val_loss: 1.5000 - val_acc: 0.4229\n",
      "Epoch 3/10\n",
      "1920/1920 [==============================] - 20s 10ms/sample - loss: 1.5235 - acc: 0.5109 - val_loss: 1.1671 - val_acc: 0.7000\n",
      "Epoch 4/10\n",
      "1920/1920 [==============================] - 19s 10ms/sample - loss: 1.3174 - acc: 0.5771 - val_loss: 0.9580 - val_acc: 0.7042\n",
      "Epoch 5/10\n",
      "1920/1920 [==============================] - 21s 11ms/sample - loss: 1.1541 - acc: 0.6099 - val_loss: 0.7775 - val_acc: 0.7500\n",
      "Epoch 6/10\n",
      "1920/1920 [==============================] - 19s 10ms/sample - loss: 1.0102 - acc: 0.6578 - val_loss: 0.6683 - val_acc: 0.7708\n",
      "Epoch 7/10\n",
      "1920/1920 [==============================] - 19s 10ms/sample - loss: 0.9052 - acc: 0.6969 - val_loss: 0.6118 - val_acc: 0.7833\n",
      "Epoch 8/10\n",
      "1920/1920 [==============================] - 20s 10ms/sample - loss: 0.8245 - acc: 0.7177 - val_loss: 0.5341 - val_acc: 0.8125\n",
      "Epoch 9/10\n",
      "1920/1920 [==============================] - 20s 10ms/sample - loss: 0.6916 - acc: 0.7542 - val_loss: 0.5412 - val_acc: 0.8188\n",
      "Epoch 10/10\n",
      "1920/1920 [==============================] - 22s 11ms/sample - loss: 0.6471 - acc: 0.7760 - val_loss: 0.5440 - val_acc: 0.8104\n",
      "CPU times: user 8min 26s, sys: 44.1 s, total: 9min 10s\n",
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3ca40dd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        15\n",
      "           1       0.30      0.50      0.38        14\n",
      "           2       0.71      0.25      0.37        20\n",
      "           3       0.99      0.72      0.84       109\n",
      "           4       0.75      0.43      0.55        14\n",
      "           5       0.79      0.97      0.87        91\n",
      "           6       0.81      0.87      0.84       106\n",
      "           7       0.83      0.91      0.87       111\n",
      "\n",
      "    accuracy                           0.81       480\n",
      "   macro avg       0.74      0.67      0.68       480\n",
      "weighted avg       0.83      0.81      0.81       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper - batch_normalisation=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 63, 156, 32)       544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 63, 156, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 30, 77, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 37, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 14, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 6, 17, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6528)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 80)                522320    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 560,128\n",
      "Trainable params: 559,696\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1920 samples, validate on 480 samples\n",
      "Epoch 1/10\n",
      "1920/1920 [==============================] - 48s 25ms/sample - loss: 1.1804 - acc: 0.6203 - val_loss: 1.7356 - val_acc: 0.4292\n",
      "Epoch 2/10\n",
      "1920/1920 [==============================] - 50s 26ms/sample - loss: 0.6233 - acc: 0.8229 - val_loss: 1.6220 - val_acc: 0.4333\n",
      "Epoch 3/10\n",
      "1920/1920 [==============================] - 48s 25ms/sample - loss: 0.4460 - acc: 0.8760 - val_loss: 1.6398 - val_acc: 0.4271\n",
      "Epoch 4/10\n",
      "1920/1920 [==============================] - 49s 26ms/sample - loss: 0.3360 - acc: 0.9141 - val_loss: 1.4018 - val_acc: 0.4479\n",
      "Epoch 5/10\n",
      "1920/1920 [==============================] - 59s 31ms/sample - loss: 0.2615 - acc: 0.9427 - val_loss: 1.2584 - val_acc: 0.4604\n",
      "Epoch 6/10\n",
      "1920/1920 [==============================] - 53s 28ms/sample - loss: 0.2195 - acc: 0.9510 - val_loss: 1.0832 - val_acc: 0.5292\n",
      "Epoch 7/10\n",
      "1920/1920 [==============================] - 53s 28ms/sample - loss: 0.1957 - acc: 0.9563 - val_loss: 0.9620 - val_acc: 0.6229\n",
      "Epoch 8/10\n",
      "1920/1920 [==============================] - 59s 31ms/sample - loss: 0.1579 - acc: 0.9672 - val_loss: 0.4672 - val_acc: 0.8875\n",
      "Epoch 9/10\n",
      "1920/1920 [==============================] - 51s 27ms/sample - loss: 0.1365 - acc: 0.9734 - val_loss: 0.2135 - val_acc: 0.9563\n",
      "Epoch 10/10\n",
      "1920/1920 [==============================] - 50s 26ms/sample - loss: 0.1220 - acc: 0.9760 - val_loss: 0.2530 - val_acc: 0.9250\n",
      "CPU times: user 18min 41s, sys: 3min 21s, total: 22min 2s\n",
      "Wall time: 8min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3e565250>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.93      0.97        15\n",
      "      alinda       1.00      0.36      0.53        14\n",
      "        gian       0.70      0.80      0.74        20\n",
      "     jackson       0.83      1.00      0.91       109\n",
      "      khaled       1.00      0.86      0.92        14\n",
      "     nicolas       1.00      0.88      0.94        91\n",
      "        theo       0.99      0.92      0.95       106\n",
      "        theo       0.95      1.00      0.97       111\n",
      "\n",
      "    accuracy                           0.93       480\n",
      "   macro avg       0.93      0.84      0.87       480\n",
      "weighted avg       0.94      0.93      0.92       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "## Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y_train_speaker = enc.fit_transform(np.array(y_train_speaker).reshape(-1, 1)).toarray()\n",
    "y_test_speaker = enc.transform(np.array(y_test_speaker).reshape(-1, 1)).toarray()\n",
    "label_0 = enc.inverse_transform(np.array([1, 0, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_1 = enc.inverse_transform(np.array([0, 1, 0, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_2 = enc.inverse_transform(np.array([0, 0, 1, 0, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_3 = enc.inverse_transform(np.array([0, 0, 0, 1, 0, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_4 = enc.inverse_transform(np.array([0, 0, 0, 0, 1, 0, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_5 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 1, 0, 0]).reshape(1, -1))[0][0]\n",
    "label_6 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 1, 0]).reshape(1, -1))[0][0]\n",
    "label_7 = enc.inverse_transform(np.array([0, 0, 0, 0, 0, 0, 0, 1]).reshape(1, -1))[0][0]\n",
    "target_names = [label_0, label_1, label_2, label_3, label_4, label_5, label_6, label_7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker = np.array(X_train_speaker)\n",
    "X_test_speaker = np.array(X_test_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_speaker = X_train_speaker.reshape(X_train_speaker.shape[0],\n",
    "                                          X_train_speaker.shape[1],\n",
    "                                          X_train_speaker.shape[2],\n",
    "                                          1)\n",
    "X_test_speaker = X_test_speaker.reshape(X_test_speaker.shape[0], X_test_speaker.shape[1], X_test_speaker.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train_speaker.shape[1], X_train_speaker.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 80)                153680    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 190,624\n",
      "Trainable params: 190,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23760 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "23760/23760 [==============================] - 82s 3ms/sample - loss: 1.3939 - acc: 0.4953 - val_loss: 1.5296 - val_acc: 0.4542\n",
      "Epoch 2/10\n",
      "23760/23760 [==============================] - 78s 3ms/sample - loss: 0.9199 - acc: 0.6582 - val_loss: 1.1219 - val_acc: 0.5667\n",
      "Epoch 3/10\n",
      "23760/23760 [==============================] - 79s 3ms/sample - loss: 0.7097 - acc: 0.7293 - val_loss: 0.7211 - val_acc: 0.7042\n",
      "Epoch 4/10\n",
      "23760/23760 [==============================] - 79s 3ms/sample - loss: 0.6206 - acc: 0.7652 - val_loss: 0.6700 - val_acc: 0.7583\n",
      "Epoch 5/10\n",
      "23760/23760 [==============================] - 78s 3ms/sample - loss: 0.5283 - acc: 0.7982 - val_loss: 0.4975 - val_acc: 0.8083\n",
      "Epoch 6/10\n",
      "23760/23760 [==============================] - 93s 4ms/sample - loss: 0.4776 - acc: 0.8191 - val_loss: 0.6120 - val_acc: 0.7250\n",
      "Epoch 7/10\n",
      "23760/23760 [==============================] - 138s 6ms/sample - loss: 0.4243 - acc: 0.8393 - val_loss: 0.3311 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "23760/23760 [==============================] - 113s 5ms/sample - loss: 0.3921 - acc: 0.8503 - val_loss: 0.2776 - val_acc: 0.9167\n",
      "Epoch 9/10\n",
      "23760/23760 [==============================] - 99s 4ms/sample - loss: 0.3583 - acc: 0.8659 - val_loss: 0.2195 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "23760/23760 [==============================] - 109s 5ms/sample - loss: 0.3272 - acc: 0.8754 - val_loss: 0.1736 - val_acc: 0.9417\n",
      "CPU times: user 32min 42s, sys: 2min 51s, total: 35min 33s\n",
      "Wall time: 15min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3bb3efd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test_speaker, y_test_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       0.93      0.93      0.93        30\n",
      "      alinda       0.93      0.93      0.93        30\n",
      "        gian       1.00      0.97      0.98        30\n",
      "     jackson       0.83      1.00      0.91        30\n",
      "      khaled       1.00      0.77      0.87        30\n",
      "     nicolas       0.97      1.00      0.98        30\n",
      "        theo       0.97      0.93      0.95        30\n",
      "    yweweler       0.94      1.00      0.97        30\n",
      "\n",
      "    accuracy                           0.94       240\n",
      "   macro avg       0.95      0.94      0.94       240\n",
      "weighted avg       0.95      0.94      0.94       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch_normalization = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 63, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 30, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 14, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 80)                153680    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 80)                320       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 328       \n",
      "=================================================================\n",
      "Total params: 191,488\n",
      "Trainable params: 191,056\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(8, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23760 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "23760/23760 [==============================] - 251s 11ms/sample - loss: 0.9276 - acc: 0.6698 - val_loss: 0.6872 - val_acc: 0.7625\n",
      "Epoch 2/10\n",
      "23760/23760 [==============================] - 225s 9ms/sample - loss: 0.5510 - acc: 0.7910 - val_loss: 0.2836 - val_acc: 0.9292\n",
      "Epoch 3/10\n",
      "23760/23760 [==============================] - 226s 10ms/sample - loss: 0.4298 - acc: 0.8372 - val_loss: 0.2189 - val_acc: 0.9292\n",
      "Epoch 4/10\n",
      "23760/23760 [==============================] - 230s 10ms/sample - loss: 0.3748 - acc: 0.8571 - val_loss: 0.2276 - val_acc: 0.9167\n",
      "Epoch 5/10\n",
      "23760/23760 [==============================] - 303s 13ms/sample - loss: 0.3342 - acc: 0.8735 - val_loss: 0.1035 - val_acc: 0.9708\n",
      "Epoch 6/10\n",
      "23760/23760 [==============================] - 341s 14ms/sample - loss: 0.2997 - acc: 0.8879 - val_loss: 0.2797 - val_acc: 0.8833\n",
      "Epoch 7/10\n",
      "23760/23760 [==============================] - 360s 15ms/sample - loss: 0.2897 - acc: 0.8893 - val_loss: 0.0795 - val_acc: 0.9833\n",
      "Epoch 8/10\n",
      "23760/23760 [==============================] - 360s 15ms/sample - loss: 0.2666 - acc: 0.8994 - val_loss: 0.1093 - val_acc: 0.9542\n",
      "Epoch 9/10\n",
      "23760/23760 [==============================] - 360s 15ms/sample - loss: 0.2604 - acc: 0.9018 - val_loss: 0.1061 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      "23760/23760 [==============================] - 302s 13ms/sample - loss: 0.2399 - acc: 0.9095 - val_loss: 0.0450 - val_acc: 0.9833\n",
      "CPU times: user 1h 17min 43s, sys: 14min 38s, total: 1h 32min 22s\n",
      "Wall time: 49min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a405949d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test_speaker, y_test_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.97      0.98        30\n",
      "      alinda       1.00      1.00      1.00        30\n",
      "        gian       1.00      0.97      0.98        30\n",
      "     jackson       0.94      1.00      0.97        30\n",
      "      khaled       1.00      0.93      0.97        30\n",
      "     nicolas       0.97      1.00      0.98        30\n",
      "        theo       0.97      1.00      0.98        30\n",
      "    yweweler       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.98       240\n",
      "   macro avg       0.98      0.98      0.98       240\n",
      "weighted avg       0.98      0.98      0.98       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different architecture\n",
    "Let's change a bit the architecture and see if we can improve scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 27, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 10752)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               1376384   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 1,410,792\n",
      "Trainable params: 1,410,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(8, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23760 samples, validate on 240 samples\n",
      "Epoch 1/10\n",
      "23760/23760 [==============================] - 212s 9ms/sample - loss: 1.0306 - acc: 0.6256 - val_loss: 0.6918 - val_acc: 0.7375\n",
      "Epoch 2/10\n",
      "23760/23760 [==============================] - 179s 8ms/sample - loss: 0.5285 - acc: 0.7957 - val_loss: 0.3108 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "23760/23760 [==============================] - 175s 7ms/sample - loss: 0.3513 - acc: 0.8658 - val_loss: 0.1635 - val_acc: 0.9500\n",
      "Epoch 4/10\n",
      "23760/23760 [==============================] - 176s 7ms/sample - loss: 0.2707 - acc: 0.8956 - val_loss: 0.1519 - val_acc: 0.9542\n",
      "Epoch 5/10\n",
      "23760/23760 [==============================] - 178s 8ms/sample - loss: 0.2200 - acc: 0.9146 - val_loss: 0.0805 - val_acc: 0.9833\n",
      "Epoch 6/10\n",
      "23760/23760 [==============================] - 179s 8ms/sample - loss: 0.1928 - acc: 0.9231 - val_loss: 0.1015 - val_acc: 0.9792\n",
      "Epoch 7/10\n",
      "23760/23760 [==============================] - 177s 7ms/sample - loss: 0.1699 - acc: 0.9328 - val_loss: 0.0808 - val_acc: 0.9792\n",
      "Epoch 8/10\n",
      "23760/23760 [==============================] - 177s 7ms/sample - loss: 0.1516 - acc: 0.9397 - val_loss: 0.1007 - val_acc: 0.9708\n",
      "CPU times: user 54min 33s, sys: 9min 28s, total: 1h 4min 2s\n",
      "Wall time: 24min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4099cbd0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_speaker, y_train_speaker,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test_speaker, y_test_speaker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ale       1.00      0.97      0.98        30\n",
      "      alinda       1.00      1.00      1.00        30\n",
      "        gian       0.97      1.00      0.98        30\n",
      "     jackson       1.00      1.00      1.00        30\n",
      "      khaled       1.00      0.97      0.98        30\n",
      "     nicolas       1.00      1.00      1.00        30\n",
      "        theo       0.94      0.97      0.95        30\n",
      "    yweweler       0.97      0.97      0.97        30\n",
      "\n",
      "    accuracy                           0.98       240\n",
      "   macro avg       0.98      0.98      0.98       240\n",
      "weighted avg       0.98      0.98      0.98       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test_speaker, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test_speaker)\n",
    "print(classification_report(Y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_digit_nn = np.array(X_train_digit)\n",
    "X_test_digit_nn = np.array(X_test_digit)\n",
    "X_train_digit_nn = X_train_digit_nn.reshape(X_train_digit_nn.shape[0], X_train_digit_nn.shape[1], X_train_digit_nn.shape[2], 1)\n",
    "X_test_digit_nn = X_test_digit_nn.reshape(X_test_digit_nn.shape[0], X_test_digit_nn.shape[1], X_test_digit_nn.shape[2], 1)\n",
    "y_train_digit_nn = tf.keras.utils.to_categorical(y_train_digit, 10)\n",
    "y_test_digit_nn = tf.keras.utils.to_categorical(y_test_digit, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train_digit_nn.shape[1], X_train_digit_nn.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 63, 56, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 30, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 14, 12, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 14, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 6, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 100)               192100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 232,020\n",
      "Trainable params: 231,528\n",
      "Non-trainable params: 492\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.paper_architecture(10, input_shape=input_shape, batch_normalisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23100 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "23100/23100 [==============================] - 216s 9ms/sample - loss: 1.5178 - acc: 0.4597 - val_loss: 0.9186 - val_acc: 0.6867\n",
      "Epoch 2/10\n",
      "23100/23100 [==============================] - 206s 9ms/sample - loss: 1.0116 - acc: 0.6526 - val_loss: 0.5175 - val_acc: 0.8400\n",
      "Epoch 3/10\n",
      "23100/23100 [==============================] - 212s 9ms/sample - loss: 0.8419 - acc: 0.7142 - val_loss: 0.3905 - val_acc: 0.9033\n",
      "Epoch 4/10\n",
      "23100/23100 [==============================] - 208s 9ms/sample - loss: 0.7701 - acc: 0.7374 - val_loss: 0.3749 - val_acc: 0.8800\n",
      "Epoch 5/10\n",
      "23100/23100 [==============================] - 221s 10ms/sample - loss: 0.6947 - acc: 0.7643 - val_loss: 0.3934 - val_acc: 0.8833\n",
      "Epoch 6/10\n",
      "23100/23100 [==============================] - 215s 9ms/sample - loss: 0.6530 - acc: 0.7807 - val_loss: 0.2742 - val_acc: 0.9167\n",
      "Epoch 7/10\n",
      "23100/23100 [==============================] - 209s 9ms/sample - loss: 0.6182 - acc: 0.7917 - val_loss: 0.3083 - val_acc: 0.8933\n",
      "Epoch 8/10\n",
      "23100/23100 [==============================] - 212s 9ms/sample - loss: 0.5848 - acc: 0.8032 - val_loss: 0.2513 - val_acc: 0.9233\n",
      "Epoch 9/10\n",
      "23100/23100 [==============================] - 243s 11ms/sample - loss: 0.5549 - acc: 0.8123 - val_loss: 0.2390 - val_acc: 0.9267\n",
      "Epoch 10/10\n",
      "23100/23100 [==============================] - 261s 11ms/sample - loss: 0.5643 - acc: 0.8099 - val_loss: 0.2338 - val_acc: 0.9233\n",
      "CPU times: user 1h 14min 34s, sys: 13min 8s, total: 1h 27min 43s\n",
      "Wall time: 36min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a446f1890>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit_nn, y_train_digit_nn,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test_digit_nn, y_test_digit_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        30\n",
      "           1       0.96      0.87      0.91        30\n",
      "           2       0.88      0.97      0.92        30\n",
      "           3       0.90      0.90      0.90        30\n",
      "           4       0.88      1.00      0.94        30\n",
      "           5       0.90      0.87      0.88        30\n",
      "           6       0.96      0.87      0.91        30\n",
      "           7       0.94      0.97      0.95        30\n",
      "           8       0.90      0.90      0.90        30\n",
      "           9       0.96      0.90      0.93        30\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.93      0.92      0.92       300\n",
      "weighted avg       0.93      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test_digit_nn, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test_digit_nn)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 63, 56, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 30, 27, 64)        32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 14, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 10752)             0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 128)               1376384   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,411,050\n",
      "Trainable params: 1,411,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_models.custom_cnn(10, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23100 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "23100/23100 [==============================] - 278s 12ms/sample - loss: 1.5071 - acc: 0.4624 - val_loss: 0.7149 - val_acc: 0.7833\n",
      "Epoch 2/10\n",
      "23100/23100 [==============================] - 208s 9ms/sample - loss: 0.9832 - acc: 0.6505 - val_loss: 0.4521 - val_acc: 0.8567\n",
      "Epoch 3/10\n",
      "23100/23100 [==============================] - 222s 10ms/sample - loss: 0.7937 - acc: 0.7180 - val_loss: 0.3445 - val_acc: 0.8933\n",
      "Epoch 4/10\n",
      "23100/23100 [==============================] - 225s 10ms/sample - loss: 0.6822 - acc: 0.7599 - val_loss: 0.2504 - val_acc: 0.9200\n",
      "Epoch 5/10\n",
      "23100/23100 [==============================] - 246s 11ms/sample - loss: 0.6088 - acc: 0.7839 - val_loss: 0.2348 - val_acc: 0.9300\n",
      "Epoch 6/10\n",
      "23100/23100 [==============================] - 216s 9ms/sample - loss: 0.5535 - acc: 0.8026 - val_loss: 0.3203 - val_acc: 0.9067\n",
      "Epoch 7/10\n",
      "23100/23100 [==============================] - 196s 8ms/sample - loss: 0.5150 - acc: 0.8172 - val_loss: 0.2015 - val_acc: 0.9467\n",
      "Epoch 8/10\n",
      "23100/23100 [==============================] - 180s 8ms/sample - loss: 0.4831 - acc: 0.8281 - val_loss: 0.1878 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "23100/23100 [==============================] - 180s 8ms/sample - loss: 0.4586 - acc: 0.8384 - val_loss: 0.1863 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "23100/23100 [==============================] - 164s 7ms/sample - loss: 0.4278 - acc: 0.8475 - val_loss: 0.2181 - val_acc: 0.9467\n",
      "CPU times: user 1h 6min 34s, sys: 11min 53s, total: 1h 18min 28s\n",
      "Wall time: 35min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a48566a90>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_digit_nn, y_train_digit_nn,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          callbacks=[callback],\n",
    "          validation_data=(X_test_digit_nn, y_test_digit_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        30\n",
      "           1       1.00      0.93      0.97        30\n",
      "           2       0.86      1.00      0.92        30\n",
      "           3       0.88      1.00      0.94        30\n",
      "           4       1.00      1.00      1.00        30\n",
      "           5       0.94      0.97      0.95        30\n",
      "           6       0.96      0.87      0.91        30\n",
      "           7       0.91      1.00      0.95        30\n",
      "           8       0.96      0.87      0.91        30\n",
      "           9       1.00      0.90      0.95        30\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.argmax(y_test_digit_nn, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict_classes(X_test_digit_nn)\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import subprocess\n",
    "\n",
    "import time\n",
    "import librosa\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "from scipy.io import wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_zeros_single_rec(rec, max_y):\n",
    "    rec = np.array(rec)\n",
    "    diff_in_y = max_y - rec.shape[0]\n",
    "    if diff_in_y > 0:\n",
    "        half_diff = int(diff_in_y/2)\n",
    "        remaining_diff = diff_in_y-half_diff\n",
    "        v = np.pad(rec, (half_diff, remaining_diff), 'constant', constant_values=0)\n",
    "        return v\n",
    "    else:\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recording(duration, rec_rate, name = \"test.wav\", output_dir = \"test/\"):\n",
    "    print(\"Ready in 3...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"2...\", end = \"\")\n",
    "    time.sleep(1)\n",
    "    print(\"1...\")\n",
    "    time.sleep(1)\n",
    "    print(\"Go.\")\n",
    "    rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "    print(\"Playing the recording.\")\n",
    "    sd.play(rec, rec_rate)\n",
    "\n",
    "    # after hearing the recording, decide whether to record it again or continue to next number\n",
    "    # if you type anything, record again\n",
    "    # if you press enter, save current recording & go to next number\n",
    "    ok = input(\"OK?\")\n",
    "    if ok == \"\":\n",
    "        librosa.output.write_wav(output_dir+name, rec, rec_rate)\n",
    "        return rec\n",
    "    ipd.clear_output(wait=True)\n",
    "    create_recording(duration, rec_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_audio(file, input_dir=\"test/\", output_dir=\"test/\", db=-48):\n",
    "\n",
    "    if not os.path.isdir(input_dir):\n",
    "        print(f\"There should be an input \\\"{input_dir}\\\" directory.\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # create output directory if not there yet\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    temp1 = output_dir+\"temp1.wav\"\n",
    "    temp2 = output_dir+\"temp2.wav\"\n",
    "    temp3 = output_dir+\"temp3.wav\"\n",
    " \n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", input_dir+file, \"-af\", f\"silenceremove=1:0:{db}dB\", temp1])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp1, \"-af\", \"areverse\", temp2])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp2, \"-af\", f\"silenceremove=1:0.1:{db}dB\", temp3])\n",
    "    subprocess.run([\"ffmpeg\", \"-y\", \"-i\", temp3, \"-af\", \"areverse\", output_dir+file])\n",
    "    \n",
    "    os.remove(temp1)\n",
    "    os.remove(temp2)\n",
    "    os.remove(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NN(nn, max_y, target_names, answer = None, duration=2, rec_rate=8000, directory = \"test/\", filename = \"test.wav\"):\n",
    "    create_recording(duration, rec_rate, filename, directory)   \n",
    "    ipd.clear_output()\n",
    "    trim_audio(filename, directory, directory)\n",
    "    # _, rec = wav.read(directory + \"/\" + filename)\n",
    "    rec, _ = librosa.core.load(directory + \"/\" + filename, sr = rec_rate)\n",
    "    rec = pad_zeros_single_rec(rec, max_y)\n",
    "    # sd.play(rec, rec_rate)\n",
    "    rec = data_preparation.compute_spectrogram(rec, normalize=True)\n",
    "    rec = rec[np.newaxis,:,:,np.newaxis]\n",
    "    preds = nn.predict_classes(rec)\n",
    "    print(\"Model prediction: {}\".format(target_names[preds[0]]))\n",
    "    if answer is not None:\n",
    "        print(f\"Correct answer {answer}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_y = len(data_augm_pad_recordings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test_NN(model, max_y, target_names, answer = \"gian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- [x] Set random seed\n",
    "- [x] Use only original recordings in test set of augmented scenario\n",
    "- Use proper validation set (optional: also crossvalidation) for picking best models and params\n",
    "- Data augmentation also for digit recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
