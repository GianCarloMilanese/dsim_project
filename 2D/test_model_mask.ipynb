{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications import resnet_v2\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for face alignment\n",
    "# pip install imutils\n",
    "# conda install -c conda-forge dlib  \n",
    "import imutils\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLIB Face detector for alignment\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good models:\n",
    "\n",
    "- 8, more or less\n",
    "- 13\n",
    "- 14\n",
    "- 17\n",
    "- 18/19?\n",
    "- 20 (model trained on heavily resized pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keras model\n",
    "model_number = 21\n",
    "model = keras.models.load_model(f\"./models/{model_number}_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"models/{model_number}_model.json\") as jf:\n",
    "    json_file = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't save the \"class_indicices\" field for some models...\n",
    "if \"class_indices\" not in json_file:\n",
    "    if model.output_shape[1] == 8:\n",
    "        labels = np.array([\"alessandro\", \"alinda\", \"cami\", \"gian\",\n",
    "                           \"luca\", \"mamma\", \"papi\", \"umbe\"])\n",
    "        \n",
    "    if model.output_shape[1] == 7:\n",
    "        labels = np.array([\"alessandro\", \"alinda\", \"cami\", \"gian\",\n",
    "                           \"luca\", \"mamma\", \"papi\"])\n",
    "    if model.output_shape[1] == 6:\n",
    "        labels = np.array([\"alessandro\", \"alinda\", \"cami\", \"gian\",\n",
    "                           \"mamma\", \"papi\"])\n",
    "    if model.output_shape[1] == 5:\n",
    "        labels = np.array([\"alinda\", \"cami\",  \"gian\",\n",
    "                           \"mamma\",  \"papi\",])\n",
    "else:\n",
    "    labels = np.array(json_file[\"class_indices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if json_file[\"featurewise_center\"] == True:\n",
    "    mu = np.array([float(e) for e in json_file[\"mean\"]]).reshape(1,1)\n",
    "    std = np.array([float(e) for e in json_file[\"std\"]]).reshape(1,1)\n",
    "    preprocess_fun = lambda x : (x-mu)/std\n",
    "else:\n",
    "    preprocess_fun = lambda x : x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_fun(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TODO: Maybe define a function \"create_mask\" with the following default values\n",
    "# and put it in utils_2d.py when cleaning code\n",
    "\n",
    "a, b = 92, 112 # center of the ellipsis\n",
    "n = 224 # the mask will b n*n\n",
    "r = 112\n",
    "\n",
    "y,x = np.ogrid[-a:n-a, -b:n-b]\n",
    "\n",
    "mask = x*x + y*y/2 <= r*r/2\n",
    "\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, labels, mask, preprocess_fun = preprocess_fun, model_number = model_number,\n",
    "               basedir = \"test_pictures\", new_width=200, mirror=True, more_space=10, threshold = 50):\n",
    "    \n",
    "    file_format = \"png\"\n",
    "    \n",
    "    if not os.path.isdir(basedir):\n",
    "        print(f\"Created new directory {basedir}\")\n",
    "        os.makedirs(basedir)\n",
    "\n",
    "    current_images = [img for img in os.listdir(basedir) if (img.endswith(file_format) and img.startswith(str(model_number)))]\n",
    "    if len(current_images) == 0:\n",
    "        latest_picture = -1\n",
    "    else:\n",
    "        latest_picture = max([int(current_images[i].split(\".\")[0].split(\"_\")[1]) for i in range(len(current_images))])\n",
    "    \n",
    "    filename_format = f\"{basedir}/{model_number}_\"+\"{}\"+f\".{file_format}\"\n",
    "    \n",
    "    i = latest_picture\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    cap = cv.VideoCapture(0)\n",
    "    while(True):\n",
    "        \n",
    "        r, frame = cap.read()\n",
    "        if mirror:\n",
    "            frame = cv.flip(frame, 1)\n",
    "        \n",
    "        try:\n",
    "            frame = add_box(frame, model, labels, mask, preprocess_fun, new_width, more_space, threshold)\n",
    "            cv.imshow('Video', frame)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    \n",
    "        if cv.waitKey(1) & 0xFF == ord('s'):\n",
    "            \n",
    "            i += 1\n",
    "            filename = filename_format.format(i)\n",
    "            cv.imwrite(filename, frame)\n",
    "            ipd.clear_output(wait=True)\n",
    "            print(f\"Saved {filename}\".replace(\"//\", \"/\"))\n",
    "                \n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "                        \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_box(img, model, labels, mask, preprocess_fun = preprocess_fun, new_width=200, more_space=10, threshold=50):\n",
    "    m = more_space\n",
    "    \n",
    "    fontColors = [(0,0,255), (255,160,0), (0,255,0),\n",
    "                  (0,255, 255), (193,182,255)]\n",
    "    fontScale              = 2\n",
    "    lineType               = 2\n",
    "    font                   = cv.FONT_HERSHEY_PLAIN\n",
    "    \n",
    "    if img is not None:\n",
    "        \n",
    "        face = 0\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        og_width = gray.shape[1]\n",
    "        scaler = og_width/new_width\n",
    "        gray = imutils.resize(gray, width = new_width)\n",
    "\n",
    "        faces = detector(gray, 2) # check: what is the 2\n",
    "        \n",
    "        for rect in faces:\n",
    "            (x, y, w, h) = rect_to_bb(rect)\n",
    "            # if align:\n",
    "            gray2 = fa.align(gray, gray, rect)\n",
    "            # else:\n",
    "                # gray2 = gray[(y-m):(y+h+m), (x-m):(x+w+m)]\n",
    "                # gray2 = cv.resize(gray, (224, 224))\n",
    "\n",
    "            gray2 = cv.equalizeHist(gray2)\n",
    "            gray2[~mask] = 0\n",
    "            # plt.imshow(gray2, cmap=\"gray\")\n",
    "            # plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "            gray2 = preprocess_fun(gray2)\n",
    "            \n",
    "            # gray2 = gray2/255\n",
    "            \n",
    "            (x, y, w, h) = (np.array((x,y,w,h))*scaler).astype(int)\n",
    "                \n",
    "            pred = model.predict(gray2[np.newaxis,:,:, np.newaxis])[0]            \n",
    "            text = labels[np.argmax(pred)]\n",
    "            # print(text)\n",
    "            conf = pred[np.argmax(pred)]*100\n",
    "            if conf < threshold:\n",
    "                text = \"?\"\n",
    "                \n",
    "            topLeftCornerOfText = (x-m,y-m-5)\n",
    "            bottomLeftCornerOfText = (x-m,y+h+35)    \n",
    "            fontColor              = fontColors[face]\n",
    "            face += 1\n",
    "                  \n",
    "            cv.rectangle(img,(x-m,y-m),(x+w+m,y+h+m),fontColor,2)\n",
    "            cv.putText(img, f\"{text}\", topLeftCornerOfText,\n",
    "                       font, fontScale, fontColor, lineType)\n",
    "            cv.putText(img, f\"{conf:.2f}%\", bottomLeftCornerOfText,\n",
    "                       font, fontScale, fontColor, lineType)\n",
    "                    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`new_width` is the width of the resized image passed to the dlib detector.\n",
    "\n",
    "Smaller values mean smoother webcam preview, but prediction is slightly affected.\n",
    "\n",
    "OK values are between 150/250 depending on how far the face is from the webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# spam q to exit, the save function makes exiting lag a bit\n",
    "n = 2\n",
    "basedir=\"test_pictures/\"+str(n)+\"/\"\n",
    "test_model(model,labels, mask, new_width=300, threshold=50, basedir=basedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test single shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_single_shot(model,labels, mask, preprocess_fun = preprocess_fun,\n",
    "                           new_width=200, threshold=50, mirror = True):\n",
    "    \n",
    "    cap = cv.VideoCapture(0)\n",
    "    result, img = cap.read()\n",
    "    \n",
    "    if mirror:\n",
    "            img = cv.flip(img, 1)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    img2 = add_box(img, model, labels, mask, preprocess_fun, new_width, threshold=threshold)[:,:,::-1]\n",
    "    \n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "    \n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "img = test_model_single_shot(model, labels, mask, threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'C:/Users/gianc/Anaconda3/envs/dsim/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml'\n",
    "face_detector = cv.CascadeClassifier(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_picture(filename, model, labels, mask, preprocess_fun = preprocess_fun, new_width=500,\n",
    "                 threshold = 50, resize = None, cut = False):\n",
    "    # might make sense to test on some pictures not used during training\n",
    "\n",
    "    img = cv.imread(filename)\n",
    "    \n",
    "    if resize is not None:\n",
    "        img = imutils.resize(img, resize)\n",
    "    img2 = add_box(img, model, labels, mask, preprocess_fun, new_width, threshold=threshold)[:,:,::-1]\n",
    "    \n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "    \n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = test_picture(\"misc_pictures/1.jpg\", model, labels, mask, resize = 200, new_width=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = test_picture(\"misc_pictures/3.jpg\", model, labels, mask, new_width=500, resize = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_directory(name, basedir, labels, model, mask, preprocess_fun=preprocess_fun, new_width=200):\n",
    "    # might make sense to test on some pictures not used during training\n",
    "    \n",
    "    srcdir = basedir+\"/\"+name\n",
    "    counts={}\n",
    "    for label in labels:\n",
    "        counts[label] = 0\n",
    "    total = 1\n",
    "    \n",
    "    for file in os.listdir(srcdir):\n",
    "        img = cv.imread(srcdir+\"/\"+file)\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        gray = imutils.resize(gray, new_width)\n",
    "        faces = detector(gray, 2)\n",
    "        if len(faces)>0:\n",
    "            rect = faces[0]\n",
    "            gray2 = fa.align(gray, gray, rect)\n",
    "        else:\n",
    "            gray2 = cv.resize(gray, (224, 224))\n",
    "        gray2 = cv.equalizeHist(gray2)\n",
    "        gray2[~mask] = 0\n",
    "        gray2 = preprocess_fun(gray2)\n",
    "        \n",
    "        pred = model.predict(gray2[np.newaxis,:,:, np.newaxis])[0]            \n",
    "        text = labels[np.argmax(pred)]\n",
    "        \n",
    "        counts[text] += 1\n",
    "        ipd.clear_output(wait=True)\n",
    "        for i in counts.keys():\n",
    "            print(\"{}: {}\".format(i, counts[i]))\n",
    "        print(\"\\ntotal: \", total)\n",
    "        print(\"accuracy: \", counts[name]/total)\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also gives an idea of the difference in speed and accuracy when resizing the picture before detecting the face with dlib.\n",
    "\n",
    "(Note that the following is resizing a picture that is already cropped and with a face, while in the above tests it is resizing the picture from the webcam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(most folders in \"picture_new\" also contain images not used during training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_directory(\"alinda\", \"test_pictures\", labels, model, mask, new_width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_directory(\"alinda\", \"test_pictures\", labels, model, mask, new_width=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_directory(\"alinda\", \"test_pictures\", labels, model, mask, new_width=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_directory(\"alinda\", \"test_pictures\", labels, model, mask, new_width=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_directory(\"alinda\", \"test_pictures\", labels, model, mask, new_width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Occhi\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
