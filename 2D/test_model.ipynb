{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications import resnet_v2\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load keras model\n",
    "model_number = 8\n",
    "model = keras.models.load_model(f\"./models/{model_number}_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"models/{model_number}_model.json\") as jf:\n",
    "    mjson = json.load(jf)\n",
    "\n",
    "# get mean and standard deviation learned by the train processor\n",
    "# (featurewise center and std)\n",
    "mu = np.array([float(e) for e in mjson[\"mean\"]]).reshape(1,1,3)\n",
    "std = np.array([float(e) for e in mjson[\"std\"]]).reshape(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento modello per il rilevamento di volti frontali\n",
    "model_filename = 'C:/Users/gianc/Anaconda3/envs/dsim/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml'\n",
    "face_detector = cv.CascadeClassifier(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I didn't save the \"class_indicices\" field for some models...\n",
    "if \"class_indices\" not in mjson:\n",
    "    if model.output_shape[1] == 8:\n",
    "        labels = np.array([\"alessandro\", \"alinda\", \"cami\", \"gian\",\n",
    "                           \"luca\", \"mamma\", \"papi\", \"umbe\"])\n",
    "        \n",
    "    if model.output_shape[1] == 7:\n",
    "        labels = np.array([\"alessandro\", \"alinda\", \"cami\", \"gian\",\n",
    "                           \"luca\", \"mamma\", \"papi\"])\n",
    "    if model.output_shape[1] == 6:\n",
    "        labels = np.array([\"alessandro\", \"alinda\", \"cami\", \"gian\",\n",
    "                           \"mamma\", \"papi\"])\n",
    "    if model.output_shape[1] == 5:\n",
    "        labels = np.array([\"alinda\", \"cami\",  \"gian\",\n",
    "                           \"mamma\",  \"papi\",])\n",
    "else:\n",
    "    labels = np.array(mjson[\"class_indices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranks(ar):\n",
    "    return ar.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_box(img, model, mu, std, labels, more_space=10):\n",
    "    m = more_space\n",
    "    if img is not None:\n",
    "        faces = face_detector.detectMultiScale(img[:,:,1])\n",
    "        face = 0\n",
    "        fontColors = [(0,0,255), (255,160,0)]\n",
    "        for (x,y,w,h) in faces:\n",
    "            \n",
    "            # -1::-1 because cv img is BGR, but we need RGB (check)\n",
    "            # and crop image as the model was fed with cropped images\n",
    "            img2 = img[(y-m):(y+h+m), (x-m):(x+w+m), ::-1]\n",
    "\n",
    "            # resize to match model input shape\n",
    "            img2 = cv.resize(img2, (224, 224))\n",
    "            \n",
    "            # Apply same preprocessing as simple conv model\n",
    "            # does not work for fine-tuned resnet model\n",
    "            # TODO: pass general preprocessing function\n",
    "            img2 = (img2 - mu)/std\n",
    "            \n",
    "            # prediction\n",
    "            pred = model.predict(img2[np.newaxis,:,:,:])[0]\n",
    "                        \n",
    "            text = labels[np.argmax(pred)]\n",
    "\n",
    "            top3 = labels[ranks(pred)][:2]\n",
    "            conf3 = pred[ranks(pred)][:2]\n",
    "            \n",
    "            font                   = cv.FONT_HERSHEY_PLAIN\n",
    "            bottomLeftCornerOfText = (x-m,y-m-5)\n",
    "            fontScale              = 2\n",
    "            fontColor              = fontColors[face]\n",
    "            lineType               = 2\n",
    "            \n",
    "            \n",
    "            cv.rectangle(img,(x-m,y-m),(x+w+m,y+h+m),fontColor,2)\n",
    "            cv.putText(img, text, bottomLeftCornerOfText, \n",
    "                       font, fontScale, fontColor, lineType)\n",
    "            \n",
    "            for i in range(len(top3)):\n",
    "                line = \"{}: {}\".format(top3[i], str(np.around(conf3[i]*100, decimals = 2))+\"%\")\n",
    "                cv.putText(img, line, (10, 25+30*i+face*420), # this won't work for more than two faces\n",
    "                           font, fontScale, fontColor, lineType)\n",
    "            face += 1\n",
    "            \n",
    "            if face > 1:\n",
    "                # this function would not work for more than two faces anyway\n",
    "                break\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, mu, std, labels):\n",
    "    labels = np.array(labels)\n",
    "    cap = cv.VideoCapture(0)\n",
    "    while(True):\n",
    "        \n",
    "        r, frame = cap.read()\n",
    "        \n",
    "        try:\n",
    "            frame = add_box(frame, model, mu, std, labels)\n",
    "            cv.imshow('Video', frame)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "                        \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_model(model, mu, std, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test single shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_single_shot(model, mu, std, labels):\n",
    "    cap = cv.VideoCapture(0)\n",
    "    result, img = cap.read()\n",
    "    cap.release()\n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.imshow(add_box(img, model, mu, std, labels)[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_single_shot(model, mu, std, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might make sense to test on some pictures not used during training\n",
    "name = \"mamma\"\n",
    "basedir = \"pictures_table/\"+name\n",
    "counts={}\n",
    "for label in labels:\n",
    "    counts[label] = 0\n",
    "total = 1\n",
    "for file in os.listdir(basedir):\n",
    "    img = cv.imread(basedir+\"/\"+file)\n",
    "    img2 = img[:,:,::-1]\n",
    "    img2 = cv.resize(img2, (224, 224))\n",
    "    img2 = (img2 - mu)/std\n",
    "\n",
    "    pred = model.predict(img2[np.newaxis,:,:,:])\n",
    "    \n",
    "    text = labels[np.argmax(pred)]\n",
    "    counts[text] += 1\n",
    "    ipd.clear_output(wait=True)\n",
    "    for i in counts.keys():\n",
    "        print(\"{}: {}\".format(i, counts[i]))\n",
    "    print(\"\\ntotal: \", total)\n",
    "    print(\"accuracy: \", counts[name]/total)\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsim] *",
   "language": "python",
   "name": "conda-env-dsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
